{"id": "2506.15843", "categories": ["eess.SP", "eess.IV"], "pdf": "https://arxiv.org/pdf/2506.15843", "abs": "https://arxiv.org/abs/2506.15843", "authors": ["Ninghe Liu", "Yu Xi Huang", "Simon Mahler", "Changhuei Yang"], "title": "Optimized cerebral blood flow measurement in speckle contrast optical spectroscopy via refinement of noise calibration", "comment": "5 pages, 3 figures", "summary": "Speckle contrast optical spectroscopy (SCOS) offers a non-invasive and\ncost-effective method for monitoring cerebral blood flow (CBF). However,\nextracting accurate CBF from SCOS necessitates precise noise pre-calibration.\nErrors from this can degrade CBF measurement fidelity, particularly when the\noverall signal level is low. Such errors primarily stem from residual speckle\ncontrast associated with camera and shot noise, whose fluctuations exhibit a\ntemporal structure that mimics cerebral blood volume (CBV) waveforms. We\npropose an optimization-based framework that performs an adaptive refinement of\nnoise calibration, mitigating the CBV-mimicking artifacts by reducing the\nCBF-CBV waveform correlation. Validated on 10 human subjects, our approach\neffectively lowered the signal threshold for reliable CBF signal from 97 to 26\nelectrons per pixel for a 1920x1200 pixels SCOS system. This improvement\nenables more accurate and robust CBF measurements in SCOS, especially at large\nsource-detector (SD) distances for deeper tissue interrogation."}
{"id": "2506.15950", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.15950", "abs": "https://arxiv.org/abs/2506.15950", "authors": ["Saeed Razavikia", "Carlo Fischione"], "title": "On Designing Modulation for Over-the-Air Computation -- Part I: Noise-Aware Design", "comment": null, "summary": "Over-the-air computation (OAC) leverages the physical superposition property\nof wireless multiple access channels (MACs) to compute functions while\ncommunication occurs, enabling scalable and low-latency processing in\ndistributed networks. While analog OAC methods suffer from noise sensitivity\nand hardware constraints, existing digital approaches are often limited in\ndesign complexity, which may hinder scalability and fail to exploit spectral\nefficiency fully. This two-part paper revisits and extends the ChannelComp\nframework, a general methodology for computing arbitrary finite-valued\nfunctions using digital modulation. In Part I, we develop a novel constellation\ndesign approach that is aware of the noise distribution and formulates the\nencoder design as a max-min optimization problem using noise-tailored distance\nmetrics. Our design supports noise models, including Gaussian, Laplace, and\nheavy-tailed distributions. We further demonstrate that, for heavy-tailed\nnoise, the optimal ChannelComp setup coincides with the solution to the\ncorresponding max-min criterion for the channel noise with heavy-tailed\ndistributions. Numerical experiments confirm that our noise-aware design\nachieves a substantially lower mean-square error than leading digital OAC\nmethods over noisy MACs. In Part II, we consider a constellation design with a\nquantization-based sampling scheme to enhance modulation scalability and\ncomputational accuracy for large-scale digital OAC."}
{"id": "2506.15972", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.15972", "abs": "https://arxiv.org/abs/2506.15972", "authors": ["Haiyang Miao", "Jianhua Zhang", "Pan Tang", "Heng Wang", "Lei Tian", "Guangyi Liu"], "title": "Theoretical Analysis of Near-Field MIMO Channel Capacity and Mid-Band Experimental Validation", "comment": null, "summary": "With the increase of multiple-input-multiple-output (MIMO) array size and\ncarrier frequency, near-field MIMO communications will become crucial in 6G\nwireless networks. Due to the increase of MIMO near-field range, the research\nof near-field MIMO capacity has aroused wide interest. In this paper, we focus\non the theoretical analysis and empirical study of near-field MIMO capacity.\nFirst, the near-field channel model is characterized from the electromagnetic\ninformation perspective. Second, with the uniform planar array (UPA), the\nchannel capacity based on effective degree of freedom (EDoF) is analyzed\ntheoretically, and the closed-form analytical expressions are derived in\ndetail. Finally, based on the numerical verification of near-field channel\nmeasurement experiment at 13 GHz band, we reveal that the channel capacity of\nUPA-type MIMO systems decreases continuously with the communication distance\nincreasing. It can be observed that the near-field channel capacity gain is\nrelatively obvious when large-scale MIMO is adopted at both receiving and\ntransmitter ends, but the near-field channel capacity gain may be limited in\nthe actual communication system with the small antenna array at receiving end.\nThis work will give some reference to the near-field communication systems."}
{"id": "2506.15998", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.15998", "abs": "https://arxiv.org/abs/2506.15998", "authors": ["Chen Xu", "Xianghao Yu", "Fan Liu", "Shi Jin"], "title": "Exploiting Both Pilots and Data Payloads for Integrated Sensing and Communications", "comment": null, "summary": "Integrated sensing and communications (ISAC) is one of the key enabling\ntechnologies in future sixth-generation (6G) networks. Current ISAC systems\npredominantly rely on deterministic pilot signals within the signal frame to\naccomplish sensing tasks. However, these pilot signals typically occupy only a\nsmall portion, e.g., 0.15% to 25%, of the time-frequency resources. To enhance\nthe system utility, a promising solution is to repurpose the extensive random\ndata payload signals for sensing tasks. In this paper, we analyze the ISAC\nperformance of a multi-antenna system where both deterministic pilot and random\ndata symbols are employed for sensing tasks. By capitalizing on random matrix\ntheory (RMT), we first derive a semi-closed-form asymptotic expression of the\nergodic linear minimum mean square error (ELMMSE). Then, we formulate an ISAC\nprecoding optimization problem to minimize the ELMMSE, which is solved via a\nspecifically tailored successive convex approximation (SAC) algorithm. To\nprovide system insights, we further derive a closed-form expression for the\nasymptotic ELMMSE at high signal-to-noise ratios (SNRs). Our analysis reveals\nthat, compared with conventional sensing implemented by deterministic signals,\nthe sensing performance degradation induced by random signals is critically\ndetermined by the ratio of the transmit antenna size to the data symbol length.\nBased on this result, the ISAC precoding optimization problem at high SNRs is\ntransformed into a convex optimization problem that can be efficiently solved.\nSimulation results validate the accuracy of the derived asymptotic expressions\nof ELMMSE and the performance of the proposed precoding schemes. Particularly,\nby leveraging data payload signals for sensing tasks, the sensing error is\nreduced by up to 5.6 dB compared to conventional pilot-based sensing."}
{"id": "2506.16011", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.16011", "abs": "https://arxiv.org/abs/2506.16011", "authors": ["Rang Liu", "Ming Li", "Mehdi Zafari", "Bjorn Ottersten", "A. Lee Swindlehurst"], "title": "Multi-Domain Optimization Framework for ISAC: From Electromagnetic Shaping to Network Cooperation", "comment": "10 pages, 5 figures, submitted to IEEE", "summary": "Integrated sensing and communication (ISAC) has emerged as a key feature for\nsixth-generation (6G) networks, providing an opportunity to meet the dual\ndemands of communication and sensing. Existing ISAC research primarily focuses\non baseband optimization at individual access points, with limited attention to\nthe roles of electromagnetic (EM) shaping and network-wide coordination. The\nintricate interdependencies between these domains remain insufficiently\nexplored, leaving their full potential for enhancing ISAC performance largely\nuntapped. To bridge this gap, we consider multi-domain ISAC optimization\nintegrating EM shaping, baseband processing, and network cooperation strategies\nthat facilitate efficient resource management and system-level design. We\nanalyze the fundamental trade-offs between these domains and offer insights\ninto domain-specific and cross-domain strategies contributing to ISAC\nperformance and efficiency. We then conduct a case study demonstrating the\neffectiveness of joint multi-domain optimization. Finally, we discuss key\nchallenges and future research directions to connect theoretical advancements\nand practical ISAC deployments. This work paves the way for intelligent and\nscalable ISAC architectures, providing critical insights for their seamless\nintegration into next-generation wireless networks."}
{"id": "2506.16070", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.16070", "abs": "https://arxiv.org/abs/2506.16070", "authors": ["Mathushaharan Rathakrishnan", "Samiru Gayan", "Rohit Singh", "Amandeep Kaur", "Hazer Inaltekin", "Sampath Edirisinghe", "H. Vincent Poor"], "title": "Towards AI-Driven RANs for 6G and Beyond: Architectural Advancements and Future Horizons", "comment": null, "summary": "It is envisioned that 6G networks will be supported by key architectural\nprinciples, including intelligence, decentralization, interoperability, and\ndigitalization. With the advances in artificial intelligence (AI) and machine\nlearning (ML), embedding intelligence into the foundation of wireless\ncommunication systems is recognized as essential for 6G and beyond. Existing\nradio access network (RAN) architectures struggle to meet the ever growing\ndemands for flexibility, automation, and adaptability required to build\nself-evolving and autonomous wireless networks. In this context, this paper\nexplores the transition towards AI-driven RAN (AI-RAN) by developing a novel\nAI-RAN framework whose performance is evaluated through a practical scenario\nfocused on intelligent orchestration and resource optimization. Besides, the\npaper reviews the evolution of RAN architectures and sheds light on key\nenablers of AI-RAN including digital twins (DTs), intelligent reflecting\nsurfaces (IRSs), large generative AI (GenAI) models, and blockchain (BC).\nFurthermore, it discusses the deployment challenges of AI-RAN, including\ntechnical and regulatory perspectives, and outlines future research directions\nincorporating technologies such as integrated sensing and communication (ISAC)\nand agentic AI."}
{"id": "2506.16184", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.16184", "abs": "https://arxiv.org/abs/2506.16184", "authors": ["Shan Shan", "Chongjun Ouyang", "Yong Li", "Yuanwei Liu"], "title": "Multigroup Multicast Design for Pinching-Antenna Systems: Waveguide-Division or Waveguide-Multiplexing?", "comment": null, "summary": "This article addresses the design of multigroup multicast communications in\nthe pinching-antenna system (PASS). A PASS-enabled multigroup transmission\nframework is proposed to maximize multicast rates under a couple of\ntransmission architectures: waveguide-division (WD) and waveguide-multiplexing\n(WM). 1) For WD, an element-wise sequential optimization strategy is proposed\nfor pinching beamforming, i.e., optimizing the activated positions of pinching\nantennas along dielectric waveguides. Meanwhile, a log-sum-exp projected\ngradient descent algorithm is proposed for transmit power allocation across\nwaveguides. 2) For WM, a majorization-minimization (MM)-based framework is\nproposed to tackle the problem's non-smoothness and non-convexity. On this\nbasis, a low-complexity element-wise sequential optimization method is\ndeveloped for pinching beamforming using the MM surrogate objective.\nFurthermore, the optimal transmit beamformer structure is derived from the MM\nsurrogate objective using the Lagrange duality, with an efficient transmit\nbeamforming algorithm proposed using projected adaptive gradient descent.\nNumerical results demonstrate that: i) both WD and WM architectures in PASS\nachieve significant multicast rate improvements over conventional MIMO\ntechniques, especially for systems with large service areas; ii) WM is more\nrobust than WD in dense deployments, while WD excels when user groups are\nspatially separated."}
{"id": "2506.16191", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.16191", "abs": "https://arxiv.org/abs/2506.16191", "authors": ["Hyeonho Noh", "Hyeonsu Lyu", "Moe Z. Win", "Hyun Jong Yang"], "title": "DCFNet: Doppler Correction Filter Network for Integrated Sensing and Communication in Multi-User MIMO-OFDM Systems", "comment": null, "summary": "Integrated sensing and communication (ISAC) is a headline feature for the\nforthcoming IMT-2030 and 6G releases, yet a concrete solution that fits within\nthe established orthogonal frequency division multiplexing (OFDM) family\nremains open. Specifically, Doppler-induced inter-carrier interference (ICI)\ndestroys sub-carrier orthogonality of OFDM sensing signals, blurring\nrange-velocity maps and severely degrading sensing accuracy. Building on\nmulti-user multi-input-multi-output (MIMO) OFDM systems, this paper proposes\nDoppler-Correction Filter Network (DCFNet), an AI-native ISAC model that\ndelivers fine range-velocity resolution at minimal complexity without altering\nthe legacy frame structure. A bank of DCFs first shifts dominant ICI energy\naway from critical Doppler bins; a compact deep learning network then\nsuppresses the ICI. To further enhance the range and velocity resolutions, we\npropose DCFNet with local refinement (DCFNet-LR), which applies a generalized\nlikelihood ratio test (GLRT) to refine target estimates of DCFNet to sub-cell\naccuracy. Simulation results show that DCFNet-LR runs $143\\times$ faster than\nmaximum likelihood search and achieves significantly superior performance,\nreducing the range RMSE by up to $2.7 \\times 10^{-4}$ times and the velocity\nRMSE by $6.7 \\times 10^{-4}$ times compared to conventional detection methods."}
{"id": "2506.16198", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.16198", "abs": "https://arxiv.org/abs/2506.16198", "authors": ["Haofan Dong", "Ozgur B. Akan"], "title": "MASC: Integrated Sensing and Communications for the Martian Internet of Space", "comment": "11 pages, 9 figures, journal", "summary": "Mars exploration missions increasingly demand reliable communication systems,\nyet harsh environmental conditions -- particularly frequent dust storms,\nextreme Doppler effects, and stringent resource constraints -- pose\nunprecedented challenges to conventional communication approaches. This paper\npresents the Martian Adaptive Sensing and Communication (MASC) system\nspecifically designed for the Martian environment. MASC establishes a\nphysically interpretable channel model and develops three key components:\nenvironment-aware hybrid precoding, adaptive parameter mapping, and robust\ncommunication precoding. Simulation results demonstrate that MASC maintains 45\npercent sensing coverage under severe dust conditions compared to only 5\npercent with conventional methods, provides up to 2.5 dB\nsignal-to-interference-plus-noise ratio (SINR) improvement at 50 percent\nchannel state information (CSI) uncertainty, and yields 80 percent higher\ncapacity in moderate dust storms. Using an epsilon-constraint multi-objective\noptimization approach, we enable mission planners to select operational modes\nranging from communication-priority (0.33 bps/Hz capacity, 28 percent sensing\ncoverage) to sensing-priority (90 percent coverage with minimal capacity),\noffering a versatile framework that balances environmental awareness with\nhyper-reliable data transmission. This work provides a validated blueprint for\nintegrated sensing and communication (ISAC) in non-terrestrial networks (NTN),\na key enabler for achieving ubiquitous connectivity in the 6G era."}
{"id": "2506.16208", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.16208", "abs": "https://arxiv.org/abs/2506.16208", "authors": ["Saeed Razavikia", "Carlo Fischione"], "title": "On Designing Modulation for Over-the-Air Computation -- Part II: Pyramid Sampling", "comment": null, "summary": "Over-the-air computation (OAC) harnesses the natural superposition of\nwireless signals to compute aggregate functions during transmission, thereby\ncollapsing communication and computation into a single step and significantly\nreducing latency and resource usage. In Part I, digital OAC was formulated as a\nnoise-aware constellation design problem by casting encoder design as a max-min\noptimization that aligns minimum Euclidean distances between superimposed\nconstellation points with squared differences of their corresponding function\noutputs.\n  In this paper, Part II, we address the prohibitive complexity and\nquantization challenges inherent in digital OAC constellation design for\nlarge-scale edge networks. More precisely, we introduce a pyramid sampling\nstrategy that judiciously selects a subset of superimposed constellation points\nto reduce the encoder design complexity from $\\mathcal{O}(q^K)$ to\n$\\mathcal{O}(q^{K-p+1})$, where $p\\in\\{1,\\dots, K\\}$ denotes the sampling\norder, $q$ levels of modulation, and $K$ denotes the number nodes in the\nnetwork. Under the assumption of symmetric aggregation, this approach enables a\ncontrolled trade-off between computational complexity and function computation\naccuracy. As a special case, we propose majority-based sampling ($p=K$), which\nconfines aggregation to only $q$ consensus points, inherently avoiding\ndestructive overlaps and permitting the use of standard digital modulations\n(e.g., QAM, PSK, ASK) without bespoke constellation designs. We also show via\nseveral simulations, across various aggregation functions, modulation levels,\nand noise levels, that moderate sampling orders attain acceptable performance\nwith orders-of-magnitude fewer constraints than exhaustive designs."}
{"id": "2506.16236", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.16236", "abs": "https://arxiv.org/abs/2506.16236", "authors": ["Romain Charbonnier", "Thierry Tenoux", "Yoann Corre"], "title": "Refining Ray-Tracing Accuracy and Efficiency in the Context of FRMCS Urban Railway Channel Predictions", "comment": "Presented at Workshop \"Emerging information and communication\n  technologies for smart railway Challenges and Opportunities for mmWave, THz,\n  ISAC, 5G and 6G\" in IEEE VTC-Spring 2025 Conference, June 2025, Oslo, Norway", "summary": "The upcoming roll-out of the new wireless communication standard for wireless\nrailway services, FRMCS, requires a thorough understanding of the system\nperformance in real-world conditions, since this will strongly influence the\ndeployment costs and the effectiveness of an infrastructure planned for\ndecades. The virtual testing of the equipment and network performance in\nrealistic simulated scenarios is key; its accuracy depends on the reliability\nof the predicted radio channel properties. In this article, the authors explain\nhow they are evolving a ray-tracing (RT) tool to apply it to the specific case\nof simulating the radio link between the FRMCS fixed infrastructure and an\nantenna placed on the roof of a train moving in an urban environment. First, a\ndynamic version of the RT tool is used to capture the rapid variations of all\nchannel metrics; a compromise is sought between computation time and accuracy.\nBesides, a hybridization of RT and physical optics (PO) allows the integration\nof objects near the track, such as catenary pylons, into the simulation. A case\nstudy shows that the scattering by metallic pylons brings a significant\ncontribution."}
{"id": "2506.16304", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.16304", "abs": "https://arxiv.org/abs/2506.16304", "authors": ["Junyi Jiang", "Wei Chen", "Xin Guo", "Shenghui Song", "Ying Jun", "Zhang", "Zhu Han", "Merouane Debbah", "Khaled B. Letaief"], "title": "A Tractable Approach to Massive Communication and Ubiquitous Connectivity in 6G Standardization", "comment": null, "summary": "The full-scale 6G standardization has attracted considerable recent\nattention, especially since the first 3GPP-wide 6G workshop held in March 2025.\nTo understand the practical and fundamental values of 6G and facilitate its\nstandardization, it is crucial to explore the theoretical limits of spectrum,\nenergy, and coverage efficiency considering practical hardware and signaling\nconstraints. In this paper, we present a mean-field-approximation-based\ninvestigation on two out of six use case scenarios defined by IMT-2030, namely,\nmassive communication and ubiquitous connectivity. Being aware of the\nlimitation in interference cancellation owing to constrained cost and hardware\ncomplexity, we investigate the spectrum reuse architecture in both usage\nscenarios. We propose a tractable spectrum reuse with low signaling overhead\nconsumed for channel estimation and channel state information (CSI) feedback.\nOur analysis indicates that the massive communication over cellular and\ndevice-to-device (D2D) networks can benefit from channel orthogonalization,\nwhile it is unnecessary to share the CSI of interfering links. Moreover,\ndeploying relays or movable base stations, e.g. unmanned aerial vehicle, yields\nsubstantial energy and spectrum gain for ubiquitous connectivity, despite\nintroducing interference. As such, the mean-field-optimization-based evaluation\nis expected to positively impact 6G and NextG standardization in 3GPP and other\nstandardization bodies."}
{"id": "2506.16767", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.16767", "abs": "https://arxiv.org/abs/2506.16767", "authors": ["Esa Ollila", "Xavier Mestre", "Elias Raninen"], "title": "Beamforming design for minimizing the signal power estimation error", "comment": null, "summary": "We study the properties of beamformers in their ability to either maintain or\nestimate the true signal power of the signal of interest (SOI). Our focus is\nparticularly on the Capon beamformer and the minimum mean squared error (MMSE)\nbeamformer. The Capon beamformer, also known as the minimum power\ndistortionless response (MPDR) or the minimum variance distortionless response\n(MVDR) beamformer, is a widely used method in array signal processing. A\ncurious feature of both the Capon and the MMSE beamformers is their tendency to\neither overestimate or underestimate the signal power. That is, they are not\nasymptotically unbiased (as the sample size approaches infinity). To address\nthis issue, we propose to shrink the Capon beamformer by finding a scaling\nfactor that minimizes the mean squared error (MSE) of the signal power\nestimate. The new beamformer, referred to as the Capon$^+$ beamformer, is\nevaluated against the Capon and MMSE beamformers in terms of bias, signal power\nMSE, and signal waveform MSE. The Capon$^+$ beamformer strikes a better balance\nbetween signal power and waveform estimation while also exhibiting minimal\nbias, which approaches zero as the sample size increases."}
{"id": "2506.16957", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.16957", "abs": "https://arxiv.org/abs/2506.16957", "authors": ["Zisheng Wang", "Feng Li", "Hangbin Zhao", "Zihuan Mao", "Yaodong Zhang", "Qisheng Huang", "Bo Cao", "Mingming Cao", "Baolin He", "Qilin Hou"], "title": "Wi-Fi Sensing Tool Release: Gathering 802.11ax Channel State Information from a Commercial Wi-Fi Access Point", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Wi-Fi sensing has emerged as a powerful technology, leveraging channel state\ninformation (CSI) extracted from wireless data packets to enable diverse\napplications, ranging from human presence detection to gesture recognition and\nhealth monitoring. However, CSI extraction from commercial Wi-Fi access point\nlacks and out of date. This paper introduces ZTECSITool,a toolkit designed to\ncapture high-resolution CSI measurements from commercial Wi-Fi 6 (802.11ax)\naccess points, supporting bandwidths up to 160 MHz and 512 subcarriers.\nZTECSITool bridges a critical gap in Wi-Fi sensing research, facilitating the\ndevelopment of next-generation sensing systems. The toolkit includes customized\nfirmware and open-source software tools for configuring, collecting, and\nparsing CSI data, offering researchers a robust platform for advanced sensing\napplications. We detail the command protocols for CSI extraction, including\nband selection,STA filtering, and report configuration, and provide insights\ninto the data structure of the reported CSI. Additionally, we present a\nPython-based graphical interface for real-time CSI visualization and analysis"}
{"id": "2506.17010", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.17010", "abs": "https://arxiv.org/abs/2506.17010", "authors": ["Kuranage Roche Rayan Ranasinghe", "Bruno S. Chang", "Giuseppe Thadeu Freitas de Abreu"], "title": "Low-Complexity Receiver Design for Affine Filter Bank Modulation", "comment": "Submitted to an IEEE conference. arXiv admin note: substantial text\n  overlap with arXiv:2505.03589", "summary": "We propose a low-complexity receiver structure for the recently introduced\nAffine Filter Bank Modulation (AFBM) scheme, which is a novel waveform designed\nfor integrated sensing and communications (ISAC) systems operating in\ndoubly-dispersive (DD) channels. The proposed receiver structure is based on\nthe Gaussian Belief Propagation (GaBP) framework, making use of only\nelement-wise scalar operations to perform detection of the transmitted symbols.\nSimulation results demonstrate that AFBM in conjunction with GaBP outperforms\naffine frequency division multiplexing (AFDM) in terms of bit error rates\n(BERs) in DD channels, while achieving very low out-of-band emissions (OOBE) in\nhigh-mobility scenarios."}
{"id": "2506.17108", "categories": ["eess.SP", "cs.IT", "math.IT", "stat.ML"], "pdf": "https://arxiv.org/pdf/2506.17108", "abs": "https://arxiv.org/abs/2506.17108", "authors": ["Levli Citron", "Kobi Cohen", "Qing Zhao"], "title": "Searching for a Hidden Markov Anomaly over Multiple Processes", "comment": "13 pages, 9 figures", "summary": "We address the problem of detecting an anomalous process among a large number\nof processes. At each time t, normal processes are in state zero (normal\nstate), while the abnormal process may be in either state zero (normal state)\nor state one (abnormal state), with the states being hidden. The transition\nbetween states for the abnormal process is governed by a Markov chain over\ntime. At each time step, observations can be drawn from a selected subset of\nprocesses. Each probed process generates an observation depending on its hidden\nstate, either a typical distribution under state zero or an abnormal\ndistribution under state one. The objective is to design a sequential search\nstrategy that minimizes the expected detection time, subject to an error\nprobability constraint. In contrast to prior works that assume i.i.d.\nobservations, we address a new setting where anomalies evolve according to a\nhidden Markov model. To this end, we propose a novel algorithm, dubbed Anomaly\nDetection under Hidden Markov model (ADHM), which dynamically adapts the\nprobing strategy based on accumulated statistical evidence and predictive\nbelief updates over hidden states. ADHM effectively leverages temporal\ncorrelations to focus sensing resources on the most informative processes. The\nalgorithm is supported by an asymptotic theoretical foundation, grounded in an\noracle analysis that characterizes the fundamental limits of detection under\nthe assumption of a known distribution of the hidden states. In addition, the\nalgorithm demonstrates strong empirical performance, consistently outperforming\nexisting methods in extensive simulations."}
{"id": "2506.17189", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.17189", "abs": "https://arxiv.org/abs/2506.17189", "authors": ["Muhammad Umer", "Muhammad Ahmed Mohsin", "Aamir Mahmood", "Haejoon Jung", "Haris Pervaiz", "Mikael Gidlund", "Syed Ali Hassan"], "title": "On Energy-Efficient Passive Beamforming Design of RIS-Assisted CoMP-NOMA Networks", "comment": "Accepted and presented at IEEE ICC'25 [SAC-12 Track]. arXiv admin\n  note: substantial text overlap with arXiv:2504.00975", "summary": "This paper investigates the synergistic potential of reconfigurable\nintelligent surfaces (RIS) and non-orthogonal multiple access (NOMA) to enhance\nthe energy efficiency and performance of next-generation wireless networks. We\ndelve into the design of energy-efficient passive beamforming (PBF) strategies\nwithin RIS-assisted coordinated multi-point (CoMP)-NOMA networks. Two distinct\nRIS configurations, namely, enhancement-only PBF (EO) and enhancement &\ncancellation PBF (EC), are proposed and analyzed. Our findings demonstrate that\nRIS-assisted CoMP-NOMA networks offer significant efficiency gains compared to\ntraditional CoMP-NOMA systems. Furthermore, we formulate a PBF design problem\nto optimize the RIS phase shifts for maximizing energy efficiency. Our results\nreveal that the optimal PBF design is contingent upon several factors,\nincluding the number of cooperating base stations (BSs), the number of RIS\nelements deployed, and the RIS configuration. This study underscores the\npotential of RIS-assisted CoMP-NOMA networks as a promising solution for\nachieving superior energy efficiency and overall performance in future wireless\nnetworks."}
{"id": "2506.17200", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.17200", "abs": "https://arxiv.org/abs/2506.17200", "authors": ["Qingqing Wu", "Yanze Zhu", "Qiaoyan Peng", "Wanming Hao", "Yanzhao Hou", "Fengyuan Yang", "Wencai Yan", "Guoning Wang", "Wen Chen", "Chi Qiu"], "title": "Intelligent Reflecting Surfaces for THz Communications: Fundamentals, Key Solutions, and System Prototyping", "comment": null, "summary": "Intelligent reflecting surfaces (IRSs) have emerged as a cost-effective\ntechnology for terahertz (THz) communications by enabling programmable control\nof the wireless environment. This paper provides a comprehensive overview of\nIRSs-aided THz communications, covering hardware designs, advanced signal\nprocessing techniques, and practical deployment strategies. It first examines\nkey THz reconfigurable metasurface architectures, including electronic,\noptical, phase-change material, and micro-electromechanical systems\n(MEMS)-based implementations, highlighting their reconfiguration mechanisms and\nchallenges. Then, fundamental effects including near field and beam squint in\nwideband THz systems are analyzed, along with their impacts on system\nperformance. The paper further explores conventional and beam-squint-assisted\nchannel estimation methods, innovative beam management strategies, and\ndeployment considerations across large- and small-scale scenarios. Practical\nexperiments at 220 gigahertz (GHz) validate the effectiveness of IRS in\nimproving signal strength and communication reliability for both single-user\nand multi-user setups."}
{"id": "2506.17205", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.17205", "abs": "https://arxiv.org/abs/2506.17205", "authors": ["Jennifer Bondarchuk", "Anthony Trezza", "Donald J. Bucci Jr"], "title": "Efficient Implementation of Multi-sensor Adaptive Birth Samplers for Labeled Random Finite Set Tracking", "comment": "Accepted to the 2024 Proc. IEEE 27th Int. Conf. Inf. Fusion. arXiv\n  admin note: text overlap with arXiv:2307.06401", "summary": "Adaptive track initiation remains a crucial component of many modern\nmulti-target tracking systems. For labeled random finite sets multi-object\nfilters, prior work has been established to construct a labeled multi-object\nbirth density using measurements from multiple sensors. A naive construction of\nthis adaptive birth set density results in an exponential number of newborn\ncomponents in the number of sensors. A truncation procedure was provided that\nleverages a Gibbs sampler to truncate the birth density, reducing the\ncomplexity to quadratic in the number of sensors. However, only a limited\ndiscussion has been provided on additional algorithmic techniques that can be\nemployed to substantially reduce the complexity in practical tracking\napplications. In this paper, we propose five efficiency enhancements for the\nlabeled random finite sets multi-sensor adaptive birth procedure. Simulation\nresults are provided to demonstrate their computational benefits and show that\nthey result in a negligible change to the multi-target tracking performance."}
{"id": "2506.15843", "categories": ["eess.SP", "eess.IV"], "pdf": "https://arxiv.org/pdf/2506.15843", "abs": "https://arxiv.org/abs/2506.15843", "authors": ["Ninghe Liu", "Yu Xi Huang", "Simon Mahler", "Changhuei Yang"], "title": "Optimized cerebral blood flow measurement in speckle contrast optical spectroscopy via refinement of noise calibration", "comment": "5 pages, 3 figures", "summary": "Speckle contrast optical spectroscopy (SCOS) offers a non-invasive and\ncost-effective method for monitoring cerebral blood flow (CBF). However,\nextracting accurate CBF from SCOS necessitates precise noise pre-calibration.\nErrors from this can degrade CBF measurement fidelity, particularly when the\noverall signal level is low. Such errors primarily stem from residual speckle\ncontrast associated with camera and shot noise, whose fluctuations exhibit a\ntemporal structure that mimics cerebral blood volume (CBV) waveforms. We\npropose an optimization-based framework that performs an adaptive refinement of\nnoise calibration, mitigating the CBV-mimicking artifacts by reducing the\nCBF-CBV waveform correlation. Validated on 10 human subjects, our approach\neffectively lowered the signal threshold for reliable CBF signal from 97 to 26\nelectrons per pixel for a 1920x1200 pixels SCOS system. This improvement\nenables more accurate and robust CBF measurements in SCOS, especially at large\nsource-detector (SD) distances for deeper tissue interrogation."}
{"id": "2506.15950", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.15950", "abs": "https://arxiv.org/abs/2506.15950", "authors": ["Saeed Razavikia", "Carlo Fischione"], "title": "On Designing Modulation for Over-the-Air Computation -- Part I: Noise-Aware Design", "comment": null, "summary": "Over-the-air computation (OAC) leverages the physical superposition property\nof wireless multiple access channels (MACs) to compute functions while\ncommunication occurs, enabling scalable and low-latency processing in\ndistributed networks. While analog OAC methods suffer from noise sensitivity\nand hardware constraints, existing digital approaches are often limited in\ndesign complexity, which may hinder scalability and fail to exploit spectral\nefficiency fully. This two-part paper revisits and extends the ChannelComp\nframework, a general methodology for computing arbitrary finite-valued\nfunctions using digital modulation. In Part I, we develop a novel constellation\ndesign approach that is aware of the noise distribution and formulates the\nencoder design as a max-min optimization problem using noise-tailored distance\nmetrics. Our design supports noise models, including Gaussian, Laplace, and\nheavy-tailed distributions. We further demonstrate that, for heavy-tailed\nnoise, the optimal ChannelComp setup coincides with the solution to the\ncorresponding max-min criterion for the channel noise with heavy-tailed\ndistributions. Numerical experiments confirm that our noise-aware design\nachieves a substantially lower mean-square error than leading digital OAC\nmethods over noisy MACs. In Part II, we consider a constellation design with a\nquantization-based sampling scheme to enhance modulation scalability and\ncomputational accuracy for large-scale digital OAC."}
{"id": "2506.15972", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.15972", "abs": "https://arxiv.org/abs/2506.15972", "authors": ["Haiyang Miao", "Jianhua Zhang", "Pan Tang", "Heng Wang", "Lei Tian", "Guangyi Liu"], "title": "Theoretical Analysis of Near-Field MIMO Channel Capacity and Mid-Band Experimental Validation", "comment": null, "summary": "With the increase of multiple-input-multiple-output (MIMO) array size and\ncarrier frequency, near-field MIMO communications will become crucial in 6G\nwireless networks. Due to the increase of MIMO near-field range, the research\nof near-field MIMO capacity has aroused wide interest. In this paper, we focus\non the theoretical analysis and empirical study of near-field MIMO capacity.\nFirst, the near-field channel model is characterized from the electromagnetic\ninformation perspective. Second, with the uniform planar array (UPA), the\nchannel capacity based on effective degree of freedom (EDoF) is analyzed\ntheoretically, and the closed-form analytical expressions are derived in\ndetail. Finally, based on the numerical verification of near-field channel\nmeasurement experiment at 13 GHz band, we reveal that the channel capacity of\nUPA-type MIMO systems decreases continuously with the communication distance\nincreasing. It can be observed that the near-field channel capacity gain is\nrelatively obvious when large-scale MIMO is adopted at both receiving and\ntransmitter ends, but the near-field channel capacity gain may be limited in\nthe actual communication system with the small antenna array at receiving end.\nThis work will give some reference to the near-field communication systems."}
{"id": "2506.15998", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.15998", "abs": "https://arxiv.org/abs/2506.15998", "authors": ["Chen Xu", "Xianghao Yu", "Fan Liu", "Shi Jin"], "title": "Exploiting Both Pilots and Data Payloads for Integrated Sensing and Communications", "comment": null, "summary": "Integrated sensing and communications (ISAC) is one of the key enabling\ntechnologies in future sixth-generation (6G) networks. Current ISAC systems\npredominantly rely on deterministic pilot signals within the signal frame to\naccomplish sensing tasks. However, these pilot signals typically occupy only a\nsmall portion, e.g., 0.15% to 25%, of the time-frequency resources. To enhance\nthe system utility, a promising solution is to repurpose the extensive random\ndata payload signals for sensing tasks. In this paper, we analyze the ISAC\nperformance of a multi-antenna system where both deterministic pilot and random\ndata symbols are employed for sensing tasks. By capitalizing on random matrix\ntheory (RMT), we first derive a semi-closed-form asymptotic expression of the\nergodic linear minimum mean square error (ELMMSE). Then, we formulate an ISAC\nprecoding optimization problem to minimize the ELMMSE, which is solved via a\nspecifically tailored successive convex approximation (SAC) algorithm. To\nprovide system insights, we further derive a closed-form expression for the\nasymptotic ELMMSE at high signal-to-noise ratios (SNRs). Our analysis reveals\nthat, compared with conventional sensing implemented by deterministic signals,\nthe sensing performance degradation induced by random signals is critically\ndetermined by the ratio of the transmit antenna size to the data symbol length.\nBased on this result, the ISAC precoding optimization problem at high SNRs is\ntransformed into a convex optimization problem that can be efficiently solved.\nSimulation results validate the accuracy of the derived asymptotic expressions\nof ELMMSE and the performance of the proposed precoding schemes. Particularly,\nby leveraging data payload signals for sensing tasks, the sensing error is\nreduced by up to 5.6 dB compared to conventional pilot-based sensing."}
{"id": "2506.15744", "categories": ["eess.IV", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.15744", "abs": "https://arxiv.org/abs/2506.15744", "authors": ["Seyed Mohsen Hosseini"], "title": "Pixel-wise Modulated Dice Loss for Medical Image Segmentation", "comment": null, "summary": "Class imbalance and the difficulty imbalance are the two types of data\nimbalance that affect the performance of neural networks in medical\nsegmentation tasks. In class imbalance the loss is dominated by the majority\nclasses and in difficulty imbalance the loss is dominated by easy to classify\npixels. This leads to an ineffective training. Dice loss, which is based on a\ngeometrical metric, is very effective in addressing the class imbalance\ncompared to the cross entropy (CE) loss, which is adopted directly from\nclassification tasks. To address the difficulty imbalance, the common approach\nis employing a re-weighted CE loss or a modified Dice loss to focus the\ntraining on difficult to classify areas. The existing modification methods are\ncomputationally costly and with limited success. In this study we propose a\nsimple modification to the Dice loss with minimal computational cost. With a\npixel level modulating term, we take advantage of the effectiveness of Dice\nloss in handling the class imbalance to also handle the difficulty imbalance.\nResults on three commonly used medical segmentation tasks show that the\nproposed Pixel-wise Modulated Dice loss (PM Dice loss) outperforms other\nmethods, which are designed to tackle the difficulty imbalance problem."}
{"id": "2506.16011", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.16011", "abs": "https://arxiv.org/abs/2506.16011", "authors": ["Rang Liu", "Ming Li", "Mehdi Zafari", "Bjorn Ottersten", "A. Lee Swindlehurst"], "title": "Multi-Domain Optimization Framework for ISAC: From Electromagnetic Shaping to Network Cooperation", "comment": "10 pages, 5 figures, submitted to IEEE", "summary": "Integrated sensing and communication (ISAC) has emerged as a key feature for\nsixth-generation (6G) networks, providing an opportunity to meet the dual\ndemands of communication and sensing. Existing ISAC research primarily focuses\non baseband optimization at individual access points, with limited attention to\nthe roles of electromagnetic (EM) shaping and network-wide coordination. The\nintricate interdependencies between these domains remain insufficiently\nexplored, leaving their full potential for enhancing ISAC performance largely\nuntapped. To bridge this gap, we consider multi-domain ISAC optimization\nintegrating EM shaping, baseband processing, and network cooperation strategies\nthat facilitate efficient resource management and system-level design. We\nanalyze the fundamental trade-offs between these domains and offer insights\ninto domain-specific and cross-domain strategies contributing to ISAC\nperformance and efficiency. We then conduct a case study demonstrating the\neffectiveness of joint multi-domain optimization. Finally, we discuss key\nchallenges and future research directions to connect theoretical advancements\nand practical ISAC deployments. This work paves the way for intelligent and\nscalable ISAC architectures, providing critical insights for their seamless\nintegration into next-generation wireless networks."}
{"id": "2506.15745", "categories": ["eess.IV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.15745", "abs": "https://arxiv.org/abs/2506.15745", "authors": ["Minsoo Kim", "Kyuhong Shim", "Jungwook Choi", "Simyung Chang"], "title": "InfiniPot-V: Memory-Constrained KV Cache Compression for Streaming Video Understanding", "comment": null, "summary": "Modern multimodal large language models (MLLMs) can reason over hour-long\nvideo, yet their key-value (KV) cache grows linearly with time--quickly\nexceeding the fixed memory of phones, AR glasses, and edge robots. Prior\ncompression schemes either assume the whole video and user query are available\noffline or must first build the full cache, so memory still scales with stream\nlength. InfiniPot-V is the first training-free, query-agnostic framework that\nenforces a hard, length-independent memory cap for streaming video\nunderstanding. During video encoding it monitors the cache and, once a user-set\nthreshold is reached, runs a lightweight compression pass that (i) removes\ntemporally redundant tokens via Temporal-axis Redundancy (TaR) metric and (ii)\nkeeps semantically significant tokens via Value-Norm (VaN) ranking. Across four\nopen-source MLLMs and four long-video and two streaming-video benchmarks,\nInfiniPot-V cuts peak GPU memory by up to 94%, sustains real-time generation,\nand matches or surpasses full-cache accuracy--even in multi-turn dialogues. By\ndissolving the KV cache bottleneck without retraining or query knowledge,\nInfiniPot-V closes the gap for on-device streaming video assistants."}
{"id": "2506.16070", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.16070", "abs": "https://arxiv.org/abs/2506.16070", "authors": ["Mathushaharan Rathakrishnan", "Samiru Gayan", "Rohit Singh", "Amandeep Kaur", "Hazer Inaltekin", "Sampath Edirisinghe", "H. Vincent Poor"], "title": "Towards AI-Driven RANs for 6G and Beyond: Architectural Advancements and Future Horizons", "comment": null, "summary": "It is envisioned that 6G networks will be supported by key architectural\nprinciples, including intelligence, decentralization, interoperability, and\ndigitalization. With the advances in artificial intelligence (AI) and machine\nlearning (ML), embedding intelligence into the foundation of wireless\ncommunication systems is recognized as essential for 6G and beyond. Existing\nradio access network (RAN) architectures struggle to meet the ever growing\ndemands for flexibility, automation, and adaptability required to build\nself-evolving and autonomous wireless networks. In this context, this paper\nexplores the transition towards AI-driven RAN (AI-RAN) by developing a novel\nAI-RAN framework whose performance is evaluated through a practical scenario\nfocused on intelligent orchestration and resource optimization. Besides, the\npaper reviews the evolution of RAN architectures and sheds light on key\nenablers of AI-RAN including digital twins (DTs), intelligent reflecting\nsurfaces (IRSs), large generative AI (GenAI) models, and blockchain (BC).\nFurthermore, it discusses the deployment challenges of AI-RAN, including\ntechnical and regulatory perspectives, and outlines future research directions\nincorporating technologies such as integrated sensing and communication (ISAC)\nand agentic AI."}
{"id": "2506.15748", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.15748", "abs": "https://arxiv.org/abs/2506.15748", "authors": ["Zhe Wang", "Yuhua Ru", "Aladine Chetouani", "Tina Shiang", "Fang Chen", "Fabian Bauer", "Liping Zhang", "Didier Hans", "Rachid Jennane", "William Ewing Palmer", "Mohamed Jarraya", "Yung Hsin Chen"], "title": "Diffusion-based Counterfactual Augmentation: Towards Robust and Interpretable Knee Osteoarthritis Grading", "comment": null, "summary": "Automated grading of Knee Osteoarthritis (KOA) from radiographs is challenged\nby significant inter-observer variability and the limited robustness of deep\nlearning models, particularly near critical decision boundaries. To address\nthese limitations, this paper proposes a novel framework, Diffusion-based\nCounterfactual Augmentation (DCA), which enhances model robustness and\ninterpretability by generating targeted counterfactual examples. The method\nnavigates the latent space of a diffusion model using a Stochastic Differential\nEquation (SDE), governed by balancing a classifier-informed boundary drive with\na manifold constraint. The resulting counterfactuals are then used within a\nself-corrective learning strategy to improve the classifier by focusing on its\nspecific areas of uncertainty. Extensive experiments on the public\nOsteoarthritis Initiative (OAI) and Multicenter Osteoarthritis Study (MOST)\ndatasets demonstrate that this approach significantly improves classification\naccuracy across multiple model architectures. Furthermore, the method provides\ninterpretability by visualizing minimal pathological changes and revealing that\nthe learned latent space topology aligns with clinical knowledge of KOA\nprogression. The DCA framework effectively converts model uncertainty into a\nrobust training signal, offering a promising pathway to developing more\naccurate and trustworthy automated diagnostic systems. Our code is available at\nhttps://github.com/ZWang78/DCA."}
{"id": "2506.16184", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.16184", "abs": "https://arxiv.org/abs/2506.16184", "authors": ["Shan Shan", "Chongjun Ouyang", "Yong Li", "Yuanwei Liu"], "title": "Multigroup Multicast Design for Pinching-Antenna Systems: Waveguide-Division or Waveguide-Multiplexing?", "comment": null, "summary": "This article addresses the design of multigroup multicast communications in\nthe pinching-antenna system (PASS). A PASS-enabled multigroup transmission\nframework is proposed to maximize multicast rates under a couple of\ntransmission architectures: waveguide-division (WD) and waveguide-multiplexing\n(WM). 1) For WD, an element-wise sequential optimization strategy is proposed\nfor pinching beamforming, i.e., optimizing the activated positions of pinching\nantennas along dielectric waveguides. Meanwhile, a log-sum-exp projected\ngradient descent algorithm is proposed for transmit power allocation across\nwaveguides. 2) For WM, a majorization-minimization (MM)-based framework is\nproposed to tackle the problem's non-smoothness and non-convexity. On this\nbasis, a low-complexity element-wise sequential optimization method is\ndeveloped for pinching beamforming using the MM surrogate objective.\nFurthermore, the optimal transmit beamformer structure is derived from the MM\nsurrogate objective using the Lagrange duality, with an efficient transmit\nbeamforming algorithm proposed using projected adaptive gradient descent.\nNumerical results demonstrate that: i) both WD and WM architectures in PASS\nachieve significant multicast rate improvements over conventional MIMO\ntechniques, especially for systems with large service areas; ii) WM is more\nrobust than WD in dense deployments, while WD excels when user groups are\nspatially separated."}
{"id": "2506.15750", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2506.15750", "abs": "https://arxiv.org/abs/2506.15750", "authors": ["Sanuwani Dayarathna", "Himashi Peiris", "Kh Tohidul Islam", "Tien-Tsin Wong", "Zhaolin Chen"], "title": "D2Diff : A Dual Domain Diffusion Model for Accurate Multi-Contrast MRI Synthesis", "comment": null, "summary": "Multi contrast MRI synthesis is inherently challenging due to the complex and\nnonlinear relationships among different contrasts. Each MRI contrast highlights\nunique tissue properties, but their complementary information is difficult to\nexploit due to variations in intensity distributions and contrast specific\ntextures. Existing methods for multi contrast MRI synthesis primarily utilize\nspatial domain features, which capture localized anatomical structures but\nstruggle to model global intensity variations and distributed patterns.\nConversely, frequency domain features provide structured inter contrast\ncorrelations but lack spatial precision, limiting their ability to retain finer\ndetails. To address this, we propose a dual domain learning framework that\nintegrates spatial and frequency domain information across multiple MRI\ncontrasts for enhanced synthesis. Our method employs two mutually trained\ndenoising networks, one conditioned on spatial domain and the other on\nfrequency domain contrast features through a shared critic network.\nAdditionally, an uncertainty driven mask loss directs the models focus toward\nmore critical regions, further improving synthesis accuracy. Extensive\nexperiments show that our method outperforms SOTA baselines, and the downstream\nsegmentation performance highlights the diagnostic value of the synthetic\nresults."}
{"id": "2506.16191", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.16191", "abs": "https://arxiv.org/abs/2506.16191", "authors": ["Hyeonho Noh", "Hyeonsu Lyu", "Moe Z. Win", "Hyun Jong Yang"], "title": "DCFNet: Doppler Correction Filter Network for Integrated Sensing and Communication in Multi-User MIMO-OFDM Systems", "comment": null, "summary": "Integrated sensing and communication (ISAC) is a headline feature for the\nforthcoming IMT-2030 and 6G releases, yet a concrete solution that fits within\nthe established orthogonal frequency division multiplexing (OFDM) family\nremains open. Specifically, Doppler-induced inter-carrier interference (ICI)\ndestroys sub-carrier orthogonality of OFDM sensing signals, blurring\nrange-velocity maps and severely degrading sensing accuracy. Building on\nmulti-user multi-input-multi-output (MIMO) OFDM systems, this paper proposes\nDoppler-Correction Filter Network (DCFNet), an AI-native ISAC model that\ndelivers fine range-velocity resolution at minimal complexity without altering\nthe legacy frame structure. A bank of DCFs first shifts dominant ICI energy\naway from critical Doppler bins; a compact deep learning network then\nsuppresses the ICI. To further enhance the range and velocity resolutions, we\npropose DCFNet with local refinement (DCFNet-LR), which applies a generalized\nlikelihood ratio test (GLRT) to refine target estimates of DCFNet to sub-cell\naccuracy. Simulation results show that DCFNet-LR runs $143\\times$ faster than\nmaximum likelihood search and achieves significantly superior performance,\nreducing the range RMSE by up to $2.7 \\times 10^{-4}$ times and the velocity\nRMSE by $6.7 \\times 10^{-4}$ times compared to conventional detection methods."}
{"id": "2506.15762", "categories": ["eess.IV", "cs.LG", "physics.med-ph"], "pdf": "https://arxiv.org/pdf/2506.15762", "abs": "https://arxiv.org/abs/2506.15762", "authors": ["Tom Hendriks", "Gerrit Arends", "Edwin Versteeg", "Anna Vilanova", "Maxime Chamberland", "Chantal M. W. Tax"], "title": "Implicit neural representations for accurate estimation of the standard model of white matter", "comment": "27 pages, 12 figures", "summary": "Diffusion magnetic resonance imaging (dMRI) enables non-invasive\ninvestigation of tissue microstructure. The Standard Model (SM) of white matter\naims to disentangle dMRI signal contributions from intra- and extra-axonal\nwater compartments. However, due to the model its high-dimensional nature,\nextensive acquisition protocols with multiple b-values and diffusion tensor\nshapes are typically required to mitigate parameter degeneracies. Even then,\naccurate estimation remains challenging due to noise. This work introduces a\nnovel estimation framework based on implicit neural representations (INRs),\nwhich incorporate spatial regularization through the sinusoidal encoding of the\ninput coordinates. The INR method is evaluated on both synthetic and in vivo\ndatasets and compared to parameter estimates using cubic polynomials,\nsupervised neural networks, and nonlinear least squares. Results demonstrate\nsuperior accuracy of the INR method in estimating SM parameters, particularly\nin low signal-to-noise conditions. Additionally, spatial upsampling of the INR\ncan represent the underlying dataset anatomically plausibly in a continuous\nway, which is unattainable with linear or cubic interpolation. The INR is fully\nunsupervised, eliminating the need for labeled training data. It achieves fast\ninference ($\\sim$6 minutes), is robust to both Gaussian and Rician noise,\nsupports joint estimation of SM kernel parameters and the fiber orientation\ndistribution function with spherical harmonics orders up to at least 8 and\nnon-negativity constraints, and accommodates spatially varying acquisition\nprotocols caused by magnetic gradient non-uniformities. The combination of\nthese properties along with the possibility to easily adapt the framework to\nother dMRI models, positions INRs as a potentially important tool for analyzing\nand interpreting diffusion MRI data."}
{"id": "2506.16198", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.16198", "abs": "https://arxiv.org/abs/2506.16198", "authors": ["Haofan Dong", "Ozgur B. Akan"], "title": "MASC: Integrated Sensing and Communications for the Martian Internet of Space", "comment": "11 pages, 9 figures, journal", "summary": "Mars exploration missions increasingly demand reliable communication systems,\nyet harsh environmental conditions -- particularly frequent dust storms,\nextreme Doppler effects, and stringent resource constraints -- pose\nunprecedented challenges to conventional communication approaches. This paper\npresents the Martian Adaptive Sensing and Communication (MASC) system\nspecifically designed for the Martian environment. MASC establishes a\nphysically interpretable channel model and develops three key components:\nenvironment-aware hybrid precoding, adaptive parameter mapping, and robust\ncommunication precoding. Simulation results demonstrate that MASC maintains 45\npercent sensing coverage under severe dust conditions compared to only 5\npercent with conventional methods, provides up to 2.5 dB\nsignal-to-interference-plus-noise ratio (SINR) improvement at 50 percent\nchannel state information (CSI) uncertainty, and yields 80 percent higher\ncapacity in moderate dust storms. Using an epsilon-constraint multi-objective\noptimization approach, we enable mission planners to select operational modes\nranging from communication-priority (0.33 bps/Hz capacity, 28 percent sensing\ncoverage) to sensing-priority (90 percent coverage with minimal capacity),\noffering a versatile framework that balances environmental awareness with\nhyper-reliable data transmission. This work provides a validated blueprint for\nintegrated sensing and communication (ISAC) in non-terrestrial networks (NTN),\na key enabler for achieving ubiquitous connectivity in the 6G era."}
{"id": "2506.15835", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.15835", "abs": "https://arxiv.org/abs/2506.15835", "authors": ["Mingyuan Luo", "Xin Yang", "Zhongnuo Yan", "Yan Cao", "Yuanji Zhang", "Xindi Hu", "Jin Wang", "Haoxuan Ding", "Wei Han", "Litao Sun", "Dong Ni"], "title": "MoNetV2: Enhanced Motion Network for Freehand 3D Ultrasound Reconstruction", "comment": null, "summary": "Three-dimensional (3D) ultrasound (US) aims to provide sonographers with the\nspatial relationships of anatomical structures, playing a crucial role in\nclinical diagnosis. Recently, deep-learning-based freehand 3D US has made\nsignificant advancements. It reconstructs volumes by estimating transformations\nbetween images without external tracking. However, image-only reconstruction\nposes difficulties in reducing cumulative drift and further improving\nreconstruction accuracy, particularly in scenarios involving complex motion\ntrajectories. In this context, we propose an enhanced motion network (MoNetV2)\nto enhance the accuracy and generalizability of reconstruction under diverse\nscanning velocities and tactics. First, we propose a sensor-based temporal and\nmulti-branch structure that fuses image and motion information from a velocity\nperspective to improve image-only reconstruction accuracy. Second, we devise an\nonline multi-level consistency constraint that exploits the inherent\nconsistency of scans to handle various scanning velocities and tactics. This\nconstraint exploits both scan-level velocity consistency, path-level appearance\nconsistency, and patch-level motion consistency to supervise inter-frame\ntransformation estimation. Third, we distill an online multi-modal\nself-supervised strategy that leverages the correlation between network\nestimation and motion information to further reduce cumulative errors.\nExtensive experiments clearly demonstrate that MoNetV2 surpasses existing\nmethods in both reconstruction quality and generalizability performance across\nthree large datasets."}
{"id": "2506.16208", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.16208", "abs": "https://arxiv.org/abs/2506.16208", "authors": ["Saeed Razavikia", "Carlo Fischione"], "title": "On Designing Modulation for Over-the-Air Computation -- Part II: Pyramid Sampling", "comment": null, "summary": "Over-the-air computation (OAC) harnesses the natural superposition of\nwireless signals to compute aggregate functions during transmission, thereby\ncollapsing communication and computation into a single step and significantly\nreducing latency and resource usage. In Part I, digital OAC was formulated as a\nnoise-aware constellation design problem by casting encoder design as a max-min\noptimization that aligns minimum Euclidean distances between superimposed\nconstellation points with squared differences of their corresponding function\noutputs.\n  In this paper, Part II, we address the prohibitive complexity and\nquantization challenges inherent in digital OAC constellation design for\nlarge-scale edge networks. More precisely, we introduce a pyramid sampling\nstrategy that judiciously selects a subset of superimposed constellation points\nto reduce the encoder design complexity from $\\mathcal{O}(q^K)$ to\n$\\mathcal{O}(q^{K-p+1})$, where $p\\in\\{1,\\dots, K\\}$ denotes the sampling\norder, $q$ levels of modulation, and $K$ denotes the number nodes in the\nnetwork. Under the assumption of symmetric aggregation, this approach enables a\ncontrolled trade-off between computational complexity and function computation\naccuracy. As a special case, we propose majority-based sampling ($p=K$), which\nconfines aggregation to only $q$ consensus points, inherently avoiding\ndestructive overlaps and permitting the use of standard digital modulations\n(e.g., QAM, PSK, ASK) without bespoke constellation designs. We also show via\nseveral simulations, across various aggregation functions, modulation levels,\nand noise levels, that moderate sampling orders attain acceptable performance\nwith orders-of-magnitude fewer constraints than exhaustive designs."}
{"id": "2506.15853", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.15853", "abs": "https://arxiv.org/abs/2506.15853", "authors": ["Amit Das", "Naofumi Tomita", "Kyle J. Syme", "Weijie Ma", "Paige O'Connor", "Kristin N. Corbett", "Bing Ren", "Xiaoying Liu", "Saeed Hassanpour"], "title": "Cross-Modality Learning for Predicting IHC Biomarkers from H&E-Stained Whole-Slide Images", "comment": null, "summary": "Hematoxylin and Eosin (H&E) staining is a cornerstone of pathological\nanalysis, offering reliable visualization of cellular morphology and tissue\narchitecture for cancer diagnosis, subtyping, and grading. Immunohistochemistry\n(IHC) staining provides molecular insights by detecting specific proteins\nwithin tissues, enhancing diagnostic accuracy, and improving treatment\nplanning. However, IHC staining is costly, time-consuming, and\nresource-intensive, requiring specialized expertise. To address these\nlimitations, this study proposes HistoStainAlign, a novel deep learning\nframework that predicts IHC staining patterns directly from H&E whole-slide\nimages (WSIs) by learning joint representations of morphological and molecular\nfeatures. The framework integrates paired H&E and IHC embeddings through a\ncontrastive training strategy, capturing complementary features across staining\nmodalities without patch-level annotations or tissue registration. The model\nwas evaluated on gastrointestinal and lung tissue WSIs with three commonly used\nIHC stains: P53, PD-L1, and Ki-67. HistoStainAlign achieved weighted F1 scores\nof 0.735 [95% Confidence Interval (CI): 0.670-0.799], 0.830 [95% CI:\n0.772-0.886], and 0.723 [95% CI: 0.607-0.836], respectively for these three IHC\nstains. Embedding analyses demonstrated the robustness of the contrastive\nalignment in capturing meaningful cross-stain relationships. Comparisons with a\nbaseline model further highlight the advantage of incorporating contrastive\nlearning for improved stain pattern prediction. This study demonstrates the\npotential of computational approaches to serve as a pre-screening tool, helping\nprioritize cases for IHC staining and improving workflow efficiency."}
{"id": "2506.16236", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.16236", "abs": "https://arxiv.org/abs/2506.16236", "authors": ["Romain Charbonnier", "Thierry Tenoux", "Yoann Corre"], "title": "Refining Ray-Tracing Accuracy and Efficiency in the Context of FRMCS Urban Railway Channel Predictions", "comment": "Presented at Workshop \"Emerging information and communication\n  technologies for smart railway Challenges and Opportunities for mmWave, THz,\n  ISAC, 5G and 6G\" in IEEE VTC-Spring 2025 Conference, June 2025, Oslo, Norway", "summary": "The upcoming roll-out of the new wireless communication standard for wireless\nrailway services, FRMCS, requires a thorough understanding of the system\nperformance in real-world conditions, since this will strongly influence the\ndeployment costs and the effectiveness of an infrastructure planned for\ndecades. The virtual testing of the equipment and network performance in\nrealistic simulated scenarios is key; its accuracy depends on the reliability\nof the predicted radio channel properties. In this article, the authors explain\nhow they are evolving a ray-tracing (RT) tool to apply it to the specific case\nof simulating the radio link between the FRMCS fixed infrastructure and an\nantenna placed on the roof of a train moving in an urban environment. First, a\ndynamic version of the RT tool is used to capture the rapid variations of all\nchannel metrics; a compromise is sought between computation time and accuracy.\nBesides, a hybridization of RT and physical optics (PO) allows the integration\nof objects near the track, such as catenary pylons, into the simulation. A case\nstudy shows that the scattering by metallic pylons brings a significant\ncontribution."}
{"id": "2506.16102", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.16102", "abs": "https://arxiv.org/abs/2506.16102", "authors": ["Ziran Zhu", "Tongda Xu", "Minye Huang", "Dailan He", "Xingtong Ge", "Xinjie Zhang", "Ling Li", "Yan Wang"], "title": "Fast Training-free Perceptual Image Compression", "comment": null, "summary": "Training-free perceptual image codec adopt pre-trained unconditional\ngenerative model during decoding to avoid training new conditional generative\nmodel. However, they heavily rely on diffusion inversion or sample\ncommunication, which take 1 min to intractable amount of time to decode a\nsingle image. In this paper, we propose a training-free algorithm that improves\nthe perceptual quality of any existing codec with theoretical guarantee. We\nfurther propose different implementations for optimal perceptual quality when\ndecoding time budget is $\\approx 0.1$s, $0.1-10$s and $\\ge 10$s. Our approach:\n1). improves the decoding time of training-free codec from 1 min to $0.1-10$s\nwith comparable perceptual quality. 2). can be applied to non-differentiable\ncodec such as VTM. 3). can be used to improve previous perceptual codecs, such\nas MS-ILLM. 4). can easily achieve perception-distortion trade-off.\nEmpirically, we show that our approach successfully improves the perceptual\nquality of ELIC, VTM and MS-ILLM with fast decoding. Our approach achieves\ncomparable FID to previous training-free codec with significantly less decoding\ntime. And our approach still outperforms previous conditional generative model\nbased codecs such as HiFiC and MS-ILLM in terms of FID. The source code is\nprovided in the supplementary material."}
{"id": "2506.16304", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.16304", "abs": "https://arxiv.org/abs/2506.16304", "authors": ["Junyi Jiang", "Wei Chen", "Xin Guo", "Shenghui Song", "Ying Jun", "Zhang", "Zhu Han", "Merouane Debbah", "Khaled B. Letaief"], "title": "A Tractable Approach to Massive Communication and Ubiquitous Connectivity in 6G Standardization", "comment": null, "summary": "The full-scale 6G standardization has attracted considerable recent\nattention, especially since the first 3GPP-wide 6G workshop held in March 2025.\nTo understand the practical and fundamental values of 6G and facilitate its\nstandardization, it is crucial to explore the theoretical limits of spectrum,\nenergy, and coverage efficiency considering practical hardware and signaling\nconstraints. In this paper, we present a mean-field-approximation-based\ninvestigation on two out of six use case scenarios defined by IMT-2030, namely,\nmassive communication and ubiquitous connectivity. Being aware of the\nlimitation in interference cancellation owing to constrained cost and hardware\ncomplexity, we investigate the spectrum reuse architecture in both usage\nscenarios. We propose a tractable spectrum reuse with low signaling overhead\nconsumed for channel estimation and channel state information (CSI) feedback.\nOur analysis indicates that the massive communication over cellular and\ndevice-to-device (D2D) networks can benefit from channel orthogonalization,\nwhile it is unnecessary to share the CSI of interfering links. Moreover,\ndeploying relays or movable base stations, e.g. unmanned aerial vehicle, yields\nsubstantial energy and spectrum gain for ubiquitous connectivity, despite\nintroducing interference. As such, the mean-field-optimization-based evaluation\nis expected to positively impact 6G and NextG standardization in 3GPP and other\nstandardization bodies."}
{"id": "2506.16116", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.16116", "abs": "https://arxiv.org/abs/2506.16116", "authors": ["Ignacio Hernández Montilla", "Alfonso Medela", "Paola Pasquali", "Andy Aguilar", "Taig Mac Carthy", "Gerardo Fernández", "Antonio Martorell", "Enrique Onieva"], "title": "Enhanced Dermatology Image Quality Assessment via Cross-Domain Training", "comment": "9 pages, 4 figures. This manuscript has been accepted to the 2025\n  12th International Conference on Bioinformatics Research and Applications\n  (ICBRA 2025). It will be published in International Conference Proceedings by\n  ACM, which will be archived in ACM Digital Library, indexed by Ei Compendex\n  and Scopus", "summary": "Teledermatology has become a widely accepted communication method in daily\nclinical practice, enabling remote care while showing strong agreement with\nin-person visits. Poor image quality remains an unsolved problem in\nteledermatology and is a major concern to practitioners, as bad-quality images\nreduce the usefulness of the remote consultation process. However, research on\nImage Quality Assessment (IQA) in dermatology is sparse, and does not leverage\nthe latest advances in non-dermatology IQA, such as using larger image\ndatabases with ratings from large groups of human observers. In this work, we\npropose cross-domain training of IQA models, combining dermatology and\nnon-dermatology IQA datasets. For this purpose, we created a novel dermatology\nIQA database, Legit.Health-DIQA-Artificial, using dermatology images from\nseveral sources and having them annotated by a group of human observers. We\ndemonstrate that cross-domain training yields optimal performance across\ndomains and overcomes one of the biggest limitations in dermatology IQA, which\nis the small scale of data, and leads to models trained on a larger pool of\nimage distortions, resulting in a better management of image quality in the\nteledermatology process."}
{"id": "2506.16767", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.16767", "abs": "https://arxiv.org/abs/2506.16767", "authors": ["Esa Ollila", "Xavier Mestre", "Elias Raninen"], "title": "Beamforming design for minimizing the signal power estimation error", "comment": null, "summary": "We study the properties of beamformers in their ability to either maintain or\nestimate the true signal power of the signal of interest (SOI). Our focus is\nparticularly on the Capon beamformer and the minimum mean squared error (MMSE)\nbeamformer. The Capon beamformer, also known as the minimum power\ndistortionless response (MPDR) or the minimum variance distortionless response\n(MVDR) beamformer, is a widely used method in array signal processing. A\ncurious feature of both the Capon and the MMSE beamformers is their tendency to\neither overestimate or underestimate the signal power. That is, they are not\nasymptotically unbiased (as the sample size approaches infinity). To address\nthis issue, we propose to shrink the Capon beamformer by finding a scaling\nfactor that minimizes the mean squared error (MSE) of the signal power\nestimate. The new beamformer, referred to as the Capon$^+$ beamformer, is\nevaluated against the Capon and MMSE beamformers in terms of bias, signal power\nMSE, and signal waveform MSE. The Capon$^+$ beamformer strikes a better balance\nbetween signal power and waveform estimation while also exhibiting minimal\nbias, which approaches zero as the sample size increases."}
{"id": "2506.16210", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.16210", "abs": "https://arxiv.org/abs/2506.16210", "authors": ["Zhenxuan Zhang", "Lipei Zhang", "Yanqi Cheng", "Zi Wang", "Fanwen Wang", "Haosen Zhang", "Yue Yang", "Yinzhe Wu", "Jiahao Huang", "Angelica I Aviles-Rivero", "Zhifan Gao", "Guang Yang", "Peter J. Lally"], "title": "From Coarse to Continuous: Progressive Refinement Implicit Neural Representation for Motion-Robust Anisotropic MRI Reconstruction", "comment": null, "summary": "In motion-robust magnetic resonance imaging (MRI), slice-to-volume\nreconstruction is critical for recovering anatomically consistent 3D brain\nvolumes from 2D slices, especially under accelerated acquisitions or patient\nmotion. However, this task remains challenging due to hierarchical structural\ndisruptions. It includes local detail loss from k-space undersampling, global\nstructural aliasing caused by motion, and volumetric anisotropy. Therefore, we\npropose a progressive refinement implicit neural representation (PR-INR)\nframework. Our PR-INR unifies motion correction, structural refinement, and\nvolumetric synthesis within a geometry-aware coordinate space. Specifically, a\nmotion-aware diffusion module is first employed to generate coarse volumetric\nreconstructions that suppress motion artifacts and preserve global anatomical\nstructures. Then, we introduce an implicit detail restoration module that\nperforms residual refinement by aligning spatial coordinates with visual\nfeatures. It corrects local structures and enhances boundary precision.\nFurther, a voxel continuous-aware representation module represents the image as\na continuous function over 3D coordinates. It enables accurate inter-slice\ncompletion and high-frequency detail recovery. We evaluate PR-INR on five\npublic MRI datasets under various motion conditions (3% and 5% displacement),\nundersampling rates (4x and 8x) and slice resolutions (scale = 5). Experimental\nresults demonstrate that PR-INR outperforms state-of-the-art methods in both\nquantitative reconstruction metrics and visual quality. It further shows\ngeneralization and robustness across diverse unseen domains."}
{"id": "2506.16957", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.16957", "abs": "https://arxiv.org/abs/2506.16957", "authors": ["Zisheng Wang", "Feng Li", "Hangbin Zhao", "Zihuan Mao", "Yaodong Zhang", "Qisheng Huang", "Bo Cao", "Mingming Cao", "Baolin He", "Qilin Hou"], "title": "Wi-Fi Sensing Tool Release: Gathering 802.11ax Channel State Information from a Commercial Wi-Fi Access Point", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Wi-Fi sensing has emerged as a powerful technology, leveraging channel state\ninformation (CSI) extracted from wireless data packets to enable diverse\napplications, ranging from human presence detection to gesture recognition and\nhealth monitoring. However, CSI extraction from commercial Wi-Fi access point\nlacks and out of date. This paper introduces ZTECSITool,a toolkit designed to\ncapture high-resolution CSI measurements from commercial Wi-Fi 6 (802.11ax)\naccess points, supporting bandwidths up to 160 MHz and 512 subcarriers.\nZTECSITool bridges a critical gap in Wi-Fi sensing research, facilitating the\ndevelopment of next-generation sensing systems. The toolkit includes customized\nfirmware and open-source software tools for configuring, collecting, and\nparsing CSI data, offering researchers a robust platform for advanced sensing\napplications. We detail the command protocols for CSI extraction, including\nband selection,STA filtering, and report configuration, and provide insights\ninto the data structure of the reported CSI. Additionally, we present a\nPython-based graphical interface for real-time CSI visualization and analysis"}
{"id": "2506.16213", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.16213", "abs": "https://arxiv.org/abs/2506.16213", "authors": ["Raghav Mehta", "Fabio De Sousa Ribeiro", "Tian Xia", "Melanie Roschewitz", "Ainkaran Santhirasekaram", "Dominic C. Marshall", "Ben Glocker"], "title": "CF-Seg: Counterfactuals meet Segmentation", "comment": "Accepted at MICCAI 2025", "summary": "Segmenting anatomical structures in medical images plays an important role in\nthe quantitative assessment of various diseases. However, accurate segmentation\nbecomes significantly more challenging in the presence of disease. Disease\npatterns can alter the appearance of surrounding healthy tissues, introduce\nambiguous boundaries, or even obscure critical anatomical structures. As such,\nsegmentation models trained on real-world datasets may struggle to provide good\nanatomical segmentation, leading to potential misdiagnosis. In this paper, we\ngenerate counterfactual (CF) images to simulate how the same anatomy would\nappear in the absence of disease without altering the underlying structure. We\nthen use these CF images to segment structures of interest, without requiring\nany changes to the underlying segmentation model. Our experiments on two\nreal-world clinical chest X-ray datasets show that the use of counterfactual\nimages improves anatomical segmentation, thereby aiding downstream clinical\ndecision-making."}
{"id": "2506.17010", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.17010", "abs": "https://arxiv.org/abs/2506.17010", "authors": ["Kuranage Roche Rayan Ranasinghe", "Bruno S. Chang", "Giuseppe Thadeu Freitas de Abreu"], "title": "Low-Complexity Receiver Design for Affine Filter Bank Modulation", "comment": "Submitted to an IEEE conference. arXiv admin note: substantial text\n  overlap with arXiv:2505.03589", "summary": "We propose a low-complexity receiver structure for the recently introduced\nAffine Filter Bank Modulation (AFBM) scheme, which is a novel waveform designed\nfor integrated sensing and communications (ISAC) systems operating in\ndoubly-dispersive (DD) channels. The proposed receiver structure is based on\nthe Gaussian Belief Propagation (GaBP) framework, making use of only\nelement-wise scalar operations to perform detection of the transmitted symbols.\nSimulation results demonstrate that AFBM in conjunction with GaBP outperforms\naffine frequency division multiplexing (AFDM) in terms of bit error rates\n(BERs) in DD channels, while achieving very low out-of-band emissions (OOBE) in\nhigh-mobility scenarios."}
{"id": "2506.16256", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.16256", "abs": "https://arxiv.org/abs/2506.16256", "authors": ["César Díaz-Parga", "Marta Nuñez-Garcia", "Maria J. Carreira", "Gabriel Bernardino", "Nicolás Vila-Blanco"], "title": "AGE-US: automated gestational age estimation based on fetal ultrasound images", "comment": "Accepted in Iberian Conference on Pattern Recognition and Image\n  Analysis (IbPRIA) 2025", "summary": "Being born small carries significant health risks, including increased\nneonatal mortality and a higher likelihood of future cardiac diseases. Accurate\nestimation of gestational age is critical for monitoring fetal growth, but\ntraditional methods, such as estimation based on the last menstrual period, are\nin some situations difficult to obtain. While ultrasound-based approaches offer\ngreater reliability, they rely on manual measurements that introduce\nvariability. This study presents an interpretable deep learning-based method\nfor automated gestational age calculation, leveraging a novel segmentation\narchitecture and distance maps to overcome dataset limitations and the scarcity\nof segmentation masks. Our approach achieves performance comparable to\nstate-of-the-art models while reducing complexity, making it particularly\nsuitable for resource-constrained settings and with limited annotated data.\nFurthermore, our results demonstrate that the use of distance maps is\nparticularly suitable for estimating femur endpoints."}
{"id": "2506.17108", "categories": ["eess.SP", "cs.IT", "math.IT", "stat.ML"], "pdf": "https://arxiv.org/pdf/2506.17108", "abs": "https://arxiv.org/abs/2506.17108", "authors": ["Levli Citron", "Kobi Cohen", "Qing Zhao"], "title": "Searching for a Hidden Markov Anomaly over Multiple Processes", "comment": "13 pages, 9 figures", "summary": "We address the problem of detecting an anomalous process among a large number\nof processes. At each time t, normal processes are in state zero (normal\nstate), while the abnormal process may be in either state zero (normal state)\nor state one (abnormal state), with the states being hidden. The transition\nbetween states for the abnormal process is governed by a Markov chain over\ntime. At each time step, observations can be drawn from a selected subset of\nprocesses. Each probed process generates an observation depending on its hidden\nstate, either a typical distribution under state zero or an abnormal\ndistribution under state one. The objective is to design a sequential search\nstrategy that minimizes the expected detection time, subject to an error\nprobability constraint. In contrast to prior works that assume i.i.d.\nobservations, we address a new setting where anomalies evolve according to a\nhidden Markov model. To this end, we propose a novel algorithm, dubbed Anomaly\nDetection under Hidden Markov model (ADHM), which dynamically adapts the\nprobing strategy based on accumulated statistical evidence and predictive\nbelief updates over hidden states. ADHM effectively leverages temporal\ncorrelations to focus sensing resources on the most informative processes. The\nalgorithm is supported by an asymptotic theoretical foundation, grounded in an\noracle analysis that characterizes the fundamental limits of detection under\nthe assumption of a known distribution of the hidden states. In addition, the\nalgorithm demonstrates strong empirical performance, consistently outperforming\nexisting methods in extensive simulations."}
{"id": "2506.16556", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.16556", "abs": "https://arxiv.org/abs/2506.16556", "authors": ["Salvatore Esposito", "Daniel Rebain", "Arno Onken", "Changjian Li", "Oisin Mac Aodha"], "title": "VesselSDF: Distance Field Priors for Vascular Network Reconstruction", "comment": null, "summary": "Accurate segmentation of vascular networks from sparse CT scan slices remains\na significant challenge in medical imaging, particularly due to the thin,\nbranching nature of vessels and the inherent sparsity between imaging planes.\nExisting deep learning approaches, based on binary voxel classification, often\nstruggle with structural continuity and geometric fidelity. To address this\nchallenge, we present VesselSDF, a novel framework that leverages signed\ndistance fields (SDFs) for robust vessel reconstruction. Our method\nreformulates vessel segmentation as a continuous SDF regression problem, where\neach point in the volume is represented by its signed distance to the nearest\nvessel surface. This continuous representation inherently captures the smooth,\ntubular geometry of blood vessels and their branching patterns. We obtain\naccurate vessel reconstructions while eliminating common SDF artifacts such as\nfloating segments, thanks to our adaptive Gaussian regularizer which ensures\nsmoothness in regions far from vessel surfaces while producing precise geometry\nnear the surface boundaries. Our experimental results demonstrate that\nVesselSDF significantly outperforms existing methods and preserves vessel\ngeometry and connectivity, enabling more reliable vascular analysis in clinical\nsettings."}
{"id": "2506.17189", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.17189", "abs": "https://arxiv.org/abs/2506.17189", "authors": ["Muhammad Umer", "Muhammad Ahmed Mohsin", "Aamir Mahmood", "Haejoon Jung", "Haris Pervaiz", "Mikael Gidlund", "Syed Ali Hassan"], "title": "On Energy-Efficient Passive Beamforming Design of RIS-Assisted CoMP-NOMA Networks", "comment": "Accepted and presented at IEEE ICC'25 [SAC-12 Track]. arXiv admin\n  note: substantial text overlap with arXiv:2504.00975", "summary": "This paper investigates the synergistic potential of reconfigurable\nintelligent surfaces (RIS) and non-orthogonal multiple access (NOMA) to enhance\nthe energy efficiency and performance of next-generation wireless networks. We\ndelve into the design of energy-efficient passive beamforming (PBF) strategies\nwithin RIS-assisted coordinated multi-point (CoMP)-NOMA networks. Two distinct\nRIS configurations, namely, enhancement-only PBF (EO) and enhancement &\ncancellation PBF (EC), are proposed and analyzed. Our findings demonstrate that\nRIS-assisted CoMP-NOMA networks offer significant efficiency gains compared to\ntraditional CoMP-NOMA systems. Furthermore, we formulate a PBF design problem\nto optimize the RIS phase shifts for maximizing energy efficiency. Our results\nreveal that the optimal PBF design is contingent upon several factors,\nincluding the number of cooperating base stations (BSs), the number of RIS\nelements deployed, and the RIS configuration. This study underscores the\npotential of RIS-assisted CoMP-NOMA networks as a promising solution for\nachieving superior energy efficiency and overall performance in future wireless\nnetworks."}
{"id": "2506.16572", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.16572", "abs": "https://arxiv.org/abs/2506.16572", "authors": ["Chanung Park", "Joo Chan Lee", "Jong Hwan Ko"], "title": "DiffO: Single-step Diffusion for Image Compression at Ultra-Low Bitrates", "comment": null, "summary": "Although image compression is fundamental to visual data processing and has\ninspired numerous standard and learned codecs, these methods still suffer\nsevere quality degradation at extremely low bits per pixel. While recent\ndiffusion based models provided enhanced generative performance at low\nbitrates, they still yields limited perceptual quality and prohibitive decoding\nlatency due to multiple denoising steps. In this paper, we propose the first\nsingle step diffusion model for image compression (DiffO) that delivers high\nperceptual quality and fast decoding at ultra low bitrates. DiffO achieves\nthese goals by coupling two key innovations: (i) VQ Residual training, which\nfactorizes a structural base code and a learned residual in latent space,\ncapturing both global geometry and high frequency details; and (ii) rate\nadaptive noise modulation, which tunes denoising strength on the fly to match\nthe desired bitrate. Extensive experiments show that DiffO surpasses state of\nthe art compression performance while improving decoding speed by about 50x\ncompared to prior diffusion-based methods, greatly improving the practicality\nof generative codecs. The code will be available at\nhttps://github.com/Freemasti/DiffO."}
{"id": "2506.17200", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.17200", "abs": "https://arxiv.org/abs/2506.17200", "authors": ["Qingqing Wu", "Yanze Zhu", "Qiaoyan Peng", "Wanming Hao", "Yanzhao Hou", "Fengyuan Yang", "Wencai Yan", "Guoning Wang", "Wen Chen", "Chi Qiu"], "title": "Intelligent Reflecting Surfaces for THz Communications: Fundamentals, Key Solutions, and System Prototyping", "comment": null, "summary": "Intelligent reflecting surfaces (IRSs) have emerged as a cost-effective\ntechnology for terahertz (THz) communications by enabling programmable control\nof the wireless environment. This paper provides a comprehensive overview of\nIRSs-aided THz communications, covering hardware designs, advanced signal\nprocessing techniques, and practical deployment strategies. It first examines\nkey THz reconfigurable metasurface architectures, including electronic,\noptical, phase-change material, and micro-electromechanical systems\n(MEMS)-based implementations, highlighting their reconfiguration mechanisms and\nchallenges. Then, fundamental effects including near field and beam squint in\nwideband THz systems are analyzed, along with their impacts on system\nperformance. The paper further explores conventional and beam-squint-assisted\nchannel estimation methods, innovative beam management strategies, and\ndeployment considerations across large- and small-scale scenarios. Practical\nexperiments at 220 gigahertz (GHz) validate the effectiveness of IRS in\nimproving signal strength and communication reliability for both single-user\nand multi-user setups."}
{"id": "2506.16592", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.16592", "abs": "https://arxiv.org/abs/2506.16592", "authors": ["Muhammad Azeem Aslam", "Asim Naveed", "Nisar Ahmed"], "title": "Hybrid Attention Network for Accurate Breast Tumor Segmentation in Ultrasound Images", "comment": null, "summary": "Breast ultrasound imaging is a valuable tool for early breast cancer\ndetection, but automated tumor segmentation is challenging due to inherent\nnoise, variations in scale of lesions, and fuzzy boundaries. To address these\nchallenges, we propose a novel hybrid attention-based network for lesion\nsegmentation. Our proposed architecture integrates a pre-trained DenseNet121 in\nthe encoder part for robust feature extraction with a multi-branch\nattention-enhanced decoder tailored for breast ultrasound images. The\nbottleneck incorporates Global Spatial Attention (GSA), Position Encoding (PE),\nand Scaled Dot-Product Attention (SDPA) to learn global context, spatial\nrelationships, and relative positional features. The Spatial Feature\nEnhancement Block (SFEB) is embedded at skip connections to refine and enhance\nspatial features, enabling the network to focus more effectively on tumor\nregions. A hybrid loss function combining Binary Cross-Entropy (BCE) and\nJaccard Index loss optimizes both pixel-level accuracy and region-level overlap\nmetrics, enhancing robustness to class imbalance and irregular tumor shapes.\nExperiments on public datasets demonstrate that our method outperforms existing\napproaches, highlighting its potential to assist radiologists in early and\naccurate breast cancer diagnosis."}
{"id": "2506.17205", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.17205", "abs": "https://arxiv.org/abs/2506.17205", "authors": ["Jennifer Bondarchuk", "Anthony Trezza", "Donald J. Bucci Jr"], "title": "Efficient Implementation of Multi-sensor Adaptive Birth Samplers for Labeled Random Finite Set Tracking", "comment": "Accepted to the 2024 Proc. IEEE 27th Int. Conf. Inf. Fusion. arXiv\n  admin note: text overlap with arXiv:2307.06401", "summary": "Adaptive track initiation remains a crucial component of many modern\nmulti-target tracking systems. For labeled random finite sets multi-object\nfilters, prior work has been established to construct a labeled multi-object\nbirth density using measurements from multiple sensors. A naive construction of\nthis adaptive birth set density results in an exponential number of newborn\ncomponents in the number of sensors. A truncation procedure was provided that\nleverages a Gibbs sampler to truncate the birth density, reducing the\ncomplexity to quadratic in the number of sensors. However, only a limited\ndiscussion has been provided on additional algorithmic techniques that can be\nemployed to substantially reduce the complexity in practical tracking\napplications. In this paper, we propose five efficiency enhancements for the\nlabeled random finite sets multi-sensor adaptive birth procedure. Simulation\nresults are provided to demonstrate their computational benefits and show that\nthey result in a negligible change to the multi-target tracking performance."}
{"id": "2506.16631", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.16631", "abs": "https://arxiv.org/abs/2506.16631", "authors": ["Saghir Alfasly", "Ghazal Alabtah", "H. R. Tizhoosh"], "title": "Overfitting in Histopathology Model Training: The Need for Customized Architectures", "comment": null, "summary": "This study investigates the critical problem of overfitting in deep learning\nmodels applied to histopathology image analysis. We show that simply adopting\nand fine-tuning large-scale models designed for natural image analysis often\nleads to suboptimal performance and significant overfitting when applied to\nhistopathology tasks. Through extensive experiments with various model\narchitectures, including ResNet variants and Vision Transformers (ViT), we show\nthat increasing model capacity does not necessarily improve performance on\nhistopathology datasets. Our findings emphasize the need for customized\narchitectures specifically designed for histopathology image analysis,\nparticularly when working with limited datasets. Using Oesophageal\nAdenocarcinomas public dataset, we demonstrate that simpler, domain-specific\narchitectures can achieve comparable or better performance while minimizing\noverfitting."}
{"id": "2506.16733", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.16733", "abs": "https://arxiv.org/abs/2506.16733", "authors": ["Fang Chen", "Weifeng Zhang", "Xingyu Ai", "BingXuan Li", "An Li", "Qiegen Liu"], "title": "A Prior-Guided Joint Diffusion Model in Projection Domain for PET Tracer Conversion", "comment": null, "summary": "Positron emission tomography (PET) is widely used to assess metabolic\nactivity, but its application is limited by the availability of radiotracers.\n18F-labeled fluorodeoxyglucose (18F-FDG) is the most commonly used tracer but\nshows limited effectiveness for certain tumors. In contrast,\n6-18F-fluoro-3,4-dihydroxy-L-phenylalanine (18F-DOPA) offers higher specificity\nfor neuroendocrine tumors and neurological disorders. However, its complex\nsynthesis and limitations in transportation and clinical use hinder widespread\nadoption. During PET imaging, the sinogram represents a form of raw data\nacquired by the scanner. Therefore, modeling in projection domain enables more\ndirect utilization of the original information, potentially reducing the\naccumulation of errors introduced during the image reconstruction process.\nInspired by these factors, this study proposes a prior-guided joint diffusion\nmodel (PJDM) for transforming 18F-FDG PET images into 18F-DOPA PET images in\nprojection domain. Specifically, a coarse estimation model and a prior\nrefinement model are trained independently. During inference, an initial\nsynthetic 18F-DOPA PET sinogram is generated using a higher-order hybrid\nsampler. This sinogram is then degraded and serves as an additional condition\nto guide the iterative refinement process using learned prior. Experimental\nresults demonstrated that PJDM effectively improved both sinogram quality and\nsynthetic outcomes. The code is available at: https://github.com/yqx7150/PJDM."}
{"id": "2506.16803", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.16803", "abs": "https://arxiv.org/abs/2506.16803", "authors": ["Ning Chu", "Siya Zheng", "Shanqing Zhang", "Li Li", "Caifang Cai", "Ali Mohammad-Djafari", "Feng Zhao", "Yuanbo Song"], "title": "Temperature calibration of surface emissivities with an improved thermal image enhancement network", "comment": null, "summary": "Infrared thermography faces persistent challenges in temperature accuracy due\nto material emissivity variations, where existing methods often neglect the\njoint optimization of radiometric calibration and image degradation. This study\nintroduces a physically guided neural framework that unifies temperature\ncorrection and image enhancement through a symmetric skip-CNN architecture and\nan emissivity-aware attention module. The pre-processing stage segments the\nROIs of the image and and initially corrected the firing rate. A novel\ndual-constrained loss function strengthens the statistical consistency between\nthe target and reference regions through mean-variance alignment and histogram\nmatching based on Kullback-Leibler dispersion. The method works by dynamically\nfusing thermal radiation features and spatial context, and the model suppresses\nemissivity artifacts while recovering structural details. After validating the\nindustrial blower system under different conditions, the improved network\nrealizes the dynamic fusion of thermal radiation characteristics and spatial\nbackground, with accurate calibration results in various industrial conditions."}
{"id": "2506.16934", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.16934", "abs": "https://arxiv.org/abs/2506.16934", "authors": ["Bin Huang", "Feihong Xu", "Xinchong Shi", "Shan Huang", "Binxuan Li", "Fei Li", "Qiegen Liu"], "title": "PET Tracer Separation Using Conditional Diffusion Transformer with Multi-latent Space Learning", "comment": null, "summary": "In clinical practice, single-radiotracer positron emission tomography (PET)\nis commonly used for imaging. Although multi-tracer PET imaging can provide\nsupplementary information of radiotracers that are sensitive to physiological\nfunction changes, enabling a more comprehensive characterization of\nphysiological and pathological states, the gamma-photon pairs generated by\npositron annihilation reactions of different tracers in PET imaging have the\nsame energy, making it difficult to distinguish the tracer signals. In this\nstudy, a multi-latent space guided texture conditional diffusion transformer\nmodel (MS-CDT) is proposed for PET tracer separation. To the best of our\nknowledge, this is the first attempt to use texture condition and multi-latent\nspace for tracer separation in PET imaging. The proposed model integrates\ndiffusion and transformer architectures into a unified optimization framework,\nwith the novel addition of texture masks as conditional inputs to enhance image\ndetails. By leveraging multi-latent space prior derived from different tracers,\nthe model captures multi-level feature representations, aiming to balance\ncomputational efficiency and detail preservation. The texture masks, serving as\nconditional guidance, help the model focus on salient structural patterns,\nthereby improving the extraction and utilization of fine-grained image\ntextures. When combined with the diffusion transformer backbone, this\nconditioning mechanism contributes to more accurate and robust tracer\nseparation. To evaluate its effectiveness, the proposed MS-CDT is compared with\nseveral advanced methods on two types of 3D PET datasets: brain and chest\nscans. Experimental results indicate that MS-CDT achieved competitive\nperformance in terms of image quality and preservation of clinically relevant\ninformation. Code is available at: https://github.com/yqx7150/MS-CDT."}
{"id": "2506.17133", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17133", "abs": "https://arxiv.org/abs/2506.17133", "authors": ["Josué Martínez-Martínez", "Olivia Brown", "Mostafa Karami", "Sheida Nabavi"], "title": "Robust Training with Data Augmentation for Medical Imaging Classification", "comment": null, "summary": "Deep neural networks are increasingly being used to detect and diagnose\nmedical conditions using medical imaging. Despite their utility, these models\nare highly vulnerable to adversarial attacks and distribution shifts, which can\naffect diagnostic reliability and undermine trust among healthcare\nprofessionals. In this study, we propose a robust training algorithm with data\naugmentation (RTDA) to mitigate these vulnerabilities in medical image\nclassification. We benchmark classifier robustness against adversarial\nperturbations and natural variations of RTDA and six competing baseline\ntechniques, including adversarial training and data augmentation approaches in\nisolation and combination, using experimental data sets with three different\nimaging technologies (mammograms, X-rays, and ultrasound). We demonstrate that\nRTDA achieves superior robustness against adversarial attacks and improved\ngeneralization performance in the presence of distribution shift in each image\nclassification task while maintaining high clean accuracy."}
{"id": "2506.17140", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.17140", "abs": "https://arxiv.org/abs/2506.17140", "authors": ["David Jacob Drexlin", "Jonas Dippel", "Julius Hense", "Niklas Prenißl", "Grégoire Montavon", "Frederick Klauschen", "Klaus-Robert Müller"], "title": "MeDi: Metadata-Guided Diffusion Models for Mitigating Biases in Tumor Classification", "comment": null, "summary": "Deep learning models have made significant advances in histological\nprediction tasks in recent years. However, for adaptation in clinical practice,\ntheir lack of robustness to varying conditions such as staining, scanner,\nhospital, and demographics is still a limiting factor: if trained on\noverrepresented subpopulations, models regularly struggle with less frequent\npatterns, leading to shortcut learning and biased predictions. Large-scale\nfoundation models have not fully eliminated this issue. Therefore, we propose a\nnovel approach explicitly modeling such metadata into a Metadata-guided\ngenerative Diffusion model framework (MeDi). MeDi allows for a targeted\naugmentation of underrepresented subpopulations with synthetic data, which\nbalances limited training data and mitigates biases in downstream models. We\nexperimentally show that MeDi generates high-quality histopathology images for\nunseen subpopulations in TCGA, boosts the overall fidelity of the generated\nimages, and enables improvements in performance for downstream classifiers on\ndatasets with subpopulation shifts. Our work is a proof-of-concept towards\nbetter mitigating data biases with generative models."}
{"id": "2506.17165", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.17165", "abs": "https://arxiv.org/abs/2506.17165", "authors": ["Mahin Montasir Afif", "Abdullah Al Noman", "K. M. Tahsin Kabir", "Md. Mortuza Ahmmed", "Md. Mostafizur Rahman", "Mufti Mahmud", "Md. Ashraful Babu"], "title": "Proportional Sensitivity in Generative Adversarial Network (GAN)-Augmented Brain Tumor Classification Using Convolutional Neural Network", "comment": "This papaer has been submitted to The 18th International Conference\n  on Brain Informatics (BI'25), Italy", "summary": "Generative Adversarial Networks (GAN) have shown potential in expanding\nlimited medical imaging datasets. This study explores how different ratios of\nGAN-generated and real brain tumor MRI images impact the performance of a CNN\nin classifying healthy vs. tumorous scans. A DCGAN was used to create synthetic\nimages which were mixed with real ones at various ratios to train a custom CNN.\nThe CNN was then evaluated on a separate real-world test set. Our results\nindicate that the model maintains high sensitivity and precision in tumor\nclassification, even when trained predominantly on synthetic data. When only a\nsmall portion of GAN data was added, such as 900 real images and 100 GAN\nimages, the model achieved excellent performance, with test accuracy reaching\n95.2%, and precision, recall, and F1-score all exceeding 95%. However, as the\nproportion of GAN images increased further, performance gradually declined.\nThis study suggests that while GANs are useful for augmenting limited datasets\nespecially when real data is scarce, too much synthetic data can introduce\nartifacts that affect the model's ability to generalize to real world cases."}
{"id": "2506.15843", "categories": ["eess.SP", "eess.IV"], "pdf": "https://arxiv.org/pdf/2506.15843", "abs": "https://arxiv.org/abs/2506.15843", "authors": ["Ninghe Liu", "Yu Xi Huang", "Simon Mahler", "Changhuei Yang"], "title": "Optimized cerebral blood flow measurement in speckle contrast optical spectroscopy via refinement of noise calibration", "comment": "5 pages, 3 figures", "summary": "Speckle contrast optical spectroscopy (SCOS) offers a non-invasive and\ncost-effective method for monitoring cerebral blood flow (CBF). However,\nextracting accurate CBF from SCOS necessitates precise noise pre-calibration.\nErrors from this can degrade CBF measurement fidelity, particularly when the\noverall signal level is low. Such errors primarily stem from residual speckle\ncontrast associated with camera and shot noise, whose fluctuations exhibit a\ntemporal structure that mimics cerebral blood volume (CBV) waveforms. We\npropose an optimization-based framework that performs an adaptive refinement of\nnoise calibration, mitigating the CBV-mimicking artifacts by reducing the\nCBF-CBV waveform correlation. Validated on 10 human subjects, our approach\neffectively lowered the signal threshold for reliable CBF signal from 97 to 26\nelectrons per pixel for a 1920x1200 pixels SCOS system. This improvement\nenables more accurate and robust CBF measurements in SCOS, especially at large\nsource-detector (SD) distances for deeper tissue interrogation."}
{"id": "2506.15843", "categories": ["eess.SP", "eess.IV"], "pdf": "https://arxiv.org/pdf/2506.15843", "abs": "https://arxiv.org/abs/2506.15843", "authors": ["Ninghe Liu", "Yu Xi Huang", "Simon Mahler", "Changhuei Yang"], "title": "Optimized cerebral blood flow measurement in speckle contrast optical spectroscopy via refinement of noise calibration", "comment": "5 pages, 3 figures", "summary": "Speckle contrast optical spectroscopy (SCOS) offers a non-invasive and\ncost-effective method for monitoring cerebral blood flow (CBF). However,\nextracting accurate CBF from SCOS necessitates precise noise pre-calibration.\nErrors from this can degrade CBF measurement fidelity, particularly when the\noverall signal level is low. Such errors primarily stem from residual speckle\ncontrast associated with camera and shot noise, whose fluctuations exhibit a\ntemporal structure that mimics cerebral blood volume (CBV) waveforms. We\npropose an optimization-based framework that performs an adaptive refinement of\nnoise calibration, mitigating the CBV-mimicking artifacts by reducing the\nCBF-CBV waveform correlation. Validated on 10 human subjects, our approach\neffectively lowered the signal threshold for reliable CBF signal from 97 to 26\nelectrons per pixel for a 1920x1200 pixels SCOS system. This improvement\nenables more accurate and robust CBF measurements in SCOS, especially at large\nsource-detector (SD) distances for deeper tissue interrogation."}
{"id": "2506.15950", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.15950", "abs": "https://arxiv.org/abs/2506.15950", "authors": ["Saeed Razavikia", "Carlo Fischione"], "title": "On Designing Modulation for Over-the-Air Computation -- Part I: Noise-Aware Design", "comment": null, "summary": "Over-the-air computation (OAC) leverages the physical superposition property\nof wireless multiple access channels (MACs) to compute functions while\ncommunication occurs, enabling scalable and low-latency processing in\ndistributed networks. While analog OAC methods suffer from noise sensitivity\nand hardware constraints, existing digital approaches are often limited in\ndesign complexity, which may hinder scalability and fail to exploit spectral\nefficiency fully. This two-part paper revisits and extends the ChannelComp\nframework, a general methodology for computing arbitrary finite-valued\nfunctions using digital modulation. In Part I, we develop a novel constellation\ndesign approach that is aware of the noise distribution and formulates the\nencoder design as a max-min optimization problem using noise-tailored distance\nmetrics. Our design supports noise models, including Gaussian, Laplace, and\nheavy-tailed distributions. We further demonstrate that, for heavy-tailed\nnoise, the optimal ChannelComp setup coincides with the solution to the\ncorresponding max-min criterion for the channel noise with heavy-tailed\ndistributions. Numerical experiments confirm that our noise-aware design\nachieves a substantially lower mean-square error than leading digital OAC\nmethods over noisy MACs. In Part II, we consider a constellation design with a\nquantization-based sampling scheme to enhance modulation scalability and\ncomputational accuracy for large-scale digital OAC."}
{"id": "2506.15972", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.15972", "abs": "https://arxiv.org/abs/2506.15972", "authors": ["Haiyang Miao", "Jianhua Zhang", "Pan Tang", "Heng Wang", "Lei Tian", "Guangyi Liu"], "title": "Theoretical Analysis of Near-Field MIMO Channel Capacity and Mid-Band Experimental Validation", "comment": null, "summary": "With the increase of multiple-input-multiple-output (MIMO) array size and\ncarrier frequency, near-field MIMO communications will become crucial in 6G\nwireless networks. Due to the increase of MIMO near-field range, the research\nof near-field MIMO capacity has aroused wide interest. In this paper, we focus\non the theoretical analysis and empirical study of near-field MIMO capacity.\nFirst, the near-field channel model is characterized from the electromagnetic\ninformation perspective. Second, with the uniform planar array (UPA), the\nchannel capacity based on effective degree of freedom (EDoF) is analyzed\ntheoretically, and the closed-form analytical expressions are derived in\ndetail. Finally, based on the numerical verification of near-field channel\nmeasurement experiment at 13 GHz band, we reveal that the channel capacity of\nUPA-type MIMO systems decreases continuously with the communication distance\nincreasing. It can be observed that the near-field channel capacity gain is\nrelatively obvious when large-scale MIMO is adopted at both receiving and\ntransmitter ends, but the near-field channel capacity gain may be limited in\nthe actual communication system with the small antenna array at receiving end.\nThis work will give some reference to the near-field communication systems."}
{"id": "2506.15998", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.15998", "abs": "https://arxiv.org/abs/2506.15998", "authors": ["Chen Xu", "Xianghao Yu", "Fan Liu", "Shi Jin"], "title": "Exploiting Both Pilots and Data Payloads for Integrated Sensing and Communications", "comment": null, "summary": "Integrated sensing and communications (ISAC) is one of the key enabling\ntechnologies in future sixth-generation (6G) networks. Current ISAC systems\npredominantly rely on deterministic pilot signals within the signal frame to\naccomplish sensing tasks. However, these pilot signals typically occupy only a\nsmall portion, e.g., 0.15% to 25%, of the time-frequency resources. To enhance\nthe system utility, a promising solution is to repurpose the extensive random\ndata payload signals for sensing tasks. In this paper, we analyze the ISAC\nperformance of a multi-antenna system where both deterministic pilot and random\ndata symbols are employed for sensing tasks. By capitalizing on random matrix\ntheory (RMT), we first derive a semi-closed-form asymptotic expression of the\nergodic linear minimum mean square error (ELMMSE). Then, we formulate an ISAC\nprecoding optimization problem to minimize the ELMMSE, which is solved via a\nspecifically tailored successive convex approximation (SAC) algorithm. To\nprovide system insights, we further derive a closed-form expression for the\nasymptotic ELMMSE at high signal-to-noise ratios (SNRs). Our analysis reveals\nthat, compared with conventional sensing implemented by deterministic signals,\nthe sensing performance degradation induced by random signals is critically\ndetermined by the ratio of the transmit antenna size to the data symbol length.\nBased on this result, the ISAC precoding optimization problem at high SNRs is\ntransformed into a convex optimization problem that can be efficiently solved.\nSimulation results validate the accuracy of the derived asymptotic expressions\nof ELMMSE and the performance of the proposed precoding schemes. Particularly,\nby leveraging data payload signals for sensing tasks, the sensing error is\nreduced by up to 5.6 dB compared to conventional pilot-based sensing."}
{"id": "2506.15744", "categories": ["eess.IV", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.15744", "abs": "https://arxiv.org/abs/2506.15744", "authors": ["Seyed Mohsen Hosseini"], "title": "Pixel-wise Modulated Dice Loss for Medical Image Segmentation", "comment": null, "summary": "Class imbalance and the difficulty imbalance are the two types of data\nimbalance that affect the performance of neural networks in medical\nsegmentation tasks. In class imbalance the loss is dominated by the majority\nclasses and in difficulty imbalance the loss is dominated by easy to classify\npixels. This leads to an ineffective training. Dice loss, which is based on a\ngeometrical metric, is very effective in addressing the class imbalance\ncompared to the cross entropy (CE) loss, which is adopted directly from\nclassification tasks. To address the difficulty imbalance, the common approach\nis employing a re-weighted CE loss or a modified Dice loss to focus the\ntraining on difficult to classify areas. The existing modification methods are\ncomputationally costly and with limited success. In this study we propose a\nsimple modification to the Dice loss with minimal computational cost. With a\npixel level modulating term, we take advantage of the effectiveness of Dice\nloss in handling the class imbalance to also handle the difficulty imbalance.\nResults on three commonly used medical segmentation tasks show that the\nproposed Pixel-wise Modulated Dice loss (PM Dice loss) outperforms other\nmethods, which are designed to tackle the difficulty imbalance problem."}
{"id": "2506.16011", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.16011", "abs": "https://arxiv.org/abs/2506.16011", "authors": ["Rang Liu", "Ming Li", "Mehdi Zafari", "Bjorn Ottersten", "A. Lee Swindlehurst"], "title": "Multi-Domain Optimization Framework for ISAC: From Electromagnetic Shaping to Network Cooperation", "comment": "10 pages, 5 figures, submitted to IEEE", "summary": "Integrated sensing and communication (ISAC) has emerged as a key feature for\nsixth-generation (6G) networks, providing an opportunity to meet the dual\ndemands of communication and sensing. Existing ISAC research primarily focuses\non baseband optimization at individual access points, with limited attention to\nthe roles of electromagnetic (EM) shaping and network-wide coordination. The\nintricate interdependencies between these domains remain insufficiently\nexplored, leaving their full potential for enhancing ISAC performance largely\nuntapped. To bridge this gap, we consider multi-domain ISAC optimization\nintegrating EM shaping, baseband processing, and network cooperation strategies\nthat facilitate efficient resource management and system-level design. We\nanalyze the fundamental trade-offs between these domains and offer insights\ninto domain-specific and cross-domain strategies contributing to ISAC\nperformance and efficiency. We then conduct a case study demonstrating the\neffectiveness of joint multi-domain optimization. Finally, we discuss key\nchallenges and future research directions to connect theoretical advancements\nand practical ISAC deployments. This work paves the way for intelligent and\nscalable ISAC architectures, providing critical insights for their seamless\nintegration into next-generation wireless networks."}
{"id": "2506.15745", "categories": ["eess.IV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.15745", "abs": "https://arxiv.org/abs/2506.15745", "authors": ["Minsoo Kim", "Kyuhong Shim", "Jungwook Choi", "Simyung Chang"], "title": "InfiniPot-V: Memory-Constrained KV Cache Compression for Streaming Video Understanding", "comment": null, "summary": "Modern multimodal large language models (MLLMs) can reason over hour-long\nvideo, yet their key-value (KV) cache grows linearly with time--quickly\nexceeding the fixed memory of phones, AR glasses, and edge robots. Prior\ncompression schemes either assume the whole video and user query are available\noffline or must first build the full cache, so memory still scales with stream\nlength. InfiniPot-V is the first training-free, query-agnostic framework that\nenforces a hard, length-independent memory cap for streaming video\nunderstanding. During video encoding it monitors the cache and, once a user-set\nthreshold is reached, runs a lightweight compression pass that (i) removes\ntemporally redundant tokens via Temporal-axis Redundancy (TaR) metric and (ii)\nkeeps semantically significant tokens via Value-Norm (VaN) ranking. Across four\nopen-source MLLMs and four long-video and two streaming-video benchmarks,\nInfiniPot-V cuts peak GPU memory by up to 94%, sustains real-time generation,\nand matches or surpasses full-cache accuracy--even in multi-turn dialogues. By\ndissolving the KV cache bottleneck without retraining or query knowledge,\nInfiniPot-V closes the gap for on-device streaming video assistants."}
{"id": "2506.16070", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.16070", "abs": "https://arxiv.org/abs/2506.16070", "authors": ["Mathushaharan Rathakrishnan", "Samiru Gayan", "Rohit Singh", "Amandeep Kaur", "Hazer Inaltekin", "Sampath Edirisinghe", "H. Vincent Poor"], "title": "Towards AI-Driven RANs for 6G and Beyond: Architectural Advancements and Future Horizons", "comment": null, "summary": "It is envisioned that 6G networks will be supported by key architectural\nprinciples, including intelligence, decentralization, interoperability, and\ndigitalization. With the advances in artificial intelligence (AI) and machine\nlearning (ML), embedding intelligence into the foundation of wireless\ncommunication systems is recognized as essential for 6G and beyond. Existing\nradio access network (RAN) architectures struggle to meet the ever growing\ndemands for flexibility, automation, and adaptability required to build\nself-evolving and autonomous wireless networks. In this context, this paper\nexplores the transition towards AI-driven RAN (AI-RAN) by developing a novel\nAI-RAN framework whose performance is evaluated through a practical scenario\nfocused on intelligent orchestration and resource optimization. Besides, the\npaper reviews the evolution of RAN architectures and sheds light on key\nenablers of AI-RAN including digital twins (DTs), intelligent reflecting\nsurfaces (IRSs), large generative AI (GenAI) models, and blockchain (BC).\nFurthermore, it discusses the deployment challenges of AI-RAN, including\ntechnical and regulatory perspectives, and outlines future research directions\nincorporating technologies such as integrated sensing and communication (ISAC)\nand agentic AI."}
{"id": "2506.15748", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.15748", "abs": "https://arxiv.org/abs/2506.15748", "authors": ["Zhe Wang", "Yuhua Ru", "Aladine Chetouani", "Tina Shiang", "Fang Chen", "Fabian Bauer", "Liping Zhang", "Didier Hans", "Rachid Jennane", "William Ewing Palmer", "Mohamed Jarraya", "Yung Hsin Chen"], "title": "Diffusion-based Counterfactual Augmentation: Towards Robust and Interpretable Knee Osteoarthritis Grading", "comment": null, "summary": "Automated grading of Knee Osteoarthritis (KOA) from radiographs is challenged\nby significant inter-observer variability and the limited robustness of deep\nlearning models, particularly near critical decision boundaries. To address\nthese limitations, this paper proposes a novel framework, Diffusion-based\nCounterfactual Augmentation (DCA), which enhances model robustness and\ninterpretability by generating targeted counterfactual examples. The method\nnavigates the latent space of a diffusion model using a Stochastic Differential\nEquation (SDE), governed by balancing a classifier-informed boundary drive with\na manifold constraint. The resulting counterfactuals are then used within a\nself-corrective learning strategy to improve the classifier by focusing on its\nspecific areas of uncertainty. Extensive experiments on the public\nOsteoarthritis Initiative (OAI) and Multicenter Osteoarthritis Study (MOST)\ndatasets demonstrate that this approach significantly improves classification\naccuracy across multiple model architectures. Furthermore, the method provides\ninterpretability by visualizing minimal pathological changes and revealing that\nthe learned latent space topology aligns with clinical knowledge of KOA\nprogression. The DCA framework effectively converts model uncertainty into a\nrobust training signal, offering a promising pathway to developing more\naccurate and trustworthy automated diagnostic systems. Our code is available at\nhttps://github.com/ZWang78/DCA."}
{"id": "2506.16184", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.16184", "abs": "https://arxiv.org/abs/2506.16184", "authors": ["Shan Shan", "Chongjun Ouyang", "Yong Li", "Yuanwei Liu"], "title": "Multigroup Multicast Design for Pinching-Antenna Systems: Waveguide-Division or Waveguide-Multiplexing?", "comment": null, "summary": "This article addresses the design of multigroup multicast communications in\nthe pinching-antenna system (PASS). A PASS-enabled multigroup transmission\nframework is proposed to maximize multicast rates under a couple of\ntransmission architectures: waveguide-division (WD) and waveguide-multiplexing\n(WM). 1) For WD, an element-wise sequential optimization strategy is proposed\nfor pinching beamforming, i.e., optimizing the activated positions of pinching\nantennas along dielectric waveguides. Meanwhile, a log-sum-exp projected\ngradient descent algorithm is proposed for transmit power allocation across\nwaveguides. 2) For WM, a majorization-minimization (MM)-based framework is\nproposed to tackle the problem's non-smoothness and non-convexity. On this\nbasis, a low-complexity element-wise sequential optimization method is\ndeveloped for pinching beamforming using the MM surrogate objective.\nFurthermore, the optimal transmit beamformer structure is derived from the MM\nsurrogate objective using the Lagrange duality, with an efficient transmit\nbeamforming algorithm proposed using projected adaptive gradient descent.\nNumerical results demonstrate that: i) both WD and WM architectures in PASS\nachieve significant multicast rate improvements over conventional MIMO\ntechniques, especially for systems with large service areas; ii) WM is more\nrobust than WD in dense deployments, while WD excels when user groups are\nspatially separated."}
{"id": "2506.15750", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2506.15750", "abs": "https://arxiv.org/abs/2506.15750", "authors": ["Sanuwani Dayarathna", "Himashi Peiris", "Kh Tohidul Islam", "Tien-Tsin Wong", "Zhaolin Chen"], "title": "D2Diff : A Dual Domain Diffusion Model for Accurate Multi-Contrast MRI Synthesis", "comment": null, "summary": "Multi contrast MRI synthesis is inherently challenging due to the complex and\nnonlinear relationships among different contrasts. Each MRI contrast highlights\nunique tissue properties, but their complementary information is difficult to\nexploit due to variations in intensity distributions and contrast specific\ntextures. Existing methods for multi contrast MRI synthesis primarily utilize\nspatial domain features, which capture localized anatomical structures but\nstruggle to model global intensity variations and distributed patterns.\nConversely, frequency domain features provide structured inter contrast\ncorrelations but lack spatial precision, limiting their ability to retain finer\ndetails. To address this, we propose a dual domain learning framework that\nintegrates spatial and frequency domain information across multiple MRI\ncontrasts for enhanced synthesis. Our method employs two mutually trained\ndenoising networks, one conditioned on spatial domain and the other on\nfrequency domain contrast features through a shared critic network.\nAdditionally, an uncertainty driven mask loss directs the models focus toward\nmore critical regions, further improving synthesis accuracy. Extensive\nexperiments show that our method outperforms SOTA baselines, and the downstream\nsegmentation performance highlights the diagnostic value of the synthetic\nresults."}
{"id": "2506.16191", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.16191", "abs": "https://arxiv.org/abs/2506.16191", "authors": ["Hyeonho Noh", "Hyeonsu Lyu", "Moe Z. Win", "Hyun Jong Yang"], "title": "DCFNet: Doppler Correction Filter Network for Integrated Sensing and Communication in Multi-User MIMO-OFDM Systems", "comment": null, "summary": "Integrated sensing and communication (ISAC) is a headline feature for the\nforthcoming IMT-2030 and 6G releases, yet a concrete solution that fits within\nthe established orthogonal frequency division multiplexing (OFDM) family\nremains open. Specifically, Doppler-induced inter-carrier interference (ICI)\ndestroys sub-carrier orthogonality of OFDM sensing signals, blurring\nrange-velocity maps and severely degrading sensing accuracy. Building on\nmulti-user multi-input-multi-output (MIMO) OFDM systems, this paper proposes\nDoppler-Correction Filter Network (DCFNet), an AI-native ISAC model that\ndelivers fine range-velocity resolution at minimal complexity without altering\nthe legacy frame structure. A bank of DCFs first shifts dominant ICI energy\naway from critical Doppler bins; a compact deep learning network then\nsuppresses the ICI. To further enhance the range and velocity resolutions, we\npropose DCFNet with local refinement (DCFNet-LR), which applies a generalized\nlikelihood ratio test (GLRT) to refine target estimates of DCFNet to sub-cell\naccuracy. Simulation results show that DCFNet-LR runs $143\\times$ faster than\nmaximum likelihood search and achieves significantly superior performance,\nreducing the range RMSE by up to $2.7 \\times 10^{-4}$ times and the velocity\nRMSE by $6.7 \\times 10^{-4}$ times compared to conventional detection methods."}
{"id": "2506.15762", "categories": ["eess.IV", "cs.LG", "physics.med-ph"], "pdf": "https://arxiv.org/pdf/2506.15762", "abs": "https://arxiv.org/abs/2506.15762", "authors": ["Tom Hendriks", "Gerrit Arends", "Edwin Versteeg", "Anna Vilanova", "Maxime Chamberland", "Chantal M. W. Tax"], "title": "Implicit neural representations for accurate estimation of the standard model of white matter", "comment": "27 pages, 12 figures", "summary": "Diffusion magnetic resonance imaging (dMRI) enables non-invasive\ninvestigation of tissue microstructure. The Standard Model (SM) of white matter\naims to disentangle dMRI signal contributions from intra- and extra-axonal\nwater compartments. However, due to the model its high-dimensional nature,\nextensive acquisition protocols with multiple b-values and diffusion tensor\nshapes are typically required to mitigate parameter degeneracies. Even then,\naccurate estimation remains challenging due to noise. This work introduces a\nnovel estimation framework based on implicit neural representations (INRs),\nwhich incorporate spatial regularization through the sinusoidal encoding of the\ninput coordinates. The INR method is evaluated on both synthetic and in vivo\ndatasets and compared to parameter estimates using cubic polynomials,\nsupervised neural networks, and nonlinear least squares. Results demonstrate\nsuperior accuracy of the INR method in estimating SM parameters, particularly\nin low signal-to-noise conditions. Additionally, spatial upsampling of the INR\ncan represent the underlying dataset anatomically plausibly in a continuous\nway, which is unattainable with linear or cubic interpolation. The INR is fully\nunsupervised, eliminating the need for labeled training data. It achieves fast\ninference ($\\sim$6 minutes), is robust to both Gaussian and Rician noise,\nsupports joint estimation of SM kernel parameters and the fiber orientation\ndistribution function with spherical harmonics orders up to at least 8 and\nnon-negativity constraints, and accommodates spatially varying acquisition\nprotocols caused by magnetic gradient non-uniformities. The combination of\nthese properties along with the possibility to easily adapt the framework to\nother dMRI models, positions INRs as a potentially important tool for analyzing\nand interpreting diffusion MRI data."}
{"id": "2506.16198", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.16198", "abs": "https://arxiv.org/abs/2506.16198", "authors": ["Haofan Dong", "Ozgur B. Akan"], "title": "MASC: Integrated Sensing and Communications for the Martian Internet of Space", "comment": "11 pages, 9 figures, journal", "summary": "Mars exploration missions increasingly demand reliable communication systems,\nyet harsh environmental conditions -- particularly frequent dust storms,\nextreme Doppler effects, and stringent resource constraints -- pose\nunprecedented challenges to conventional communication approaches. This paper\npresents the Martian Adaptive Sensing and Communication (MASC) system\nspecifically designed for the Martian environment. MASC establishes a\nphysically interpretable channel model and develops three key components:\nenvironment-aware hybrid precoding, adaptive parameter mapping, and robust\ncommunication precoding. Simulation results demonstrate that MASC maintains 45\npercent sensing coverage under severe dust conditions compared to only 5\npercent with conventional methods, provides up to 2.5 dB\nsignal-to-interference-plus-noise ratio (SINR) improvement at 50 percent\nchannel state information (CSI) uncertainty, and yields 80 percent higher\ncapacity in moderate dust storms. Using an epsilon-constraint multi-objective\noptimization approach, we enable mission planners to select operational modes\nranging from communication-priority (0.33 bps/Hz capacity, 28 percent sensing\ncoverage) to sensing-priority (90 percent coverage with minimal capacity),\noffering a versatile framework that balances environmental awareness with\nhyper-reliable data transmission. This work provides a validated blueprint for\nintegrated sensing and communication (ISAC) in non-terrestrial networks (NTN),\na key enabler for achieving ubiquitous connectivity in the 6G era."}
{"id": "2506.15835", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.15835", "abs": "https://arxiv.org/abs/2506.15835", "authors": ["Mingyuan Luo", "Xin Yang", "Zhongnuo Yan", "Yan Cao", "Yuanji Zhang", "Xindi Hu", "Jin Wang", "Haoxuan Ding", "Wei Han", "Litao Sun", "Dong Ni"], "title": "MoNetV2: Enhanced Motion Network for Freehand 3D Ultrasound Reconstruction", "comment": null, "summary": "Three-dimensional (3D) ultrasound (US) aims to provide sonographers with the\nspatial relationships of anatomical structures, playing a crucial role in\nclinical diagnosis. Recently, deep-learning-based freehand 3D US has made\nsignificant advancements. It reconstructs volumes by estimating transformations\nbetween images without external tracking. However, image-only reconstruction\nposes difficulties in reducing cumulative drift and further improving\nreconstruction accuracy, particularly in scenarios involving complex motion\ntrajectories. In this context, we propose an enhanced motion network (MoNetV2)\nto enhance the accuracy and generalizability of reconstruction under diverse\nscanning velocities and tactics. First, we propose a sensor-based temporal and\nmulti-branch structure that fuses image and motion information from a velocity\nperspective to improve image-only reconstruction accuracy. Second, we devise an\nonline multi-level consistency constraint that exploits the inherent\nconsistency of scans to handle various scanning velocities and tactics. This\nconstraint exploits both scan-level velocity consistency, path-level appearance\nconsistency, and patch-level motion consistency to supervise inter-frame\ntransformation estimation. Third, we distill an online multi-modal\nself-supervised strategy that leverages the correlation between network\nestimation and motion information to further reduce cumulative errors.\nExtensive experiments clearly demonstrate that MoNetV2 surpasses existing\nmethods in both reconstruction quality and generalizability performance across\nthree large datasets."}
{"id": "2506.16208", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.16208", "abs": "https://arxiv.org/abs/2506.16208", "authors": ["Saeed Razavikia", "Carlo Fischione"], "title": "On Designing Modulation for Over-the-Air Computation -- Part II: Pyramid Sampling", "comment": null, "summary": "Over-the-air computation (OAC) harnesses the natural superposition of\nwireless signals to compute aggregate functions during transmission, thereby\ncollapsing communication and computation into a single step and significantly\nreducing latency and resource usage. In Part I, digital OAC was formulated as a\nnoise-aware constellation design problem by casting encoder design as a max-min\noptimization that aligns minimum Euclidean distances between superimposed\nconstellation points with squared differences of their corresponding function\noutputs.\n  In this paper, Part II, we address the prohibitive complexity and\nquantization challenges inherent in digital OAC constellation design for\nlarge-scale edge networks. More precisely, we introduce a pyramid sampling\nstrategy that judiciously selects a subset of superimposed constellation points\nto reduce the encoder design complexity from $\\mathcal{O}(q^K)$ to\n$\\mathcal{O}(q^{K-p+1})$, where $p\\in\\{1,\\dots, K\\}$ denotes the sampling\norder, $q$ levels of modulation, and $K$ denotes the number nodes in the\nnetwork. Under the assumption of symmetric aggregation, this approach enables a\ncontrolled trade-off between computational complexity and function computation\naccuracy. As a special case, we propose majority-based sampling ($p=K$), which\nconfines aggregation to only $q$ consensus points, inherently avoiding\ndestructive overlaps and permitting the use of standard digital modulations\n(e.g., QAM, PSK, ASK) without bespoke constellation designs. We also show via\nseveral simulations, across various aggregation functions, modulation levels,\nand noise levels, that moderate sampling orders attain acceptable performance\nwith orders-of-magnitude fewer constraints than exhaustive designs."}
{"id": "2506.15853", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.15853", "abs": "https://arxiv.org/abs/2506.15853", "authors": ["Amit Das", "Naofumi Tomita", "Kyle J. Syme", "Weijie Ma", "Paige O'Connor", "Kristin N. Corbett", "Bing Ren", "Xiaoying Liu", "Saeed Hassanpour"], "title": "Cross-Modality Learning for Predicting IHC Biomarkers from H&E-Stained Whole-Slide Images", "comment": null, "summary": "Hematoxylin and Eosin (H&E) staining is a cornerstone of pathological\nanalysis, offering reliable visualization of cellular morphology and tissue\narchitecture for cancer diagnosis, subtyping, and grading. Immunohistochemistry\n(IHC) staining provides molecular insights by detecting specific proteins\nwithin tissues, enhancing diagnostic accuracy, and improving treatment\nplanning. However, IHC staining is costly, time-consuming, and\nresource-intensive, requiring specialized expertise. To address these\nlimitations, this study proposes HistoStainAlign, a novel deep learning\nframework that predicts IHC staining patterns directly from H&E whole-slide\nimages (WSIs) by learning joint representations of morphological and molecular\nfeatures. The framework integrates paired H&E and IHC embeddings through a\ncontrastive training strategy, capturing complementary features across staining\nmodalities without patch-level annotations or tissue registration. The model\nwas evaluated on gastrointestinal and lung tissue WSIs with three commonly used\nIHC stains: P53, PD-L1, and Ki-67. HistoStainAlign achieved weighted F1 scores\nof 0.735 [95% Confidence Interval (CI): 0.670-0.799], 0.830 [95% CI:\n0.772-0.886], and 0.723 [95% CI: 0.607-0.836], respectively for these three IHC\nstains. Embedding analyses demonstrated the robustness of the contrastive\nalignment in capturing meaningful cross-stain relationships. Comparisons with a\nbaseline model further highlight the advantage of incorporating contrastive\nlearning for improved stain pattern prediction. This study demonstrates the\npotential of computational approaches to serve as a pre-screening tool, helping\nprioritize cases for IHC staining and improving workflow efficiency."}
{"id": "2506.16236", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.16236", "abs": "https://arxiv.org/abs/2506.16236", "authors": ["Romain Charbonnier", "Thierry Tenoux", "Yoann Corre"], "title": "Refining Ray-Tracing Accuracy and Efficiency in the Context of FRMCS Urban Railway Channel Predictions", "comment": "Presented at Workshop \"Emerging information and communication\n  technologies for smart railway Challenges and Opportunities for mmWave, THz,\n  ISAC, 5G and 6G\" in IEEE VTC-Spring 2025 Conference, June 2025, Oslo, Norway", "summary": "The upcoming roll-out of the new wireless communication standard for wireless\nrailway services, FRMCS, requires a thorough understanding of the system\nperformance in real-world conditions, since this will strongly influence the\ndeployment costs and the effectiveness of an infrastructure planned for\ndecades. The virtual testing of the equipment and network performance in\nrealistic simulated scenarios is key; its accuracy depends on the reliability\nof the predicted radio channel properties. In this article, the authors explain\nhow they are evolving a ray-tracing (RT) tool to apply it to the specific case\nof simulating the radio link between the FRMCS fixed infrastructure and an\nantenna placed on the roof of a train moving in an urban environment. First, a\ndynamic version of the RT tool is used to capture the rapid variations of all\nchannel metrics; a compromise is sought between computation time and accuracy.\nBesides, a hybridization of RT and physical optics (PO) allows the integration\nof objects near the track, such as catenary pylons, into the simulation. A case\nstudy shows that the scattering by metallic pylons brings a significant\ncontribution."}
{"id": "2506.16102", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.16102", "abs": "https://arxiv.org/abs/2506.16102", "authors": ["Ziran Zhu", "Tongda Xu", "Minye Huang", "Dailan He", "Xingtong Ge", "Xinjie Zhang", "Ling Li", "Yan Wang"], "title": "Fast Training-free Perceptual Image Compression", "comment": null, "summary": "Training-free perceptual image codec adopt pre-trained unconditional\ngenerative model during decoding to avoid training new conditional generative\nmodel. However, they heavily rely on diffusion inversion or sample\ncommunication, which take 1 min to intractable amount of time to decode a\nsingle image. In this paper, we propose a training-free algorithm that improves\nthe perceptual quality of any existing codec with theoretical guarantee. We\nfurther propose different implementations for optimal perceptual quality when\ndecoding time budget is $\\approx 0.1$s, $0.1-10$s and $\\ge 10$s. Our approach:\n1). improves the decoding time of training-free codec from 1 min to $0.1-10$s\nwith comparable perceptual quality. 2). can be applied to non-differentiable\ncodec such as VTM. 3). can be used to improve previous perceptual codecs, such\nas MS-ILLM. 4). can easily achieve perception-distortion trade-off.\nEmpirically, we show that our approach successfully improves the perceptual\nquality of ELIC, VTM and MS-ILLM with fast decoding. Our approach achieves\ncomparable FID to previous training-free codec with significantly less decoding\ntime. And our approach still outperforms previous conditional generative model\nbased codecs such as HiFiC and MS-ILLM in terms of FID. The source code is\nprovided in the supplementary material."}
{"id": "2506.16304", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.16304", "abs": "https://arxiv.org/abs/2506.16304", "authors": ["Junyi Jiang", "Wei Chen", "Xin Guo", "Shenghui Song", "Ying Jun", "Zhang", "Zhu Han", "Merouane Debbah", "Khaled B. Letaief"], "title": "A Tractable Approach to Massive Communication and Ubiquitous Connectivity in 6G Standardization", "comment": null, "summary": "The full-scale 6G standardization has attracted considerable recent\nattention, especially since the first 3GPP-wide 6G workshop held in March 2025.\nTo understand the practical and fundamental values of 6G and facilitate its\nstandardization, it is crucial to explore the theoretical limits of spectrum,\nenergy, and coverage efficiency considering practical hardware and signaling\nconstraints. In this paper, we present a mean-field-approximation-based\ninvestigation on two out of six use case scenarios defined by IMT-2030, namely,\nmassive communication and ubiquitous connectivity. Being aware of the\nlimitation in interference cancellation owing to constrained cost and hardware\ncomplexity, we investigate the spectrum reuse architecture in both usage\nscenarios. We propose a tractable spectrum reuse with low signaling overhead\nconsumed for channel estimation and channel state information (CSI) feedback.\nOur analysis indicates that the massive communication over cellular and\ndevice-to-device (D2D) networks can benefit from channel orthogonalization,\nwhile it is unnecessary to share the CSI of interfering links. Moreover,\ndeploying relays or movable base stations, e.g. unmanned aerial vehicle, yields\nsubstantial energy and spectrum gain for ubiquitous connectivity, despite\nintroducing interference. As such, the mean-field-optimization-based evaluation\nis expected to positively impact 6G and NextG standardization in 3GPP and other\nstandardization bodies."}
{"id": "2506.16116", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.16116", "abs": "https://arxiv.org/abs/2506.16116", "authors": ["Ignacio Hernández Montilla", "Alfonso Medela", "Paola Pasquali", "Andy Aguilar", "Taig Mac Carthy", "Gerardo Fernández", "Antonio Martorell", "Enrique Onieva"], "title": "Enhanced Dermatology Image Quality Assessment via Cross-Domain Training", "comment": "9 pages, 4 figures. This manuscript has been accepted to the 2025\n  12th International Conference on Bioinformatics Research and Applications\n  (ICBRA 2025). It will be published in International Conference Proceedings by\n  ACM, which will be archived in ACM Digital Library, indexed by Ei Compendex\n  and Scopus", "summary": "Teledermatology has become a widely accepted communication method in daily\nclinical practice, enabling remote care while showing strong agreement with\nin-person visits. Poor image quality remains an unsolved problem in\nteledermatology and is a major concern to practitioners, as bad-quality images\nreduce the usefulness of the remote consultation process. However, research on\nImage Quality Assessment (IQA) in dermatology is sparse, and does not leverage\nthe latest advances in non-dermatology IQA, such as using larger image\ndatabases with ratings from large groups of human observers. In this work, we\npropose cross-domain training of IQA models, combining dermatology and\nnon-dermatology IQA datasets. For this purpose, we created a novel dermatology\nIQA database, Legit.Health-DIQA-Artificial, using dermatology images from\nseveral sources and having them annotated by a group of human observers. We\ndemonstrate that cross-domain training yields optimal performance across\ndomains and overcomes one of the biggest limitations in dermatology IQA, which\nis the small scale of data, and leads to models trained on a larger pool of\nimage distortions, resulting in a better management of image quality in the\nteledermatology process."}
{"id": "2506.16767", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.16767", "abs": "https://arxiv.org/abs/2506.16767", "authors": ["Esa Ollila", "Xavier Mestre", "Elias Raninen"], "title": "Beamforming design for minimizing the signal power estimation error", "comment": null, "summary": "We study the properties of beamformers in their ability to either maintain or\nestimate the true signal power of the signal of interest (SOI). Our focus is\nparticularly on the Capon beamformer and the minimum mean squared error (MMSE)\nbeamformer. The Capon beamformer, also known as the minimum power\ndistortionless response (MPDR) or the minimum variance distortionless response\n(MVDR) beamformer, is a widely used method in array signal processing. A\ncurious feature of both the Capon and the MMSE beamformers is their tendency to\neither overestimate or underestimate the signal power. That is, they are not\nasymptotically unbiased (as the sample size approaches infinity). To address\nthis issue, we propose to shrink the Capon beamformer by finding a scaling\nfactor that minimizes the mean squared error (MSE) of the signal power\nestimate. The new beamformer, referred to as the Capon$^+$ beamformer, is\nevaluated against the Capon and MMSE beamformers in terms of bias, signal power\nMSE, and signal waveform MSE. The Capon$^+$ beamformer strikes a better balance\nbetween signal power and waveform estimation while also exhibiting minimal\nbias, which approaches zero as the sample size increases."}
{"id": "2506.16210", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.16210", "abs": "https://arxiv.org/abs/2506.16210", "authors": ["Zhenxuan Zhang", "Lipei Zhang", "Yanqi Cheng", "Zi Wang", "Fanwen Wang", "Haosen Zhang", "Yue Yang", "Yinzhe Wu", "Jiahao Huang", "Angelica I Aviles-Rivero", "Zhifan Gao", "Guang Yang", "Peter J. Lally"], "title": "From Coarse to Continuous: Progressive Refinement Implicit Neural Representation for Motion-Robust Anisotropic MRI Reconstruction", "comment": null, "summary": "In motion-robust magnetic resonance imaging (MRI), slice-to-volume\nreconstruction is critical for recovering anatomically consistent 3D brain\nvolumes from 2D slices, especially under accelerated acquisitions or patient\nmotion. However, this task remains challenging due to hierarchical structural\ndisruptions. It includes local detail loss from k-space undersampling, global\nstructural aliasing caused by motion, and volumetric anisotropy. Therefore, we\npropose a progressive refinement implicit neural representation (PR-INR)\nframework. Our PR-INR unifies motion correction, structural refinement, and\nvolumetric synthesis within a geometry-aware coordinate space. Specifically, a\nmotion-aware diffusion module is first employed to generate coarse volumetric\nreconstructions that suppress motion artifacts and preserve global anatomical\nstructures. Then, we introduce an implicit detail restoration module that\nperforms residual refinement by aligning spatial coordinates with visual\nfeatures. It corrects local structures and enhances boundary precision.\nFurther, a voxel continuous-aware representation module represents the image as\na continuous function over 3D coordinates. It enables accurate inter-slice\ncompletion and high-frequency detail recovery. We evaluate PR-INR on five\npublic MRI datasets under various motion conditions (3% and 5% displacement),\nundersampling rates (4x and 8x) and slice resolutions (scale = 5). Experimental\nresults demonstrate that PR-INR outperforms state-of-the-art methods in both\nquantitative reconstruction metrics and visual quality. It further shows\ngeneralization and robustness across diverse unseen domains."}
{"id": "2506.16957", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.16957", "abs": "https://arxiv.org/abs/2506.16957", "authors": ["Zisheng Wang", "Feng Li", "Hangbin Zhao", "Zihuan Mao", "Yaodong Zhang", "Qisheng Huang", "Bo Cao", "Mingming Cao", "Baolin He", "Qilin Hou"], "title": "Wi-Fi Sensing Tool Release: Gathering 802.11ax Channel State Information from a Commercial Wi-Fi Access Point", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Wi-Fi sensing has emerged as a powerful technology, leveraging channel state\ninformation (CSI) extracted from wireless data packets to enable diverse\napplications, ranging from human presence detection to gesture recognition and\nhealth monitoring. However, CSI extraction from commercial Wi-Fi access point\nlacks and out of date. This paper introduces ZTECSITool,a toolkit designed to\ncapture high-resolution CSI measurements from commercial Wi-Fi 6 (802.11ax)\naccess points, supporting bandwidths up to 160 MHz and 512 subcarriers.\nZTECSITool bridges a critical gap in Wi-Fi sensing research, facilitating the\ndevelopment of next-generation sensing systems. The toolkit includes customized\nfirmware and open-source software tools for configuring, collecting, and\nparsing CSI data, offering researchers a robust platform for advanced sensing\napplications. We detail the command protocols for CSI extraction, including\nband selection,STA filtering, and report configuration, and provide insights\ninto the data structure of the reported CSI. Additionally, we present a\nPython-based graphical interface for real-time CSI visualization and analysis"}
{"id": "2506.16213", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.16213", "abs": "https://arxiv.org/abs/2506.16213", "authors": ["Raghav Mehta", "Fabio De Sousa Ribeiro", "Tian Xia", "Melanie Roschewitz", "Ainkaran Santhirasekaram", "Dominic C. Marshall", "Ben Glocker"], "title": "CF-Seg: Counterfactuals meet Segmentation", "comment": "Accepted at MICCAI 2025", "summary": "Segmenting anatomical structures in medical images plays an important role in\nthe quantitative assessment of various diseases. However, accurate segmentation\nbecomes significantly more challenging in the presence of disease. Disease\npatterns can alter the appearance of surrounding healthy tissues, introduce\nambiguous boundaries, or even obscure critical anatomical structures. As such,\nsegmentation models trained on real-world datasets may struggle to provide good\nanatomical segmentation, leading to potential misdiagnosis. In this paper, we\ngenerate counterfactual (CF) images to simulate how the same anatomy would\nappear in the absence of disease without altering the underlying structure. We\nthen use these CF images to segment structures of interest, without requiring\nany changes to the underlying segmentation model. Our experiments on two\nreal-world clinical chest X-ray datasets show that the use of counterfactual\nimages improves anatomical segmentation, thereby aiding downstream clinical\ndecision-making."}
{"id": "2506.17010", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.17010", "abs": "https://arxiv.org/abs/2506.17010", "authors": ["Kuranage Roche Rayan Ranasinghe", "Bruno S. Chang", "Giuseppe Thadeu Freitas de Abreu"], "title": "Low-Complexity Receiver Design for Affine Filter Bank Modulation", "comment": "Submitted to an IEEE conference. arXiv admin note: substantial text\n  overlap with arXiv:2505.03589", "summary": "We propose a low-complexity receiver structure for the recently introduced\nAffine Filter Bank Modulation (AFBM) scheme, which is a novel waveform designed\nfor integrated sensing and communications (ISAC) systems operating in\ndoubly-dispersive (DD) channels. The proposed receiver structure is based on\nthe Gaussian Belief Propagation (GaBP) framework, making use of only\nelement-wise scalar operations to perform detection of the transmitted symbols.\nSimulation results demonstrate that AFBM in conjunction with GaBP outperforms\naffine frequency division multiplexing (AFDM) in terms of bit error rates\n(BERs) in DD channels, while achieving very low out-of-band emissions (OOBE) in\nhigh-mobility scenarios."}
{"id": "2506.16256", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.16256", "abs": "https://arxiv.org/abs/2506.16256", "authors": ["César Díaz-Parga", "Marta Nuñez-Garcia", "Maria J. Carreira", "Gabriel Bernardino", "Nicolás Vila-Blanco"], "title": "AGE-US: automated gestational age estimation based on fetal ultrasound images", "comment": "Accepted in Iberian Conference on Pattern Recognition and Image\n  Analysis (IbPRIA) 2025", "summary": "Being born small carries significant health risks, including increased\nneonatal mortality and a higher likelihood of future cardiac diseases. Accurate\nestimation of gestational age is critical for monitoring fetal growth, but\ntraditional methods, such as estimation based on the last menstrual period, are\nin some situations difficult to obtain. While ultrasound-based approaches offer\ngreater reliability, they rely on manual measurements that introduce\nvariability. This study presents an interpretable deep learning-based method\nfor automated gestational age calculation, leveraging a novel segmentation\narchitecture and distance maps to overcome dataset limitations and the scarcity\nof segmentation masks. Our approach achieves performance comparable to\nstate-of-the-art models while reducing complexity, making it particularly\nsuitable for resource-constrained settings and with limited annotated data.\nFurthermore, our results demonstrate that the use of distance maps is\nparticularly suitable for estimating femur endpoints."}
{"id": "2506.17108", "categories": ["eess.SP", "cs.IT", "math.IT", "stat.ML"], "pdf": "https://arxiv.org/pdf/2506.17108", "abs": "https://arxiv.org/abs/2506.17108", "authors": ["Levli Citron", "Kobi Cohen", "Qing Zhao"], "title": "Searching for a Hidden Markov Anomaly over Multiple Processes", "comment": "13 pages, 9 figures", "summary": "We address the problem of detecting an anomalous process among a large number\nof processes. At each time t, normal processes are in state zero (normal\nstate), while the abnormal process may be in either state zero (normal state)\nor state one (abnormal state), with the states being hidden. The transition\nbetween states for the abnormal process is governed by a Markov chain over\ntime. At each time step, observations can be drawn from a selected subset of\nprocesses. Each probed process generates an observation depending on its hidden\nstate, either a typical distribution under state zero or an abnormal\ndistribution under state one. The objective is to design a sequential search\nstrategy that minimizes the expected detection time, subject to an error\nprobability constraint. In contrast to prior works that assume i.i.d.\nobservations, we address a new setting where anomalies evolve according to a\nhidden Markov model. To this end, we propose a novel algorithm, dubbed Anomaly\nDetection under Hidden Markov model (ADHM), which dynamically adapts the\nprobing strategy based on accumulated statistical evidence and predictive\nbelief updates over hidden states. ADHM effectively leverages temporal\ncorrelations to focus sensing resources on the most informative processes. The\nalgorithm is supported by an asymptotic theoretical foundation, grounded in an\noracle analysis that characterizes the fundamental limits of detection under\nthe assumption of a known distribution of the hidden states. In addition, the\nalgorithm demonstrates strong empirical performance, consistently outperforming\nexisting methods in extensive simulations."}
{"id": "2506.16556", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.16556", "abs": "https://arxiv.org/abs/2506.16556", "authors": ["Salvatore Esposito", "Daniel Rebain", "Arno Onken", "Changjian Li", "Oisin Mac Aodha"], "title": "VesselSDF: Distance Field Priors for Vascular Network Reconstruction", "comment": null, "summary": "Accurate segmentation of vascular networks from sparse CT scan slices remains\na significant challenge in medical imaging, particularly due to the thin,\nbranching nature of vessels and the inherent sparsity between imaging planes.\nExisting deep learning approaches, based on binary voxel classification, often\nstruggle with structural continuity and geometric fidelity. To address this\nchallenge, we present VesselSDF, a novel framework that leverages signed\ndistance fields (SDFs) for robust vessel reconstruction. Our method\nreformulates vessel segmentation as a continuous SDF regression problem, where\neach point in the volume is represented by its signed distance to the nearest\nvessel surface. This continuous representation inherently captures the smooth,\ntubular geometry of blood vessels and their branching patterns. We obtain\naccurate vessel reconstructions while eliminating common SDF artifacts such as\nfloating segments, thanks to our adaptive Gaussian regularizer which ensures\nsmoothness in regions far from vessel surfaces while producing precise geometry\nnear the surface boundaries. Our experimental results demonstrate that\nVesselSDF significantly outperforms existing methods and preserves vessel\ngeometry and connectivity, enabling more reliable vascular analysis in clinical\nsettings."}
{"id": "2506.17189", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.17189", "abs": "https://arxiv.org/abs/2506.17189", "authors": ["Muhammad Umer", "Muhammad Ahmed Mohsin", "Aamir Mahmood", "Haejoon Jung", "Haris Pervaiz", "Mikael Gidlund", "Syed Ali Hassan"], "title": "On Energy-Efficient Passive Beamforming Design of RIS-Assisted CoMP-NOMA Networks", "comment": "Accepted and presented at IEEE ICC'25 [SAC-12 Track]. arXiv admin\n  note: substantial text overlap with arXiv:2504.00975", "summary": "This paper investigates the synergistic potential of reconfigurable\nintelligent surfaces (RIS) and non-orthogonal multiple access (NOMA) to enhance\nthe energy efficiency and performance of next-generation wireless networks. We\ndelve into the design of energy-efficient passive beamforming (PBF) strategies\nwithin RIS-assisted coordinated multi-point (CoMP)-NOMA networks. Two distinct\nRIS configurations, namely, enhancement-only PBF (EO) and enhancement &\ncancellation PBF (EC), are proposed and analyzed. Our findings demonstrate that\nRIS-assisted CoMP-NOMA networks offer significant efficiency gains compared to\ntraditional CoMP-NOMA systems. Furthermore, we formulate a PBF design problem\nto optimize the RIS phase shifts for maximizing energy efficiency. Our results\nreveal that the optimal PBF design is contingent upon several factors,\nincluding the number of cooperating base stations (BSs), the number of RIS\nelements deployed, and the RIS configuration. This study underscores the\npotential of RIS-assisted CoMP-NOMA networks as a promising solution for\nachieving superior energy efficiency and overall performance in future wireless\nnetworks."}
{"id": "2506.16572", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.16572", "abs": "https://arxiv.org/abs/2506.16572", "authors": ["Chanung Park", "Joo Chan Lee", "Jong Hwan Ko"], "title": "DiffO: Single-step Diffusion for Image Compression at Ultra-Low Bitrates", "comment": null, "summary": "Although image compression is fundamental to visual data processing and has\ninspired numerous standard and learned codecs, these methods still suffer\nsevere quality degradation at extremely low bits per pixel. While recent\ndiffusion based models provided enhanced generative performance at low\nbitrates, they still yields limited perceptual quality and prohibitive decoding\nlatency due to multiple denoising steps. In this paper, we propose the first\nsingle step diffusion model for image compression (DiffO) that delivers high\nperceptual quality and fast decoding at ultra low bitrates. DiffO achieves\nthese goals by coupling two key innovations: (i) VQ Residual training, which\nfactorizes a structural base code and a learned residual in latent space,\ncapturing both global geometry and high frequency details; and (ii) rate\nadaptive noise modulation, which tunes denoising strength on the fly to match\nthe desired bitrate. Extensive experiments show that DiffO surpasses state of\nthe art compression performance while improving decoding speed by about 50x\ncompared to prior diffusion-based methods, greatly improving the practicality\nof generative codecs. The code will be available at\nhttps://github.com/Freemasti/DiffO."}
{"id": "2506.17200", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.17200", "abs": "https://arxiv.org/abs/2506.17200", "authors": ["Qingqing Wu", "Yanze Zhu", "Qiaoyan Peng", "Wanming Hao", "Yanzhao Hou", "Fengyuan Yang", "Wencai Yan", "Guoning Wang", "Wen Chen", "Chi Qiu"], "title": "Intelligent Reflecting Surfaces for THz Communications: Fundamentals, Key Solutions, and System Prototyping", "comment": null, "summary": "Intelligent reflecting surfaces (IRSs) have emerged as a cost-effective\ntechnology for terahertz (THz) communications by enabling programmable control\nof the wireless environment. This paper provides a comprehensive overview of\nIRSs-aided THz communications, covering hardware designs, advanced signal\nprocessing techniques, and practical deployment strategies. It first examines\nkey THz reconfigurable metasurface architectures, including electronic,\noptical, phase-change material, and micro-electromechanical systems\n(MEMS)-based implementations, highlighting their reconfiguration mechanisms and\nchallenges. Then, fundamental effects including near field and beam squint in\nwideband THz systems are analyzed, along with their impacts on system\nperformance. The paper further explores conventional and beam-squint-assisted\nchannel estimation methods, innovative beam management strategies, and\ndeployment considerations across large- and small-scale scenarios. Practical\nexperiments at 220 gigahertz (GHz) validate the effectiveness of IRS in\nimproving signal strength and communication reliability for both single-user\nand multi-user setups."}
{"id": "2506.16592", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.16592", "abs": "https://arxiv.org/abs/2506.16592", "authors": ["Muhammad Azeem Aslam", "Asim Naveed", "Nisar Ahmed"], "title": "Hybrid Attention Network for Accurate Breast Tumor Segmentation in Ultrasound Images", "comment": null, "summary": "Breast ultrasound imaging is a valuable tool for early breast cancer\ndetection, but automated tumor segmentation is challenging due to inherent\nnoise, variations in scale of lesions, and fuzzy boundaries. To address these\nchallenges, we propose a novel hybrid attention-based network for lesion\nsegmentation. Our proposed architecture integrates a pre-trained DenseNet121 in\nthe encoder part for robust feature extraction with a multi-branch\nattention-enhanced decoder tailored for breast ultrasound images. The\nbottleneck incorporates Global Spatial Attention (GSA), Position Encoding (PE),\nand Scaled Dot-Product Attention (SDPA) to learn global context, spatial\nrelationships, and relative positional features. The Spatial Feature\nEnhancement Block (SFEB) is embedded at skip connections to refine and enhance\nspatial features, enabling the network to focus more effectively on tumor\nregions. A hybrid loss function combining Binary Cross-Entropy (BCE) and\nJaccard Index loss optimizes both pixel-level accuracy and region-level overlap\nmetrics, enhancing robustness to class imbalance and irregular tumor shapes.\nExperiments on public datasets demonstrate that our method outperforms existing\napproaches, highlighting its potential to assist radiologists in early and\naccurate breast cancer diagnosis."}
{"id": "2506.17205", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.17205", "abs": "https://arxiv.org/abs/2506.17205", "authors": ["Jennifer Bondarchuk", "Anthony Trezza", "Donald J. Bucci Jr"], "title": "Efficient Implementation of Multi-sensor Adaptive Birth Samplers for Labeled Random Finite Set Tracking", "comment": "Accepted to the 2024 Proc. IEEE 27th Int. Conf. Inf. Fusion. arXiv\n  admin note: text overlap with arXiv:2307.06401", "summary": "Adaptive track initiation remains a crucial component of many modern\nmulti-target tracking systems. For labeled random finite sets multi-object\nfilters, prior work has been established to construct a labeled multi-object\nbirth density using measurements from multiple sensors. A naive construction of\nthis adaptive birth set density results in an exponential number of newborn\ncomponents in the number of sensors. A truncation procedure was provided that\nleverages a Gibbs sampler to truncate the birth density, reducing the\ncomplexity to quadratic in the number of sensors. However, only a limited\ndiscussion has been provided on additional algorithmic techniques that can be\nemployed to substantially reduce the complexity in practical tracking\napplications. In this paper, we propose five efficiency enhancements for the\nlabeled random finite sets multi-sensor adaptive birth procedure. Simulation\nresults are provided to demonstrate their computational benefits and show that\nthey result in a negligible change to the multi-target tracking performance."}
{"id": "2506.16631", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.16631", "abs": "https://arxiv.org/abs/2506.16631", "authors": ["Saghir Alfasly", "Ghazal Alabtah", "H. R. Tizhoosh"], "title": "Overfitting in Histopathology Model Training: The Need for Customized Architectures", "comment": null, "summary": "This study investigates the critical problem of overfitting in deep learning\nmodels applied to histopathology image analysis. We show that simply adopting\nand fine-tuning large-scale models designed for natural image analysis often\nleads to suboptimal performance and significant overfitting when applied to\nhistopathology tasks. Through extensive experiments with various model\narchitectures, including ResNet variants and Vision Transformers (ViT), we show\nthat increasing model capacity does not necessarily improve performance on\nhistopathology datasets. Our findings emphasize the need for customized\narchitectures specifically designed for histopathology image analysis,\nparticularly when working with limited datasets. Using Oesophageal\nAdenocarcinomas public dataset, we demonstrate that simpler, domain-specific\narchitectures can achieve comparable or better performance while minimizing\noverfitting."}
{"id": "2506.16733", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.16733", "abs": "https://arxiv.org/abs/2506.16733", "authors": ["Fang Chen", "Weifeng Zhang", "Xingyu Ai", "BingXuan Li", "An Li", "Qiegen Liu"], "title": "A Prior-Guided Joint Diffusion Model in Projection Domain for PET Tracer Conversion", "comment": null, "summary": "Positron emission tomography (PET) is widely used to assess metabolic\nactivity, but its application is limited by the availability of radiotracers.\n18F-labeled fluorodeoxyglucose (18F-FDG) is the most commonly used tracer but\nshows limited effectiveness for certain tumors. In contrast,\n6-18F-fluoro-3,4-dihydroxy-L-phenylalanine (18F-DOPA) offers higher specificity\nfor neuroendocrine tumors and neurological disorders. However, its complex\nsynthesis and limitations in transportation and clinical use hinder widespread\nadoption. During PET imaging, the sinogram represents a form of raw data\nacquired by the scanner. Therefore, modeling in projection domain enables more\ndirect utilization of the original information, potentially reducing the\naccumulation of errors introduced during the image reconstruction process.\nInspired by these factors, this study proposes a prior-guided joint diffusion\nmodel (PJDM) for transforming 18F-FDG PET images into 18F-DOPA PET images in\nprojection domain. Specifically, a coarse estimation model and a prior\nrefinement model are trained independently. During inference, an initial\nsynthetic 18F-DOPA PET sinogram is generated using a higher-order hybrid\nsampler. This sinogram is then degraded and serves as an additional condition\nto guide the iterative refinement process using learned prior. Experimental\nresults demonstrated that PJDM effectively improved both sinogram quality and\nsynthetic outcomes. The code is available at: https://github.com/yqx7150/PJDM."}
{"id": "2506.16803", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.16803", "abs": "https://arxiv.org/abs/2506.16803", "authors": ["Ning Chu", "Siya Zheng", "Shanqing Zhang", "Li Li", "Caifang Cai", "Ali Mohammad-Djafari", "Feng Zhao", "Yuanbo Song"], "title": "Temperature calibration of surface emissivities with an improved thermal image enhancement network", "comment": null, "summary": "Infrared thermography faces persistent challenges in temperature accuracy due\nto material emissivity variations, where existing methods often neglect the\njoint optimization of radiometric calibration and image degradation. This study\nintroduces a physically guided neural framework that unifies temperature\ncorrection and image enhancement through a symmetric skip-CNN architecture and\nan emissivity-aware attention module. The pre-processing stage segments the\nROIs of the image and and initially corrected the firing rate. A novel\ndual-constrained loss function strengthens the statistical consistency between\nthe target and reference regions through mean-variance alignment and histogram\nmatching based on Kullback-Leibler dispersion. The method works by dynamically\nfusing thermal radiation features and spatial context, and the model suppresses\nemissivity artifacts while recovering structural details. After validating the\nindustrial blower system under different conditions, the improved network\nrealizes the dynamic fusion of thermal radiation characteristics and spatial\nbackground, with accurate calibration results in various industrial conditions."}
{"id": "2506.16934", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.16934", "abs": "https://arxiv.org/abs/2506.16934", "authors": ["Bin Huang", "Feihong Xu", "Xinchong Shi", "Shan Huang", "Binxuan Li", "Fei Li", "Qiegen Liu"], "title": "PET Tracer Separation Using Conditional Diffusion Transformer with Multi-latent Space Learning", "comment": null, "summary": "In clinical practice, single-radiotracer positron emission tomography (PET)\nis commonly used for imaging. Although multi-tracer PET imaging can provide\nsupplementary information of radiotracers that are sensitive to physiological\nfunction changes, enabling a more comprehensive characterization of\nphysiological and pathological states, the gamma-photon pairs generated by\npositron annihilation reactions of different tracers in PET imaging have the\nsame energy, making it difficult to distinguish the tracer signals. In this\nstudy, a multi-latent space guided texture conditional diffusion transformer\nmodel (MS-CDT) is proposed for PET tracer separation. To the best of our\nknowledge, this is the first attempt to use texture condition and multi-latent\nspace for tracer separation in PET imaging. The proposed model integrates\ndiffusion and transformer architectures into a unified optimization framework,\nwith the novel addition of texture masks as conditional inputs to enhance image\ndetails. By leveraging multi-latent space prior derived from different tracers,\nthe model captures multi-level feature representations, aiming to balance\ncomputational efficiency and detail preservation. The texture masks, serving as\nconditional guidance, help the model focus on salient structural patterns,\nthereby improving the extraction and utilization of fine-grained image\ntextures. When combined with the diffusion transformer backbone, this\nconditioning mechanism contributes to more accurate and robust tracer\nseparation. To evaluate its effectiveness, the proposed MS-CDT is compared with\nseveral advanced methods on two types of 3D PET datasets: brain and chest\nscans. Experimental results indicate that MS-CDT achieved competitive\nperformance in terms of image quality and preservation of clinically relevant\ninformation. Code is available at: https://github.com/yqx7150/MS-CDT."}
{"id": "2506.17133", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17133", "abs": "https://arxiv.org/abs/2506.17133", "authors": ["Josué Martínez-Martínez", "Olivia Brown", "Mostafa Karami", "Sheida Nabavi"], "title": "Robust Training with Data Augmentation for Medical Imaging Classification", "comment": null, "summary": "Deep neural networks are increasingly being used to detect and diagnose\nmedical conditions using medical imaging. Despite their utility, these models\nare highly vulnerable to adversarial attacks and distribution shifts, which can\naffect diagnostic reliability and undermine trust among healthcare\nprofessionals. In this study, we propose a robust training algorithm with data\naugmentation (RTDA) to mitigate these vulnerabilities in medical image\nclassification. We benchmark classifier robustness against adversarial\nperturbations and natural variations of RTDA and six competing baseline\ntechniques, including adversarial training and data augmentation approaches in\nisolation and combination, using experimental data sets with three different\nimaging technologies (mammograms, X-rays, and ultrasound). We demonstrate that\nRTDA achieves superior robustness against adversarial attacks and improved\ngeneralization performance in the presence of distribution shift in each image\nclassification task while maintaining high clean accuracy."}
{"id": "2506.17140", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.17140", "abs": "https://arxiv.org/abs/2506.17140", "authors": ["David Jacob Drexlin", "Jonas Dippel", "Julius Hense", "Niklas Prenißl", "Grégoire Montavon", "Frederick Klauschen", "Klaus-Robert Müller"], "title": "MeDi: Metadata-Guided Diffusion Models for Mitigating Biases in Tumor Classification", "comment": null, "summary": "Deep learning models have made significant advances in histological\nprediction tasks in recent years. However, for adaptation in clinical practice,\ntheir lack of robustness to varying conditions such as staining, scanner,\nhospital, and demographics is still a limiting factor: if trained on\noverrepresented subpopulations, models regularly struggle with less frequent\npatterns, leading to shortcut learning and biased predictions. Large-scale\nfoundation models have not fully eliminated this issue. Therefore, we propose a\nnovel approach explicitly modeling such metadata into a Metadata-guided\ngenerative Diffusion model framework (MeDi). MeDi allows for a targeted\naugmentation of underrepresented subpopulations with synthetic data, which\nbalances limited training data and mitigates biases in downstream models. We\nexperimentally show that MeDi generates high-quality histopathology images for\nunseen subpopulations in TCGA, boosts the overall fidelity of the generated\nimages, and enables improvements in performance for downstream classifiers on\ndatasets with subpopulation shifts. Our work is a proof-of-concept towards\nbetter mitigating data biases with generative models."}
{"id": "2506.17165", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.17165", "abs": "https://arxiv.org/abs/2506.17165", "authors": ["Mahin Montasir Afif", "Abdullah Al Noman", "K. M. Tahsin Kabir", "Md. Mortuza Ahmmed", "Md. Mostafizur Rahman", "Mufti Mahmud", "Md. Ashraful Babu"], "title": "Proportional Sensitivity in Generative Adversarial Network (GAN)-Augmented Brain Tumor Classification Using Convolutional Neural Network", "comment": "This papaer has been submitted to The 18th International Conference\n  on Brain Informatics (BI'25), Italy", "summary": "Generative Adversarial Networks (GAN) have shown potential in expanding\nlimited medical imaging datasets. This study explores how different ratios of\nGAN-generated and real brain tumor MRI images impact the performance of a CNN\nin classifying healthy vs. tumorous scans. A DCGAN was used to create synthetic\nimages which were mixed with real ones at various ratios to train a custom CNN.\nThe CNN was then evaluated on a separate real-world test set. Our results\nindicate that the model maintains high sensitivity and precision in tumor\nclassification, even when trained predominantly on synthetic data. When only a\nsmall portion of GAN data was added, such as 900 real images and 100 GAN\nimages, the model achieved excellent performance, with test accuracy reaching\n95.2%, and precision, recall, and F1-score all exceeding 95%. However, as the\nproportion of GAN images increased further, performance gradually declined.\nThis study suggests that while GANs are useful for augmenting limited datasets\nespecially when real data is scarce, too much synthetic data can introduce\nartifacts that affect the model's ability to generalize to real world cases."}
{"id": "2506.15843", "categories": ["eess.SP", "eess.IV"], "pdf": "https://arxiv.org/pdf/2506.15843", "abs": "https://arxiv.org/abs/2506.15843", "authors": ["Ninghe Liu", "Yu Xi Huang", "Simon Mahler", "Changhuei Yang"], "title": "Optimized cerebral blood flow measurement in speckle contrast optical spectroscopy via refinement of noise calibration", "comment": "5 pages, 3 figures", "summary": "Speckle contrast optical spectroscopy (SCOS) offers a non-invasive and\ncost-effective method for monitoring cerebral blood flow (CBF). However,\nextracting accurate CBF from SCOS necessitates precise noise pre-calibration.\nErrors from this can degrade CBF measurement fidelity, particularly when the\noverall signal level is low. Such errors primarily stem from residual speckle\ncontrast associated with camera and shot noise, whose fluctuations exhibit a\ntemporal structure that mimics cerebral blood volume (CBV) waveforms. We\npropose an optimization-based framework that performs an adaptive refinement of\nnoise calibration, mitigating the CBV-mimicking artifacts by reducing the\nCBF-CBV waveform correlation. Validated on 10 human subjects, our approach\neffectively lowered the signal threshold for reliable CBF signal from 97 to 26\nelectrons per pixel for a 1920x1200 pixels SCOS system. This improvement\nenables more accurate and robust CBF measurements in SCOS, especially at large\nsource-detector (SD) distances for deeper tissue interrogation."}
