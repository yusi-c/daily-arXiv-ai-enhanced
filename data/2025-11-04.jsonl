{"id": "2511.00449", "categories": ["eess.IV", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00449", "abs": "https://arxiv.org/abs/2511.00449", "authors": ["Xiaolong Li", "Zhi-Qin John Xu", "Yan Ren", "Tianming Qiu", "Xiaowen Wang"], "title": "Towards Reliable Pediatric Brain Tumor Segmentation: Task-Specific nnU-Net Enhancements", "comment": null, "summary": "Accurate segmentation of pediatric brain tumors in multi-parametric magnetic\nresonance imaging (mpMRI) is critical for diagnosis, treatment planning, and\nmonitoring, yet faces unique challenges due to limited data, high anatomical\nvariability, and heterogeneous imaging across institutions. In this work, we\npresent an advanced nnU-Net framework tailored for BraTS 2025 Task-6 (PED), the\nlargest public dataset of pre-treatment pediatric high-grade gliomas. Our\ncontributions include: (1) a widened residual encoder with\nsqueeze-and-excitation (SE) attention; (2) 3D depthwise separable convolutions;\n(3) a specificity-driven regularization term; and (4) small-scale Gaussian\nweight initialization. We further refine predictions with two postprocessing\nsteps. Our models achieved first place on the Task-6 validation leaderboard,\nattaining lesion-wise Dice scores of 0.759 (CC), 0.967 (ED), 0.826 (ET), 0.910\n(NET), 0.928 (TC) and 0.928 (WT)."}
{"id": "2511.00477", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00477", "abs": "https://arxiv.org/abs/2511.00477", "authors": ["Aditya Parikh", "Sneha Das", "Aasa Feragen"], "title": "Investigating Label Bias and Representational Sources of Age-Related Disparities in Medical Segmentation", "comment": "Submitted to ISBI 2026", "summary": "Algorithmic bias in medical imaging can perpetuate health disparities, yet\nits causes remain poorly understood in segmentation tasks. While fairness has\nbeen extensively studied in classification, segmentation remains underexplored\ndespite its clinical importance. In breast cancer segmentation, models exhibit\nsignificant performance disparities against younger patients, commonly\nattributed to physiological differences in breast density. We audit the\nMAMA-MIA dataset, establishing a quantitative baseline of age-related bias in\nits automated labels, and reveal a critical Biased Ruler effect where\nsystematically flawed labels for validation misrepresent a model's actual bias.\nHowever, whether this bias originates from lower-quality annotations (label\nbias) or from fundamentally more challenging image characteristics remains\nunclear. Through controlled experiments, we systematically refute hypotheses\nthat the bias stems from label quality sensitivity or quantitative case\ndifficulty imbalance. Balancing training data by difficulty fails to mitigate\nthe disparity, revealing that younger patient cases are intrinsically harder to\nlearn. We provide direct evidence that systemic bias is learned and amplified\nwhen training on biased, machine-generated labels, a critical finding for\nautomated annotation pipelines. This work introduces a systematic framework for\ndiagnosing algorithmic bias in medical segmentation and demonstrates that\nachieving fairness requires addressing qualitative distributional differences\nrather than merely balancing case counts."}
{"id": "2511.00548", "categories": ["eess.IV", "cs.CV", "cs.GR", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.00548", "abs": "https://arxiv.org/abs/2511.00548", "authors": ["Baochao Wang", "Xingyu Zhang", "Qingtao Zong", "Alim Pulatov", "Shuqi Shang", "Dongwei Wang"], "title": "Image-based ground distance detection for crop-residue-covered soil", "comment": "under review at Computers and Electronics in Agriculture", "summary": "Conservation agriculture features a soil surface covered with crop residues,\nwhich brings benefits of improving soil health and saving water. However, one\nsignificant challenge in conservation agriculture lies in precisely controlling\nthe seeding depth on the soil covered with crop residues. This is constrained\nby the lack of ground distance information, since current distance measurement\ntechniques, like laser, ultrasonic, or mechanical displacement sensors, are\nincapable of differentiating whether the distance information comes from the\nresidue or the soil. This paper presents an image-based method to get the\nground distance information for the crop-residues-covered soil. This method is\nperformed with 3D camera and RGB camera, obtaining depth image and color image\nat the same time. The color image is used to distinguish the different areas of\nresidues and soil and finally generates a mask image. The mask image is applied\nto the depth image so that only the soil area depth information can be used to\ncalculate the ground distance, and residue areas can be recognized and excluded\nfrom ground distance detection. Experimentation shows that this distance\nmeasurement method is feasible for real-time implementation, and the\nmeasurement error is within plus or minus 3mm. It can be applied in\nconservation agriculture machinery for precision depth seeding, as well as\nother depth-control-demanding applications like transplant or tillage."}
{"id": "2511.00598", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00598", "abs": "https://arxiv.org/abs/2511.00598", "authors": ["Zixuan Sun", "Shuaifeng Zhi", "Ruize Li", "Jingyuan Xia", "Yongxiang Liu", "Weidong Jiang"], "title": "GDROS: A Geometry-Guided Dense Registration Framework for Optical-SAR Images under Large Geometric Transformations", "comment": "To be published in IEEE Transactions on Geoscience and Remote Sensing\n  (T-GRS) 2025", "summary": "Registration of optical and synthetic aperture radar (SAR) remote sensing\nimages serves as a critical foundation for image fusion and visual navigation\ntasks. This task is particularly challenging because of their modal\ndiscrepancy, primarily manifested as severe nonlinear radiometric differences\n(NRD), geometric distortions, and noise variations. Under large geometric\ntransformations, existing classical template-based and sparse keypoint-based\nstrategies struggle to achieve reliable registration results for optical-SAR\nimage pairs. To address these limitations, we propose GDROS, a geometry-guided\ndense registration framework leveraging global cross-modal image interactions.\nFirst, we extract cross-modal deep features from optical and SAR images through\na CNN-Transformer hybrid feature extraction module, upon which a multi-scale 4D\ncorrelation volume is constructed and iteratively refined to establish\npixel-wise dense correspondences. Subsequently, we implement a least squares\nregression (LSR) module to geometrically constrain the predicted dense optical\nflow field. Such geometry guidance mitigates prediction divergence by directly\nimposing an estimated affine transformation on the final flow predictions.\nExtensive experiments have been conducted on three representative datasets\nWHU-Opt-SAR dataset, OS dataset, and UBCv2 dataset with different spatial\nresolutions, demonstrating robust performance of our proposed method across\ndifferent imaging resolutions. Qualitative and quantitative results show that\nGDROS significantly outperforms current state-of-the-art methods in all\nmetrics. Our source code will be released at:\nhttps://github.com/Zi-Xuan-Sun/GDROS."}
{"id": "2511.00225", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.00225", "abs": "https://arxiv.org/abs/2511.00225", "authors": ["Pinjun Zheng", "Md. Jahangir Hossain", "Anas Chaaban"], "title": "Model-Free Channel Estimation for Massive MIMO: A Channel Charting-Inspired Approach", "comment": null, "summary": "Channel estimation is fundamental to wireless communications, yet it becomes\nincreasingly challenging in massive multiple-input multiple-output (MIMO)\nsystems where base stations employ hundreds of antennas. Traditional\nleast-squares methods require prohibitive pilot overhead that scales with\nantenna count, while sparse estimation methods depend on precise channel models\nthat may not always be practical. This paper proposes a model-free approach\ncombining deep autoencoders and LSTM networks. The method first learns\nlow-dimensional channel representations preserving temporal correlation through\naugmenting a channel charting-inspired loss function, then tracks these\nfeatures to recover full channel information from limited pilots. Simulation\nresults using ray-tracing datasets show that the proposed approach achieves up\nto 9 dB improvement in normalized mean square error compared to the\nleast-squares methods under ill-conditioned scenarios, while maintaining\nscalability across MIMO configurations."}
{"id": "2511.00652", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00652", "abs": "https://arxiv.org/abs/2511.00652", "authors": ["Ali Khalid", "Jaiaid Mobin", "Sumanth Rao Appala", "Avinash Maurya", "Stephany Berrio Perez", "M. Mustafa Rafique", "Fawad Ahmad"], "title": "Been There, Scanned That: Nostalgia-Driven LiDAR Compression for Self-Driving Cars", "comment": null, "summary": "An autonomous vehicle can generate several terabytes of sensor data per day.\nA significant portion of this data consists of 3D point clouds produced by\ndepth sensors such as LiDARs. This data must be transferred to cloud storage,\nwhere it is utilized for training machine learning models or conducting\nanalyses, such as forensic investigations in the event of an accident. To\nreduce network and storage costs, this paper introduces DejaView. Although\nprior work uses interframe redundancies to compress data, DejaView searches for\nand uses redundancies on larger temporal scales (days and months) for more\neffective compression. We designed DejaView with the insight that the operating\narea of autonomous vehicles is limited and that vehicles mostly traverse the\nsame routes daily. Consequently, the 3D data they collect daily is likely\nsimilar to the data they have captured in the past. To capture this, the core\nof DejaView is a diff operation that compactly represents point clouds as delta\nw.r.t. 3D data from the past. Using two months of LiDAR data, an end-to-end\nimplementation of DejaView can compress point clouds by a factor of 210 at a\nreconstruction error of only 15 cm."}
{"id": "2511.00482", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.00482", "abs": "https://arxiv.org/abs/2511.00482", "authors": ["Ying Zhang", "Fan Liu", "Yifeng Xiong", "Tao Liu", "Shi Jin"], "title": "Discrete-Periodic Ambiguity Function of Random Communication Signals", "comment": "5 pages, 2 figures, submitted to ICASSP 2026 for possible publication", "summary": "This paper investigates the ambiguity function (AF) of communication signals\ncarrying random data payloads, which is a fundamental metric characterizing\nsensing capability in ISAC systems. We first develop a unified analytical\nframework to evaluate the AF of communication-centric ISAC signals constructed\nfrom arbitrary orthonormal bases and independent identically distributed\n(i.i.d.) constellation symbols. Subsequently, we derive the discrete periodic\nambiguity function (DP-AF) and provide closed-form expressions for its expected\nintegrated sidelobe level (EISL) and average sidelobe level. Notably, we prove\nthat the normalized EISL is invariant across all constellations and modulation\nbases. Finally, the theoretical findings are validated through simulations."}
{"id": "2511.00881", "categories": ["eess.IV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00881", "abs": "https://arxiv.org/abs/2511.00881", "authors": ["Simone Sarrocco", "Philippe C. Cattin", "Peter M. Maloca", "Paul Friedrich", "Philippe Valmaggia"], "title": "Deep Generative Models for Enhanced Vitreous OCT Imaging", "comment": null, "summary": "Purpose: To evaluate deep learning (DL) models for enhancing vitreous optical\ncoherence tomography (OCT) image quality and reducing acquisition time.\nMethods: Conditional Denoising Diffusion Probabilistic Models (cDDPMs),\nBrownian Bridge Diffusion Models (BBDMs), U-Net, Pix2Pix, and Vector-Quantised\nGenerative Adversarial Network (VQ-GAN) were used to generate high-quality\nspectral-domain (SD) vitreous OCT images. Inputs were SD ART10 images, and\noutputs were compared to pseudoART100 images obtained by averaging ten ART10\nimages per eye location. Model performance was assessed using image quality\nmetrics and Visual Turing Tests, where ophthalmologists ranked generated images\nand evaluated anatomical fidelity. The best model's performance was further\ntested within the manually segmented vitreous on newly acquired data. Results:\nU-Net achieved the highest Peak Signal-to-Noise Ratio (PSNR: 30.230) and\nStructural Similarity Index Measure (SSIM: 0.820), followed by cDDPM. For\nLearned Perceptual Image Patch Similarity (LPIPS), Pix2Pix (0.697) and cDDPM\n(0.753) performed best. In the first Visual Turing Test, cDDPM ranked highest\n(3.07); in the second (best model only), cDDPM achieved a 32.9% fool rate and\n85.7% anatomical preservation. On newly acquired data, cDDPM generated vitreous\nregions more similar in PSNR to the ART100 reference than true ART1 or ART10\nB-scans and achieved higher PSNR on whole images when conditioned on ART1 than\nART10. Conclusions: Results reveal discrepancies between quantitative metrics\nand clinical evaluation, highlighting the need for combined assessment. cDDPM\nshowed strong potential for generating clinically meaningful vitreous OCT\nimages while reducing acquisition time fourfold. Translational Relevance:\ncDDPMs show promise for clinical integration, supporting faster, higher-quality\nvitreous imaging. Dataset and code will be made publicly available."}
{"id": "2511.00491", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.00491", "abs": "https://arxiv.org/abs/2511.00491", "authors": ["Leatile Marata", "Juhani Sankari", "Eslam Eldeeb", "Mikko Valkama", "Elena Simona Lohan"], "title": "Meta-Learning Based Radio Frequency Fingerprinting for GNSS Spoofing Detection", "comment": null, "summary": "The rapid development of technology has led to an increase in the number of\ndevices that rely on position, velocity, and time (PVT) information to perform\ntheir functions. As such, the Global Navigation Satellite Systems (GNSS) have\nbeen adopted as one of the most promising solutions to provide PVT.\nConsequently, there are renewed efforts aimed at enhancing GNSS capabilities to\nmeet emerging use cases and their requirements. For example, GNSS is evolving\nto rely on low-earth-orbit satellites, shifting the focus from traditional\nmedium-earth-orbit satellites. Unfortunately, these developments also bring\nforth higher risks of interference signals such as spoofers, which pose serious\nsecurity threats. To address this challenge, artificial intelligence\n(AI)-inspired solutions are being developed to overcome the limitations of\nconventional mathematics-based approaches, which have proven inflexible when\ndealing with diverse forms of interference. In this paper, we advance this\ndirection by proposing a meta-learning framework that enables GNSS receivers to\ndetect various types of spoofers. Specifically, our approach exploits the radio\nfrequency fingerprints present in the signal at both the pre-correlation and\npost-correlation stages of the receiver. The proposed solution has superior\ngeneralization properties compared to the state-of-the-art solutions. Numerical\nresults demonstrate that our proposed solution significantly detects spoofers\nof different forms, with spoofing detection accuracies of more than 95% on\nmultiple datasets from the Texas Spoofing Test Battery (TEXBAT) and the Oak\nRidge Spoofing and Interference Test Battery (OAKBAT) repositories"}
{"id": "2511.00969", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2511.00969", "abs": "https://arxiv.org/abs/2511.00969", "authors": ["Benjamin Herb", "Rakesh Rao Ramachandra Rao", "Steve Göring", "Alexander Raake"], "title": "Evaluating Video Quality Metrics for Neural and Traditional Codecs using 4K/UHD-1 Videos", "comment": "Accepted for the 2025 Picture Coding Symposium (PCS)", "summary": "With neural video codecs (NVCs) emerging as promising alternatives for\ntraditional compression methods, it is increasingly important to determine\nwhether existing quality metrics remain valid for evaluating their performance.\nHowever, few studies have systematically investigated this using well-designed\nsubjective tests. To address this gap, this paper presents a subjective quality\nassessment study using two traditional (AV1 and VVC) and two variants of a\nneural video codec (DCVC-FM and DCVC-RT). Six source videos (8-10 seconds each,\n4K/UHD-1, 60 fps) were encoded at four resolutions (360p to 2160p) using nine\ndifferent QP values, resulting in 216 sequences that were rated in a controlled\nenvironment by 30 participants. These results were used to evaluate a range of\nfull-reference, hybrid, and no-reference quality metrics to assess their\napplicability to the induced quality degradations. The objective quality\nassessment results show that VMAF and AVQBits|H0|f demonstrate strong Pearson\ncorrelation, while FasterVQA performed best among the tested no-reference\nmetrics. Furthermore, PSNR shows the highest Spearman rank order correlation\nfor within-sequence comparisons across the different codecs. Importantly, no\nsignificant performance differences in metric reliability are observed between\ntraditional and neural video codecs across the tested metrics. The dataset,\nconsisting of source videos, encoded videos, and both subjective and quality\nmetric scores will be made publicly available following an open-science\napproach\n(https://github.com/Telecommunication-Telemedia-Assessment/AVT-VQDB-UHD-1-NVC)."}
{"id": "2511.00494", "categories": ["eess.SP", "cs.AI", "94-11", "H.4.3; I.6.3"], "pdf": "https://arxiv.org/pdf/2511.00494", "abs": "https://arxiv.org/abs/2511.00494", "authors": ["Ljupcho Milosheski", "Kuon Akiyama", "Blaž Bertalanič", "Jernej Hribar", "Ryoichi Shinkuma"], "title": "A Multimodal Dataset for Indoor Radio Mapping with 3D Point Clouds and RSSI", "comment": "11 pages, 7 figures, 3 tables, under review to Nature Scientific Data", "summary": "The growing number of smart devices supporting bandwidth-intensive and\nlatency-sensitive applications, such as real-time video analytics, smart\nsensing, and Extended Reality (XR), necessitates reliable wireless connectivity\nin indoor environments. Therein, accurate estimation of Radio Environment Maps\n(REMs) enables adaptive wireless network planning and optimization of Access\nPoint (AP) placement. However, generating realistic REMs remains challenging\ndue to the complexity of indoor spaces. To overcome this challenge, this paper\nintroduces a multimodal dataset that integrates high-resolution 3D LiDAR scans\nwith Wi-Fi Received Signal Strength Indicator (RSSI) measurements collected\nunder 20 distinct AP configurations in a multi-room indoor environment. The\ndataset captures two measurement scenarios: the first without human presence in\nthe environment, and the second with human presence. Thus, the presented\ndataset supports the study of dynamic environmental effects on wireless signal\npropagation. This resource is designed to facilitate research in data-driven\nwireless modeling, particularly in the context of emerging high-frequency\nstandards such as IEEE 802.11be (Wi-Fi 7), and aims to advance the development\nof robust, high-capacity indoor communication systems."}
{"id": "2511.01620", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2511.01620", "abs": "https://arxiv.org/abs/2511.01620", "authors": ["Piyush Narhari Pise", "Sanjay Ghosh"], "title": "Learned Adaptive Kernels for High-Fidelity Image Downscaling", "comment": "10 pages, 6 figures, and 3 tables", "summary": "Image downscaling is a fundamental operation in image processing, crucial for\nadapting high-resolution content to various display and storage constraints.\nWhile classic methods often introduce blurring or aliasing, recent\nlearning-based approaches offer improved adaptivity. However, achieving maximal\nfidelity against ground-truth low-resolution (LR) images, particularly by\naccounting for channel-specific characteristics, remains an open challenge.\nThis paper introduces ADK-Net (Adaptive Downscaling Kernel Network), a novel\ndeep convolutional neural network framework for high-fidelity supervised image\ndownscaling. ADK-Net explicitly addresses channel interdependencies by learning\nto predict spatially-varying, adaptive resampling kernels independently for\neach pixel and uniquely for each color channel (RGB). The architecture employs\na hierarchical design featuring a ResNet-based feature extractor and parallel\nchannel-specific kernel generators, themselves composed of ResNet-based trunk\nand branch sub-modules, enabling fine-grained kernel prediction. Trained\nend-to-end using an L1 reconstruction loss against ground-truth LR data,\nADK-Net effectively learns the target downscaling transformation. Extensive\nquantitative and qualitative experiments on standard benchmarks, including the\nRealSR dataset, demonstrate that ADK-Net establishes a new state-of-the-art in\nsupervised image downscaling, yielding significant improvements in PSNR and\nSSIM metrics compared to existing learning-based and traditional methods."}
{"id": "2511.00607", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.00607", "abs": "https://arxiv.org/abs/2511.00607", "authors": ["Tianyu Jiang", "Yan Yang", "Hongjin Liu", "Runyu Han", "Bo Ai", "Mohsen Guizani"], "title": "Fast Time-Varying mmWave Channel Estimation: A Rank-Aware Matrix Completion Approach", "comment": null, "summary": "We consider the problem of high-dimensional channel estimation in fast\ntime-varying millimeter-wave MIMO systems with a hybrid architecture. By\nexploiting the low-rank and sparsity properties of the channel matrix, we\npropose a two-phase compressed sensing framework consisting of observation\nmatrix completion and channel matrix sparse recovery, respectively. First, we\nformulate the observation matrix completion problem as a low-rank matrix\ncompletion (LRMC) problem and develop a robust rank-one matrix completion\n(R1MC) algorithm that enables the matrix and its rank to iteratively update.\nThis approach achieves high-precision completion of the observation matrix and\nexplicit rank estimation without prior knowledge. Second, we devise a\nrank-aware batch orthogonal matching pursuit (OMP) method for achieving\nlow-latency sparse channel recovery. To handle abrupt rank changes caused by\nuser mobility, we establish a discrete-time autoregressive (AR) model that\nleverages the temporal rank correlation between continuous-time instances to\nobtain a complete observation matrix capable of perceiving rank changes for\nmore accurate channel estimates. Simulation results confirm the effectiveness\nof the proposed channel estimation frame and demonstrate that our algorithms\nachieve state-of-the-art performance in low-rank matrix recovery with\ntheoretical guarantees."}
{"id": "2511.00721", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.00721", "abs": "https://arxiv.org/abs/2511.00721", "authors": ["Thanh Nha To", "Hoang Lai Pham", "Quynh Nguyen Thi", "Tuan Anh Pham", "Le Thanh Bang"], "title": "Fairness-Aware Secure Communication in ISAC Systems with STAR-RIS and RSMA", "comment": null, "summary": "In this paper, we investigate the integration of simultaneously transmitting\nand reflecting reconfigurable intelligent surfaces (STAR-RIS) with\nrate-splitting multiple access (RSMA) for improving physical layer security\n(PLS) in integrated sensing and communication (ISAC) systems. Specifically, we\nconsider a multi-user, multi-sensing target scenario, where each sensing target\nis treated as a potential eavesdropper, reflecting realistic deployment\nconditions. To enable fairness-aware secure communication among users while\nmaintaining sensing performance, we formulate a joint optimization problem that\ndesigns the base station beamforming vectors and STAR-RIS coefficients, aiming\nto maximize the minimum secrecy rate under a minimum beampattern gain\nconstraint. To solve the resulting non-convex problem, we propose an efficient\nalgorithm based on alternating optimization (AO) and the\nmajorization-minimization (MM) method. Simulation results verify the fast\nconvergence of the proposed algorithm and demonstrate significant improvements\nin secure communication performance."}
{"id": "2511.00779", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.00779", "abs": "https://arxiv.org/abs/2511.00779", "authors": ["Erfan Khordad", "Peter J. Smith", "Sachitha C. Bandara", "Rajitha Senanayake", "Robert W. Heath Jr"], "title": "Target Detection with Tightly-coupled Antennas: Analysis for Unknown Wideband Signals", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "This paper presents analysis for target detection using tightly-coupled\nantenna (TCA) arrays with high mutual coupling (MC). We show that the wide\noperational bandwidth of TCAs is advantageous for target detection. We assume a\nsensing receiver equipped with a TCA array that collects joint time and\nfrequency samples of the target's echo signals. Echoes are assumed to be\nunknown wideband signals, and noise at the TCA array follows a\nfrequency-varying correlation model due to MC. We also assume that the echo\nsignals are time varying, with no assumption on the temporal variation. We\nconsider three regimes in frequency as constant, slowly or rapidly varying, to\ncapture all possible spectral dynamics of the echoes. We propose a novel\ndetector for the slowly-varying regime, and derive detectors based on maximum\nlikelihood estimation (MLE) for the other regimes. For the rapidly-varying\nregime, we derive an extended energy detector for correlated noise with\nfrequency and time samples. We analyze the performance of all the detectors. We\nalso derive and analyze an ideal detector giving an upper bound on performance.\nWe validate our analysis with simulations and demonstrate that our proposed\ndetector outperforms the MLE-based detectors in terms of robustness to\nfrequency variation. Also, we highlight that TCA arrays offer clear advantages\nover weakly-coupled antenna arrays in target detection."}
{"id": "2511.00878", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.00878", "abs": "https://arxiv.org/abs/2511.00878", "authors": ["Ahmed Magbool", "Vaibhav Kumar", "Marco Di Renzo", "Mark F. Flanagan"], "title": "Stacked Flexible Intelligent Metasurface Design for Multi-User Wireless Communications", "comment": "Submitted to IEEE for possible publication", "summary": "Stacked intelligent metasurfaces (SIMs) have recently emerged as an effective\nsolution for next-generation wireless networks. A SIM comprises multiple\nmetasurface layers that enable signal processing directly in the wave domain.\nMoreover, recent advances in flexible metamaterials have highlighted the\npotential of flexible intelligent metasurfaces (FIMs), which can be physically\nmorphed to enhance communication performance. In this paper, we propose a\nstacked flexible intelligent metasurface (SFIM)-based communication system for\nthe first time, where each metasurface layer is deformable to improve the\nsystem's performance. We first present the system model, including the transmit\nand receive signal models as well as the channel model, and then formulate an\noptimization problem to maximize the system sum rate under constraints on the\ntransmit power budget, morphing distance, and the unit-modulus condition of the\nmeta-atom responses. To solve this problem, we develop an alternating\noptimization framework based on the gradient projection method. Simulation\nresults demonstrate that the proposed SFIM-based system achieves significant\nperformance gains compared to its rigid SIM counterpart."}
{"id": "2511.00919", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00919", "abs": "https://arxiv.org/abs/2511.00919", "authors": ["Mahdi Maleki", "Reza Agahzadeh Ayoubi", "Marouan Mizmizi", "Umberto Spagnolini"], "title": "Towards Channel Charting Enhancement with Non-Reconfigurable Intelligent Surfaces", "comment": null, "summary": "We investigate how fully-passive electromagnetic skins (EMSs) can be\nengineered to enhance channel charting (CC) in dense urban environments. We\nemploy two complementary state-of-the-art CC techniques, semi-supervised\nt-distributed stochastic neighbor embedding (t-SNE) and a semi-supervised\nAutoencoder (AE), to verify the consistency of results across nonparametric and\nparametric mappings. We show that the accuracy of CC hinges on a balance\nbetween signal-to-noise ratio (SNR) and spatial dissimilarity: EMS codebooks\nthat only maximize gain, as in conventional Reconfigurable Intelligent Surface\n(RIS) optimization, suppress location fingerprints and degrade CC, while\nrandomized phases increase diversity but reduce SNR. To address this trade-off,\nwe design static EMS phase profiles via a quantile-driven criterion that\ntargets worst-case users and improves both trustworthiness and continuity. In a\n3D ray-traced city at 30 GHz, the proposed EMS reduces the 90th-percentile\nlocalization error from > 50 m to < 25 m for both t-SNE and AE-based CC, and\ndecreases severe trajectory dropouts by over 4x under 15% supervision. The\nimprovements hold consistently across the evaluated configurations,\nestablishing static, pre-configured EMS as a practical enabler of CC without\nreconfiguration overheads."}
{"id": "2511.00943", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.00943", "abs": "https://arxiv.org/abs/2511.00943", "authors": ["Yangyang Zhao", "Matti Kaisti", "Olli Lahdenoja", "Jonas Sandelin", "Arman Anzanpour", "Joonas Lehto", "Joel Nuotio", "Jussi Jaakkola", "Arto Relander", "Tuija Vasankari", "Juhani Airaksinen", "Tuomas Kiviniemi", "Tero Koivisto"], "title": "Lightweight ResNet-Based Deep Learning for Photoplethysmography Signal Quality Assessment", "comment": "Accepted for presentation at IEEE Engineering in Medicine and Biology\n  Conference (EMBC 2025). 7 pages, 3 figures. Author's accepted manuscript\n  (AAM). The final version will appear in IEEE Xplore", "summary": "With the growing application of deep learning in wearable devices,\nlightweight and efficient models are critical to address the computational\nconstraints in resource-limited platforms. The performance of these approaches\ncan be potentially improved by using various preprocessing methods. This study\nproposes a lightweight ResNet-based deep learning framework with\nSqueeze-and-Excitation (SE) modules for photoplethysmography (PPG) signal\nquality assessment (SQA) and compares different input configurations, including\nthe PPG signal alone, its first derivative (FDP), its second derivative (SDP),\nthe autocorrelation of PPG (ATC), and various combinations of these channels.\nExperimental evaluations on the Moore4Medical (M4M) and MIMIC-IV datasets\ndemonstrate the model's performance, achieving up to 96.52% AUC on the M4M test\ndataset and up to 84.43% AUC on the MIMIC-IV dataset. The novel M4M dataset was\ncollected to explore PPG-based monitoring for detecting atrial fibrillation\n(AF) and AF burden in high-risk patients. Compared to the five reproduced\nexisting studies, our models achieves over 99% reduction in parameters and more\nthan 60% reduction in floating-point operations (FLOPs)."}
{"id": "2511.00966", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.00966", "abs": "https://arxiv.org/abs/2511.00966", "authors": ["Andrea De Simone", "Noemi Giordano", "Silvia Seoni", "Kristen M. Meiburger", "Fabrizio Riente"], "title": "Optimizing Uncertainty-Aware Deep Learning for On-the-Edge Murmur Detection in Low-Resource Settings", "comment": null, "summary": "Early and reliable detection of heart murmurs is essential for the timely\ndiagnosis of cardiovascular diseases, yet traditional auscultation remains\nsubjective and dependent on expert interpretation. This work investigates\nartificial intelligence (AI)-based murmur detection using the CirCor Heart\nSound dataset, with a focus on enabling uncertainty-aware, resource-efficient\ndeployment on edge devices. Three convolutional neural network (CNN)\narchitectures of increasing complexity (Light, Baseline, and Heavy) were\ncompared in terms of classification performance, computational cost, and\nsuitability for on-device inference. Additionally, Monte Carlo Dropout was\napplied for uncertainty estimation, providing confidence measures to improve\nprediction sensitivity. Results show that lightweight models can achieve\naccuracy comparable to deeper networks (91%) while requiring two orders of\nmagnitude fewer parameters. Incorporating uncertainty-based selective\nclassification further improved sensitivity by 3%, enhancing robustness and\nclinical reliability. The findings highlight the feasibility of developing\ncomputationally efficient, uncertainty-aware AI systems for heart murmur\nscreening in low-resource and remote healthcare settings."}
{"id": "2511.01023", "categories": ["eess.SP", "cs.AI", "cs.CR", "cs.LG", "68T07, 68P25, 94A60, 68Q32, 68Q87, 94A17", "I.2.6; C.2.0; D.4.6; E.3; I.5.1; K.6.5"], "pdf": "https://arxiv.org/pdf/2511.01023", "abs": "https://arxiv.org/abs/2511.01023", "authors": ["Ayşe Selin Okatan", "Mustafa İlhan Akbaş", "Laxima Niure Kandel", "Berker Peköz"], "title": "Seed-Induced Uniqueness in Transformer Models: Subspace Alignment Governs Subliminal Transfer", "comment": "Cite as A. S. Okatan, M. I. Akba\\c{s}, L. N. Kandel, and B. Pek\\\"oz,\n  \"Seed-Induced Uniqueness in Transformer Models: Subspace Alignment Governs\n  Subliminal Transfer,\" in Proc. 2025 Cyber Awareness and Research Symp. (IEEE\n  CARS 2025), Grand Forks, ND, Oct. 2025, pp. 6", "summary": "We analyze subliminal transfer in Transformer models, where a teacher embeds\nhidden traits that can be linearly decoded by a student without degrading\nmain-task performance. Prior work often attributes transferability to global\nrepresentational similarity, typically quantified with Centered Kernel\nAlignment (CKA). Using synthetic corpora with disentangled public and private\nlabels, we distill students under matched and independent random\ninitializations. We find that transfer strength hinges on alignment within a\ntrait-discriminative subspace: same-seed students inherit this alignment and\nshow higher leakage {\\tau \\approx} 0.24, whereas different-seed\nstudents--despite global CKA > 0.9--exhibit substantially reduced excess\naccuracy {\\tau \\approx} 0.12 - 0.13. We formalize this with subspace-level CKA\ndiagnostic and residualized probes, showing that leakage tracks alignment\nwithin the trait-discriminative subspace rather than global representational\nsimilarity. Security controls (projection penalty, adversarial reversal,\nright-for-the-wrong-reasons regularization) reduce leakage in same-base models\nwithout impairing public-task fidelity. These results establish seed-induced\nuniqueness as a resilience property and argue for subspace-aware diagnostics\nfor secure multi-model deployments."}
{"id": "2511.01099", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.01099", "abs": "https://arxiv.org/abs/2511.01099", "authors": ["Zhenqiao Cheng", "Chongjun Ouyang", "Nicola Marchetti"], "title": "On the Performance of Tri-Hybrid Beamforming Using Pinching Antennas", "comment": "6 pages", "summary": "The Pinching-Antenna System (PASS) reconfigures wireless channels through\n\\emph{pinching beamforming}, in which the active positions of pinching antennas\n(PAs) along dielectric waveguides are optimized to shape the radiation pattern.\nThis article investigates the performance of PASS-enabled tri-hybrid\nbeamforming, where pinched waveguides are integrated with a hybrid\ndigital-analog beamformer to mitigate path loss and enhance spectral\nefficiency. The channel capacity of the proposed system is characterized by\nderiving the optimal tri-hybrid beamformer at both the digital and analog\ndomains, as well as the optimal placement of PAs. Closed-form upper and lower\nbounds of the channel capacity are obtained, leading to a capacity scaling law\nwith respect to the number of PAs. Numerical results verify the tightness of\nthe derived bounds and demonstrate that applying PASS to tri-hybrid beamforming\nyields a significant performance gain over conventional hybrid beamforming\nunder the same number of radio-frequency chains."}
{"id": "2511.01254", "categories": ["eess.SP", "cs.NE"], "pdf": "https://arxiv.org/pdf/2511.01254", "abs": "https://arxiv.org/abs/2511.01254", "authors": ["Huseyin Goksu"], "title": "Hi-WaveTST: A Hybrid High-Frequency Wavelet-Transformer for Time-Series Classification", "comment": null, "summary": "Transformers have become state-of-the-art (SOTA) for time-series\nclassification, with models like PatchTST demonstrating exceptional\nperformance. These models rely on patching the time series and learning\nrelationships between raw temporal data blocks. We argue that this approach is\nblind to critical, non-obvious high-frequency information that is complementary\nto the temporal dynamics. In this letter, we propose Hi-WaveTST, a novel Hybrid\narchitecture that augments the original temporal patch with a learnable,\nHigh-Frequency wavelet feature stream. Our wavelet stream uses a deep Wavelet\nPacket Decomposition (WPD) on each patch and extracts features using a\nlearnable Generalized Mean (GeM) pooling layer. On the UCI-HAR benchmark\ndataset, our hybrid model achieves a mean accuracy of 93.38 percent plus-minus\n0.0043, significantly outperforming the SOTA PatchTST baseline (92.59 percent\nplus-minus 0.0039). A comprehensive ablation study proves that every component\nof our design-the hybrid architecture, the deep high-frequency wavelet\ndecomposition, and the learnable GeM pooling-is essential for this\nstate-of-the-art performance."}
{"id": "2511.01371", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.01371", "abs": "https://arxiv.org/abs/2511.01371", "authors": ["Sagar Dutta", "Banani Basu", "Fazal Ahmed Talukdar"], "title": "Classification of motor faults based on transmission coefficient and reflection coefficient of omni-directional antenna using DCNN", "comment": null, "summary": "The most commonly used electrical rotary machines in the field are induction\nmachines. In this paper, we propose an antenna based approach for the\nclassification of motor faults in induction motors using the reflection\ncoefficient S11 and the transmission coefficient S21 of the antenna. The\nspectrograms of S11 and S21 are seen to possess unique signatures for various\nfault conditions that are used for the classification. To learn the required\ncharacteristics and classification boundaries, deep convolution neural network\n(DCNN) is applied to the spectrogram of the S-parameter. DCNN has been found to\nreach classification accuracy 93% using S11, 98.1% using S21 and 100% using\nboth S11 and S21. The effect of antenna operating frequency, its location and\nduration of signal on the classification accuracy is also presented and\ndiscussed."}
{"id": "2511.01398", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.01398", "abs": "https://arxiv.org/abs/2511.01398", "authors": ["Wang Hao", "Kuang Zhang", "Hou Chengyu", "Tan Chenxing", "Cui Weiming", "Fu Weifeng", "Yao Xinran"], "title": "CRMD: Complex Robust Modal Decomposition", "comment": null, "summary": "Compared to real-valued signals, complex-valued signals provide a unique and\nintuitive representation of the phase of real physical systems and processes,\nwhich holds fundamental significance and is widely applied across many fields\nof science and engineering. In this paper, we propose a robust modal\ndecomposition (RMD) in the complex domain as a natural and general extension of\nthe original real-valued RMD. We revisit and derive the mathematical principles\nof RMD in the complex domain, and develop an algorithmic version tailored for\nthis domain. Extensive experiments are conducted on synthetic simulation\ndatasets and real-world datasets from diverse fields, including a\nmillimeter-wave radar physiological signal detection dataset, a faulty bearing\ndataset, a radio-frequency unmanned aerial vehicle identification dataset, and\na WiFi CSI-based respiration detection dataset. The results demonstrate that\nthe proposed complex-domain robust modal decomposition significantly improves\nperformance across these various applications."}
{"id": "2511.01405", "categories": ["eess.SP", "cs.ET"], "pdf": "https://arxiv.org/pdf/2511.01405", "abs": "https://arxiv.org/abs/2511.01405", "authors": ["Vanessa Wirth", "Johanna Bräunig", "Martin Vossiek", "Tim Weyrich", "Marc Stamminger"], "title": "MM-2FSK: Multimodal Frequency Shift Keying for Ultra-Efficient and Robust High-Resolution MIMO Radar Imaging", "comment": "9 pages", "summary": "Accurate reconstruction of static and rapidly moving targets demands\nthree-dimensional imaging solutions with high temporal and spatial resolution.\nRadar sensors are a promising sensing modality because of their fast capture\nrates and their independence from lighting conditions. To achieve high spatial\nresolution, MIMO radars with large apertures are required. Yet, they are\ninfrequently used for dynamic scenarios due to significant limitations in\nsignal processing algorithms. These limitations impose substantial hardware\nconstraints due to their computational intensity and reliance on large signal\nbandwidths, ultimately restricting the sensor's capture rate.\n  One solution of previous work is to use few frequencies only, which enables\nfaster capture and requires less computation; however, this requires coarse\nknowledge of the target's position and works in a limited depth range only. To\naddress these challenges, we extend previous work into the multimodal domain\nwith MM-2FSK, which leverages an assistive optical depth sensing modality to\nobtain a depth prior, enabling high framerate capture with only few\nfrequencies.\n  We evaluate our method using various target objects with known ground truth\ngeometry that is spatially registered to real millimeter-wave MIMO radar\nmeasurements. Our method demonstrates superior performance in terms of depth\nquality, being able to compete with the time- and resource-intensive\nmeasurements with many frequencies."}
{"id": "2511.01406", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.01406", "abs": "https://arxiv.org/abs/2511.01406", "authors": ["Abolfazl Zakeri", "Nhan Thanh Nguyen", "Ahmed Alkhateeb", "Markku Juntti"], "title": "AoI-Aware Machine Learning for Constrained Multimodal Sensing-Aided Communications", "comment": "Submitted to an IEEE conference", "summary": "Using environmental sensory data can enhance communications beam training and\nreduce its overhead compared to conventional methods. However, the availability\nof fresh sensory data during inference may be limited due to sensing\nconstraints or sensor failures, necessitating a realistic model for multimodal\nsensing. This paper proposes a joint multimodal sensing and beam prediction\nframework that operates under a constraint on the average sensing rate, i.e.,\nhow often fresh sensory data should be obtained. The proposed method combines\ndeep reinforcement learning, i.e., a deep Q-network (DQN), with a neural\nnetwork (NN)-based beam predictor. The DQN determines the sensing decisions,\nwhile the NN predicts the best beam from the codebook. To capture the effect of\nlimited fresh data during inference, the age of information (AoI) is\nincorporated into the training of both the DQN and the beam predictor. Lyapunov\noptimization is employed to design a reward function that enforces the average\nsensing constraint. Simulation results on a real-world dataset show that\nAoI-aware training improves top-1 and top-3 inference accuracy by 44.16% and\n52.96%, respectively, under a strict sensing constraint. The performance gain,\nhowever, diminishes as the sensing constraint is relaxed."}
{"id": "2511.01431", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.01431", "abs": "https://arxiv.org/abs/2511.01431", "authors": ["Simin Zhu", "Satish Ravindran", "Lihui Chen", "Alexander Yarovoy", "Francesco Fioranelli"], "title": "Robust Radar Mounting Angle Estimation in Operational Driving Conditions", "comment": "10 pages, 6 figures, under review at IEEE Transactions on Radar\n  Systems", "summary": "The robust estimation of the mounting angle for millimeter-wave automotive\nradars installed on moving vehicles is investigated. We propose a novel signal\nprocessing pipeline that combines radar and inertial measurement unit (IMU)\ndata to achieve accurate and reliable performance in realistic driving\nscenarios. Unlike previous studies, the method employs neural networks to\nprocess sparse and noisy radar measurements, reject detections from moving\nobjects, and estimate radar motion. In addition, a measurement model is\nintroduced to correct IMU bias and scale factor errors. Using vehicle\nkinematics, the radar mounting angle is then computed from the estimated radar\nmotion and the vehicle's yaw rate. To benchmark performance, the proposed\napproach is comprehensively compared with two problem formulations and four\nestimation techniques reported in the literature. Validation is carried out on\nthe challenging RadarScenes dataset, covering over 79 km of real-world driving.\nResults show that the proposed method achieves state-of-the-art accuracy and\nrobustness, with reliable estimates obtained within approximately 25 seconds of\ndriving. To the best of our knowledge, this is the first study to demonstrate\nthat automotive radar mounting angles can be accurately estimated in complex,\nreal traffic conditions, without requiring controlled environments, dedicated\ntargets, or specially designed driving routes."}
{"id": "2511.01575", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.01575", "abs": "https://arxiv.org/abs/2511.01575", "authors": ["Marjan Boloori", "Chu Li", "Aydin Sezgin"], "title": "Optimizing Movable Antenna Position and Transmissive RIS Phase for Efficient Base Station Design", "comment": null, "summary": "Movable antennas (MA) and transmissive reconfigurable intelligent surfaces\n(TRIS) represent two innovative technologies that significantly enhance the\nflexibility of wireless communication systems. In this paper, we propose a\nnovel and compact base station architecture that synergistically integrates a\nmovable antenna with a transmissive RIS in the near field, enabling joint\noptimization of antenna positioning and TRIS phase adjustments. The proposed\nmodel compensates for phase quantization loss and significantly enhances signal\nstrength, even with low-resolution (1-2 bit) phase shifters. Leveraging this\nframework, we systematically evaluate system performance as a function of TRIS\nsize and antenna placement. Our results indicate that antenna mobility provides\nan additional degree of freedom to enhance the desired signal and achieve a\nhigher SNR, particularly when combined with TRIS capabilities. These findings\ndemonstrate that MA-TRIS integration offers a cost-effective and\nenergy-efficient pathway toward compact 6G base stations, combining hardware\nsimplicity with strong performance gains."}
{"id": "2511.01599", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.01599", "abs": "https://arxiv.org/abs/2511.01599", "authors": ["M. Ertug Pihtili", "Julia Equi", "Ossi Kaltiokallio", "Jukka Talvitie", "Elena Simona Lohan", "Ertugrul Basar", "Mikko Valkama"], "title": "Clutter Suppression in Bistatic ISAC with Joint Angle and Doppler Estimation", "comment": null, "summary": "The coexistence of radar and communications in wireless systems marks a\nparadigm shift for the sixth-generation (6G) networks. As 6G systems are\nexpected to operate at higher frequencies and employ larger antenna arrays than\nfifth-generation (5G) systems, they can also enable more accurate sensing\ncapabilities. To this end, the integrated sensing and communication (ISAC)\nparadigm aims to unify the physical and radio frequency (RF) domains by\nintroducing the sensing functionality into the communication network. However,\nthe clutter poses a challenge, as it can significantly degrade the sensing\naccuracy in ISAC systems. This paper presents a novel two-dimensional root\nmultiple signal classification (2D-rootMUSIC)-based algorithm for static\nbackground clutter suppression. Computer simulation results indicate that the\nproposed method effectively mitigates the strong background clutter, yields\naccurate parameter estimation performance, and offers a notable improvement in\nthe signal-to-clutter-and-noise ratio (SCNR), while outperforming the prior-art\nbenchmark methods."}
{"id": "2511.01747", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.01747", "abs": "https://arxiv.org/abs/2511.01747", "authors": ["Guangkun Nie", "Gongzheng Tang", "Yujie Xiao", "Jun Li", "Shun Huang", "Deyun Zhang", "Qinghao Zhao", "Shenda Hong"], "title": "AnyPPG: An ECG-Guided PPG Foundation Model Trained on Over 100,000 Hours of Recordings for Holistic Health Profiling", "comment": null, "summary": "Background: Photoplethysmography (PPG) offers a noninvasive and accessible\nmodality for health monitoring beyond clinical settings. However, existing\nstudies are limited by the scale and diversity of labeled data, constraining\nmodel accuracy, generalizability, and the exploration of broader applications.\nThis study investigates the potential of PPG for holistic health profiling\nthrough the integration of foundation model techniques.\n  Methods: We present AnyPPG, a PPG foundation model pretrained on large-scale,\nmulti-source synchronized PPG-ECG data. By aligning PPG and ECG representations\nwithin a shared space, AnyPPG learns physiologically meaningful features from\nunlabeled signals. Its capability was further evaluated across a diverse set of\ndownstream tasks, encompassing both conventional physiological analysis and\ncomprehensive multi-organ disease diagnosis.\n  Results: Across eleven physiological analysis tasks spanning six independent\ndatasets, AnyPPG achieved state-of-the-art performance, with average\nimprovements of 12.8% in regression and 9.1% in classification tasks over the\nnext-best model. In multi-organ disease diagnosis, AnyPPG demonstrated broad\ncross-system diagnostic potential. Among 1,014 ICD-10 three-digit disease\ncategories, 13 achieved an AUC above 0.8 and 137 exceeded 0.7. Beyond strong\nperformance in cardiovascular diseases such as heart failure, valvular\ndisorders, and hypertension, AnyPPG also showed substantial diagnostic value\nfor non-cardiovascular conditions, exemplified by Parkinson's disease (AUC =\n0.78) and chronic kidney disease (AUC = 0.74).\n  Conclusions: AnyPPG demonstrates that a PPG foundation model trained through\nphysiological alignment with ECG can produce accurate and robust signal\nrepresentations. Building on this capability, it underscores the potential of\nPPG as a modality for comprehensive assessment of systemic and multi-organ\nhealth."}
{"id": "2511.01780", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.01780", "abs": "https://arxiv.org/abs/2511.01780", "authors": ["Quan Gao", "Shuai S. A. Yuan", "Zhanwen Wang", "Wanchen Yang", "Chongwen Huang", "Xiaoming Chen", "Wei E. I. Sha"], "title": "On Systematic Performance of 3-D Holographic MIMO: Clarke, Kronecker, and 3GPP Models", "comment": "11 pages, 17 figures, submitted to Electromagnetic Science", "summary": "Holographic multiple-input multiple-output (MIMO) has emerged as a key\nenabler for 6G networks, yet conventional planar implementations suffer from\nspatial correlation and mutual coupling at sub-wavelength spacing, which\nfundamentally limit the effective degrees of freedom (EDOF) and channel\ncapacity. Three-dimensional (3-D) holographic MIMO offers a pathway to overcome\nthese constraints by exploiting volumetric array configurations that enlarge\nthe effective aperture and unlock additional spatial modes. This work presents\nthe first systematic evaluation that jointly incorporates electromagnetic (EM)\ncharacteristics, such as mutual coupling and radiation efficiency, into the\nanalysis of 3-D arrays under Clarke, Kronecker, and standardized 3rd Generation\nPartnership Project (3GPP) channel models. Analytical derivations and full-wave\nsimulations demonstrate that 3-D architectures achieve higher EDOF, narrower\nbeamwidths, and notable capacity improvements compared with planar baselines.\nIn 3GPP urban macro channels with horizontal element spacing of 0.3 lambda, 3-D\nconfigurations yield approximately 20% capacity improvement over conventional\n2-D arrays, confirming the robustness and scalability of volumetric designs\nunder realistic conditions. These findings bridge the gap between theoretical\nfeasibility and practical deployment, offering design guidance for\nnext-generation 6G base station arrays."}
{"id": "2511.01787", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.01787", "abs": "https://arxiv.org/abs/2511.01787", "authors": ["David Nozadze", "Zurab Kiguradze", "Amendra Koul", "Sayed Ashraf Mamun", "Mike Sapozhnikov"], "title": "Practical Approaches to Quantifying Intra-Pair Skew Impact via Insertion Loss Deviation", "comment": null, "summary": "The surge in AI workloads and escalating data center requirements have\ncreated demand for ultra-high-speed interconnects exceeding 200 Gb/s. As unit\nintervals (UI) shrink, even a few picoseconds of intra-pair skew can\nsignificantly degrade serializer-deserializer (SerDes) performance. To quantify\nthe impact of intra-pair skew, conventional time-domain methods are often\nunreliable for coupled interconnects due to skew variations across voltage\nlevels, while frequency-domain approaches frequently fail to address\nreciprocity and symmetry issues. This can result in channels that meet skew\nspecifications in one direction but not the other, despite the inherently\nreciprocal nature of skew impact. To address these limitations, we introduce\ntwo new reciprocal parameters for quantifying intra-pair skew effects:\nSkew-Induced Insertion Loss Deviation (SILD) and its complementary Figure of\nMerit (FOM SILD). Measurements conducted using 224 Gb/s SerDes IP and a variety\nof channels with different intra-pair skews demonstrate a strong correlation\nbetween FOM SILD and bit error rate (BER). Results show that when FOM SILD is\nbelow 0.2-0.3 dB, BER remains stable, indicating minimal signal integrity\ndegradation; however, BER increases noticeably as FOM SILD exceeds 0.3 dB.\nStatistical analysis across more than 3,000 high-speed twinax cables reveals\nthat the majority exhibit FOM SILD values less than 0.1 dB, underscoring the\npractical relevance of the proposed metrics for high-speed interconnect\nassessment."}
