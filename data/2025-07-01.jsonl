{"id": "2506.22448", "categories": ["eess.SP", "cs.AI", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2506.22448", "abs": "https://arxiv.org/abs/2506.22448", "authors": ["Yu Ma", "Xingyu Zhou", "Xiao Li", "Le Liang", "Shi Jin"], "title": "Unsupervised Learning-Based Joint Resource Allocation and Beamforming Design for RIS-Assisted MISO-OFDMA Systems", "comment": "Due to the limitation \"The abstract field cannot be longer than 1,920\n  characters\", the abstract here is shorter than that in the PDF file", "summary": "Reconfigurable intelligent surfaces (RIS) are key enablers for 6G wireless\nsystems. This paper studies downlink transmission in an RIS-assisted MISO-OFDMA\nsystem, addressing resource allocation challenges. A two-stage unsupervised\nlearning-based framework is proposed to jointly design RIS phase shifts, BS\nbeamforming, and resource block (RB) allocation. The framework includes\nBeamNet, which predicts RIS phase shifts from CSI, and AllocationNet, which\nallocates RBs using equivalent CSI derived from BeamNet outputs. Active\nbeamforming is implemented via maximum ratio transmission and water-filling. To\nhandle discrete constraints while ensuring differentiability, quantization and\nthe Gumbel-softmax trick are adopted. A customized loss and phased training\nenhance performance under QoS constraints. Simulations show the method achieves\n99.93% of the sum rate of the SCA baseline with only 0.036% of its runtime, and\nit remains robust across varying channel and user conditions."}
{"id": "2506.22454", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.22454", "abs": "https://arxiv.org/abs/2506.22454", "authors": ["Ana Luiza S. Tavares", "Artur Pedro M. Neto", "Francinaldo L. Gomes", "Paul Rodrigo dos Reis", "Arthur G. da Silva", "Antonio P. Junior", "Bruno D. Gomes"], "title": "Microelectrode Signal Dynamics as Biomarkers of Subthalamic Nucleus Entry on Deep Brain Stimulation: A Nonlinear Feature Approach", "comment": "8 pages, 5 figures", "summary": "Accurate intraoperative localization of the subthalamic nucleus (STN) is\nessential for the efficacy of Deep Brain Stimulation (DBS) in patients with\nParkinson's disease. While microelectrode recordings (MERs) provide rich\nelectrophysiological information during DBS electrode implantation, current\nlocalization practices often rely on subjective interpretation of signal\nfeatures. In this study, we propose a quantitative framework that leverages\nnonlinear dynamics and entropy-based metrics to classify neural activity\nrecorded inside versus outside the STN. MER data from three patients were\npreprocessed using a robust artifact correction pipeline, segmented, and\nlabelled based on surgical annotations. A comprehensive set of recurrence\nquantification analysis, nonlinear, and entropy features were extracted from\neach segment. Multiple supervised classifiers were trained on every combination\nof feature domains using stratified 10-fold cross-validation, followed by\nstatistical comparison using paired Wilcoxon signed-rank tests with\nHolm-Bonferroni correction. The combination of entropy and nonlinear features\nyielded the highest discriminative power, and the Extra Trees classifier\nemerged as the best model with a cross-validated F1-score of 0.902+/-0.027 and\nROC AUC of 0.887+/-0.055. Final evaluation on a 20% hold-out test set confirmed\nrobust generalization (F1= 0.922, ROC AUC = 0.941). These results highlight the\npotential of nonlinear and entropy signal descriptors in supporting real-time,\ndata-driven decision-making during DBS surgeries"}
{"id": "2506.22455", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.22455", "abs": "https://arxiv.org/abs/2506.22455", "authors": ["Dung Truong", "Arnaud Delorme"], "title": "Data Normalization Strategies for EEG Deep Learning", "comment": null, "summary": "Normalization is a critical yet often overlooked component in the\npreprocessing pipeline for EEG deep learning applications. The rise of\nlarge-scale pretraining paradigms such as self-supervised learning (SSL)\nintroduces a new set of tasks whose nature is substantially different from\nsupervised training common in EEG deep learning applications. This raises new\nquestions about optimal normalization strategies for the applicable task. In\nthis study, we systematically evaluate the impact of normalization granularity\n(recording vs. window level) and scope (cross-channel vs. within-channel) on\nboth supervised (age and gender prediction) and self-supervised (Contrastive\nPredictive Coding) tasks. Using high-density resting-state EEG from 2,836\nsubjects in the Healthy Brain Network dataset, we show that optimal\nnormalization strategies differ significantly between training paradigms.\nWindow-level within-channel normalization yields the best performance in\nsupervised tasks, while minimal or cross-channel normalization at the window\nlevel is more effective for SSL. These results underscore the necessity of\ntask-specific normalization choices and challenge the assumption that a\nuniversal normalization strategy can generalize across learning settings. Our\nfindings provide practical insights for developing robust EEG deep learning\npipelines as the field shifts toward large-scale, foundation model training."}
{"id": "2506.22456", "categories": ["eess.SP", "eess.IV"], "pdf": "https://arxiv.org/pdf/2506.22456", "abs": "https://arxiv.org/abs/2506.22456", "authors": ["Rahul Gulia", "Amlan Ganguly", "Andres Kwasinski", "Michael E. Kuhl", "Ehsan Rashedi", "Clark Hochgraf"], "title": "WISVA: Generative AI for 5G Network Optimization in Smart Warehouses", "comment": null, "summary": "The next decade will usher in a profound transformation of wireless\ncommunication, driven by the ever-increasing demand for data-intensive\napplications and the rapid adoption of emerging technologies. To fully unlock\nthe potential of 5G and beyond, substantial advancements are required in signal\nprocessing techniques, innovative network architectures, and efficient spectrum\nutilization strategies. These advancements facilitate seamless integration of\nemerging technologies, driving industrial digital transformation and\nconnectivity. This paper introduces a novel Variational Autoencoder (VAE)-based\nframework, Wireless Infrastructure for Smart Warehouses using VAE (WISVA),\ndesigned for accurate indoor radio propagation modeling in automated Industry\n4.0 environments such as warehouses and factory floors operating within 5G\nwireless bands. The research delves into the meticulous creation of training\ndata tensors, capturing complex electromagnetic (EM) wave behaviors influenced\nby diverse obstacles, and outlines the architecture and training methodology of\nthe proposed VAE model. The model's robustness and adaptability are showcased\nthrough its ability to predict signal-to-interference-plus-noise ratio (SINR)\nheatmaps across various scenarios, including denoising tasks, validation\ndatasets, extrapolation to unseen configurations, and previously unencountered\nwarehouse layouts. Compelling reconstruction error heatmaps are presented,\nhighlighting the superior accuracy of WISVA compared to traditional autoencoder\nmodels. The paper also analyzes the model's performance in handling complex\nsmart warehouse environments, demonstrating its potential as a key enabler for\noptimizing wireless infrastructure in Industry 4.0."}
{"id": "2506.22532", "categories": ["eess.IV", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.22532", "abs": "https://arxiv.org/abs/2506.22532", "authors": ["Mark Wrobel", "Michele Pascale", "Tina Yao", "Ruaraidh Campbell", "Elena Milano", "Michael Quail", "Jennifer Steeden", "Vivek Muthurangu"], "title": "High Resolution Isotropic 3D Cine imaging with Automated Segmentation using Concatenated 2D Real-time Imaging and Deep Learning", "comment": null, "summary": "Background: Conventional cardiovascular magnetic resonance (CMR) in\npaediatric and congenital heart disease uses 2D, breath-hold, balanced steady\nstate free precession (bSSFP) cine imaging for assessment of function and\ncardiac-gated, respiratory-navigated, static 3D bSSFP whole-heart imaging for\nanatomical assessment. Our aim is to concatenate a stack 2D free-breathing\nreal-time cines and use Deep Learning (DL) to create an isotropic a fully\nsegmented 3D cine dataset from these images. Methods: Four DL models were\ntrained on open-source data that performed: a) Interslice contrast correction;\nb) Interslice respiratory motion correction; c) Super-resolution (slice\ndirection); and d) Segmentation of right and left atria and ventricles (RA, LA,\nRV, and LV), thoracic aorta (Ao) and pulmonary arteries (PA). In 10 patients\nundergoing routine cardiovascular examination, our method was validated on\nprospectively acquired sagittal stacks of real-time cine images. Quantitative\nmetrics (ventricular volumes and vessel diameters) and image quality of the 3D\ncines were compared to conventional breath hold cine and whole heart imaging.\nResults: All real-time data were successfully transformed into 3D cines with a\ntotal post-processing time of <1 min in all cases. There were no significant\nbiases in any LV or RV metrics with reasonable limits of agreement and\ncorrelation. There is also reasonable agreement for all vessel diameters,\nalthough there was a small but significant overestimation of RPA diameter.\nConclusion: We have demonstrated the potential of creating a 3D-cine data from\nconcatenated 2D real-time cine images using a series of DL models. Our method\nhas short acquisition and reconstruction times with fully segmented data being\navailable within 2 minutes. The good agreement with conventional imaging\nsuggests that our method could help to significantly speed up CMR in clinical\npractice."}
{"id": "2506.22457", "categories": ["eess.SP", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22457", "abs": "https://arxiv.org/abs/2506.22457", "authors": ["Iulia Orvas", "Andrei Radu", "Alessandra Galli", "Ana Neacsu", "Elisabetta Peri"], "title": "A Complex UNet Approach for Non-Invasive Fetal ECG Extraction Using Single-Channel Dry Textile Electrodes", "comment": null, "summary": "Continuous, non-invasive pregnancy monitoring is crucial for minimising\npotential complications. The fetal electrocardiogram (fECG) represents a\npromising tool for assessing fetal health beyond clinical environments.\nHome-based monitoring necessitates the use of a minimal number of comfortable\nand durable electrodes, such as dry textile electrodes. However, this setup\npresents many challenges, including increased noise and motion artefacts, which\ncomplicate the accurate extraction of fECG signals. To overcome these\nchallenges, we introduce a pioneering method for extracting fECG from\nsingle-channel recordings obtained using dry textile electrodes using AI\ntechniques. We created a new dataset by simulating abdominal recordings,\nincluding noise closely resembling real-world characteristics of in-vivo\nrecordings through dry textile electrodes, alongside mECG and fECG. To ensure\nthe reliability of the extracted fECG, we propose an innovative pipeline based\non a complex-valued denoising network, Complex UNet. Unlike previous approaches\nthat focused solely on signal magnitude, our method processes both real and\nimaginary components of the spectrogram, addressing phase information and\npreventing incongruous predictions. We evaluated our novel pipeline against\ntraditional, well-established approaches, on both simulated and real data in\nterms of fECG extraction and R-peak detection. The results showcase that our\nsuggested method achieves new state-of-the-art results, enabling an accurate\nextraction of fECG morphology across all evaluated settings. This method is the\nfirst to effectively extract fECG signals from single-channel recordings using\ndry textile electrodes, making a significant advancement towards a fully\nnon-invasive and self-administered fECG extraction solution."}
{"id": "2506.22580", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.22580", "abs": "https://arxiv.org/abs/2506.22580", "authors": ["Vasilis Siomos", "Jonathan Passerat-Palmbach", "Giacomo Tarroni"], "title": "FedCLAM: Client Adaptive Momentum with Foreground Intensity Matching for Federated Medical Image Segmentation", "comment": "10 pages, 2 figures, Accepted at MICCAI 2025", "summary": "Federated learning is a decentralized training approach that keeps data under\nstakeholder control while achieving superior performance over isolated\ntraining. While inter-institutional feature discrepancies pose a challenge in\nall federated settings, medical imaging is particularly affected due to diverse\nimaging devices and population variances, which can diminish the global model's\neffectiveness. Existing aggregation methods generally fail to adapt across\nvaried circumstances. To address this, we propose FedCLAM, which integrates\n\\textit{client-adaptive momentum} terms derived from each client's loss\nreduction during local training, as well as a \\textit{personalized dampening\nfactor} to curb overfitting. We further introduce a novel \\textit{intensity\nalignment} loss that matches predicted and ground-truth foreground\ndistributions to handle heterogeneous image intensity profiles across\ninstitutions and devices. Extensive evaluations on two datasets show that\nFedCLAM surpasses eight cutting-edge methods in medical segmentation tasks,\nunderscoring its efficacy. The code is available at\nhttps://github.com/siomvas/FedCLAM."}
{"id": "2506.22458", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.22458", "abs": "https://arxiv.org/abs/2506.22458", "authors": ["S M Minhazur Rahman", "Md. Amrin Ibna Hasnath", "Rifatul Islam", "Ahmed Faizul Haque Dhrubo", "Mohammad Abdul Qayum"], "title": "A Portable and Cost-Effective System for Real-Time Air Quality Monitoring and Environmental Impact Assessment", "comment": "This is a 7-page paper with 5 figures, and it has not been submitted\n  to any conference", "summary": "Air pollution remains a major global issue that seriously impacts public\nhealth, environmental quality, and ultimately human health. To help monitor\nproblem, we have created and constructed a low-cost, real-time, portable air\nquality monitoring system using cheap sensors. The system measures critical\npollutants PM2.5, PM10, and carbon monoxide (CO), and environmental variables\nsuch as temperature and humidity. The system computes the Air Quality Index\n(AQI) and transmits the data via a Bluetooth connection. The data is relayed,\nin real time, to a mobile application. Because of its small size and low\nmanufacturing cost the system readily lends itself to indoor and outdoor use\nand in urban and rural environments. In this paper we give an account of the\nsystem design, development, and validation, while demonstrating its accuracy\nand low-cost capabilities. We also consider its wider environmental, social,\nand regulatory implications with regards to; improving public awareness, being\nused for sustainability purposes and providing valuable information for\ninformed decision making."}
{"id": "2506.22596", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2506.22596", "abs": "https://arxiv.org/abs/2506.22596", "authors": ["Md Rahatul Islam Udoy", "Wantong Li", "Kai Ni", "Ahmedullah Aziz"], "title": "Multi-Domain FeFET-Based Pixel for In-Sensor Multiply-and-Accumulate Operations", "comment": null, "summary": "This paper presents an FeFET-based active pixel sensor that performs\nin-sensor multiply-and-accumulate (MAC) operations by leveraging the\nmulti-domain polarization states of ferroelectric layers. The proposed design\nintegrates a programmable FeFET into a 3-transistor pixel circuit, where the\nFeFET's non-volatile conductance encodes the weight, and the photodiode voltage\ndrop encodes the input. Their interaction generates an output current\nproportional to the product, enabling in-pixel analog multiplication.\nAccumulation is achieved by summing output currents along shared column lines,\nrealizing full MAC functionality within the image sensor array. Extensive\nHSPICE simulations, using 45 nm CMOS models, validate the operation and confirm\nthe scalability of the design. This compact and power-efficient architecture\nminimizes data movement, making it ideal for real-time edge computing,\nneuromorphic vision, and secure sensing applications."}
{"id": "2506.22459", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.22459", "abs": "https://arxiv.org/abs/2506.22459", "authors": ["Wending Heng", "Chaoyuan Liang", "Yihui Zhao", "Zhiqiang Zhang", "Glen Cooper", "Zhenhong Li"], "title": "Physics-Embedded Neural Networks for sEMG-based Continuous Motion Estimation", "comment": "Accepted by 2025 IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS)", "summary": "Accurately decoding human motion intentions from surface electromyography\n(sEMG) is essential for myoelectric control and has wide applications in\nrehabilitation robotics and assistive technologies. However, existing\nsEMG-based motion estimation methods often rely on subject-specific\nmusculoskeletal (MSK) models that are difficult to calibrate, or purely\ndata-driven models that lack physiological consistency. This paper introduces a\nnovel Physics-Embedded Neural Network (PENN) that combines interpretable MSK\nforward-dynamics with data-driven residual learning, thereby preserving\nphysiological consistency while achieving accurate motion estimation. The PENN\nemploys a recursive temporal structure to propagate historical estimates and a\nlightweight convolutional neural network for residual correction, leading to\nrobust and temporally coherent estimations. A two-phase training strategy is\ndesigned for PENN. Experimental evaluations on six healthy subjects show that\nPENN outperforms state-of-the-art baseline methods in both root mean square\nerror (RMSE) and $R^2$ metrics."}
{"id": "2506.22790", "categories": ["eess.IV", "cs.CV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2506.22790", "abs": "https://arxiv.org/abs/2506.22790", "authors": ["Yixu Chen", "Bowen Chen", "Hai Wei", "Alan C. Bovik", "Baojun Li", "Wei Sun", "Linhan Cao", "Kang Fu", "Dandan Zhu", "Jun Jia", "Menghan Hu", "Xiongkuo Min", "Guangtao Zhai", "Dounia Hammou", "Fei Yin", "Rafal Mantiuk", "Amritha Premkumar", "Prajit T Rajendran", "Vignesh V Menon"], "title": "ICME 2025 Generalizable HDR and SDR Video Quality Measurement Grand Challenge", "comment": "ICME 2025 Grand Challenges", "summary": "This paper reports IEEE International Conference on Multimedia \\& Expo (ICME)\n2025 Grand Challenge on Generalizable HDR and SDR Video Quality Measurement.\nWith the rapid development of video technology, especially High Dynamic Range\n(HDR) and Standard Dynamic Range (SDR) contents, the need for robust and\ngeneralizable Video Quality Assessment (VQA) methods has become increasingly\ndemanded. Existing VQA models often struggle to deliver consistent performance\nacross varying dynamic ranges, distortion types, and diverse content. This\nchallenge was established to benchmark and promote VQA approaches capable of\njointly handling HDR and SDR content. In the final evaluation phase, five teams\nsubmitted seven models along with technical reports to the Full Reference (FR)\nand No Reference (NR) tracks. Among them, four methods outperformed VMAF\nbaseline, while the top-performing model achieved state-of-the-art performance,\nsetting a new benchmark for generalizable video quality assessment."}
{"id": "2506.22460", "categories": ["eess.SP", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22460", "abs": "https://arxiv.org/abs/2506.22460", "authors": ["Ibne Farabi Shihab"], "title": "Heart rate and respiratory rate prediction from noisy real-world smartphone based on Deep Learning methods", "comment": null, "summary": "Using mobile phone video of the fingertip as a data source for estimating\nvital signs such as heart rate (HR) and respiratory rate (RR) during daily life\nhas long been suggested. While existing literature indicates that these\nestimates are accurate to within several beats or breaths per minute, the data\nused to draw these conclusions are typically collected in laboratory\nenvironments under careful experimental control, and yet the results are\nassumed to generalize to daily life. In an effort to test it, a team of\nresearchers collected a large dataset of mobile phone video recordings made\nduring daily life and annotated with ground truth HR and RR labels from N=111\nparticipants. They found that traditional algorithm performance on the\nfingerprint videos is worse than previously reported (7 times and 13 times\nworse for RR and HR, respectively). Fortunately, recent advancements in deep\nlearning, especially in convolutional neural networks (CNNs), offer a promising\nsolution to improve this performance. This study proposes a new method for\nestimating HR and RR using a novel 3D deep CNN, demonstrating a reduced error\nin estimated HR by 68% and RR by 75%. These promising results suggest that\nregressor-based deep learning approaches should be used in estimating HR and\nRR."}
{"id": "2506.22882", "categories": ["eess.IV", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.22882", "abs": "https://arxiv.org/abs/2506.22882", "authors": ["Qilong Xing", "Zikai Song", "Yuteng Ye", "Yuke Chen", "Youjia Zhang", "Na Feng", "Junqing Yu", "Wei Yang"], "title": "CA-Diff: Collaborative Anatomy Diffusion for Brain Tissue Segmentation", "comment": "ICME 2025", "summary": "Segmentation of brain structures from MRI is crucial for evaluating brain\nmorphology, yet existing CNN and transformer-based methods struggle to\ndelineate complex structures accurately. While current diffusion models have\nshown promise in image segmentation, they are inadequate when applied directly\nto brain MRI due to neglecting anatomical information. To address this, we\npropose Collaborative Anatomy Diffusion (CA-Diff), a framework integrating\nspatial anatomical features to enhance segmentation accuracy of the diffusion\nmodel. Specifically, we introduce distance field as an auxiliary anatomical\ncondition to provide global spatial context, alongside a collaborative\ndiffusion process to model its joint distribution with anatomical structures,\nenabling effective utilization of anatomical features for segmentation.\nFurthermore, we introduce a consistency loss to refine relationships between\nthe distance field and anatomical structures and design a time adapted channel\nattention module to enhance the U-Net feature fusion procedure. Extensive\nexperiments show that CA-Diff outperforms state-of-the-art (SOTA) methods."}
{"id": "2506.22461", "categories": ["eess.SP", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22461", "abs": "https://arxiv.org/abs/2506.22461", "authors": ["Chuan Li", "Ruoxuan Yang"], "title": "Machine Learning for Proactive Groundwater Management: Early Warning and Resource Allocation", "comment": null, "summary": "Groundwater supports ecosystems, agriculture, and drinking water supplies\nworldwide, yet effective monitoring remains challenging due to sparse data,\ncomputational constraints, and delayed outputs from traditional approaches. We\ndevelop a machine learning pipeline that predicts groundwater level categories\nusing climate data, hydro-meteorological records, and physiographic attributes\nprocessed through AutoGluon's automated ensemble framework. Our approach\nintegrates geospatial preprocessing, domain-driven feature engineering, and\nautomated model selection to overcome conventional monitoring limitations.\nApplied to a large-scale French dataset (n $>$ 3,440,000 observations from\n1,500+ wells), the model achieves weighted F\\_1 scores of 0.927 on validation\ndata and 0.67 on temporally distinct test data. Scenario-based evaluations\ndemonstrate practical utility for early warning systems and water allocation\ndecisions under changing climate conditions. The open-source implementation\nprovides a scalable framework for integrating machine learning into national\ngroundwater monitoring networks, enabling more responsive and data-driven water\nmanagement strategies."}
{"id": "2506.22952", "categories": ["eess.IV", "cs.CV", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2506.22952", "abs": "https://arxiv.org/abs/2506.22952", "authors": ["Yanwu Yang", "Thomas Wolfers"], "title": "Hierarchical Characterization of Brain Dynamics via State Space-based Vector Quantization", "comment": null, "summary": "Understanding brain dynamics through functional Magnetic Resonance Imaging\n(fMRI) remains a fundamental challenge in neuroscience, particularly in\ncapturing how the brain transitions between various functional states.\nRecently, metastability, which refers to temporarily stable brain states, has\noffered a promising paradigm to quantify complex brain signals into\ninterpretable, discretized representations. In particular, compared to\ncluster-based machine learning approaches, tokenization approaches leveraging\nvector quantization have shown promise in representation learning with powerful\nreconstruction and predictive capabilities. However, most existing methods\nignore brain transition dependencies and lack a quantification of brain\ndynamics into representative and stable embeddings. In this study, we propose a\nHierarchical State space-based Tokenization network, termed HST, which\nquantizes brain states and transitions in a hierarchical structure based on a\nstate space-based model. We introduce a refined clustered Vector-Quantization\nVariational AutoEncoder (VQ-VAE) that incorporates quantization error feedback\nand clustering to improve quantization performance while facilitating\nmetastability with representative and stable token representations. We validate\nour HST on two public fMRI datasets, demonstrating its effectiveness in\nquantifying the hierarchical dynamics of the brain and its potential in disease\ndiagnosis and reconstruction performance. Our method offers a promising\nframework for the characterization of brain dynamics, facilitating the analysis\nof metastability."}
{"id": "2506.22462", "categories": ["eess.SP", "cs.AI", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2506.22462", "abs": "https://arxiv.org/abs/2506.22462", "authors": ["Abdallah Lakhdari", "Jiajie Li", "Amani Abusafia", "Athman Bouguettaya"], "title": "Privacy-aware IoT Fall Detection Services For Aging in Place", "comment": "11 pages, 12 figures, This paper is accepted in the 2025 IEEE\n  International Conference on Web Services (ICWS 2025)", "summary": "Fall detection is critical to support the growing elderly population,\nprojected to reach 2.1 billion by 2050. However, existing methods often face\ndata scarcity challenges or compromise privacy. We propose a novel IoT-based\nFall Detection as a Service (FDaaS) framework to assist the elderly in living\nindependently and safely by accurately detecting falls. We design a\nservice-oriented architecture that leverages Ultra-wideband (UWB) radar sensors\nas an IoT health-sensing service, ensuring privacy and minimal intrusion. We\naddress the challenges of data scarcity by utilizing a Fall Detection\nGenerative Pre-trained Transformer (FD-GPT) that uses augmentation techniques.\nWe developed a protocol to collect a comprehensive dataset of the elderly daily\nactivities and fall events. This resulted in a real dataset that carefully\nmimics the elderly's routine. We rigorously evaluate and compare various models\nusing this dataset. Experimental results show our approach achieves 90.72%\naccuracy and 89.33% precision in distinguishing between fall events and regular\nactivities of daily living."}
{"id": "2506.23002", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2506.23002", "abs": "https://arxiv.org/abs/2506.23002", "authors": ["Vaigai Nayaki Yokar", "Hoa Le-Minh", "Zabih Ghassemlooy", "Wai Lok Woo"], "title": "An Image Processing Based Blur Reduction Technique in Smartphone-to-Smartphone Visible Light Communication System", "comment": null, "summary": "In this paper, we present a blur reduction technique for\nsmartphone-to-smartphone visible light communications (S2SVLC). The key\ntechnique it to avoid the repeated scanning of the transmitted data and to\nlower the amount of data discarded at the receiver end of the S2SVLC system.\nThis image processing method will improve the system recognition efficiency and\ndata rate. The proposed method includes converting the red-green-blue (RGB)\nimage into grayscale, applying contrast enhancement, scaling and binarizing the\nimage to reduce the blur levels in the image. The experiment includes practical\ndata acquisition and further processing and estimation in MATLAB. The\nexperiment is carried out in different conditions like distance, rotation, and\ntilt also considering different surrounding illuminations like ambient light\nand no light conditions to estimate the blur levels in S2SVLC. In this\nexperimental investigation two types of coding, American Standard code for\ninformation interchange (ASCII), and quick response (QR) code are used for data\ntransmission in S2SVLC. The obtained results indicate that, the proposed\ntechnique is proven to improve the recovery efficiency to 96% in the receiver\nend at different conditions."}
{"id": "2506.22465", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2506.22465", "abs": "https://arxiv.org/abs/2506.22465", "authors": ["Jun Zhu", "Yin Xu", "Dazhi He", "Haoyang Li", "Yunfeng Guan", "Wenjun Zhang"], "title": "Preconditioned Conjugate Gradient for MIMO-AFDM System", "comment": "arXiv admin note: text overlap with arXiv:2503.10525", "summary": "Affine frequency division multiplexing (AFDM) is a promising chirp-assisted\nmulticarrier waveform for future high mobility communications. A significant\nchallenge in MIMO-AFDM systems is the multi-user interference (MUI), which can\nbe effectively addressed by employing precoding techniques. However, the\ncomplexity introduced by AFDM makes the precoding process computationally\nexpensive and challenging. To overcome this issue, We combine AFDM channel\nsparse property and using Preconditioned Conjugate Gradient (PCG) method to\niteratively process the precoding, thereby reducing the complexity of the\nprecoding design. Simulation results demonstrate that the proposed\nsparsification approach, coupled with the PCG method, achieving quite precoding\nperformance while significantly reducing computational complexity. This makes\nthe application of AFDM more feasible and efficient for high-mobility\ncommunication scenarios, paving the way for its broader implementation in\nnext-generation communication systems."}
{"id": "2506.23005", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2506.23005", "abs": "https://arxiv.org/abs/2506.23005", "authors": ["Vaigai Nayaki Yokar", "Hoa Le Minh", "Zabih Ghassemlooy", "Wai Lok Woo"], "title": "Channel characterization in screen-to-camera based optical camera communication", "comment": null, "summary": "With the increase in optical camera communication (OCC), a screen to\ncamera-based communication can be established. This opens a new field of\nvisible light communication (VLC) known as smartphone to smartphone based\nvisible light communication (S2SVLC) system. In this paper, we experimentally\ndemonstrate a S2SVLC system based on VLC technology using a smartphone screen\nand a smartphone camera over a link span of 20 cms. We analyze the Lambertian\norder of the smartphone screen and carry out a channel characterization of a\nscreen to camera link-based VLC system under specific test conditions."}
{"id": "2506.22467", "categories": ["eess.SP", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.22467", "abs": "https://arxiv.org/abs/2506.22467", "authors": ["Roy Colglazier", "Jisoo Lee", "Haoyu Dong", "Hanxue Gu", "Yaqian Chen", "Joseph Cao", "Zafer Yildiz", "Zhonghao Liu", "Nicholas Konz", "Jichen Yang", "Jikai Zhang", "Yuwen Chen", "Lin Li", "Adrian Camarena", "Maciej A. Mazurowski"], "title": "SegmentAnyMuscle: A universal muscle segmentation model across different locations in MRI", "comment": "24 pages, 6 figures", "summary": "The quantity and quality of muscles are increasingly recognized as important\npredictors of health outcomes. While MRI offers a valuable modality for such\nassessments, obtaining precise quantitative measurements of musculature remains\nchallenging. This study aimed to develop a publicly available model for muscle\nsegmentation in MRIs and demonstrate its applicability across various\nanatomical locations and imaging sequences. A total of 362 MRIs from 160\npatients at a single tertiary center (Duke University Health System, 2016-2020)\nwere included, with 316 MRIs from 114 patients used for model development. The\nmodel was tested on two separate sets: one with 28 MRIs representing common\nsequence types, achieving an average Dice Similarity Coefficient (DSC) of\n88.45%, and another with 18 MRIs featuring less frequent sequences and\nabnormalities such as muscular atrophy, hardware, and significant noise,\nachieving 86.21% DSC. These results demonstrate the feasibility of a fully\nautomated deep learning algorithm for segmenting muscles on MRI across diverse\nsettings. The public release of this model enables consistent, reproducible\nresearch into the relationship between musculature and health."}
{"id": "2506.23102", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.23102", "abs": "https://arxiv.org/abs/2506.23102", "authors": ["Sunggu Kyung", "Jinyoung Seo", "Hyunseok Lim", "Dongyeong Kim", "Hyungbin Park", "Jimin Sung", "Jihyun Kim", "Wooyoung Jo", "Yoojin Nam", "Namkug Kim"], "title": "MedRegion-CT: Region-Focused Multimodal LLM for Comprehensive 3D CT Report Generation", "comment": "14 pages, 5 figures, submitted to ICCV 2025", "summary": "The recent release of RadGenome-Chest CT has significantly advanced CT-based\nreport generation. However, existing methods primarily focus on global\nfeatures, making it challenging to capture region-specific details, which may\ncause certain abnormalities to go unnoticed. To address this, we propose\nMedRegion-CT, a region-focused Multi-Modal Large Language Model (MLLM)\nframework, featuring three key innovations. First, we introduce Region\nRepresentative ($R^2$) Token Pooling, which utilizes a 2D-wise pretrained\nvision model to efficiently extract 3D CT features. This approach generates\nglobal tokens representing overall slice features and region tokens\nhighlighting target areas, enabling the MLLM to process comprehensive\ninformation effectively. Second, a universal segmentation model generates\npseudo-masks, which are then processed by a mask encoder to extract\nregion-centric features. This allows the MLLM to focus on clinically relevant\nregions, using six predefined region masks. Third, we leverage segmentation\nresults to extract patient-specific attributions, including organ size,\ndiameter, and locations. These are converted into text prompts, enriching the\nMLLM's understanding of patient-specific contexts. To ensure rigorous\nevaluation, we conducted benchmark experiments on report generation using the\nRadGenome-Chest CT. MedRegion-CT achieved state-of-the-art performance,\noutperforming existing methods in natural language generation quality and\nclinical relevance while maintaining interpretability. The code for our\nframework is publicly available."}
{"id": "2506.22468", "categories": ["eess.SP", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22468", "abs": "https://arxiv.org/abs/2506.22468", "authors": ["Konstantinos Koutras", "Agorakis Bompotas", "Constantinos Halkiopoulos", "Athanasios Kalogeras", "Christos Alexakos"], "title": "Dimensionality Reduction on IoT Monitoring Data of Smart Building for Energy Consumption Forecasting", "comment": "Version of submitted paper on 2023 IEEE International Smart Cities\n  Conference (ISC2), 1-6, 2023", "summary": "The Internet of Things (IoT) plays a major role today in smart building\ninfrastructures, from simple smart-home applications, to more sophisticated\nindustrial type installations. The vast amounts of data generated from relevant\nsystems can be processed in different ways revealing important information.\nThis is especially true in the era of edge computing, when advanced data\nanalysis and decision-making is gradually moving to the edge of the network\nwhere devices are generally characterised by low computing resources. In this\ncontext, one of the emerging main challenges is related to maintaining data\nanalysis accuracy even with less data that can be efficiently handled by low\nresource devices. The present work focuses on correlation analysis of data\nretrieved from a pilot IoT network installation monitoring a small smart office\nby means of environmental and energy consumption sensors. The research\nmotivation was to find statistical correlation between the monitoring variables\nthat will allow the use of machine learning (ML) prediction algorithms for\nenergy consumption reducing input parameters. For this to happen, a series of\nhypothesis tests for the correlation of three different environmental variables\nwith the energy consumption were carried out. A total of ninety tests were\nperformed, thirty for each pair of variables. In these tests, p-values showed\nthe existence of strong or semi-strong correlation with two environmental\nvariables, and of a weak correlation with a third one. Using the proposed\nmethodology, we manage without examining the entire data set to exclude weak\ncorrelated variables while keeping the same score of accuracy."}
{"id": "2506.23121", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.23121", "abs": "https://arxiv.org/abs/2506.23121", "authors": ["Xinlei Yu", "Chanmiao Wang", "Hui Jin", "Ahmed Elazab", "Gangyong Jia", "Xiang Wan", "Changqing Zou", "Ruiquan Ge"], "title": "CRISP-SAM2: SAM2 with Cross-Modal Interaction and Semantic Prompting for Multi-Organ Segmentation", "comment": "19 pages, 9 figures, 10 tables", "summary": "Multi-organ medical segmentation is a crucial component of medical image\nprocessing, essential for doctors to make accurate diagnoses and develop\neffective treatment plans. Despite significant progress in this field, current\nmulti-organ segmentation models often suffer from inaccurate details,\ndependence on geometric prompts and loss of spatial information. Addressing\nthese challenges, we introduce a novel model named CRISP-SAM2 with CRoss-modal\nInteraction and Semantic Prompting based on SAM2. This model represents a\npromising approach to multi-organ medical segmentation guided by textual\ndescriptions of organs. Our method begins by converting visual and textual\ninputs into cross-modal contextualized semantics using a progressive\ncross-attention interaction mechanism. These semantics are then injected into\nthe image encoder to enhance the detailed understanding of visual information.\nTo eliminate reliance on geometric prompts, we use a semantic prompting\nstrategy, replacing the original prompt encoder to sharpen the perception of\nchallenging targets. In addition, a similarity-sorting self-updating strategy\nfor memory and a mask-refining process is applied to further adapt to medical\nimaging and enhance localized details. Comparative experiments conducted on\nseven public datasets indicate that CRISP-SAM2 outperforms existing models.\nExtensive analysis also demonstrates the effectiveness of our method, thereby\nconfirming its superior performance, especially in addressing the limitations\nmentioned earlier. Our code is available at:\nhttps://github.com/YU-deep/CRISP\\_SAM2.git."}
{"id": "2506.22469", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.22469", "abs": "https://arxiv.org/abs/2506.22469", "authors": ["Chen Shang", "Dinh Thai Hoang", "Jiadong Yu"], "title": "Multi-Modal Beamforming with Model Compression and Modality Generation for V2X Networks", "comment": "13 pages, 6 figures", "summary": "Integrating sensing and communication (ISAC) has emerged as a cornerstone\ntechnology for predictive beamforming in 6G-enabled vehicle-to-everything (V2X)\nnetworks. However, existing ISAC paradigms rely solely on radio frequency (RF)\nsignal, limiting sensing resolution and robustness in V2X environments with\nhigh mobility and multipath interference. Fortunately, the widespread\ndeployment of diverse non-RF sensors such as cameras and LiDAR, along with the\nintegration of artificial intelligence (AI) and communication systems, offers\nnew opportunities to improve the synergy between sensing and communication.\nMotivated by this, this work develops a novel and robust communication\nframework that leverages multi-modal sensing data and advanced AI technologies\nto assist beamforming in dynamic and realistic vehicular scenarios.\nSpecifically, we propose a multi-modal learning framework for predictive\nbeamforming that integrates modality-specific branches and employs hierarchical\nTransformer to capture cross-modal features. By exploiting the intrinsic\ncorrelation between multi-modal sensing data and beamforming decisions, this\ndesign enhances the accuracy and robustness of beamforming in dynamic V2X\nscenarios. To enable practical deployment on resource-constrained edge device\n(i.e., the roadside unit), we then develop a module-aware compression strategy\nthat significantly reduces inference latency while preserving model\nperformance. Furthermore, to address potential modality missing in real-world\nscenarios, we introduce a generative model that is able to reconstruct missing\ninputs from available observations, allowing the framework to operate reliably\neven under incomplete sensing conditions. Extensive simulation results\nconducted on real-world datasets demonstrate that the proposed scheme\nconsistently outperforms existing baselines across various metrics."}
{"id": "2506.23184", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.23184", "abs": "https://arxiv.org/abs/2506.23184", "authors": ["Anran Liu", "Xiaofei Wang", "Jing Cai", "Chao Li"], "title": "Score-based Diffusion Model for Unpaired Virtual Histology Staining", "comment": "11 pages, 3 figures", "summary": "Hematoxylin and eosin (H&E) staining visualizes histology but lacks\nspecificity for diagnostic markers. Immunohistochemistry (IHC) staining\nprovides protein-targeted staining but is restricted by tissue availability and\nantibody specificity. Virtual staining, i.e., computationally translating the\nH&E image to its IHC counterpart while preserving the tissue structure, is\npromising for efficient IHC generation. Existing virtual staining methods still\nface key challenges: 1) effective decomposition of staining style and tissue\nstructure, 2) controllable staining process adaptable to diverse tissue and\nproteins, and 3) rigorous structural consistency modelling to handle the\nnon-pixel-aligned nature of paired H&E and IHC images. This study proposes a\nmutual-information (MI)-guided score-based diffusion model for unpaired virtual\nstaining. Specifically, we design 1) a global MI-guided energy function that\ndisentangles the tissue structure and staining characteristics across\nmodalities, 2) a novel timestep-customized reverse diffusion process for\nprecise control of the staining intensity and structural reconstruction, and 3)\na local MI-driven contrastive learning strategy to ensure the cellular level\nstructural consistency between H&E-IHC images. Extensive experiments\ndemonstrate the our superiority over state-of-the-art approaches, highlighting\nits biomedical potential. Codes will be open-sourced upon acceptance."}
{"id": "2506.22471", "categories": ["eess.SP", "cs.NI"], "pdf": "https://arxiv.org/pdf/2506.22471", "abs": "https://arxiv.org/abs/2506.22471", "authors": ["Muhammad Ahmed Mohsin", "Muhammad Umer", "Ahsan Bilal", "Muhammad Ali Jamshed", "John M. Cioffi"], "title": "Continual Learning for Wireless Channel Prediction", "comment": "Accepted at ICML Workshop on ML4Wireless", "summary": "Modern 5G/6G deployments routinely face cross-configuration handovers--users\ntraversing cells with different antenna layouts, carrier frequencies, and\nscattering statistics--which inflate channel-prediction NMSE by $37.5\\%$ on\naverage when models are naively fine-tuned. The proposed improvement frames\nthis mismatch as a continual-learning problem and benchmarks three adaptation\nfamilies: replay with loss-aware reservoirs, synaptic-importance\nregularization, and memory-free learning-without-forgetting. Across three\nrepresentative 3GPP urban micro scenarios, the best replay and regularization\nschemes cut the high-SNR error floor by up to 2~dB ($\\approx 35\\%$), while even\nthe lightweight distillation recovers up to $30\\%$ improvement over baseline\nhandover prediction schemes. These results show that targeted rehearsal and\nparameter anchoring are essential for handover-robust CSI prediction and\nsuggest a clear migration path for embedding continual-learning hooks into\ncurrent channel prediction efforts in 3GPP--NR and O-RAN. The full codebase can\nbe found at\nhttps://github.com/ahmd-mohsin/continual-learning-channel-prediction.git."}
{"id": "2506.23208", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.23208", "abs": "https://arxiv.org/abs/2506.23208", "authors": ["Runtian Yuan", "Qingqiu Li", "Junlin Hou", "Jilan Xu", "Yuejie Zhang", "Rui Feng", "Hao Chen"], "title": "Multi-Source COVID-19 Detection via Variance Risk Extrapolation", "comment": null, "summary": "We present our solution for the Multi-Source COVID-19 Detection Challenge,\nwhich aims to classify chest CT scans into COVID and Non-COVID categories\nacross data collected from four distinct hospitals and medical centers. A major\nchallenge in this task lies in the domain shift caused by variations in imaging\nprotocols, scanners, and patient populations across institutions. To enhance\nthe cross-domain generalization of our model, we incorporate Variance Risk\nExtrapolation (VREx) into the training process. VREx encourages the model to\nmaintain consistent performance across multiple source domains by explicitly\nminimizing the variance of empirical risks across environments. This\nregularization strategy reduces overfitting to center-specific features and\npromotes learning of domain-invariant representations. We further apply Mixup\ndata augmentation to improve generalization and robustness. Mixup interpolates\nboth the inputs and labels of randomly selected pairs of training samples,\nencouraging the model to behave linearly between examples and enhancing its\nresilience to noise and limited data. Our method achieves an average macro F1\nscore of 0.96 across the four sources on the validation set, demonstrating\nstrong generalization."}
{"id": "2506.22472", "categories": ["eess.SP", "cs.RO"], "pdf": "https://arxiv.org/pdf/2506.22472", "abs": "https://arxiv.org/abs/2506.22472", "authors": ["Dylan Wilson", "Marco Pontin", "Peter Walters", "Perla Maiolino"], "title": "Optical Waveguide-based Spider Web Enables Resilient Impact Detection and Localization", "comment": null, "summary": "Spiders use their webs as multifunctional tools that enable capturing and\nlocalizing prey and more general environmental sensing through vibrations.\nInspired by their biological function, we present a spider web-inspired optical\nwaveguide system for resilient impulse detection and localization. The\nstructure consists of six clear thermoplastic polyurethane (TPU) waveguides\narranged radially and interconnected by a spiral TPU thread, mimicking orb\nspider webs. Light transmission losses, induced by vibrations, are measured via\ncoupled LEDs and photo-diodes, allowing real-time detection. We systematically\ncharacterize individual waveguides, analyzing key parameters such as tension,\nimpulse position, and break angle to optimize vibrational response. The\ncomplete system is validated through controlled experiments, revealing a 5 ms\npropagation delay in vibration transfer between adjacent radii, enhancing\nlocalization capabilities. We demonstrate a robust impulse detection and\nlocalization algorithm leveraging time delay analysis, achieving reliable event\nidentification even in cases of sensor failure. This study highlights the\npotential of bioinspired optical waveguide structures for adaptive sensing,\nwith applications in soft robotics, structural monitoring, and environmental\nsensing."}
{"id": "2506.23259", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.23259", "abs": "https://arxiv.org/abs/2506.23259", "authors": ["Lachin Naghashyar"], "title": "Improving Myocardial Infarction Detection via Synthetic ECG Pretraining", "comment": null, "summary": "Myocardial infarction is a major cause of death globally, and accurate early\ndiagnosis from electrocardiograms (ECGs) remains a clinical priority. Deep\nlearning models have shown promise for automated ECG interpretation, but\nrequire large amounts of labeled data, which are often scarce in practice. We\npropose a physiology-aware pipeline that (i) synthesizes 12-lead ECGs with\ntunable MI morphology and realistic noise, and (ii) pre-trains recurrent and\ntransformer classifiers with self-supervised masked-autoencoding plus a joint\nreconstruction-classification objective. We validate the realism of synthetic\nECGs via statistical and visual analysis, confirming that key morphological\nfeatures are preserved. Pretraining on synthetic data consistently improved\nclassification performance, particularly in low-data settings, with AUC gains\nof up to 4 percentage points. These results show that controlled synthetic ECGs\ncan help improve MI detection when real clinical data is limited."}
{"id": "2506.22476", "categories": ["eess.SP", "cs.ET", "cs.HC", "cs.LG", "q-bio.NC", "I.2.6; J.3; H.1.2"], "pdf": "https://arxiv.org/pdf/2506.22476", "abs": "https://arxiv.org/abs/2506.22476", "authors": ["A. Subedi", "S. De", "L. Cavuoto", "S. Schwaitzberg", "M. Hackett", "J. Norfleet"], "title": "An Interpretable Transformer-Based Foundation Model for Cross-Procedural Skill Assessment Using Raw fNIRS Signals", "comment": null, "summary": "Objective skill assessment in high-stakes procedural environments requires\nmodels that not only decode underlying cognitive and motor processes but also\ngeneralize across tasks, individuals, and experimental contexts. While prior\nwork has demonstrated the potential of functional near-infrared spectroscopy\n(fNIRS) for evaluating cognitive-motor performance, existing approaches are\noften task-specific, rely on extensive preprocessing, and lack robustness to\nnew procedures or conditions. Here, we introduce an interpretable\ntransformer-based foundation model trained on minimally processed fNIRS signals\nfor cross-procedural skill assessment. Pretrained using self-supervised\nlearning on data from laparoscopic surgical tasks and endotracheal intubation\n(ETI), the model achieves greater than 88% classification accuracy on all\ntasks, with Matthews Correlation Coefficient exceeding 0.91 on ETI. It\ngeneralizes to a novel emergency airway procedure--cricothyrotomy--using fewer\nthan 30 labeled samples and a lightweight (less than 2k parameter) adapter\nmodule, attaining an AUC greater than 87%. Interpretability is achieved via a\nnovel channel attention mechanism--developed specifically for fNIRS--that\nidentifies functionally coherent prefrontal sub-networks validated through\nablation studies. Temporal attention patterns align with task-critical phases\nand capture stress-induced changes in neural variability, offering insight into\ndynamic cognitive states."}
{"id": "2506.23298", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2506.23298", "abs": "https://arxiv.org/abs/2506.23298", "authors": ["Xing Shen", "Justin Szeto", "Mingyang Li", "Hengguan Huang", "Tal Arbel"], "title": "Exposing and Mitigating Calibration Biases and Demographic Unfairness in MLLM Few-Shot In-Context Learning for Medical Image Classification", "comment": "Preprint version. The peer-reviewed version of this paper has been\n  accepted to MICCAI 2025 main conference", "summary": "Multimodal large language models (MLLMs) have enormous potential to perform\nfew-shot in-context learning in the context of medical image analysis. However,\nsafe deployment of these models into real-world clinical practice requires an\nin-depth analysis of the accuracies of their predictions, and their associated\ncalibration errors, particularly across different demographic subgroups. In\nthis work, we present the first investigation into the calibration biases and\ndemographic unfairness of MLLMs' predictions and confidence scores in few-shot\nin-context learning for medical image classification. We introduce CALIN, an\ninference-time calibration method designed to mitigate the associated biases.\nSpecifically, CALIN estimates the amount of calibration needed, represented by\ncalibration matrices, using a bi-level procedure: progressing from the\npopulation level to the subgroup level prior to inference. It then applies this\nestimation to calibrate the predicted confidence scores during inference.\nExperimental results on three medical imaging datasets: PAPILA for fundus image\nclassification, HAM10000 for skin cancer classification, and MIMIC-CXR for\nchest X-ray classification demonstrate CALIN's effectiveness at ensuring fair\nconfidence calibration in its prediction, while improving its overall\nprediction accuracies and exhibiting minimum fairness-utility trade-off."}
{"id": "2506.22488", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.22488", "abs": "https://arxiv.org/abs/2506.22488", "authors": ["Xi Fu", "Weibang Jiang", "Rui Liu", "Gernot R. Müller-Putz", "Cuntai Guan"], "title": "Zero-Shot EEG-to-Gait Decoding via Phase-Aware Representation Learning", "comment": null, "summary": "Accurate decoding of lower-limb motion from EEG signals is essential for\nadvancing brain-computer interface (BCI) applications in movement intent\nrecognition and control. However, challenges persist in achieving causal,\nphase-consistent predictions and in modeling both inter- and intra-subject\nvariability. To address these issues, we propose NeuroDyGait, a\ndomain-generalizable EEG-to-motion decoding framework that leverages structured\ncontrastive representation learning and relational domain modeling. The\nproposed method employs relative contrastive learning to achieve semantic\nalignment between EEG and motion embeddings. Furthermore, a multi-cycle gait\nreconstruction objective is introduced to enforce temporal coherence and\nmaintain biomechanical consistency. To promote inter-session generalization,\nduring fine-tuning, a domain dynamic decoding mechanism adaptively assigns\nsession-specific prediction heads and learns to mix their outputs based on\ninter-session relationships. NeuroDyGait enables zero-shot motion prediction\nfor unseen individuals without requiring adaptation and achieves superior\nperformance in cross-subject gait decoding on benchmark datasets. Additionally,\nit demonstrates strong phase-detection capabilities even without explicit phase\nsupervision during training. These findings highlight the potential of\nrelational domain learning in enabling scalable, target-free deployment of\nBCIs."}
{"id": "2506.23305", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.23305", "abs": "https://arxiv.org/abs/2506.23305", "authors": ["Rachit Saluja", "Arzu Kovanlikaya", "Candace Chien", "Lauren Kathryn Blatt", "Jeffrey M. Perlman", "Stefan Worgall", "Mert R. Sabuncu", "Jonathan P. Dyke"], "title": "BPD-Neo: An MRI Dataset for Lung-Trachea Segmentation with Clinical Data for Neonatal Bronchopulmonary Dysplasia", "comment": null, "summary": "Bronchopulmonary dysplasia (BPD) is a common complication among preterm\nneonates, with portable X-ray imaging serving as the standard diagnostic\nmodality in neonatal intensive care units (NICUs). However, lung magnetic\nresonance imaging (MRI) offers a non-invasive alternative that avoids sedation\nand radiation while providing detailed insights into the underlying mechanisms\nof BPD. Leveraging high-resolution 3D MRI data, advanced image processing and\nsemantic segmentation algorithms can be developed to assist clinicians in\nidentifying the etiology of BPD. In this dataset, we present MRI scans paired\nwith corresponding semantic segmentations of the lungs and trachea for 40\nneonates, the majority of whom are diagnosed with BPD. The imaging data consist\nof free-breathing 3D stack-of-stars radial gradient echo acquisitions, known as\nthe StarVIBE series. Additionally, we provide comprehensive clinical data and\nbaseline segmentation models, validated against clinical assessments, to\nsupport further research and development in neonatal lung imaging."}
{"id": "2506.22490", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.22490", "abs": "https://arxiv.org/abs/2506.22490", "authors": ["Zhenke Duan", "Jiqun Pan", "Jiani Tu"], "title": "MENGLAN: Multiscale Enhanced Nonparametric Gas Analyzer with Lightweight Architecture and Networks", "comment": null, "summary": "Accurate detection of ethylene concentrations in mixed gases is crucial in\nchemical production for safety and health purposes. Traditional methods are\nhindered by high cost and complexity, limiting their practical application.\nThis study proposes MENGLAN, a Multiscale Enhanced Nonparametric Gas Analyzer\nthat integrates a dual-stream structure, a Hybrid Multi-Head Attention\nmechanism, and a Feature Reactivation Module to enable real-time, lightweight,\nand high-precision ethylene concentration prediction. Results show that MENGLAN\nachieves superior performance, reduced computational demand, and enhanced\ndeployability compared to existing methods."}
{"id": "2506.23309", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.23309", "abs": "https://arxiv.org/abs/2506.23309", "authors": ["Yiming Huang", "Long Bai", "Beilei Cui", "Kun Yuan", "Guankun Wang", "Mobarakol Islam", "Nicolas Padoy", "Nassir Navab", "Hongliang Ren"], "title": "SurgTPGS: Semantic 3D Surgical Scene Understanding with Text Promptable Gaussian Splatting", "comment": "MICCAI 2025. Project Page:\n  https://lastbasket.github.io/MICCAI-2025-SurgTPGS/", "summary": "In contemporary surgical research and practice, accurately comprehending 3D\nsurgical scenes with text-promptable capabilities is particularly crucial for\nsurgical planning and real-time intra-operative guidance, where precisely\nidentifying and interacting with surgical tools and anatomical structures is\nparamount. However, existing works focus on surgical vision-language model\n(VLM), 3D reconstruction, and segmentation separately, lacking support for\nreal-time text-promptable 3D queries. In this paper, we present SurgTPGS, a\nnovel text-promptable Gaussian Splatting method to fill this gap. We introduce\na 3D semantics feature learning strategy incorporating the Segment Anything\nmodel and state-of-the-art vision-language models. We extract the segmented\nlanguage features for 3D surgical scene reconstruction, enabling a more\nin-depth understanding of the complex surgical environment. We also propose\nsemantic-aware deformation tracking to capture the seamless deformation of\nsemantic features, providing a more precise reconstruction for both texture and\nsemantic features. Furthermore, we present semantic region-aware optimization,\nwhich utilizes regional-based semantic information to supervise the training,\nparticularly promoting the reconstruction quality and semantic smoothness. We\nconduct comprehensive experiments on two real-world surgical datasets to\ndemonstrate the superiority of SurgTPGS over state-of-the-art methods,\nhighlighting its potential to revolutionize surgical practices. SurgTPGS paves\nthe way for developing next-generation intelligent surgical systems by\nenhancing surgical precision and safety. Our code is available at:\nhttps://github.com/lastbasket/SurgTPGS."}
{"id": "2506.22495", "categories": ["eess.SP", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.22495", "abs": "https://arxiv.org/abs/2506.22495", "authors": ["He-Yang Xu", "Hongxiang Gao", "Yuwen Li", "Xiu-Shen Wei", "Chengyu Liu"], "title": "Masked Autoencoders that Feel the Heart: Unveiling Simplicity Bias for ECG Analyses", "comment": null, "summary": "The diagnostic value of electrocardiogram (ECG) lies in its dynamic\ncharacteristics, ranging from rhythm fluctuations to subtle waveform\ndeformations that evolve across time and frequency domains. However, supervised\nECG models tend to overfit dominant and repetitive patterns, overlooking\nfine-grained but clinically critical cues, a phenomenon known as Simplicity\nBias (SB), where models favor easily learnable signals over subtle but\ninformative ones. In this work, we first empirically demonstrate the presence\nof SB in ECG analyses and its negative impact on diagnostic performance, while\nsimultaneously discovering that self-supervised learning (SSL) can alleviate\nit, providing a promising direction for tackling the bias. Following the SSL\nparadigm, we propose a novel method comprising two key components: 1)\nTemporal-Frequency aware Filters to capture temporal-frequency features\nreflecting the dynamic characteristics of ECG signals, and 2) building on this,\nMulti-Grained Prototype Reconstruction for coarse and fine representation\nlearning across dual domains, further mitigating SB. To advance SSL in ECG\nanalyses, we curate a large-scale multi-site ECG dataset with 1.53 million\nrecordings from over 300 clinical centers. Experiments on three downstream\ntasks across six ECG datasets demonstrate that our method effectively reduces\nSB and achieves state-of-the-art performance. Code and dataset will be released\npublicly."}
{"id": "2506.23311", "categories": ["eess.IV", "cs.LG", "physics.med-ph"], "pdf": "https://arxiv.org/pdf/2506.23311", "abs": "https://arxiv.org/abs/2506.23311", "authors": ["Perla Mayo", "Carolin M. Pirkl", "Alin Achim", "Bjoern Menze", "Mohammad Golbabaee"], "title": "Physics informed guided diffusion for accelerated multi-parametric MRI reconstruction", "comment": "11 pages, 1 figure, 1 algorithm, 3 tables. Accepted to MICCAI 2025.\n  This is a version prior peer-review", "summary": "We introduce MRF-DiPh, a novel physics informed denoising diffusion approach\nfor multiparametric tissue mapping from highly accelerated, transient-state\nquantitative MRI acquisitions like Magnetic Resonance Fingerprinting (MRF). Our\nmethod is derived from a proximal splitting formulation, incorporating a\npretrained denoising diffusion model as an effective image prior to regularize\nthe MRF inverse problem. Further, during reconstruction it simultaneously\nenforces two key physical constraints: (1) k-space measurement consistency and\n(2) adherence to the Bloch response model. Numerical experiments on in-vivo\nbrain scans data show that MRF-DiPh outperforms deep learning and compressed\nsensing MRF baselines, providing more accurate parameter maps while better\npreserving measurement fidelity and physical model consistency-critical for\nsolving reliably inverse problems in medical imaging."}
{"id": "2506.22549", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.22549", "abs": "https://arxiv.org/abs/2506.22549", "authors": ["Omar Barrera", "Jack Kramer", "Lezli Matto", "Vakhtang Chulukhadze", "Sinwoo Cho", "Michael Liao", "Mark S. Goorsky", "Ruochen Lu"], "title": "50 GHz Piezoelectric Acoustic Filter", "comment": "8 pages, 10 Figures", "summary": "This paper presents significant frequency scaling of acoustic filter\ntechnology to 50 GHz. This achievement is enabled by the P3F LiNbO3 multilayer\nstack, in which piezoelectric thin-films of alternating orientations are\ntransferred in sequence, thereby allowing efficient exploitation of high-order\nmodes with high quality factor (Q) and coupling coefficient (k2) in a thicker\npiezoelectric stack. The demonstrated filter is comprised of twelfth-order\nsymmetric (S12) mode lateral-field-excited bulk acoustic wave resonators\n(XBARs), built on a 4-layer periodically poled piezoelectric (P3F) 128 Y-cut\nlithium niobate (LiNbO3) stack. The filter exhibits 3.3 dB insertion loss (IL)\nand a fractional bandwidth (FBW) of 2.9%. The miniature design, with a\nfootprint of 0.36 mm2, makes it promising for future wireless front-end\napplications. These results represent the highest frequency acoustic filters\nreported to date, setting a new benchmark in piezoelectric filter technology.\nUpon further development, the platform could enable filters further into the\nFR2 range, essential for next-generation communication systems."}
{"id": "2506.23334", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.23334", "abs": "https://arxiv.org/abs/2506.23334", "authors": ["Hongyi Pan", "Ziliang Hong", "Gorkem Durak", "Ziyue Xu", "Ulas Bagci"], "title": "Federated Breast Cancer Detection Enhanced by Synthetic Ultrasound Image Augmentation", "comment": null, "summary": "Federated learning (FL) has emerged as a promising paradigm for\ncollaboratively training deep learning models across institutions without\nexchanging sensitive medical data. However, its effectiveness is often hindered\nby limited data availability and non-independent, identically distributed data\nacross participating clients, which can degrade model performance and\ngeneralization. To address these challenges, we propose a generative AI based\ndata augmentation framework that integrates synthetic image sharing into the\nfederated training process for breast cancer diagnosis via ultrasound images.\nSpecifically, we train two simple class-specific Deep Convolutional Generative\nAdversarial Networks: one for benign and one for malignant lesions. We then\nsimulate a realistic FL setting using three publicly available breast\nultrasound image datasets: BUSI, BUS-BRA, and UDIAT. FedAvg and FedProx are\nadopted as baseline FL algorithms. Experimental results show that incorporating\na suitable number of synthetic images improved the average AUC from 0.9206 to\n0.9237 for FedAvg and from 0.9429 to 0.9538 for FedProx. We also note that\nexcessive use of synthetic data reduced performance, underscoring the\nimportance of maintaining a balanced ratio of real and synthetic samples. Our\nfindings highlight the potential of generative AI based data augmentation to\nenhance FL results in the breast ultrasound image classification task."}
{"id": "2506.22796", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.22796", "abs": "https://arxiv.org/abs/2506.22796", "authors": ["Ruolin Du", "Zhiqiang Wei", "Zai Yang", "Lei Yang", "Yong Zeng", "Derrick Wing Kwan Ng", "Jinhong Yuan"], "title": "Channel Knowledge Map-assisted Dual-domain Tracking and Predictive Beamforming for High-Mobility Wireless Networks", "comment": null, "summary": "This paper introduces a novel channel knowledge map (CKM)-assisted\ndual-domain tracking and predictive beamforming scheme for high-mobility\nwireless networks. The central premise is that the CKM integrates both the\ncoordinate and beam domains, thereby enabling tracking in one domain via\ntreating the other domain's input as priors or measurements. In the coordinate\ndomain (C-Domain), an extended Kalman filter (EKF) is employed to predict and\ntrack the state (i.e., location and velocity) of a moving communication\nreceiver across time slots under both line-of-sight (LoS)-present and\nLoS-absent conditions, where the CKM provides a prior mapping from multipath\nchannel parameters to potential target locations. In the beam domain\n(B-Domain), the updated location of the receiver is fed back to CKM to offer a\npriori information of angle of arrival (AoA) variations, which are incorporated\nto establish beam transition models for effective beam tracking, depending on\nthe angular variation situation of each path. Then, we analyze the Cram\\'er-Rao\nBound (CRB) for AoA estimation for each path in the considered system and\npropose a jointly predictive beamforming and power allocation design to\nminimize AoA estimation errors, directly enhancing multipath beam tracking\naccuracy and indirectly improving target tracking performance. Simulation\nresults demonstrate that the proposed scheme achieves significant improvements\nin both target and beam tracking performance compared to the state-of-the-art\napproaches, particularly in AoA tracking of non-line-of-sight (NLoS) paths,\nhighlighting the potential gain of CKM in facilitating both target and beam\ntracking in high-mobility communications."}
{"id": "2506.23466", "categories": ["eess.IV", "cs.CV", "physics.med-ph"], "pdf": "https://arxiv.org/pdf/2506.23466", "abs": "https://arxiv.org/abs/2506.23466", "authors": ["Qiqing Liu", "Guoquan Wei", "Zekun Zhou", "Yiyang Wen", "Liu Shi", "Qiegen Liu"], "title": "FD-DiT: Frequency Domain-Directed Diffusion Transformer for Low-Dose CT Reconstruction", "comment": "11pages, 11 figures", "summary": "Low-dose computed tomography (LDCT) reduces radiation exposure but suffers\nfrom image artifacts and loss of detail due to quantum and electronic noise,\npotentially impacting diagnostic accuracy. Transformer combined with diffusion\nmodels has been a promising approach for image generation. Nevertheless,\nexisting methods exhibit limitations in preserving finegrained image details.\nTo address this issue, frequency domain-directed diffusion transformer (FD-DiT)\nis proposed for LDCT reconstruction. FD-DiT centers on a diffusion strategy\nthat progressively introduces noise until the distribution statistically aligns\nwith that of LDCT data, followed by denoising processing. Furthermore, we\nemploy a frequency decoupling technique to concentrate noise primarily in\nhigh-frequency domain, thereby facilitating effective capture of essential\nanatomical structures and fine details. A hybrid denoising network is then\nutilized to optimize the overall data reconstruction process. To enhance the\ncapability in recognizing high-frequency noise, we incorporate sliding sparse\nlocal attention to leverage the sparsity and locality of shallow-layer\ninformation, propagating them via skip connections for improving feature\nrepresentation. Finally, we propose a learnable dynamic fusion strategy for\noptimal component integration. Experimental results demonstrate that at\nidentical dose levels, LDCT images reconstructed by FD-DiT exhibit superior\nnoise and artifact suppression compared to state-of-the-art methods."}
{"id": "2506.22824", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.22824", "abs": "https://arxiv.org/abs/2506.22824", "authors": ["Lingyun Xu", "Bowen Wang", "Huiyong Li", "Ziyang Cheng"], "title": "Sensing Security Oriented OFDM-ISAC Against Multi-Intercept Threats", "comment": null, "summary": "In recent years, security has emerged as a critical aspect of integrated\nsensing and communication (ISAC) systems. While significant research has\nfocused on secure communications, particularly in ensuring physical layer\nsecurity, the issue of sensing security has received comparatively less\nattention. This paper addresses the sensing security problem in ISAC,\nparticularly under the threat of multi-intercept adversaries. We consider a\nrealistic scenario in which the sensing target is an advanced electronic\nreconnaissance aircraft capable of employing multiple signal interception\ntechniques, such as power detection (PD) and cyclostationary analysis (CA). To\nevaluate sensing security under such sophisticated threats, we analyze two\ncritical features of the transmitted signal: (i) power distribution and (ii)\ncyclic spectrum. Further, we introduce a novel ergodic cyclic spectrum metric\nwhich leverages the intrinsic mathematical structure of cyclostationary signals\nto more comprehensively characterize their behavior. Building on this analysis,\nwe formulate a new ISAC design problem that explicitly considers sensing\nsecurity, and we develop a low-complexity, efficient optimization approach to\nsolve it. Simulation results demonstrate that the proposed metric is both\neffective and insightful, and that our ISAC design significantly enhances\nsensing security performance in the presence of multi-intercept threats."}
{"id": "2506.23490", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.23490", "abs": "https://arxiv.org/abs/2506.23490", "authors": ["Junxuan Yu", "Yaofei Duan", "Yuhao Huang", "Yu Wang", "Rongbo Ling", "Weihao Luo", "Ang Zhang", "Jingxian Xu", "Qiongying Ni", "Yongsong Zhou", "Binghan Li", "Haoran Dou", "Liping Liu", "Yanfen Chu", "Feng Geng", "Zhe Sheng", "Zhifeng Ding", "Dingxin Zhang", "Rui Huang", "Yuhang Zhang", "Xiaowei Xu", "Tao Tan", "Dong Ni", "Zhongshan Gou", "Xin Yang"], "title": "UltraTwin: Towards Cardiac Anatomical Twin Generation from Multi-view 2D Ultrasound", "comment": "accepted by miccai 2025", "summary": "Echocardiography is routine for cardiac examination. However, 2D ultrasound\n(US) struggles with accurate metric calculation and direct observation of 3D\ncardiac structures. Moreover, 3D US is limited by low resolution, small field\nof view and scarce availability in practice. Constructing the cardiac\nanatomical twin from 2D images is promising to provide precise treatment\nplanning and clinical quantification. However, it remains challenging due to\nthe rare paired data, complex structures, and US noises. In this study, we\nintroduce a novel generative framework UltraTwin, to obtain cardiac anatomical\ntwin from sparse multi-view 2D US. Our contribution is three-fold. First,\npioneered the construction of a real-world and high-quality dataset containing\nstrictly paired multi-view 2D US and CT, and pseudo-paired data. Second, we\npropose a coarse-to-fine scheme to achieve hierarchical reconstruction\noptimization. Last, we introduce an implicit autoencoder for topology-aware\nconstraints. Extensive experiments show that UltraTwin reconstructs\nhigh-quality anatomical twins versus strong competitors. We believe it advances\nanatomical twin modeling for potential applications in personalized cardiac\ncare."}
{"id": "2506.22844", "categories": ["eess.SP", "cs.NI"], "pdf": "https://arxiv.org/pdf/2506.22844", "abs": "https://arxiv.org/abs/2506.22844", "authors": ["Navid Keshtiarast", "Marina Petrova"], "title": "Coexistence analysis of Wi-Fi 6E and 5G NR-U in the 6 GHz band", "comment": "Accepted for Publication in ICNS3 2025", "summary": "The ever-increasing demand for broadband and IoT wireless connectivity has\nrecently urged the regulators around the world to start opening the 6 GHz\nspectrum for unlicensed use. These bands will, for example, permit the use of\nadditional 1.2 GHz in the US and 500 MHz in Europe for unlicensed radio access\ntechnologies (RATs) such as Wi-Fi and 5G New Radio Unlicensed (5G NR-U). To\nsupport QoS-sensitive applications with both technologies, fair and efficient\ncoexistence approaches between the two RATs, as well as with incumbents already\noperating in the 6 GHz band, are crucial. In this paper, we study through\nextensive simulations the achievable mean downlink throughput of both Wi-Fi 6E\nAPs and 5G NR-U gNBs when they are co-deployed in a dense residential scenario\nunder high-interference conditions. We also explore how different parameter\nsettings e.g., MAC frame aggregation, energy detection threshold and maximum\nchannel occupancy time (MCOT) affect the coexistence. Our findings give\nimportant insights into how to tune the key parameters to design fair\ncoexistence policies."}
{"id": "2506.23506", "categories": ["eess.IV", "cs.AI", "cs.CV", "physics.med-ph"], "pdf": "https://arxiv.org/pdf/2506.23506", "abs": "https://arxiv.org/abs/2506.23506", "authors": ["Bowen Xin", "Rohan Hickey", "Tamara Blake", "Jin Jin", "Claire E Wainwright", "Thomas Benkert", "Alto Stemmer", "Peter Sly", "David Coman", "Jason Dowling"], "title": "Artificial Intelligence-assisted Pixel-level Lung (APL) Scoring for Fast and Accurate Quantification in Ultra-short Echo-time MRI", "comment": "Oral presentation in ISMRM2025", "summary": "Lung magnetic resonance imaging (MRI) with ultrashort echo-time (UTE)\nrepresents a recent breakthrough in lung structure imaging, providing image\nresolution and quality comparable to computed tomography (CT). Due to the\nabsence of ionising radiation, MRI is often preferred over CT in paediatric\ndiseases such as cystic fibrosis (CF), one of the most common genetic disorders\nin Caucasians. To assess structural lung damage in CF imaging, CT scoring\nsystems provide valuable quantitative insights for disease diagnosis and\nprogression. However, few quantitative scoring systems are available in\nstructural lung MRI (e.g., UTE-MRI). To provide fast and accurate\nquantification in lung MRI, we investigated the feasibility of novel Artificial\nintelligence-assisted Pixel-level Lung (APL) scoring for CF. APL scoring\nconsists of 5 stages, including 1) image loading, 2) AI lung segmentation, 3)\nlung-bounded slice sampling, 4) pixel-level annotation, and 5) quantification\nand reporting. The results shows that our APL scoring took 8.2 minutes per\nsubject, which was more than twice as fast as the previous grid-level scoring.\nAdditionally, our pixel-level scoring was statistically more accurate\n(p=0.021), while strongly correlating with grid-level scoring (R=0.973,\np=5.85e-9). This tool has great potential to streamline the workflow of UTE\nlung MRI in clinical settings, and be extended to other structural lung MRI\nsequences (e.g., BLADE MRI), and for other lung diseases (e.g.,\nbronchopulmonary dysplasia)."}
{"id": "2506.22903", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2506.22903", "abs": "https://arxiv.org/abs/2506.22903", "authors": ["Weicong Chen", "Jiajia Guo", "Yiming Cui", "Xiao Li", "Shi Jin"], "title": "Limited Feedback in RIS-Assisted Wireless Communications: Use Cases, Challenges, and Future Directions", "comment": "This work has been submitted for possible publication", "summary": "Channel state information (CSI) is essential to unlock the potential of\nreconfigurable intelligent surfaces (RISs) in wireless communication systems.\nSince massive RIS elements are typically implemented without baseband signal\nprocessing capabilities, limited CSI feedback is necessary when designing the\nreflection/refraction coefficients of the RIS. In this article, the unique\nRIS-assisted channel features, such as the RIS position-dependent channel\nfluctuation, the ultra-high dimensional sub-channel matrix, and the structured\nsparsity, are distilled from recent advances in limited feedback and used as\nguidelines for designing feedback schemes. We begin by illustrating the use\ncases and the corresponding challenges associated with RIS feedback. We then\ndiscuss how to leverage techniques such as channel customization,\nstructured-sparsity, autoencoders, and others to reduce feedback overhead and\ncomplexity when devising feedback schemes. Finally, we identify potential\nresearch directions by considering the unresolved challenges, the new RIS\narchitecture, and the integration with multi-modal information and artificial\nintelligence."}
{"id": "2506.23537", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.23537", "abs": "https://arxiv.org/abs/2506.23537", "authors": ["Xinyue Li", "Zhangkai Ni", "Wenhan Yang"], "title": "AFUNet: Cross-Iterative Alignment-Fusion Synergy for HDR Reconstruction via Deep Unfolding Paradigm", "comment": "Accepted to International Conference on Computer Vision (ICCV) 2025", "summary": "Existing learning-based methods effectively reconstruct HDR images from\nmulti-exposure LDR inputs with extended dynamic range and improved detail, but\nthey rely more on empirical design rather than theoretical foundation, which\ncan impact their reliability. To address these limitations, we propose the\ncross-iterative Alignment and Fusion deep Unfolding Network (AFUNet), where HDR\nreconstruction is systematically decoupled into two interleaved subtasks --\nalignment and fusion -- optimized through alternating refinement, achieving\nsynergy between the two subtasks to enhance the overall performance. Our method\nformulates multi-exposure HDR reconstruction from a Maximum A Posteriori (MAP)\nestimation perspective, explicitly incorporating spatial correspondence priors\nacross LDR images and naturally bridging the alignment and fusion subproblems\nthrough joint constraints. Building on the mathematical foundation, we\nreimagine traditional iterative optimization through unfolding -- transforming\nthe conventional solution process into an end-to-end trainable AFUNet with\ncarefully designed modules that work progressively. Specifically, each\niteration of AFUNet incorporates an Alignment-Fusion Module (AFM) that\nalternates between a Spatial Alignment Module (SAM) for alignment and a Channel\nFusion Module (CFM) for adaptive feature fusion, progressively bridging\nmisaligned content and exposure discrepancies. Extensive qualitative and\nquantitative evaluations demonstrate AFUNet's superior performance,\nconsistently surpassing state-of-the-art methods. Our code is available at:\nhttps://github.com/eezkni/AFUNet"}
{"id": "2506.22935", "categories": ["eess.SP", "cs.LG", "cs.NA", "math.NA", "94A12, 65T50, 68T05", "F.2.1; I.2.6; G.1.0"], "pdf": "https://arxiv.org/pdf/2506.22935", "abs": "https://arxiv.org/abs/2506.22935", "authors": ["Marc Bara Iniesta"], "title": "Differentiable Radar Ambiguity Functions: Mathematical Formulation and Computational Implementation", "comment": "16 pages, 4 figures, source code available at\n  https://github.com/marcbara/graf-psl-lpi (DOI: 10.5281/zenodo.15763301)", "summary": "The ambiguity function is fundamental to radar waveform design,\ncharacterizing range and Doppler resolution capabilities. However, its\ntraditional formulation involves non-differentiable operations, preventing\nintegration with gradient-based optimization methods and modern machine\nlearning frameworks. This paper presents the first complete mathematical\nframework and computational implementation for differentiable radar ambiguity\nfunctions. Our approach addresses the fundamental technical challenges that\nhave prevented the radar community from leveraging automatic differentiation:\nproper handling of complex-valued gradients using Wirtinger calculus, efficient\ncomputation through parallelized FFT operations, numerical stability throughout\ncascaded operations, and composability with arbitrary differentiable\noperations. We term this approach GRAF (Gradient-based Radar Ambiguity\nFunctions), which reformulates the ambiguity function computation to maintain\nmathematical equivalence while enabling gradient flow through the entire\npipeline. The resulting implementation provides a general-purpose\ndifferentiable ambiguity function compatible with modern automatic\ndifferentiation frameworks, enabling new research directions including neural\nnetwork-based waveform generation with ambiguity constraints, end-to-end\noptimization of radar systems, and integration of classical radar theory with\nmodern deep learning. We provide complete implementation details and\ndemonstrate computational efficiency suitable for practical applications. This\nwork establishes the mathematical and computational foundation for applying\nmodern machine learning techniques to radar waveform design, bridging classical\nradar signal processing with automatic differentiation frameworks."}
{"id": "2506.23584", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.23584", "abs": "https://arxiv.org/abs/2506.23584", "authors": ["Renjie Liang", "Zhengkang Fan", "Jinqian Pan", "Chenkun Sun", "Russell Terry", "Jie Xu"], "title": "A Clinically-Grounded Two-Stage Framework for Renal CT Report Generation", "comment": null, "summary": "Generating radiology reports from CT scans remains a complex task due to the\nnuanced nature of medical imaging and the variability in clinical\ndocumentation. In this study, we propose a two-stage framework for generating\nrenal radiology reports from 2D CT slices. First, we extract structured\nabnormality features using a multi-task learning model trained to identify\nlesion attributes such as location, size, enhancement, and attenuation. These\nextracted features are subsequently combined with the corresponding CT image\nand fed into a fine-tuned vision-language model to generate natural language\nreport sentences aligned with clinical findings. We conduct experiments on a\ncurated dataset of renal CT studies with manually annotated\nsentence-slice-feature triplets and evaluate performance using both\nclassification metrics and natural language generation metrics. Our results\ndemonstrate that the proposed model outperforms random baselines across all\nabnormality types, and the generated reports capture key clinical content with\nreasonable textual accuracy. This exploratory work highlights the feasibility\nof modular, feature-informed report generation for renal imaging. Future\nefforts will focus on extending this pipeline to 3D CT volumes and further\nimproving clinical fidelity in multimodal medical AI systems."}
{"id": "2506.22943", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.22943", "abs": "https://arxiv.org/abs/2506.22943", "authors": ["Siyun Liang", "Chen Zhu", "Zhaohui Yang", "Changsheng You", "Dusit Niyato", "Kai-Kit Wong", "Zhaoyang Zhang"], "title": "Rate Maximization for Fluid Antenna System Assisted Semantic Communication", "comment": null, "summary": "In this paper, we investigate the problem of rate maximization in a fluid\nantenna system (FAS) assisted\n  semantic communication system. In the considered model, a base station (BS)\nwith multiple static antennas employs semantic extraction techniques to\ncompress the data ready to be sent to a user. The user equipped with a fluid\nantenna is located in the near field coverage region of the BS. Our aim is to\njointly optimize the transmit beamforming and the semantic compression rate at\nthe BS, as well as the selection of activated ports in FAS, to maximize the\nequivalent transmission ratio under a specific power budget. We design an\nalternating algorithm to solve the problem, where we obtain the optimal\nsemantic compression ratio is in closed form at each step. Simulation results\nvalidate the effectiveness of the proposed algorithm."}
{"id": "2506.23664", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.23664", "abs": "https://arxiv.org/abs/2506.23664", "authors": ["Fangyijie Wang", "Kevin Whelan", "Félix Balado", "Guénolé Silvestre", "Kathleen M. Curran"], "title": "Diffusion Model-based Data Augmentation Method for Fetal Head Ultrasound Segmentation", "comment": null, "summary": "Medical image data is less accessible than in other domains due to privacy\nand regulatory constraints. In addition, labeling requires costly,\ntime-intensive manual image annotation by clinical experts. To overcome these\nchallenges, synthetic medical data generation offers a promising solution.\nGenerative AI (GenAI), employing generative deep learning models, has proven\neffective at producing realistic synthetic images. This study proposes a novel\nmask-guided GenAI approach using diffusion models to generate synthetic fetal\nhead ultrasound images paired with segmentation masks. These synthetic pairs\naugment real datasets for supervised fine-tuning of the Segment Anything Model\n(SAM). Our results show that the synthetic data captures real image features\neffectively, and this approach reaches state-of-the-art fetal head\nsegmentation, especially when trained with a limited number of real image-mask\npairs. In particular, the segmentation reaches Dice Scores of 94.66\\% and\n94.38\\% using a handful of ultrasound images from the Spanish and African\ncohorts, respectively. Our code, models, and data are available on GitHub."}
{"id": "2506.23045", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2506.23045", "abs": "https://arxiv.org/abs/2506.23045", "authors": ["Saif Khan Mohammed", "Sandesh Rao Mattu", "Nishant Mehrotra", "Venkatesh Khammammetti", "Robert Calderbank"], "title": "Zak-OFDM: Low Complexity Joint Equalization of OFDM Carriers in Doubly-Spread Channels", "comment": null, "summary": "We communicate over wireless channels by first estimating and then equalizing\nthe effective channel. In Zak-OTFS (orthogonal time frequency space) modulation\nthe carrier waveform is a pulse in the delay-Doppler (DD) domain, formally a\nquasi-periodic localized function with specific periods along delay and\nDoppler. When the channel delay spread is less than the delay period, and the\nchannel Doppler spread is less than the Doppler period, the response to a\nsingle Zak-OTFS carrier provides an image of the scattering environment and can\nbe used to predict the effective channel at all other carriers. This makes\nchannel estimation straightforward, and there is no loss in spectral efficiency\nsince it is possible to design data and pilot signals that are mutually\nunbiased. However, the naive approach to equalization has complexity ${\\mathcal\nO}(M^3N^3)$ where $M$ and $N$ are respectively the number of delay and Doppler\nbins in an OTFS frame. We simplify equalization by transforming Zak-OTFS\ninformation symbols to CP-OFDM (cyclic prefix orthogonal frequency division\nmultiplexing) modulation.\n  Why not simply communicate with CP-OFDM? Inter-carrier interference (ICI) in\nCP-OFDM makes it is very challenging to acquire the complete frequency domain\n(FD) channel response between subcarriers in the presence of mobility and delay\nspread. We avoid this difficulty by estimating the effective channel in the DD\ndomain from which we are able to reconstruct the complete FD channel response.\nWe take advantage of CP-OFDM to design an ${\\mathcal O}(M^2N^2)$ low-complexity\nmethod of jointly equalizing all subcarriers, where $MN$ is the number of\nsubcarriers. Our approach removes the need for traditional pilots in CP-OFDM\nand reduces the need to vary carrier spacing with mobility."}
{"id": "2506.23688", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2506.23688", "abs": "https://arxiv.org/abs/2506.23688", "authors": ["Jiaxin Yang", "Vasileios Magoulianitis", "Catherine Aurelia Christie Alexander", "Jintang Xue", "Masatomo Kaneko", "Giovanni Cacciamani", "Andre Abreu", "Vinay Duddalwar", "C. -C. Jay Kuo", "Inderbir S. Gill", "Chrysostomos Nikias"], "title": "GUSL: A Novel and Efficient Machine Learning Model for Prostate Segmentation on MRI", "comment": null, "summary": "Prostate and zonal segmentation is a crucial step for clinical diagnosis of\nprostate cancer (PCa). Computer-aided diagnosis tools for prostate segmentation\nare based on the deep learning (DL) paradigm. However, deep neural networks are\nperceived as \"black-box\" solutions by physicians, thus making them less\npractical for deployment in the clinical setting. In this paper, we introduce a\nfeed-forward machine learning model, named Green U-shaped Learning (GUSL),\nsuitable for medical image segmentation without backpropagation. GUSL\nintroduces a multi-layer regression scheme for coarse-to-fine segmentation. Its\nfeature extraction is based on a linear model, which enables seamless\ninterpretability during feature extraction. Also, GUSL introduces a mechanism\nfor attention on the prostate boundaries, which is an error-prone region, by\nemploying regression to refine the predictions through residue correction. In\naddition, a two-step pipeline approach is used to mitigate the class imbalance,\nan issue inherent in medical imaging problems. After conducting experiments on\ntwo publicly available datasets and one private dataset, in both prostate gland\nand zonal segmentation tasks, GUSL achieves state-of-the-art performance among\nother DL-based models. Notably, GUSL features a very energy-efficient pipeline,\nsince it has a model size several times smaller and less complexity than the\nrest of the solutions. In all datasets, GUSL achieved a Dice Similarity\nCoefficient (DSC) performance greater than $0.9$ for gland segmentation.\nConsidering also its lightweight model size and transparency in feature\nextraction, it offers a competitive and practical package for medical imaging\napplications."}
{"id": "2506.23118", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.23118", "abs": "https://arxiv.org/abs/2506.23118", "authors": ["Liping Bai", "Yu Ge", "Henk Wymeersch"], "title": "Belief Propagation-based Target Handover in Distributed Integrated Sensing and Communication", "comment": null, "summary": "Distributed integrated sensing and communication (DISAC) systems are key\nenablers for 6G networks, offering the capability to jointly track multiple\ntargets using spatially distributed base stations (BSs). A fundamental\nchallenge in DISAC is the seamless and efficient handover of target tracks\nbetween BSs with partially overlapping fields of view, especially in dense and\ndynamic environments. In this paper, we propose a novel target handover\nframework based on belief propagation (BP) for multi-target tracking in DISAC\nsystems. By representing the probabilistic data association and tracking\nproblem through a factor graph, the proposed method enables efficient marginal\ninference with reduced computational complexity. Our framework introduces a\nprincipled handover criterion and message-passing strategy that minimizes\ninter-BS communication while maintaining tracking continuity and accuracy. We\ndemonstrate that the proposed handover procedure achieves performance\ncomparable to centralized processing, yet significantly reduces data exchange\nand processing overhead. Extensive simulations validate the robustness of the\napproach in urban tracking scenarios with closely spaced targets."}
{"id": "2506.23700", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.23700", "abs": "https://arxiv.org/abs/2506.23700", "authors": ["Peiting Tian", "Xi Chen", "Haixia Bi", "Fan Li"], "title": "MedSAM-CA: A CNN-Augmented ViT with Attention-Enhanced Multi-Scale Fusion for Medical Image Segmentation", "comment": null, "summary": "Medical image segmentation plays a crucial role in clinical diagnosis and\ntreatment planning, where accurate boundary delineation is essential for\nprecise lesion localization, organ identification, and quantitative assessment.\nIn recent years, deep learning-based methods have significantly advanced\nsegmentation accuracy. However, two major challenges remain. First, the\nperformance of these methods heavily relies on large-scale annotated datasets,\nwhich are often difficult to obtain in medical scenarios due to privacy\nconcerns and high annotation costs. Second, clinically challenging scenarios,\nsuch as low contrast in certain imaging modalities and blurry lesion boundaries\ncaused by malignancy, still pose obstacles to precise segmentation. To address\nthese challenges, we propose MedSAM-CA, an architecture-level fine-tuning\napproach that mitigates reliance on extensive manual annotations by adapting\nthe pretrained foundation model, Medical Segment Anything (MedSAM). MedSAM-CA\nintroduces two key components: the Convolutional Attention-Enhanced Boundary\nRefinement Network (CBR-Net) and the Attention-Enhanced Feature Fusion Block\n(Atte-FFB). CBR-Net operates in parallel with the MedSAM encoder to recover\nboundary information potentially overlooked by long-range attention mechanisms,\nleveraging hierarchical convolutional processing. Atte-FFB, embedded in the\nMedSAM decoder, fuses multi-level fine-grained features from skip connections\nin CBR-Net with global representations upsampled within the decoder to enhance\nboundary delineation accuracy. Experiments on publicly available datasets\ncovering dermoscopy, CT, and MRI imaging modalities validate the effectiveness\nof MedSAM-CA. On dermoscopy dataset, MedSAM-CA achieves 94.43% Dice with only\n2% of full training data, reaching 97.25% of full-data training performance,\ndemonstrating strong effectiveness in low-resource clinical settings."}
{"id": "2506.23203", "categories": ["eess.SP", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23203", "abs": "https://arxiv.org/abs/2506.23203", "authors": ["Feng Shu", "Jiatong Bai", "Di Wu", "Wei Zhu", "Bin Deng", "Fuhui Zhou", "Jiangzhou Wang"], "title": "Multi-Branch DNN and CRLB-Ratio-Weight Fusion for Enhanced DOA Sensing via a Massive H$^2$AD MIMO Receiver", "comment": null, "summary": "As a green MIMO structure, massive H$^2$AD is viewed as a potential\ntechnology for the future 6G wireless network. For such a structure, it is a\nchallenging task to design a low-complexity and high-performance fusion of\ntarget direction values sensed by different sub-array groups with fewer use of\nprior knowledge. To address this issue, a lightweight Cramer-Rao lower bound\n(CRLB)-ratio-weight fusion (WF) method is proposed, which approximates inverse\nCRLB of each subarray using antenna number reciprocals to eliminate real-time\nCRLB computation. This reduces complexity and prior knowledge dependence while\npreserving fusion performance. Moreover, a multi-branch deep neural network\n(MBDNN) is constructed to further enhance direction-of-arrival (DOA) sensing by\nleveraging candidate angles from multiple subarrays. The subarray-specific\nbranch networks are integrated with a shared regression module to effectively\neliminate pseudo-solutions and fuse true angles. Simulation results show that\nthe proposed CRLB-ratio-WF method achieves DOA sensing performance comparable\nto CRLB-based methods, while significantly reducing the reliance on prior\nknowledge. More notably, the proposed MBDNN has superior performance in low-SNR\nranges. At SNR $= -15$ dB, it achieves an order-of-magnitude improvement in\nestimation accuracy compared to CRLB-ratio-WF method."}
{"id": "2506.23701", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.23701", "abs": "https://arxiv.org/abs/2506.23701", "authors": ["Lingtong Zhang", "Mengdie Song", "Xiaohan Hao", "Huayu Mai", "Bensheng Qiu"], "title": "MDPG: Multi-domain Diffusion Prior Guidance for MRI Reconstruction", "comment": "Accept by MICCAI2025", "summary": "Magnetic Resonance Imaging (MRI) reconstruction is essential in medical\ndiagnostics. As the latest generative models, diffusion models (DMs) have\nstruggled to produce high-fidelity images due to their stochastic nature in\nimage domains. Latent diffusion models (LDMs) yield both compact and detailed\nprior knowledge in latent domains, which could effectively guide the model\ntowards more effective learning of the original data distribution. Inspired by\nthis, we propose Multi-domain Diffusion Prior Guidance (MDPG) provided by\npre-trained LDMs to enhance data consistency in MRI reconstruction tasks.\nSpecifically, we first construct a Visual-Mamba-based backbone, which enables\nefficient encoding and reconstruction of under-sampled images. Then pre-trained\nLDMs are integrated to provide conditional priors in both latent and image\ndomains. A novel Latent Guided Attention (LGA) is proposed for efficient fusion\nin multi-level latent domains. Simultaneously, to effectively utilize a prior\nin both the k-space and image domain, under-sampled images are fused with\ngenerated full-sampled images by the Dual-domain Fusion Branch (DFB) for\nself-adaption guidance. Lastly, to further enhance the data consistency, we\npropose a k-space regularization strategy based on the non-auto-calibration\nsignal (NACS) set. Extensive experiments on two public MRI datasets fully\ndemonstrate the effectiveness of the proposed methodology. The code is\navailable at https://github.com/Zolento/MDPG."}
{"id": "2506.23368", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.23368", "abs": "https://arxiv.org/abs/2506.23368", "authors": ["Istiaq Ahmed", "Md Asif Ul Hoq Khan", "MD Zahedul Islam", "Md Sakibul Hasan", "Tanaya Jakir", "Arat Hossain", "Joynal Abed", "Muhammad Hasanuzzaman", "Sadia Sharmeen Shatyi", "Kazi Nehal Hasnain"], "title": "Optimizing Solar Energy Production in the USA: Time-Series Analysis Using AI for Smart Energy Management", "comment": null, "summary": "As the US rapidly moves towards cleaner energy sources, solar energy is fast\nbecoming the pillar of its renewable energy mix. Even while solar energy is\nincreasingly being used, its variability is a key hindrance to grid stability,\nstorage efficiency, and system stability overall. Solar energy has emerged as\none of the fastest-growing renewable energy sources in the United States,\nadding noticeably to the country's energy mix. Retrospectively, the necessity\nof inserting the sun's energy into the grid without disrupting reliability and\ncost efficiencies highlights the necessity of good forecasting software and\nsmart control systems. The dataset utilized for this research project comprised\nboth hourly and daily solar energy production records collected from multiple\nutility-scale solar farms across diverse U.S. regions, including California,\nTexas, and Arizona. Training and evaluation of all models were performed with a\ntime-based cross-validation scheme, namely, sliding window validation. Both the\nRandom Forest and the XG-Boost models demonstrated noticeably greater and the\nsame performance across each of the measures considered, with relatively high\naccuracy. The almost perfect and equal performance by the Random Forest and\nXG-Boost models also shows both models to have learned the patterns in the data\nvery comprehensively, with high reliability in their predictions. By\nincorporating AI-powered time-series models like XG-Boost in grid management\nsoftware, utility companies can dynamically modify storage cycles in real-time\nas well as dispatch and peak load planning, based on their predictions.\nAI-powered solar forecasting also has profound implications for renewable\nenergy policy and planning, particularly as U.S. federal and state governments\naccelerate toward ambitious decarbonization goals."}
{"id": "2506.23721", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.23721", "abs": "https://arxiv.org/abs/2506.23721", "authors": ["Gijs Luijten", "Roberto Maria Scardigno", "Lisle Faray de Paiva", "Peter Hoyer", "Jens Kleesiek", "Domenico Buongiorno", "Vitoantonio Bevilacqua", "Jan Egger"], "title": "Deep Learning-Based Semantic Segmentation for Real-Time Kidney Imaging and Measurements with Augmented Reality-Assisted Ultrasound", "comment": null, "summary": "Ultrasound (US) is widely accessible and radiation-free but has a steep\nlearning curve due to its dynamic nature and non-standard imaging planes.\nAdditionally, the constant need to shift focus between the US screen and the\npatient poses a challenge. To address these issues, we integrate deep learning\n(DL)-based semantic segmentation for real-time (RT) automated kidney volumetric\nmeasurements, which are essential for clinical assessment but are traditionally\ntime-consuming and prone to fatigue. This automation allows clinicians to\nconcentrate on image interpretation rather than manual measurements.\nComplementing DL, augmented reality (AR) enhances the usability of US by\nprojecting the display directly into the clinician's field of view, improving\nergonomics and reducing the cognitive load associated with screen-to-patient\ntransitions. Two AR-DL-assisted US pipelines on HoloLens-2 are proposed: one\nstreams directly via the application programming interface for a wireless\nsetup, while the other supports any US device with video output for broader\naccessibility. We evaluate RT feasibility and accuracy using the Open Kidney\nDataset and open-source segmentation models (nnU-Net, Segmenter, YOLO with\nMedSAM and LiteMedSAM). Our open-source GitHub pipeline includes model\nimplementations, measurement algorithms, and a Wi-Fi-based streaming solution,\nenhancing US training and diagnostics, especially in point-of-care settings."}
{"id": "2506.23410", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.23410", "abs": "https://arxiv.org/abs/2506.23410", "authors": ["Byunghyun Lee", "Rang Liu", "David J. Love", "James V. Krogmeier", "A. Lee Swindlehurst"], "title": "Integrated Polarimetric Sensing and Communication with Polarization-Reconfigurable Arrays", "comment": null, "summary": "Polarization diversity offers a cost- and space-efficient solution to enhance\nthe performance of integrated sensing and communication systems. Polarimetric\nsensing exploits the signal's polarity to extract details about the target such\nas shape, pose, and material composition. From a communication perspective,\npolarization diversity can enhance the reliability and throughput of\ncommunication channels. This paper proposes an integrated polarimetric sensing\nand communication (IPSAC) system that jointly conducts polarimetric sensing and\ncommunications. We study the use of single-port polarization-reconfigurable\nantennas to adapt to channel depolarization effects, without the need for\nseparate RF chains for each polarization. We address the problem of optimizing\nwaveforms and polarizations based on two sensing metrics. We first consider\nminimizing the mean square error (MSE) of the target depolarization parameter\nestimate, which is a critical task for various polarimetric radar applications\nsuch as rainfall forecasting, vegetation identification, and target\nclassification. To address this nonconvex problem, we apply semi-definite\nrelaxation (SDR) and majorization-minimization (MM) optimization techniques.\nNext, we consider a design that maximizes the target\nsignal-to-interference-plus-noise ratio (SINR) leveraging prior knowledge of\nthe target and clutter depolarization statistics to enhance the target\ndetection performance. To tackle this problem, we modify the solution developed\nfor MSE minimization subject to the same quality-of-service (QoS) constraints.\nExtensive simulations show that the proposed polarization reconfiguration\nmethod substantially improves the depolarization parameter MSE. Furthermore,\nthe proposed method considerably boosts the target SINR due to polarization\ndiversity, particularly in cluttered environments."}
{"id": "2506.23759", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.23759", "abs": "https://arxiv.org/abs/2506.23759", "authors": ["Zheng Fang", "Xiaoming Qi", "Chun-Mei Feng", "Jialun Pei", "Weixin Si", "Yueming Jin"], "title": "Spatio-Temporal Representation Decoupling and Enhancement for Federated Instrument Segmentation in Surgical Videos", "comment": null, "summary": "Surgical instrument segmentation under Federated Learning (FL) is a promising\ndirection, which enables multiple surgical sites to collaboratively train the\nmodel without centralizing datasets. However, there exist very limited FL works\nin surgical data science, and FL methods for other modalities do not consider\ninherent characteristics in surgical domain: i) different scenarios show\ndiverse anatomical backgrounds while highly similar instrument representation;\nii) there exist surgical simulators which promote large-scale synthetic data\ngeneration with minimal efforts. In this paper, we propose a novel Personalized\nFL scheme, Spatio-Temporal Representation Decoupling and Enhancement (FedST),\nwhich wisely leverages surgical domain knowledge during both local-site and\nglobal-server training to boost segmentation. Concretely, our model embraces a\nRepresentation Separation and Cooperation (RSC) mechanism in local-site\ntraining, which decouples the query embedding layer to be trained privately, to\nencode respective backgrounds. Meanwhile, other parameters are optimized\nglobally to capture the consistent representations of instruments, including\nthe temporal layer to capture similar motion patterns. A textual-guided channel\nselection is further designed to highlight site-specific features, facilitating\nmodel adapta tion to each site. Moreover, in global-server training, we propose\nSynthesis-based Explicit Representation Quantification (SERQ), which defines an\nexplicit representation target based on synthetic data to synchronize the model\nconvergence during fusion for improving model generalization."}
{"id": "2506.23432", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.23432", "abs": "https://arxiv.org/abs/2506.23432", "authors": ["Mohammad Taghi Dabiri", "Mazen Hasna", "Saud Althunibat", "Khalid Qaraqe"], "title": "All-Optical Inter-Satellite Relays with Intelligent Beam Control: Harnessing Liquid Lenses and Optical Hard Limiters", "comment": null, "summary": "Low Earth orbit (LEO) satellite constellations are emerging as a key enabler\nof next-generation communications, offering global coverage and significantly\nlower latency compared to traditional terrestrial networks and geostationary\nsatellites. However, further latency reduction is essential for time-critical\napplications such as real-time sensing, autonomous systems, and interactive\nservices. One critical bottleneck is the optical-to-electrical (O/E) and\nelectrical-to-optical (E/O) conversions at intermediate nodes in multi-hop\nlinks, which introduce unwanted processing delays. To address this, we\ninvestigate an all-optical relay system based on Optical Hard Limiters (OHL),\nwhich operate purely in the optical domain to suppress noise and restore signal\nquality without requiring O/E conversions. First, we present a rigorous\nanalysis of inter-satellite multi-relay communication under the OHL relaying\narchitecture, comparing it against conventional Amplify-and-Forward (AF) and\nDecode-and-Forward (DF) schemes. Through this comparison, we highlight both the\nadvantages and limitations of OHL relays, including their particular\nsensitivity to parameter choices such as the threshold setting and divergence\nangle at the transmitter. Recognizing that a LEO constellation is inherently\ntime-varying - satellites move relative to one another, causing continuous\nchanges in link distances and tracking errors - we propose a joint optimization\nstrategy. This scheme adaptively tunes the OHL decision threshold and beam\ndivergence in real time to maintain optimal performance, ultimately lowering\nerror rates and latency. Extensive simulations in a large-scale LEO network\ndemonstrate the viability of our method and offer insights into practical\nimplementation for next-generation inter-satellite communication systems."}
{"id": "2506.24003", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.24003", "abs": "https://arxiv.org/abs/2506.24003", "authors": ["Junqi Liu", "Dongli He", "Wenxuan Li", "Ningyu Wang", "Alan L. Yuille", "Zongwei Zhou"], "title": "ShapeKit", "comment": null, "summary": "In this paper, we present a practical approach to improve anatomical shape\naccuracy in whole-body medical segmentation. Our analysis shows that a\nshape-focused toolkit can enhance segmentation performance by over 8%, without\nthe need for model re-training or fine-tuning. In comparison, modifications to\nmodel architecture typically lead to marginal gains of less than 3%. Motivated\nby this observation, we introduce ShapeKit, a flexible and easy-to-integrate\ntoolkit designed to refine anatomical shapes. This work highlights the\nunderappreciated value of shape-based tools and calls attention to their\npotential impact within the medical segmentation community."}
{"id": "2506.23455", "categories": ["eess.SP", "quant-ph"], "pdf": "https://arxiv.org/pdf/2506.23455", "abs": "https://arxiv.org/abs/2506.23455", "authors": ["Jieao Zhu", "Linglong Dai"], "title": "General Signal Model and Capacity Limit for Rydberg Quantum Information System", "comment": "Submitted to TWC. In this paper, we compute the dynamic response of\n  Rydberg atomic receivers by solving the small-signal perturbation solution to\n  quantum master equation. Transfer functions of this quantum receiver is\n  derived, with the instantaneous bandwidths problem and the in-band blackbody\n  radiation noise computed theoretically for the first time", "summary": "Rydberg atomic receivers represent a transformative approach to achieving\nhigh-sensitivity, broadband, and miniaturized radio frequency (RF) reception.\nHowever, existing static signal models for Rydberg atomic receivers rely on the\nsteady-state assumption of atomic quantum states, which cannot fully describe\nthe signal reception process of dynamic signals. To fill in this gap, in this\npaper, we present a general model to compute the dynamic signal response of\nRydberg atomic receivers in closed form. Specifically, by applying small-signal\nperturbation techniques to the quantum master equation, we derive closed-form\nLaplace domain transfer functions that characterize the receiver's dynamic\nresponses to time-varying signal fields. To gain more insights into the\nquantum-based RF-photocurrent conversion process, we further introduce the\nconcept of quantum transconductance that describes the quantum system as an\nequivalent classical system. By applying quantum transconductance, we quantify\nthe influence of in-band blackbody radiation (BBR) noise on the atomic receiver\nsensitivity. Extensive simulations for Rydberg atomic receivers validate the\nproposed signal model, and demonstrate the possibility of quantum receivers to\noutperform classical electronic receivers through the improvement of quantum\ntransconductance."}
{"id": "2506.24014", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2506.24014", "abs": "https://arxiv.org/abs/2506.24014", "authors": ["Peng Lin", "Xuesong Wang", "Yating Chen", "Xianyu Wu", "Feng Huang", "Shouqian Chen"], "title": "Simultaneous Super-Resolution of Spatial and Spectral Imaging with a Camera Array and Notch Filters", "comment": null, "summary": "This study proposes an algorithm based on a notch filter camera array system\nfor simultaneous super-resolution imaging and spectral reconstruction,\nenhancing the spatial resolution and multispectral imaging capabilities of\ntargets. In this study, multi-aperture super-resolution algorithms,\npan-sharpening techniques, and spectral reconstruction algorithms were\ninvestigated and integrated. The sub-pixel level offset information and\nspectral disparities among the 9 low-resolution images captured by the 9\ndistinct imaging apertures were utilized, leading to the successful\nreconstruction of 31 super-resolution spectral images. By conducting\nsimulations with a publicly available dataset and performing qualitative and\nquantitative comparisons with snapshot coded aperture spectral imaging systems,\nthe experimental results demonstrate that our system and algorithm attained a\npeak signal-to-noise ratio of 35.6dB, representing a 5dB enhancement over the\nmost advanced snapshot coded aperture spectral imaging systems, while also\nreducing processing time. This research offers an effective solution for\nachieving high temporal, spectral, and spatial resolution through the\nutilization of multi-aperture imaging systems."}
{"id": "2506.23472", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.23472", "abs": "https://arxiv.org/abs/2506.23472", "authors": ["Ruixu Geng", "Yadong Li", "Dongheng Zhang", "Pengcheng Huang", "Binquan Wang", "Binbin Zhang", "Zhi Lu", "Yang Hu", "Yan Chen"], "title": "Automatic Phase Calibration for High-resolution mmWave Sensing via Ambient Radio Anchors", "comment": "13 pages, 21 figures", "summary": "Millimeter-wave (mmWave) radar systems with large array have pushed radar\nsensing into a new era, thanks to their high angular resolution. However, our\nlong-term experiments indicate that array elements exhibit phase drift over\ntime and require periodic phase calibration to maintain high-resolution,\ncreating an obstacle for practical high-resolution mmWave sensing.\nUnfortunately, existing calibration methods are inadequate for periodic\nrecalibration, either because they rely on artificial references or fail to\nprovide sufficient precision. To address this challenge, we introduce\nAutoCalib, the first framework designed to automatically and accurately\ncalibrate high-resolution mmWave radars by identifying Ambient Radio Anchors\n(ARAs)-naturally existing objects in ambient environments that offer stable\nphase references. AutoCalib achieves calibration by first generating spatial\nspectrum templates based on theoretical electromagnetic characteristics. It\nthen employs a pattern-matching and scoring mechanism to accurately detect\nthese anchors and select the optimal one for calibration. Extensive experiments\nacross 11 environments demonstrate that AutoCalib capable of identifying ARAs\nthat existing methods miss due to their focus on strong reflectors. AutoCalib's\ncalibration performance approaches corner reflectors (74% phase error\nreduction) while outperforming existing methods by 83%. Beyond radar\ncalibration, AutoCalib effectively supports other phase-dependent applications\nlike handheld imaging, delivering 96% of corner reflector calibration\nperformance without artificial references."}
{"id": "2506.24074", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.24074", "abs": "https://arxiv.org/abs/2506.24074", "authors": ["Mayank V. Golhar", "Lucas Sebastian Galeano Fretes", "Loren Ayers", "Venkata S. Akshintala", "Taylor L. Bobrow", "Nicholas J. Durr"], "title": "C3VDv2 -- Colonoscopy 3D video dataset with enhanced realism", "comment": "19 pages, 7 figures", "summary": "Computer vision techniques have the potential to improve the diagnostic\nperformance of colonoscopy, but the lack of 3D colonoscopy datasets for\ntraining and validation hinders their development. This paper introduces\nC3VDv2, the second version (v2) of the high-definition Colonoscopy 3D Video\nDataset, featuring enhanced realism designed to facilitate the quantitative\nevaluation of 3D colon reconstruction algorithms. 192 video sequences were\ncaptured by imaging 60 unique, high-fidelity silicone colon phantom segments.\nGround truth depth, surface normals, optical flow, occlusion,\nsix-degree-of-freedom pose, coverage maps, and 3D models are provided for 169\ncolonoscopy videos. Eight simulated screening colonoscopy videos acquired by a\ngastroenterologist are provided with ground truth poses. The dataset includes\n15 videos featuring colon deformations for qualitative assessment. C3VDv2\nemulates diverse and challenging scenarios for 3D reconstruction algorithms,\nincluding fecal debris, mucous pools, blood, debris obscuring the colonoscope\nlens, en-face views, and fast camera motion. The enhanced realism of C3VDv2\nwill allow for more robust and representative development and evaluation of 3D\nreconstruction algorithms."}
{"id": "2506.23473", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.23473", "abs": "https://arxiv.org/abs/2506.23473", "authors": ["Haotian Liu", "Zhiqing Wei", "Luyang Sun", "Ruizhong Xu", "Yixin Zhang", "Zhiyong Feng"], "title": "Cooperative Sensing in Cell-free Massive MIMO ISAC Systems: Performance Optimization and Signal Processing", "comment": "13 pages, 10 figures", "summary": "Integrated sensing and communication (ISAC), as a technology enabled seamless\nconnection between communication and sensing, is regarded a core enabling\ntechnology for these applications. However, the accuracy of single-node sensing\nin ISAC system is limited, prompting the emergence of multi-node cooperative\nsensing. In multi-node cooperative sensing, the synchronization error limits\nthe sensing accuracy, which can be mitigated by the architecture of cell-free\nmassive multi-input multi-output (CF-mMIMO), since the multiple nodes are\ninterconnected via optical fibers with high synchronization accuracy. However,\nthe multi-node cooperative sensing in CF-mMIMO ISAC systems faces the following\nchallenges: 1) The joint optimization of placement and resource allocation of\ndistributed access points (APs) to improve the sensing performance in\nmulti-target detection scenario is difficult; 2) The fusion of the sensing\ninformation from distributed APs with multi-view discrepancies is difficult. To\naddress these challenges, this paper proposes a joint placement and antenna\nresource optimization scheme for distributed APs to minimize the sensing\nCramr-Rao bound for targets' parameters within the area of interest. Then, a\nsymbol-level fusion-based multi-dynamic target sensing (SL-MDTS) scheme is\nprovided, effectively fusing sensing information from multiple APs. The\nsimulation results validate the effectiveness of the joint optimization scheme\nand the superiority of the SL-MDTS scheme. Compared to state-of-the-art\ngrid-based symbol-level sensing information fusion schemes, the proposed\nSL-MDTS scheme improves the accuracy of localization and velocity estimation by\n44 % and 41.4 %, respectively."}
{"id": "2506.22456", "categories": ["eess.SP", "eess.IV"], "pdf": "https://arxiv.org/pdf/2506.22456", "abs": "https://arxiv.org/abs/2506.22456", "authors": ["Rahul Gulia", "Amlan Ganguly", "Andres Kwasinski", "Michael E. Kuhl", "Ehsan Rashedi", "Clark Hochgraf"], "title": "WISVA: Generative AI for 5G Network Optimization in Smart Warehouses", "comment": null, "summary": "The next decade will usher in a profound transformation of wireless\ncommunication, driven by the ever-increasing demand for data-intensive\napplications and the rapid adoption of emerging technologies. To fully unlock\nthe potential of 5G and beyond, substantial advancements are required in signal\nprocessing techniques, innovative network architectures, and efficient spectrum\nutilization strategies. These advancements facilitate seamless integration of\nemerging technologies, driving industrial digital transformation and\nconnectivity. This paper introduces a novel Variational Autoencoder (VAE)-based\nframework, Wireless Infrastructure for Smart Warehouses using VAE (WISVA),\ndesigned for accurate indoor radio propagation modeling in automated Industry\n4.0 environments such as warehouses and factory floors operating within 5G\nwireless bands. The research delves into the meticulous creation of training\ndata tensors, capturing complex electromagnetic (EM) wave behaviors influenced\nby diverse obstacles, and outlines the architecture and training methodology of\nthe proposed VAE model. The model's robustness and adaptability are showcased\nthrough its ability to predict signal-to-interference-plus-noise ratio (SINR)\nheatmaps across various scenarios, including denoising tasks, validation\ndatasets, extrapolation to unseen configurations, and previously unencountered\nwarehouse layouts. Compelling reconstruction error heatmaps are presented,\nhighlighting the superior accuracy of WISVA compared to traditional autoencoder\nmodels. The paper also analyzes the model's performance in handling complex\nsmart warehouse environments, demonstrating its potential as a key enabler for\noptimizing wireless infrastructure in Industry 4.0."}
{"id": "2506.23495", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.23495", "abs": "https://arxiv.org/abs/2506.23495", "authors": ["Zihang Ding", "Jianhua Zhang", "Changsheng You", "Pan Tang", "Hongbo Xing", "Zhiqiang Yuan", "Jie Meng", "Guangyi Liu"], "title": "Far-Field vs. Near-Field Propagation Channels: Key Differences and Impact on 6G XL-MIMO Performance Evaluation", "comment": "13 pages, 8 figures, 2 tables, 52 references. Note: This article has\n  been submitted to China Communications and is currently under review", "summary": "Extremely large-scale multiple-input multiple-output (XL-MIMO) is regarded as\na promising technology for next-generation communication systems. However, this\nwill expand the near-field (NF) range, rendering more users more likely to be\nlocated in the NF region. In this paper, we aim to answer two questions: What\nare the new characteristics of the NF channel? Is it necessary to develop new\ntransciver techniques to maintain system performance within the NF region? To\nthis end, we first review current NF channel models and analyze the differences\nbetween the existing 3GPP TR 38.901 channel model and the NF channel model,\nincluding the spherical wavefront and spatially non-stationarity. Then, we\nprovide examples on how these differences affect the XL-MIMO system performance\nin terms of beamforming gain and achievable rate. Simulation results\ndemonstrate that, when using far-field (FF) technique under the NF channel, the\nmaximum normalized beam gain loss is less than 3 dB for most users in the NF\nregion defined by Rayleigh distance. Moreover, the achievable rate loss of beam\ntraining is less than 3% compared to that realized by NF technique. Finally, we\ndemonstrate the necessity of employing NF transceiver techniques based on\nsimulation results."}
{"id": "2506.23511", "categories": ["eess.SP", "cs.ET"], "pdf": "https://arxiv.org/pdf/2506.23511", "abs": "https://arxiv.org/abs/2506.23511", "authors": ["Ahmad Abdel-Qader", "Anas Chaaban", "Mohamed S. Shehata"], "title": "Mutli-Level Autoencoder: Deep Learning Based Channel Coding and Modulation", "comment": "Accepted at IWCMC 2025", "summary": "In this paper, we design a deep learning-based convolutional autoencoder for\nchannel coding and modulation. The objective is to develop an adaptive scheme\ncapable of operating at various signal-to-noise ratios (SNR)s without the need\nfor re-training. Additionally, the proposed framework allows validation by\ntesting all possible codes in the codebook, as opposed to previous AI-based\nencoder/decoder frameworks which relied on testing only a small subset of the\navailable codes. This limitation in earlier methods often led to unreliable\nconclusions when generalized to larger codebooks. In contrast to previous\nmethods, our multi-level encoding and decoding approach splits the message into\nblocks, where each encoder block processes a distinct group of $B$ bits. By\ndoing so, the proposed scheme can exhaustively test $2^{B}$ possible codewords\nfor each encoder/decoder level, constituting a layer of the overall scheme. The\nproposed model was compared to classical polar codes and TurboAE-MOD schemes,\nshowing improved reliability with achieving comparable, or even superior\nresults in some settings. Notably, the architecture can adapt to different SNRs\nby selectively removing one of the encoder/decoder layers without re-training,\nthus demonstrating flexibility and efficiency in practical wireless\ncommunication scenarios."}
{"id": "2506.23525", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.23525", "abs": "https://arxiv.org/abs/2506.23525", "authors": ["Wentao Yu", "Khaled B. Letaief", "Lizhong Zheng"], "title": "Sensing for Free: Learn to Localize More Sources than Antennas without Pilots", "comment": "13 pages, 9 figures, 1 table", "summary": "Integrated sensing and communication (ISAC) represents a key paradigm for\nfuture wireless networks. However, existing approaches require waveform\nmodifications, dedicated pilots, or overhead that complicates standards\nintegration. We propose sensing for free - performing multi-source localization\nwithout pilots by reusing uplink data symbols, making sensing occur during\ntransmission and directly compatible with 3GPP 5G NR and 6G specifications.\nWith ever-increasing devices in dense 6G networks, this approach is\nparticularly compelling when combined with sparse arrays, which can localize\nmore sources than uniform arrays via an enlarged virtual array. Existing\npilot-free multi-source localization algorithms first reconstruct an extended\ncovariance matrix and apply subspace methods, incurring cubic complexity and\nlimited to second-order statistics. Performance degrades under non-Gaussian\ndata symbols and few snapshots, and higher-order statistics remain unexploited.\nWe address these challenges with an attention-only transformer that directly\nprocesses raw signal snapshots for grid-less end-to-end direction-of-arrival\n(DOA) estimation. The model efficiently captures higher-order statistics while\nbeing permutation-invariant and adaptive to varying snapshot counts. Our\nalgorithm greatly outperforms state-of-the-art AI-based benchmarks with over\n30x reduction in parameters and runtime, and enjoys excellent generalization\nunder practical mismatches. Applied to multi-user MIMO beam training, our\nalgorithm can localize uplink DOAs of multiple users during data transmission.\nThrough angular reciprocity, estimated uplink DOAs prune downlink beam sweeping\ncandidates and improve throughput via sensing-assisted beam management. This\nwork shows how reusing existing data transmission for sensing can enhance both\nmulti-source localization and beam management in 3GPP efforts towards 6G."}
{"id": "2506.23557", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.23557", "abs": "https://arxiv.org/abs/2506.23557", "authors": ["Xuehan Wang", "Hengyu Zhang", "Jintao Wang", "Zhi Sun", "Bo Ai"], "title": "Data-Driven Modulation Optimization with LMMSE Equalization for Reliability Enhancement in Underwater Acoustic Communications", "comment": "6 pages, 3 figures. This paper has been accepted for presentation in\n  IEEE/CIC ICCC 2025", "summary": "Ultra-reliable underwater acoustic (UWA) communications serve as one of the\nkey enabling technologies for future space-air-ground-underwater integrated\nnetworks. However, the reliability of current UWA transmission is still\ninsufficient since severe performance degradation occurs for conventional\nmulticarrier systems in UWA channels with severe delay-scale spread. To solve\nthis problem, we exploit learning-inspired approaches to optimize the\nmodulation scheme under the assumption of linear minimum mean square error\n(LMMSE) equalization, where the discrete representation of waveforms is adopted\nby utilizing Nyquist filters. The optimization problem is first transferred\ninto maximizing the fairness of estimation mean square error (MSE) for each\ndata symbol since the total MSE is invariant considering the property of\northogonal modulation. The Siamese architecture is then adopted to obtain\nconsistent optimization results across various channel conditions, which avoids\nthe overhead of online feedback, cooperation, and deployment of neural networks\nand guarantees generalization. The overall scheme including the loss function,\nneural network structure, and training process is also investigated in depth in\nthis paper. The excellent performance and robustness of the proposed modulation\nscheme are verified by carrying out the bit error rate test over various UWA\nchannels with severe delay-scale spread."}
{"id": "2506.23568", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.23568", "abs": "https://arxiv.org/abs/2506.23568", "authors": ["Lei Wang", "Xianxun Yao", "Tiancheng Song", "Guolin Sun"], "title": "A Fast and Accurate 3-D Reconstruction Algorithm for Near-Range Microwave Imaging with Handheld Synthetic Aperture Radar", "comment": null, "summary": "The design of image reconstruction algorithms for near-range handheld\nsynthetic aperture radar (SAR) systems has gained increasing popularity due to\nthe promising performance of portable millimeter-wave (MMW) imaging devices in\nvarious application fields. Time domain imaging algorithms including the\nbackprojection algorithm (BPA) and the Kirchhoff migration algorithm (KMA) are\nwidely adopted due to their direct applicability to arbitrary scan\ntrajectories. However, they suffer from time complexity issues that hinder\ntheir practical application. Wavenumber domain algorithms greatly improve the\ncomputational efficiency but most of them are restricted to specific array\ntopologies. Based on the factorization techniques as adopted in far-field\nsynthetic aperture radar imaging, the time domain fast factorized\nbackprojection algorithm for handheld synthetic aperture radar (HHFFBPA) is\nproposed. The local spectral properties of the radar images for handheld\nsystems are analyzed and analytical spectrum compression techniques are derived\nto realize efficient sampling of the subimages. Validated through numerical\nsimulations and experiments, HHFFBPA achieves fast and accurate 3-D imaging for\nhandheld synthetic aperture radar systems with arbitrary trajectories."}
{"id": "2506.23621", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.23621", "abs": "https://arxiv.org/abs/2506.23621", "authors": ["Steffen Schieler", "Sebastian Semper", "Reiner Thomä"], "title": "Wireless Propagation Parameter Estimation with Convolutional Neural Networks", "comment": "This is the accepted version of the article published in the\n  International Journal of Microwave and Wireless Technologies with the DOI\n  10.1017/S1759078725000431", "summary": "Wireless channel propagation parameter estimation forms the foundation of\nchannel sounding, estimation, modeling, and sensing. This paper introduces a\nDeep Learning approach for joint delay- and Doppler estimation from frequency\nand time samples of a radio channel transfer function.\n  Our work estimates the two-dimensional path parameters from a channel impulse\nresponse containing an unknown number of paths. Compared to existing deep\nlearning-based methods, the parameters are not estimated via classification but\nin a quasi-grid-free manner. We employ a deterministic preprocessing scheme\nthat incorporates a multi-channel windowing to increase the estimator's\nrobustness and enables the use of a CNN architecture. The proposed architecture\nthen jointly estimates the number of paths along with the respective delay and\nDoppler-shift parameters of the paths. Hence, it jointly solves the model order\nselection and parameter estimation task. We also integrate the CNN into an\nexisting maximum-likelihood estimator framework for efficient initialization of\na gradient-based iteration, to provide more accurate estimates.\n  In the analysis, we compare our approach to other methods in terms of\nestimate accuracy and model order error on synthetic data. Finally, we\ndemonstrate its applicability to real-world measurement data from a anechoic\nbi-static RADAR emulation measurement."}
{"id": "2506.23750", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.23750", "abs": "https://arxiv.org/abs/2506.23750", "authors": ["Ge Yan", "Lipeng Zhu", "He Sun", "Rui Zhang"], "title": "Wideband Coverage Enhancement for IRS-Aided Wireless Networks Based on Power Measurement", "comment": "5 pages, 6 figures", "summary": "By applying tunable phase shifts to incident waves via passive signal\nreflection, intelligent reflecting surface (IRS) can offer significant\nperformance improvement for wireless communication systems. To reap such\nperformance gain, channel knowledge for IRS-cascaded links is generally\nrequired, which is practically challenging to acquire due to their\nhigh-dimensional and time-varying characteristics. Conventional pilot-based\nchannel estimation incurs excessive overhead due to the large number of\nreflecting elements, thus undermining the IRS efficiency, especially for\nwideband systems with frequency-selective fading channels. To tackle this\nissue, we propose in this letter a power-measurement-based channel\nautocorrelation matrix estimation and coverage enhancement approach for\nIRS-aided orthogonal frequency division multiplexing (OFDM) systems.\nSpecifically, by estimating equivalent channel autocorrelation matrices of\nIRS-cascaded OFDM channels based on receive signal power and optimizing the IRS\nreflection vector based on them, the average coverage performance in the\nIRS-aided region is enhanced without the need for frequent reconfiguration of\nIRS reflection coefficients based on user instantaneous channels. Simulation\nresults validate the effectiveness of the proposed approach for improving the\naverage channel gain over the coverage region."}
{"id": "2506.23788", "categories": ["eess.SP", "cs.NI"], "pdf": "https://arxiv.org/pdf/2506.23788", "abs": "https://arxiv.org/abs/2506.23788", "authors": ["Naomi Stricker", "David Blaser", "Andres Gomez", "Lothar Thiele"], "title": "E-WAN: Efficient Communication in Energy Harvesting Low-Power Networks", "comment": "This is the author's version of the work. Submitted to ACM TOSN on\n  June 2023. Major revision submitted on May 2024. Minor Revision submitted on\n  March 2025", "summary": "The ever-increasing number of distributed embedded systems in the context of\nthe Internet of Things (IoT), Wireless Sensor Networks (WSN), and\nCyber-Physical Systems (CPS) rely on wireless communication to collect and\nexchange data. Nodes can employ single-hop communication which, despite its\nease, may necessitate energy-intensive long-range communication to cover long\ndistances. Conversely, multi-hop communication allows for more energy-efficient\nshort-range communication since nodes can rely on other nodes to forward their\ndata. Yet, this approach requires relay nodes to be available and continuous\nmaintenance of a dynamically changing distributed state. At the same time,\nenergy harvesting has the potential to outperform traditional battery-based\nsystems by improving their lifetime, scalability with lower maintenance costs,\nand environmental impact. However, the limited and temporally and spatially\nvariable harvested energy poses significant challenges for networking in energy\nharvesting networks, particularly considering the energy demands and\ncharacteristics of both multi-hop and single-hop communication. We propose\nE-WAN, a protocol for energy harvesting wide-area low-power networks that\nbuilds on the concept of \\emph{virtual sub-networks} to enable\nresource-efficient multi-hop communication when possible and reliable however\nenergy-intensive point-to-point communication otherwise. Nodes autonomously and\ndynamically move between the two and adjust to changing network states and\nresources based only on easily obtainable network state information. We\nillustrate E-WAN's advantages both in terms of efficiency and adaptability in\nvarious communication and harvesting scenarios. Furthermore, we demonstrate\nE-WAN operating in a realistic setting by deploying an energy harvesting\nnetwork in a real-world indoor environment."}
{"id": "2506.23937", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.23937", "abs": "https://arxiv.org/abs/2506.23937", "authors": ["Chu Li", "Marjan Boloori", "Eduard Jorswieck", "Aydin Sezgin"], "title": "Optimized Frequency-Diverse Movable Antenna Arrays for Directional Secrecy in Wireless Systems", "comment": null, "summary": "Movable-antenna (MA) arrays are envisioned as a promising technique for\nenhancing secrecy performance in wireless communications by leveraging\nadditional spatial degrees of freedom. However, when the eavesdropper is\nlocated in the same direction as the legitimate user, particularly in\nmmWave/THz bands where line-of-sight (LOS) propagation dominates, the secrecy\nperformance of MA arrays becomes significantly limited, thus directionally\ninsecure. To address this challenge, we employ a joint design that combines an\nMA array with a frequency-diverse array (FDA) at the transmitter to secure the\ntransmission across both range and direction. Specifically, we derive\nclosed-form expressions for the optimal antenna positions and frequency shifts,\nassuming small perturbations in both parameters from a linear frequency-diverse\nMA configuration. Furthermore, we compare the worst-case secrecy rate under\nthis minor perturbation assumption with that obtained under a general\nconstraint, where simulated annealing is employed to numerically determine the\noptimal parameters. Simulation results confirm that the proposed optimized\nfrequency diverse MA approach significantly enhances secrecy performance in the\npresence of an eavesdropper aligned with the direction of the legitimate\nreceiver."}
{"id": "2506.23966", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2506.23966", "abs": "https://arxiv.org/abs/2506.23966", "authors": ["Yanqing Xu", "Zhiguo Ding", "Robert Schober", "Tsung-Hui Chang"], "title": "Pinching-Antenna Systems with In-Waveguide Attenuation: Performance Analysis and Algorithm Design", "comment": "This paper aims to address a fundamental question in pinching-antenna\n  systems: Can in-waveguide attenuation be safely ignored without causing\n  significant performance degradation? Our analytical results provide a clear\n  answer -- YES, provided that certain mild and practically realizable\n  conditions on the system parameters are satisfied", "summary": "Pinching-antenna systems have emerged as a promising flexible-antenna\narchitecture for next-generation wireless networks, enabling enhanced\nadaptability and user-centric connectivity through antenna repositioning along\nwaveguides. However, existing studies often overlook in-waveguide signal\nattenuation and in the literature, there is no comprehensive analysis on\nwhether and under what conditions such an assumption is justified. This paper\naddresses this gap by explicitly incorporating in-waveguide attenuation into\nboth the system model and algorithm design, and studying its impact on the\ndownlink user data rates. We begin with a single-user scenario and derive a\nclosed-form expression for the globally optimal antenna placement, which\nreveals how the attenuation coefficient and the user-to-waveguide distance\njointly affect the optimal antenna position. Based on this analytical solution,\nwe further provide a theoretical analysis identifying the system conditions\nunder which the in-waveguide attenuation has an insignificant impact on the\nuser achievable rate. The study is then extended to the multi-user\nmultiple-input multiple-output setting, where two efficient algorithms are\ndeveloped, based on the weighted minimum mean square error method and the\nmaximum ratio combining method, to jointly optimize beamforming and antenna\nplacement. Simulation results validate the efficacy of the proposed algorithms\nand demonstrate that pinching-antenna systems substantially outperform\nconventional fixed-antenna baselines, underscoring their potential for future\nflexible wireless communications."}
{"id": "2506.24024", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.24024", "abs": "https://arxiv.org/abs/2506.24024", "authors": ["Nicolas Heintz", "Tom Francart", "Alexander Bertrand"], "title": "Post-processing of EEG-based Auditory Attention Decoding Decisions via Hidden Markov Models", "comment": null, "summary": "Auditory attention decoding (AAD) algorithms exploit brain signals, such as\nelectroencephalography (EEG), to identify which speaker a listener is focusing\non in a multi-speaker environment. While state-of-the-art AAD algorithms can\nidentify the attended speaker on short time windows, their predictions are\noften too inaccurate for practical use. In this work, we propose augmenting AAD\nwith a hidden Markov model (HMM) that models the temporal structure of\nattention. More specifically, the HMM relies on the fact that a subject is much\nless likely to switch attention than to keep attending the same speaker at any\nmoment in time. We show how a HMM can significantly improve existing AAD\nalgorithms in both causal (real-time) and non-causal (offline) settings. We\nfurther demonstrate that HMMs outperform existing postprocessing approaches in\nboth accuracy and responsiveness, and explore how various factors such as\nwindow length, switching frequency, and AAD accuracy influence overall\nperformance. The proposed method is computationally efficient, intuitive to use\nand applicable in both real-time and offline settings."}
