{"id": "2512.02025", "categories": ["eess.SP", "cs.AI", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.02025", "abs": "https://arxiv.org/abs/2512.02025", "authors": ["Aditya Sneh", "Nilesh Kumar Sahu", "Snehil Gupta", "Haroon R. Lone"], "title": "DySTAN: Joint Modeling of Sedentary Activity and Social Context from Smartphone Sensors", "comment": null, "summary": "Accurately recognizing human context from smartphone sensor data remains a significant challenge, especially in sedentary settings where activities such as studying, attending lectures, relaxing, and eating exhibit highly similar inertial patterns. Furthermore, social context plays a critical role in understanding user behavior, yet is often overlooked in mobile sensing research. To address these gaps, we introduce LogMe, a mobile sensing application that passively collects smartphone sensor data (accelerometer, gyroscope, magnetometer, and rotation vector) and prompts users for hourly self-reports capturing both sedentary activity and social context. Using this dual-label dataset, we propose DySTAN (Dynamic Cross-Stitch with Task Attention Network), a multi-task learning framework that jointly classifies both context dimensions from shared sensor inputs. It integrates task-specific layers with cross-task attention to model subtle distinctions effectively. DySTAN improves sedentary activity macro F1 scores by 21.8% over a single-task CNN-BiLSTM-GRU (CBG) model and by 8.2% over the strongest multi-task baseline, Sluice Network (SN). These results demonstrate the importance of modeling multiple, co-occurring context dimensions to improve the accuracy and robustness of mobile context recognition."}
{"id": "2512.02026", "categories": ["eess.SP", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02026", "abs": "https://arxiv.org/abs/2512.02026", "authors": ["Luis Correas-Naranjo", "Miguel Camacho-Sánchez", "Laëtitia Launet", "Milena Zuric", "Valery Naranjo"], "title": "Towards Sustainable Precision: Machine Learning for Laser Micromachining Optimization", "comment": null, "summary": "In the pursuit of sustainable manufacturing, ultra-short pulse laser micromachining stands out as a promising solution while also offering high-precision and qualitative laser processing. However, unlocking the full potential of ultra-short pulse lasers requires an optimized monitoring system capable of early detection of defective workpieces, regardless of the preprocessing technique employed. While advances in machine learning can help predict process quality features, the complexity of monitoring data necessitates reducing both model size and data dimensionality to enable real-time analysis. To address these challenges, this paper introduces a machine learning framework designed to enhance surface quality assessment across diverse preprocessing techniques. To facilitate real-time laser processing monitoring, our solution aims to optimize the computational requirements of the machine learning model. Experimental results show that the proposed model not only outperforms the generalizability achieved by previous works across diverse preprocessing techniques but also significantly reduces the computational requirements for training. Through these advancements, we aim to establish the baseline for a more sustainable manufacturing process."}
{"id": "2512.02028", "categories": ["eess.SP", "cs.LG", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2512.02028", "abs": "https://arxiv.org/abs/2512.02028", "authors": ["Yiping Wang", "Peiren Wang", "Zhenye Li", "Fang Liu", "Jinguo Huang"], "title": "Seizure-NGCLNet: Representation Learning of SEEG Spatial Pathological Patterns for Epileptic Seizure Detection via Node-Graph Dual Contrastive Learning", "comment": null, "summary": "Complex spatial connectivity patterns, such as interictal suppression and ictal propagation, complicate accurate drug-resistant epilepsy (DRE) seizure detection using stereotactic electroencephalography (SEEG) and traditional machine learning methods. Two critical challenges remain:(1)a low signal-to-noise ratio in functional connectivity estimates, making it difficult to learn seizure-related interactions; and (2)expert labels for spatial pathological connectivity patterns are difficult to obtain, meanwhile lacking the patterns' representation to improve seizure detection. To address these issues, we propose a novel node-graph dual contrastive learning framework, Seizure-NGCLNet, to learn SEEG interictal suppression and ictal propagation patterns for detecting DRE seizures with high precision. First, an adaptive graph augmentation strategy guided by centrality metrics is developed to generate seizure-related brain networks. Second, a dual-contrastive learning approach is integrated, combining global graph-level contrast with local node-graph contrast, to encode both spatial structural and semantic epileptogenic features. Third, the pretrained embeddings are fine-tuned via a top-k localized graph attention network to perform the final classification. Extensive experiments on a large-scale public SEEG dataset from 33 DRE patients demonstrate that Seizure-NGCLNet achieves state-of-the-art performance, with an average accuracy of 95.93%, sensitivity of 96.25%, and specificity of 94.12%. Visualizations confirm that the learned embeddings clearly separate ictal from interictal states, reflecting suppression and propagation patterns that correspond to the clinical mechanisms. These results highlight Seizure-NGCLNet's ability to learn interpretable spatial pathological patterns, enhancing both seizure detection and seizure onset zone localization."}
{"id": "2512.02088", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.02088", "abs": "https://arxiv.org/abs/2512.02088", "authors": ["Sina Raeisadigh", "Myles Joshua Toledo Tan", "Henning Müller", "Abderrahmane Hedjoudje"], "title": "Comparing Baseline and Day-1 Diffusion MRI Using Multimodal Deep Embeddings for Stroke Outcome Prediction", "comment": "5 pages, 5 figures, 2 tables", "summary": "This study compares baseline (J0) and 24-hour (J1) diffusion magnetic resonance imaging (MRI) for predicting three-month functional outcomes after acute ischemic stroke (AIS). Seventy-four AIS patients with paired apparent diffusion coefficient (ADC) scans and clinical data were analyzed. Three-dimensional ResNet-50 embeddings were fused with structured clinical variables, reduced via principal component analysis (<=12 components), and classified using linear support vector machines with eight-fold stratified group cross-validation. J1 multimodal models achieved the highest predictive performance (AUC = 0.923 +/- 0.085), outperforming J0-based configurations (AUC <= 0.86). Incorporating lesion-volume features further improved model stability and interpretability. These findings demonstrate that early post-treatment diffusion MRI provides superior prognostic value to pre-treatment imaging and that combining MRI, clinical, and lesion-volume features produces a robust and interpretable framework for predicting three-month functional outcomes in AIS patients."}
{"id": "2512.02153", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2512.02153", "abs": "https://arxiv.org/abs/2512.02153", "authors": ["Murat Babek Salman", "Emil Björnson", "Özlem Tugfe Demir"], "title": "Hardware Distortion Aware Precoding for ISAC Systems", "comment": "5 pages, 4 figures, Asilomar Conference on Signals, Systems, and Computers, 2025", "summary": "The impact of hardware impairments on the spectral efficiency of communication systems is well studied, but their effect on sensing performance remains unexplored. In this paper, we analyze the influence of hardware impairments on integrated sensing and communication (ISAC) systems in cluttered environments. We derive the sensing signal-to-clutter-plus-noise ratio (SCNR) and show that hardware distortions significantly degrade sensing performance by enhancing clutter-induced noise, which masks target echoes. The isotropic nature of transmit distortion due to multiple stream transmission further complicates clutter suppression. To address this, we propose a distortion- and clutter-aware precoding strategy that minimizes the deviation from the communication-optimized precoder while improving sensing robustness. We also propose an alternative power allocation-based approach that reduces computational complexity. Numerical results confirm the effectiveness of the proposed approaches in overcoming hardware- and clutter-induced limitations, demonstrating significant performance gains over distortion-unaware designs."}
{"id": "2512.02091", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2512.02091", "abs": "https://arxiv.org/abs/2512.02091", "authors": ["Showkat Osman", "Md. Tajwar Munim Turzo", "Maher Ali Rusho", "Md. Makid Haider", "Sazzadul Islam Sajin", "Ayatullah Hasnat Behesti", "Ahmed Faizul Haque Dhrubo", "Md. Khurshid Jahan", "Mohammad Abdul Qayum"], "title": "TT-Stack: A Transformer-Based Tiered-Stacking Ensemble Framework with Meta-Learning for Automated Breast Cancer Detection in Mammography", "comment": "This paper contains 15 pages with 23 figures and 4 tables. This Paper is already accepted in IEEE Computational Intelligence Magazine (CIM)", "summary": "Breast cancer continues to be the second most common cause of cancer-related deaths around the world, with early detection being important to improve survival rates for patients. Traditional computer-aided diagnosis systems have limitations in their ability to represent features and generalize to the range of mammographic images. We present a new two-level Stack of Transformers (TT-Stack) ensemble framework based on using heterogeneous lightweight vision transformer architectures to automatically identify breast cancer in mammograms. Specifically, we integrate seven state-of-the-art vision transformers: RepViT, DaViT, EfficientViT, MobileViT, FasterViT, MViT, and PVT v2 while also designing a two-tier meta-learning approach for the ensemble by simply taking the logits from the base model and applying logistic regression for binary classification (Cancer vs. Non-Cancer). Each of the transformer backbone models was developed to process single-channel grayscale mammograms while still taking advantage of transfer learning from pre-training on ImageNet so that they would offer a parameter-efficient approach that may reasonably be applied in clinical practice with minimal variance. The training process included stratified 80/20 splits when necessary, class-balanced upsampling, early stopping, and an adaptive learning rate schedule on the public Mammogram Mastery dataset. In separate evaluations here, it was determined that EfficientViT and PVT-v2 were the top per-forming models achieving 99.33% validation, 97.96% F1-score, and perfect 1.000:0 ROC-AUC with only small train/validation gaps. Finally, the TT-Stack ensemble model by the end of the evaluation reached 99.33% accuracy with 100% precision, 96% recall, 97.96% F1-score and a 99.97% ROC-AUC, and demonstrated robustness in performance due to the diversity of the architecture."}
{"id": "2512.02245", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.02245", "abs": "https://arxiv.org/abs/2512.02245", "authors": ["Ashutosh Prajapati", "Prathapasinghe Dharmawansa", "Marco Di Renzo", "Italo Atzeni"], "title": "Wavenumber-Division Multiplexing in Holographic MIMO with NLoS Channels", "comment": "Presented at the Asilomar Conference on Signals, Systems, and Computers 2025", "summary": "Wavenumber-division multiplexing (WDM) was introduced as a counterpart of orthogonal frequency-division multiplexing in the spatial-frequency domain for line-of-sight holographic multiple-input multiple-output (MIMO) systems. In this paper, we extend WDM to holographic MIMO channels with non-line-of-sight (NLoS) propagation. We show that applying WDM to the NLoS channel yields the corresponding angular-domain representation, which we characterize through the power spectral factor and power spectral density. We further obtain a closed-form characterization for the case of isotropic scattering, recovering Jakes' isotropic model. The analysis is complemented by numerical results evaluating the degrees of freedom and ergodic capacity under both isotropic and non-isotropic scattering."}
{"id": "2512.02917", "categories": ["eess.IV", "physics.med-ph"], "pdf": "https://arxiv.org/pdf/2512.02917", "abs": "https://arxiv.org/abs/2512.02917", "authors": ["Yamila Rotstein Habarnau", "Nicolás Bustos", "Paola Corona", "Christian González", "Sonia Traverso", "Federico Matorra", "Francisco Funes", "Juan Martín Giraut", "Laura Pelegrina", "Gabriel Bruno", "Mauro Namías"], "title": "Maintaining SUV Accuracy in Low-Count PET with PETfectior: A Deep Learning Denoising Solution", "comment": null, "summary": "Background: Diagnostic PET image quality depends on the administered activity and acquisition time. However, minimizing these variables is desirable to reduce patient radiation exposure and radiopharmaceutical costs. PETfectior is an artificial intelligence-based software that processes PET scans and increases signal-to-noise ratio, obtaining high-quality images from low-count-rate images. We perform an initial clinical validation of PETfectior on images acquired with half of the counting statistics required to meet the most recent EANM quantitative standards for 18F-FDG PET, evaluating lesions detectability, quantitative performance and image quality.\n  Materials and methods: 258 patients referred for 18F-FDG PET/CT were prospectively included. The standard-of-care scans (100% scans) were acquired and reconstructed according to EARL standards 2. Half-counting-statistics versions were generated from list-mode data and processed with PETfecftior (50%+PETfectior scans). All oncologic lesions were segmented on both PET/CT versions, manually or automatically, and lesions detectability was evaluated. The SUVmax of the lesions was measured and the quantitative concordance of 50%+PETfectior and 100% images was evaluated. Subjective image quality was visually assessed by two experienced physicians.\n  Results: 1649 lesions were detected in a total of 198 studies. The 50%+PETfectior images showed high sensitivity for lesion detection (99.9%) and only 1 false positive was detected. The SUVmax measured in 100% and 50%+PETfectior images agreed within 12.5% (95% limits of agreement), with a bias of -1.01%. Image quality of the 50%+PETfectior images was rated equal to or better than the standard-of-care images.\n  Conclusion: PETfectior can safely be used in clinical practice at half counting statistics, with high sensitivity and specificity, low quantitative bias and high subjective image quality."}
{"id": "2512.02462", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.02462", "abs": "https://arxiv.org/abs/2512.02462", "authors": ["Shengheng Liu", "Xingkang Li", "Yongming Huang", "Yuan Fang", "Qingji Jiang", "Dazhuan Xu", "Ziguo Zhong", "Dongming Wang", "Xiaohu You"], "title": "Bayesian Probability Fusion for Multi-AP Collaborative Sensing in Mobile Networks", "comment": "16 pages, 10 figures, submitted to Science China Information Sciences", "summary": "Integrated sensing and communication is widely acknowledged as a foundational technology for next-generation mobile networks. Compared with monostatic sensing, multi-access point (AP) collaborative sensing endows mobile networks with broader, more accurate, and resilient sensing capabilities, which are critical for diverse location-based sectors. This paper focuses on collaborative sensing in multi-AP networks and proposes a Bayesian probability fusion framework for target parameter estimation using orthogonal frequency-division multiplexing waveform. The framework models multi-AP received signals as probability distributions to capture stochastic observations from channel noise and scattering coefficients. Prior information is then incorporated into the joint probability density function to cast the problem as a constrained maximum a posteriori estimation. To address the high-dimensional optimization, we develop a prior-constrained gradient ascent (PCGA) algorithm that decouples correlated parameters and performs efficient gradient updates guided by the target prior. Theoretical analysis covers optimal fusion weights for global signal-to-noise ratio maximization, PCGA convergence, and the Cramer-Rao lower bound of the estimator, with insights applicable to broader fusion schemes. Extensive numerical simulations and real-world experiments with commercial devices show the framework reduces transmission overhead by 90% versus signal fusion and lowers estimation error by 41% relative to parameter fusion. Notably, field tests achieve submeter accuracy with 50% probability in typical coverage of mmWave APs. These improvements highlight a favorable balance between communication efficiency and estimation accuracy for practical multi-AP sensing deployment.\n  The dataset is released for research purposes and is publicly available at: http://pmldatanet.com.cn/dataapp/multimodal"}
{"id": "2512.02464", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.02464", "abs": "https://arxiv.org/abs/2512.02464", "authors": ["Jiaxuan Li", "Yilong Chen", "Fan Liu", "Jie Xu"], "title": "Channel Knowledge Map Enabled Low-Altitude ISAC Networks: Joint Air Corridor Planning and Base Station Deployment", "comment": null, "summary": "This letter addresses the joint air corridor planning and base station (BS) deployment problem for low-altitude integrated sensing and communication (ISAC) networks. In the considered system, unmanned aerial vehicles (UAVs) operate within a structured air corridor composed of connected cubic segments, and multiple BSs need to be selectively deployed at a set of candidate locations to ensure both sensing and communication coverage throughout the corridor. In particular, we leverage the channel knowledge map (CKM) to characterize wireless channels for candidate BS sites prior to deployment, thereby facilitating the offline planning. Under this setup, we minimize the system cost in terms of the weighted sum of the air corridor length and the number of deployed BSs, subject to the constraints on both sensing and communication performance across the corridor. To solve the formulated large-scale nonconvex integer programming problem, we develop a hierarchical coarse-to-fine grid decomposition algorithm. Simulation results demonstrate the benefit of the proposed joint design in reducing the overall deployment cost while ensuring the coverage of the low-altitude ISAC networks."}
{"id": "2512.02501", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.02501", "abs": "https://arxiv.org/abs/2512.02501", "authors": ["Qi Zhen", "Pan Tang", "Haiyang Miao", "Enrui Liu", "Ximan Liu", "Zihang Ding", "Jianhua Zhang"], "title": "Cell-free versus Conventional Massive MIMO : An Analysis of Channel Capacity based on Channel Measurement in the FR3 Band", "comment": null, "summary": "Cell-free massive MIMO (CF-mMIMO) has emerged as a promising technology for next generation wireless systems, combining the benefits of distributed antenna systems (DAS) and traditional MIMO technology. In this work, we present the first extensive channel measurements for CF-mMIMO in the mid-band (FR3, 6-24 GHz), using a virtual widely distributed antenna array comprising 512 elements in the urban Macrocell (UMa) environment. Based on the measurement data, this paper compares the channel capacity of CF-mMIMO and Conventional mMIMO under both line-of-sight (LOS) and non-line-of-sight (NLOS) conditions across a range of signal-to-noise ratios (SNRs). We then analyze how channel capacity varies with Rx positions from the perspectives of the full array and of individual subarrays. Finally, we conclude that the 64-element array configuration yields the greatest advantage in channel capacity for CF-mMIMO in the measurement environment considered, with gains of 14.02\\% under LOS and 24.61\\% under NLOS conditions. This in-depth analysis of channel capacity in the FR3 band provides critical insights for optimizing CF-mMIMO systems in next generation wireless networks."}
{"id": "2512.02557", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.02557", "abs": "https://arxiv.org/abs/2512.02557", "authors": ["Xuan He", "Hongwei Hou", "Yafei Wang", "Wenjin Wang", "Shi Jin", "Symeon Chatzinotas", "Björn Ottersten"], "title": "Deep Learning-Based Joint Uplink-Downlink CSI Acquisition for Next-Generation Upper Mid-Band Systems", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "In next-generation wireless communication systems, the newly designated upper mid-band has attracted considerable attention, also called frequency range 3 (FR3), highlighting the need for downlink (DL) transmission design, which fundamentally relies on accurate CSI. However, CSI acquisition in FR3 systems faces significant challenges: the increased number of antennas and wider transmission bandwidth introduces prohibitive training overhead with traditional estimation approaches, as each probing captures only incomplete spatial-frequency observation, while higher carrier frequencies lead to faster temporal channel variation. To address these challenges, we propose a novel CSI acquisition framework that integrates CSI feedback, uplink (UL) and DL channel estimation, as well as channel prediction in the FR3 TDD massive MIMO systems. Specifically, we first develop the Joint UL and DL Channel Estimation Network (JUDCEN) to fuse incomplete observations based on the SRSs and CSI-RSs. By exploiting the complementary characteristics of preliminary UL and DL estimation features, obtained through initial UL estimation and quantized-feedback-assisted DL estimation, it enables full CSI reconstruction in the spatial domain. To mitigate the performance degradation in the feedback process, we propose the Transformer-MLP CSI Feedback Network (TMCFN), employing an MLP-based module to jointly exploit angle- and delay-domain features. Building upon the reconstructed full CSI, we further develop the Mamba-based Channel Prediction Network (MCPN), which exploits selective state-space model (SSM) mechanism to capture long-range temporal dynamics in the angle-delay domain for future CSI prediction. Simulation results demonstrate that the proposed framework consistently outperforms benchmarks in both CSI acquisition accuracy and transmission spectral efficiency with lower computational complexity."}
{"id": "2512.02563", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.02563", "abs": "https://arxiv.org/abs/2512.02563", "authors": ["Xiaotong Zhao", "Yuanhao Cui", "Weijie Yuan", "Ziye Jia", "Heng Liu", "Chengwen Xing"], "title": "Predictive Beamforming in Low-Altitude Wireless Networks: A Cross-Attention Approach", "comment": null, "summary": "Accurate beam prediction is essential for maintaining reliable links and high spectral efficiency in dynamic low-altitude wireless networks. However, existing approaches often fail to capture the deep correlations across heterogeneous sensing modalities, limiting their adaptability in complex three-dimensional environments. To overcome these challenges, we propose a multi-modal predictive beamforming method based on a cross-attention fusion mechanism that jointly leverages visual and structured sensor data. The proposed model utilizes a Convolutional Neural Network (CNN) to learn multi-scale spatial feature hierarchies from visual images and a Transformer encoder to capture cross-dimensional dependencies within sensor data. Then, a cross-attention fusion module is introduced to integrate complementary information between the two modalities, generating a unified and discriminative representation for accurate beam prediction. Through experimental evaluations conducted on a real-world dataset, our method reaches 79.7% Top-1 accuracy and 99.3% Top-3 accuracy, surpassing the 3D ResNet-Transformer baseline by 4.4%-23.2% across Top-1 to Top-5 metrics. These results verify that multi-modal cross-attention fusion is effective for intelligent beam selection in dynamic low-altitude wireless networks."}
{"id": "2512.02573", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2512.02573", "abs": "https://arxiv.org/abs/2512.02573", "authors": ["Juan Vidal Alegría", "Ashkan Sheikhi", "Ove Edfors"], "title": "Zero-Forcing MU-MIMO Precoding under Power Amplifier Non-Linearities", "comment": "5 pages, 1 figure (2 subfigures). This work has been presented at the Asilomar Conference on Signals, Systems, and Computers. Copyright information may be affected upon publication at the IEEE proceedings", "summary": "In multi-user multiple-input multiple-output (MU-MIMO) systems, the non-linear behavior of the power amplifiers (PAs) may cause degradation of the linear precoding schemes dealing with interference between user equipments (UEs), e.g., the zero-forcing (ZF) precoder. One way to minimize this effect is to use digital-pre-distortion (DPD) modules to linearize the PAs. However, using perfect DPD modules is costly and it may incur significant power consumption. As an alternative, we consider the problem of characterizing non-linearity-aware ZF (NLA-ZF) precoding schemes, hereby defined as linear precoders that achieve perfect interference cancellation in the presence of PA non-linearity by exploiting knowledge of this non-linear response. We provide initial iterative solutions that allow achieving NLA-ZF (up to adjustable tolerance) in a two-UE downlink MU-MIMO scenario where the base station (BS) has an even number of antennas, and each antenna is connected to a PA exhibiting third-order memory-less non-linear behavior. The proposed approach allows for performance gains in scenarios with significant residual interference."}
{"id": "2512.02628", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2512.02628", "abs": "https://arxiv.org/abs/2512.02628", "authors": ["Carolina Nolasco-Ferencikova", "Georg Schwan", "Raphael Rolny", "Alexander Stutz-Tirri", "Christoph Studer"], "title": "Joint Beamforming and Matching for Ultra-Dense Massive Antenna Arrays", "comment": "Presented at the 59th Asilomar Conference on Signals, Systems, and Computers", "summary": "Massive multiple-input multiple-output (MIMO) offers substantial spectral-efficiency gains, but scaling to very large antenna arrays with conventional all-digital and hybrid beamforming architectures quickly results in excessively high costs and power consumption. Low-cost, switch-based architectures have recently emerged as a potential alternative. However, prior studies rely on simplified models that ignore (among others) antenna coupling, radiation patterns, and matching losses, resulting in inaccurate performance predictions. In this paper, we use a physically consistent electromagnetic modeling framework to analyze an ultra-dense patch-antenna array architecture that performs joint beamforming and matching using networks of inexpensive RF switches. Our results demonstrate that simple, switch-based beamforming architectures can approach the antenna-gain of all-digital solutions at significantly lower cost and complexity."}
{"id": "2512.02712", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.02712", "abs": "https://arxiv.org/abs/2512.02712", "authors": ["Ibrahim Shahbaz", "Mohammad J. Abdel-Rahman", "Eman Hammad"], "title": "G-PIFNN: A Generalizable Physics-informed Fourier Neural Network Framework for Electrical Circuits", "comment": null, "summary": "Physics-Informed Neural Networks (PINNs) have advanced the data-driven solution of differential equations (DEs) in dynamic physical systems, yet challenges remain in explainability, scalability, and architectural complexity. This paper presents a Generalizable Physics-Informed Fourier Neural Network (G-PIFNN) framework that enhances PINN architectures for efficient and interpretable electrical circuit analysis. The proposed G-PIFNN introduces three key advancements: (1) improved performance and interpretability via a physics activation function (PAF) and a lightweight Physics-Informed Fourier Neural Network (PIFNN) architecture; (2) automated, bond graph (BG) based formulation of physics-informed loss functions for systematic differential equation generation; and (3) integration of intra-circuit and cross-circuit class transfer learning (TL) strategies, enabling unsupervised fine-tuning for rapid adaptation to varying circuit topologies. Numerical simulations demonstrate that G-PIFNN achieves significantly better predictive performance and generalization across diverse circuit classes, while significantly reducing the number of trainable parameters compared to standard PINNs."}
{"id": "2512.02757", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.02757", "abs": "https://arxiv.org/abs/2512.02757", "authors": ["Yunzhe Zhu", "Xuewen Liao", "Zhenzhen Gao", "Yong Zeng"], "title": "Channel Knowledge Map Construction via Physics-Inspired Diffusion Model Without Prior Observations", "comment": null, "summary": "The ability to construct Channel Knowledge Map (CKM) with high precision is essential for environment awareness in 6G wireless systems. However, most existing CKM construction methods formulate the task as an image super-resolution or generation problem, thereby employing models originally developed for computer vision. As a result, the generated CKMs often fail to capture the underlying physical characteristics of wireless propagation. In this paper, we focus on the construction of CKM for large-scale fading scenarios and design three physics-based constraint terms to characterize the spatial distribution patterns of large-scale fading. By integrating these physical constraints with a state-of-the-art diffusion model that possesses superior generative capability, a physics-inspired diffusion model for CKM construction is proposed. Following this motivation, we derive the loss function of the diffusion model augmented with physics-based constraint terms and further design the training and generation framework for the proposed physics-inspired CKM generation diffusion model. Extensive experiments show that our approach outperforms all existing methods in terms of construction accuracy. Moreover, the proposed model provides a unified and effective framework with strong potential for generating diverse, accurate, and physically consistent CKM."}
{"id": "2512.02765", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.02765", "abs": "https://arxiv.org/abs/2512.02765", "authors": ["Alejandro Roig-Herrero", "Luis M. San-José-Revuelta", "Rafael Navarro-González", "Rodrigo de Luis-García", "Vicente Molina"], "title": "Effects of disease duration and antipsychotics on brain age in schizophrenia", "comment": "20 pages; 4 figures; 4 tables", "summary": "Accelerated brain aging has been consistently reported in patients with schizophrenia. Over the past decade, these findings have been replicated using the Brain Age paradigm, which applies machine learning techniques to estimate brain age from neuroimaging data. This approach yields a single index, the Brain Age Gap, defined as the difference between predicted and chronological age. Nevertheless, both the progressive nature of this phenomenon and the potential role of antipsychotic medication remain unclear. To investigate its progression, we compared the Brain Age Gap between individuals experiencing a first episode of psychosis and healthy controls using ANCOVA, adjusting for age, sex, body mass index, and estimated total intracranial volume. To enhance the robustness of our findings, we employed two distinct models: a transformer-inspired model based on harmonized volumetric brain features extracted with FastSurfer, and a previously trained deep learning model. To assess the potential effect of medication, we further compared bipolar patients who received antipsychotic treatment with those who did not. Mann-Whitney U test consistently showed that medicated bipolar patients did not exhibit a significantly larger Brain Age Gap. Both models converge on the conclusion that accelerated brain aging is unlikely to be explained by antipsychotic medication alone. Longitudinal studies are therefore required to clarify the temporal dynamics of brain aging in schizophrenia."}
{"id": "2512.02768", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.02768", "abs": "https://arxiv.org/abs/2512.02768", "authors": ["Hefei Gao", "Tianyao Huang", "Letian Guo", "Jie He", "Yonina C. Eldar"], "title": "Diffusion-Prior Split Gibbs Sampling for Synthetic Aperture Radar Imaging under Incomplete Measurements", "comment": null, "summary": "Synthetic aperture radar (SAR) imaging plays a critical role in all-weather, day-and-night remote sensing, yet reconstruction is often challenged by noise, undersampling, and complex scattering scenarios. Conventional methods, including matched filtering and sparsity-based compressed sensing, are limited in capturing intricate scene structures and frequently suffer from artifacts, elevated sidelobes, and loss of fine details. Recent diffusion models have demonstrated superior capability in representing high-order priors; however, existing diffusion-based SAR methods still yield degraded reconstructions due to oversimplified likelihood approximations in guided sampling. In this work, we propose a diffusion-driven split Gibbs sampling framework for SAR reconstruction, rigorously integrating measurement fidelity with learned diffusion priors. By alternately performing likelihood- and prior-driven updates via proximal sampling, this method ensures progressive convergence toward the true posterior while fully leveraging the expressive power of diffusion priors. Extensive experiments on simulated and Sentinel-1A datasets demonstrate substantial performance improvements: over 7 dB average PSNR gain in simulations, along with significant sidelobe suppression (MPLSR +2.96 dB, MISLR +11.5 dB) with respect to the best baseline result. On real-world Sentinel-1A data, the method achieves an average PSNR gain of 1.6 dB while effectively reducing artifacts and preserving scene details, including ridges, edges, and fine textures. These results underscore the potential of the adapted framework as a robust and generalizable solution for high-fidelity SAR imaging across diverse sensing scenarios."}
