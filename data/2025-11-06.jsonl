{"id": "2511.02845", "categories": ["eess.SP", "cs.AI", "physics.ins-det"], "pdf": "https://arxiv.org/pdf/2511.02845", "abs": "https://arxiv.org/abs/2511.02845", "authors": ["Yuxuan Liu", "Chiya Zhang", "Yifeng Yuan", "Chunlong He", "Weizheng Zhang", "Gaojie Chen"], "title": "AI-Enhanced Wi-Fi Sensing Through Single Transceiver Pair", "comment": "12 pages, 11 figures", "summary": "The advancement of next-generation Wi-Fi technology heavily relies on sensing\ncapabilities, which play a pivotal role in enabling sophisticated applications.\nIn response to the growing demand for large-scale deployments, contemporary\nWi-Fi sensing systems strive to achieve high-precision perception while\nmaintaining minimal bandwidth consumption and antenna count requirements.\nRemarkably, various AI-driven perception technologies have demonstrated the\nability to surpass the traditional resolution limitations imposed by radar\ntheory. However, the theoretical underpinnings of this phenomenon have not been\nthoroughly investigated in existing research. In this study, we found that\nunder hardware-constrained conditions, the performance gains brought by AI to\nWi-Fi sensing systems primarily originate from two aspects: prior information\nand temporal correlation. Prior information enables the AI to generate\nplausible details based on vague input, while temporal correlation helps reduce\nthe upper bound of sensing error. We developed an AI-based Wi-Fi sensing system\nusing a single transceiver pair and designed experiments focusing on human pose\nestimation and indoor localization to validate the theoretical claims. The\nresults confirm the performance gains contributed by temporal correlation and\nprior information."}
{"id": "2511.02846", "categories": ["eess.SP", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.02846", "abs": "https://arxiv.org/abs/2511.02846", "authors": ["Zan Li", "Kyongmin Yeo", "Wesley Gifford", "Lara Marcuse", "Madeline Fields", "Bülent Yener"], "title": "Spatio-Temporal Attention Network for Epileptic Seizure Prediction", "comment": null, "summary": "In this study, we present a deep learning framework that learns complex\nspatio-temporal correlation structures of EEG signals through a Spatio-Temporal\nAttention Network (STAN) for accurate predictions of onset of seizures for\nEpilepsy patients. Unlike existing methods, which rely on feature engineering\nand/or assume fixed preictal durations, our approach simultaneously models\nspatio-temporal correlations through STAN and employs an adversarial\ndiscriminator to distinguish preictal from interictal attention patterns,\nenabling patient-specific learning. Evaluation on CHB-MIT and MSSM datasets\ndemonstrates 96.6\\% sensitivity with 0.011/h false detection rate on CHB-MIT,\nand 94.2% sensitivity with 0.063/h FDR on MSSM, significantly outperforming\nstate-of-the-art methods. The framework reliably detects preictal states at\nleast 15 minutes before an onset, with patient-specific windows extending to 45\nminutes, providing sufficient intervention time for clinical applications."}
{"id": "2511.02848", "categories": ["eess.SP", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.02848", "abs": "https://arxiv.org/abs/2511.02848", "authors": ["Shantanu Sarkar", "Piotr Nabrzyski", "Saurabh Prasad", "Jose Luis Contreras-Vidal"], "title": "EEGReXferNet: A Lightweight Gen-AI Framework for EEG Subspace Reconstruction via Cross-Subject Transfer Learning and Channel-Aware Embedding", "comment": "Accepted for presentation at the NeurIPS 2025 Workshop on Foundation\n  Models for the Brain and Body", "summary": "Electroencephalography (EEG) is a widely used non-invasive technique for\nmonitoring brain activity, but low signal-to-noise ratios (SNR) due to various\nartifacts often compromise its utility. Conventional artifact removal methods\nrequire manual intervention or risk suppressing critical neural features during\nfiltering/reconstruction. Recent advances in generative models, including\nVariational Autoencoders (VAEs) and Generative Adversarial Networks (GANs),\nhave shown promise for EEG reconstruction; however, these approaches often lack\nintegrated temporal-spectral-spatial sensitivity and are computationally\nintensive, limiting their suitability for real-time applications like\nbrain-computer interfaces (BCIs). To overcome these challenges, we introduce\nEEGReXferNet, a lightweight Gen-AI framework for EEG subspace reconstruction\nvia cross-subject transfer learning - developed using Keras TensorFlow\n(v2.15.1). EEGReXferNet employs a modular architecture that leverages volume\nconduction across neighboring channels, band-specific convolution encoding, and\ndynamic latent feature extraction through sliding windows. By integrating\nreference-based scaling, the framework ensures continuity across successive\nwindows and generalizes effectively across subjects. This design improves\nspatial-temporal-spectral resolution (mean PSD correlation >= 0.95; mean\nspectrogram RV-Coefficient >= 0.85), reduces total weights by ~45% to mitigate\noverfitting, and maintains computational efficiency for robust, real-time EEG\npreprocessing in neurophysiological and BCI applications."}
{"id": "2511.02849", "categories": ["eess.SP", "cs.CV", "eess.IV"], "pdf": "https://arxiv.org/pdf/2511.02849", "abs": "https://arxiv.org/abs/2511.02849", "authors": ["Beyza Cinar", "Maria Maleshkova"], "title": "Benchmarking ResNet for Short-Term Hypoglycemia Classification with DiaData", "comment": "11 pages, 5 Tables, 4 Figures, BHI 2025 conference (JBHI special\n  issue)", "summary": "Individualized therapy is driven forward by medical data analysis, which\nprovides insight into the patient's context. In particular, for Type 1 Diabetes\n(T1D), which is an autoimmune disease, relationships between demographics,\nsensor data, and context can be analyzed. However, outliers, noisy data, and\nsmall data volumes cannot provide a reliable analysis. Hence, the research\ndomain requires large volumes of high-quality data. Moreover, missing values\ncan lead to information loss. To address this limitation, this study improves\nthe data quality of DiaData, an integration of 15 separate datasets containing\nglucose values from 2510 subjects with T1D. Notably, we make the following\ncontributions: 1) Outliers are identified with the interquartile range (IQR)\napproach and treated by replacing them with missing values. 2) Small gaps\n($\\le$ 25 min) are imputed with linear interpolation and larger gaps ($\\ge$ 30\nand $<$ 120 min) with Stineman interpolation. Based on a visual comparison,\nStineman interpolation provides more realistic glucose estimates than linear\ninterpolation for larger gaps. 3) After data cleaning, the correlation between\nglucose and heart rate is analyzed, yielding a moderate relation between 15 and\n60 minutes before hypoglycemia ($\\le$ 70 mg/dL). 4) Finally, a benchmark for\nhypoglycemia classification is provided with a state-of-the-art ResNet model.\nThe model is trained with the Maindatabase and Subdatabase II of DiaData to\nclassify hypoglycemia onset up to 2 hours in advance. Training with more data\nimproves performance by 7% while using quality-refined data yields a 2-3% gain\ncompared to raw data."}
{"id": "2511.02893", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.02893", "abs": "https://arxiv.org/abs/2511.02893", "authors": ["Chukwuemeka Arua Kalu", "Adaobi Chiazor Emegoakor", "Fortune Okafor", "Augustine Okoh Uchenna", "Chijioke Kelvin Ukpai", "Godsent Erere Onyeugbo"], "title": "Optimizing the nnU-Net model for brain tumor (Glioma) segmentation Using a BraTS Sub-Saharan Africa (SSA) dataset", "comment": "10 pages, 4 figures", "summary": "Medical image segmentation is a critical achievement in modern medical\nscience, developed over decades of research. It allows for the exact\ndelineation of anatomical and pathological features in two- or\nthree-dimensional pictures by utilizing notions like pixel intensity, texture,\nand anatomical context. With the advent of automated segmentation, physicians\nand radiologists may now concentrate on diagnosis and treatment planning while\nintelligent computers perform routine image processing tasks.\n  This study used the BraTS Sub-Saharan Africa dataset, a selected subset of\nthe BraTS dataset that included 60 multimodal MRI cases from patients with\nglioma. Surprisingly, the nnU Net model trained on the initial 60 instances\nperformed better than the network trained on an offline-augmented dataset of\n360 cases. Hypothetically, the offline augmentations introduced artificial\nanatomical variances or intensity distributions, reducing generalization. In\ncontrast, the original dataset, when paired with nnU Net's robust online\naugmentation procedures, maintained realistic variability and produced better\nresults. The study achieved a Dice score of 0.84 for whole tumor segmentation.\nThese findings highlight the significance of data quality and proper\naugmentation approaches in constructing accurate, generalizable medical picture\nsegmentation models, particularly for under-represented locations."}
{"id": "2511.02850", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.02850", "abs": "https://arxiv.org/abs/2511.02850", "authors": ["Youssif Abuzied", "Hassan AbdEltawab", "Abdelrhman Gaber", "Tamer ElBatt"], "title": "ECGXtract: Deep Learning-based ECG Feature Extraction for Automated CVD Diagnosis", "comment": null, "summary": "This paper presents ECGXtract, a deep learning-based approach for\ninterpretable ECG feature extraction, addressing the limitations of traditional\nsignal processing and black-box machine learning methods. In particular, we\ndevelop convolutional neural network models capable of extracting both temporal\nand morphological features with strong correlations to a clinically validated\nground truth. Initially, each model is trained to extract a single feature,\nensuring precise and interpretable outputs. A series of experiments is then\ncarried out to evaluate the proposed method across multiple setups, including\nglobal versus lead-specific features, different sampling frequencies, and\ncomparisons with other approaches such as ECGdeli. Our findings show that\nECGXtract achieves robust performance across most features with a mean\ncorrelation score of 0.80 with the ground truth for global features, with lead\nII consistently providing the best results. For lead-specific features,\nECGXtract achieves a mean correlation score of 0.822. Moreover, ECGXtract\nachieves superior results to the state-of-the-art open source ECGdeli as it got\na higher correlation score with the ground truth in 90% of the features.\nFurthermore, we explore the feasibility of extracting multiple features\nsimultaneously utilizing a single model. Semantic grouping is proved to be\neffective for global features, while large-scale grouping and lead-specific\nmulti-output models show notable performance drops. These results highlight the\npotential of structured grouping strategies to balance the computational\nefficiency vs. model accuracy, paving the way for more scalable and clinically\ninterpretable ECG feature extraction systems in limited resource settings."}
{"id": "2511.02928", "categories": ["eess.IV", "cs.CV", "I.2.10; I.4.8; J.3"], "pdf": "https://arxiv.org/pdf/2511.02928", "abs": "https://arxiv.org/abs/2511.02928", "authors": ["Ilerioluwakiiye Abolade", "Aniekan Udo", "Augustine Ojo", "Abdulbasit Oyetunji", "Hammed Ajigbotosho", "Aondana Iorumbur", "Confidence Raymond", "Maruf Adewole"], "title": "Domain-Adaptive Transformer for Data-Efficient Glioma Segmentation in Sub-Saharan MRI", "comment": "4 pages, 2 figures. Accepted as an abstract at the Women in Machine\n  Learning (WiML) Workshop at NeurIPS 2025", "summary": "Glioma segmentation is critical for diagnosis and treatment planning, yet\nremains challenging in Sub-Saharan Africa due to limited MRI infrastructure and\nheterogeneous acquisition protocols that induce severe domain shift. We propose\nSegFormer3D-plus, a radiomics-guided transformer architecture designed for\nrobust segmentation under domain variability. Our method combines: (1)\nhistogram matching for intensity harmonization across scanners, (2) radiomic\nfeature extraction with PCA-reduced k-means for domain-aware stratified\nsampling, (3) a dual-pathway encoder with frequency-aware feature extraction\nand spatial-channel attention, and (4) composite Dice-Cross-Entropy loss for\nboundary refinement. Pretrained on BraTS 2023 and fine-tuned on BraTS-Africa\ndata, SegFormer3D-plus demonstrates improved tumor subregion delineation and\nboundary localization across heterogeneous African clinical scans, highlighting\nthe value of radiomics-guided domain adaptation for resource-limited settings."}
{"id": "2511.02851", "categories": ["eess.SP", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.02851", "abs": "https://arxiv.org/abs/2511.02851", "authors": ["Rushuang Zhou", "Yuan-Ting Zhang", "M. Jamal Deen", "Yining Dong"], "title": "Approaching Low-Cost Cardiac Intelligence with Semi-Supervised Knowledge Distillation", "comment": null, "summary": "Deploying advanced cardiac artificial intelligence for daily cardiac\nmonitoring is hindered by its reliance on extensive medical data and high\ncomputational resources. Low-cost cardiac intelligence (LCCI) offers a\npromising alternative by using wearable device data, such as 1-lead\nelectrocardiogram (ECG), but it suffers from a significant diagnostic\nperformance gap compared to high-cost cardiac intelligence (HCCI). To bridge\nthis gap, we propose LiteHeart, a semi-supervised knowledge distillation\nframework. LiteHeart introduces a region-aware distillation module to mimic how\ncardiologists focus on diagnostically relevant ECG regions and a cross-layer\nmutual information module to align the decision processes of LCCI and HCCI\nsystems. Using a semi-supervised training strategy, LiteHeart further improves\nmodel robustness under limited supervision. Evaluated on five datasets covering\nover 38 cardiovascular diseases, LiteHeart substantially reduces the\nperformance gap between LCCI and HCCI, outperforming existing methods by 4.27%\nto 7.10% in macro F1 score. These results demonstrate that LiteHeart\nsignificantly enhances the diagnostic capabilities of low-cost cardiac\nintelligence systems, paving the way for scalable, affordable, and accurate\ndaily cardiac healthcare using wearable technologies."}
{"id": "2511.03192", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2511.03192", "abs": "https://arxiv.org/abs/2511.03192", "authors": ["Isar Lemeire", "Yee Wei Law", "Sang-Heon Lee", "Will Meakin", "Tat-Jun Chin"], "title": "SAAIPAA: Optimizing aspect-angles-invariant physical adversarial attacks on SAR target recognition models", "comment": null, "summary": "Synthetic aperture radar (SAR) enables versatile, all-time, all-weather\nremote sensing. Coupled with automatic target recognition (ATR) leveraging\nmachine learning (ML), SAR is empowering a wide range of Earth observation and\nsurveillance applications. However, the surge of attacks based on adversarial\nperturbations against the ML algorithms underpinning SAR ATR is prompting the\nneed for systematic research into adversarial perturbation mechanisms. Research\nin this area began in the digital (image) domain and evolved into the physical\n(signal) domain, resulting in physical adversarial attacks (PAAs) that\nstrategically exploit corner reflectors as attack vectors to evade ML-based\nATR. This paper proposes a novel framework called SAR Aspect-Angles-Invariant\nPhysical Adversarial Attack (SAAIPAA) for physics-based modelling of\nreflector-actuated adversarial perturbations, which improves on the rigor of\nprior work. A unique feature of SAAIPAA is its ability to remain effective even\nwhen the attacker lacks knowledge of the SAR platform's aspect angles, by\ndeploying at least one reflector in each azimuthal quadrant and optimizing\nreflector orientations. The resultant physical evasion attacks are efficiently\nrealizable and optimal over the considered range of aspect angles between a SAR\nplatform and a target, achieving state-of-the-art fooling rates (over 80% for\nDenseNet-121 and ResNet50) in the white-box setting. When aspect angles are\nknown to the attacker, an average fooling rate of 99.2% is attainable. In\nblack-box settings, although the attack efficacy of SAAIPAA transfers well\nbetween some models (e.g., from ResNet50 to DenseNet121), the transferability\nto some models (e.g., MobileNetV2) can be improved. A useful outcome of using\nthe MSTAR dataset for the experiments in this article, a method for generating\nbounding boxes for densely sampled azimuthal SAR datasets is introduced."}
{"id": "2511.02852", "categories": ["eess.SP", "cs.GR", "cs.MM"], "pdf": "https://arxiv.org/pdf/2511.02852", "abs": "https://arxiv.org/abs/2511.02852", "authors": ["Shengze Xue", "Yu Ren", "Jiacheng Hong", "Run Ni", "Shuangjiu Xiao", "Deli Dong"], "title": "Real-Time Interactive Hybrid Ocean: Spectrum-Consistent Wave Particle-FFT Coupling", "comment": null, "summary": "Fast Fourier Transform-based (FFT) spectral oceans are widely adopted for\ntheir efficiency and large-scale realism, but they assume global stationarity\nand spatial homogeneity, making it difficult to represent non-uniform seas and\nnear-field interactions (e.g., ships and floaters). In contrast, wave particles\ncapture local wakes and ripples, yet are costly to maintain at scale and hard\nto match global spectral statistics.We present a real-time interactive hybrid\nocean: a global FFT background coupled with local wave-particle (WP) patch\nregions around interactive objects, jointly driven under a unified set of\nspectral parameters and dispersion. At patch boundaries, particles are injected\naccording to the same directional spectrum as the FFT, aligning the local\nfrequency-direction distribution with the background and matching energy\ndensity, without disturbing the far field.Our approach introduces two main\ninnovations: (1) Hybrid ocean representation. We couple a global FFT background\nwith local WP patches under a unified spectrum, achieving large-scale spectral\nconsistency while supporting localized wakes and ripples.(2) Frequency-bucketed\nimplementation. We design a particle sampling and GPU-parallel synthesis scheme\nbased on frequency buckets, which preserves spectral energy consistency and\nsustains real-time interactive performance.Together, these innovations enable a\nunified framework that delivers both large-scale spectral realism and\nfine-grained interactivity in real time."}
{"id": "2511.03365", "categories": ["eess.IV", "cs.CV", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2511.03365", "abs": "https://arxiv.org/abs/2511.03365", "authors": ["Gabriela Fernandes"], "title": "Morpho-Genomic Deep Learning for Ovarian Cancer Subtype and Gene Mutation Prediction from Histopathology", "comment": null, "summary": "Ovarian cancer remains one of the most lethal gynecological malignancies,\nlargely due to late diagnosis and extensive heterogeneity across subtypes.\nCurrent diagnostic methods are limited in their ability to reveal underlying\ngenomic variations essential for precision oncology. This study introduces a\nnovel hybrid deep learning pipeline that integrates quantitative nuclear\nmorphometry with deep convolutional image features to perform ovarian cancer\nsubtype classification and gene mutation inference directly from Hematoxylin\nand Eosin (H&E) histopathological images. Using $\\sim45,000$ image patches\nsourced from The Cancer Genome Atlas (TCGA) and public datasets, a fusion model\ncombining a ResNet-50 Convolutional Neural Network (CNN) encoder and a Vision\nTransformer (ViT) was developed. This model successfully captured both local\nmorphological texture and global tissue context. The pipeline achieved a robust\noverall subtype classification accuracy of $84.2\\%$ (Macro AUC of $0.87 \\pm\n0.03$). Crucially, the model demonstrated the capacity for gene mutation\ninference with moderate-to-high accuracy: $AUC_{TP53} = 0.82 \\pm 0.02$,\n$AUC_{BRCA1} = 0.76 \\pm 0.04$, and $AUC_{ARID1A} = 0.73 \\pm 0.05$. Feature\nimportance analysis established direct quantitative links, revealing that\nnuclear solidity and eccentricity were the dominant predictors for TP53\nmutation. These findings validate that quantifiable histological phenotypes\nencode measurable genomic signals, paving the way for cost-effective, precision\nhistopathology in ovarian cancer triage and diagnosis."}
{"id": "2511.02853", "categories": ["eess.SP", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.02853", "abs": "https://arxiv.org/abs/2511.02853", "authors": ["Young-Seok Kweon", "Gi-Hwan Shin", "Ji-Yong Kim", "Bokyeong Ryu", "Seong-Whan Lee"], "title": "Consciousness-ECG Transformer for Conscious State Estimation System with Real-Time Monitoring", "comment": "30 pages, 8 figures", "summary": "Conscious state estimation is important in various medical settings,\nincluding sleep staging and anesthesia management, to ensure patient safety and\noptimize health outcomes. Traditional methods predominantly utilize\nelectroencephalography (EEG), which faces challenges such as high sensitivity\nto noise and the requirement for controlled environments. In this study, we\npropose the consciousness-ECG transformer that leverages electrocardiography\n(ECG) signals for non-invasive and reliable conscious state estimation. Our\napproach employs a transformer with decoupled query attention to effectively\ncapture heart rate variability features that distinguish between conscious and\nunconscious states. We implemented the conscious state estimation system with\nreal-time monitoring and validated our system on datasets involving sleep\nstaging and anesthesia level monitoring during surgeries. Experimental results\ndemonstrate that our model outperforms baseline models, achieving accuracies of\n0.877 on sleep staging and 0.880 on anesthesia level monitoring. Moreover, our\nmodel achieves the highest area under curve values of 0.786 and 0.895 on sleep\nstaging and anesthesia level monitoring, respectively. The proposed system\noffers a practical and robust alternative to EEG-based methods, particularly\nsuited for dynamic clinical environments. Our results highlight the potential\nof ECG-based consciousness monitoring to enhance patient safety and advance our\nunderstanding of conscious states."}
{"id": "2511.03376", "categories": ["eess.IV", "cs.AI", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2511.03376", "abs": "https://arxiv.org/abs/2511.03376", "authors": ["Syed Muqeem Mahmood", "Hassan Mohy-ud-Din"], "title": "Computational Imaging Meets LLMs: Zero-Shot IDH Mutation Prediction in Brain Gliomas", "comment": "5 pages, 1 figure, 3 tables", "summary": "We present a framework that combines Large Language Models with computational\nimage analytics for non-invasive, zero-shot prediction of IDH mutation status\nin brain gliomas. For each subject, coregistered multi-parametric MRI scans and\nmulti-class tumor segmentation maps were processed to extract interpretable\nsemantic (visual) attributes and quantitative features, serialized in a\nstandardized JSON file, and used to query GPT 4o and GPT 5 without fine-tuning.\nWe evaluated this framework on six publicly available datasets (N = 1427) and\nresults showcased high accuracy and balanced classification performance across\nheterogeneous cohorts, even in the absence of manual annotations. GPT 5\noutperformed GPT 4o in context-driven phenotype interpretation. Volumetric\nfeatures emerged as the most important predictors, supplemented by\nsubtype-specific imaging markers and clinical information. Our results\ndemonstrate the potential of integrating LLM-based reasoning with computational\nimage analytics for precise, non-invasive tumor genotyping, advancing\ndiagnostic strategies in neuro-oncology. The code is available at\nhttps://github.com/ATPLab-LUMS/CIM-LLM."}
{"id": "2511.02880", "categories": ["eess.SP", "cs.AI", "cs.CV", "eess.IV"], "pdf": "https://arxiv.org/pdf/2511.02880", "abs": "https://arxiv.org/abs/2511.02880", "authors": ["Zehui Zhan", "Yaojun Hu", "Jiajing Zhan", "Wanchen Lian", "Wanqing Wu", "Jintai Chen"], "title": "NEF-NET+: Adapting Electrocardio panorama in the wild", "comment": null, "summary": "Conventional multi-lead electrocardiogram (ECG) systems capture cardiac\nsignals from a fixed set of anatomical viewpoints defined by lead placement.\nHowever, certain cardiac conditions (e.g., Brugada syndrome) require\nadditional, non-standard viewpoints to reveal diagnostically critical patterns\nthat may be absent in standard leads. To systematically overcome this\nlimitation, Nef-Net was recently introduced to reconstruct a continuous\nelectrocardiac field, enabling virtual observation of ECG signals from\narbitrary views (termed Electrocardio Panorama). Despite its promise, Nef-Net\noperates under idealized assumptions and faces in-the-wild challenges, such as\nlong-duration ECG modeling, robustness to device-specific signal artifacts, and\nsuboptimal lead placement calibration. This paper presents NEF-NET+, an\nenhanced framework for realistic panoramic ECG synthesis that supports\narbitrary-length signal synthesis from any desired view, generalizes across ECG\ndevices, and compensates for operator-induced deviations in electrode\nplacement. These capabilities are enabled by a newly designed model\narchitecture that performs direct view transformation, incorporating a workflow\ncomprising offline pretraining, device calibration tuning steps as well as an\non-the-fly calibration step for patient-specific adaptation. To rigorously\nevaluate panoramic ECG synthesis, we construct a new Electrocardio Panorama\nbenchmark, called Panobench, comprising 5367 recordings with 48-view per\nsubject, capturing the full spatial variability of cardiac electrical activity.\nExperimental results show that NEF-NET+ delivers substantial improvements over\nNef-Net, yielding an increase of around 6 dB in PSNR in real-world setting. The\ncode and Panobench will be released in a subsequent publication."}
{"id": "2511.02849", "categories": ["eess.SP", "cs.CV", "eess.IV"], "pdf": "https://arxiv.org/pdf/2511.02849", "abs": "https://arxiv.org/abs/2511.02849", "authors": ["Beyza Cinar", "Maria Maleshkova"], "title": "Benchmarking ResNet for Short-Term Hypoglycemia Classification with DiaData", "comment": "11 pages, 5 Tables, 4 Figures, BHI 2025 conference (JBHI special\n  issue)", "summary": "Individualized therapy is driven forward by medical data analysis, which\nprovides insight into the patient's context. In particular, for Type 1 Diabetes\n(T1D), which is an autoimmune disease, relationships between demographics,\nsensor data, and context can be analyzed. However, outliers, noisy data, and\nsmall data volumes cannot provide a reliable analysis. Hence, the research\ndomain requires large volumes of high-quality data. Moreover, missing values\ncan lead to information loss. To address this limitation, this study improves\nthe data quality of DiaData, an integration of 15 separate datasets containing\nglucose values from 2510 subjects with T1D. Notably, we make the following\ncontributions: 1) Outliers are identified with the interquartile range (IQR)\napproach and treated by replacing them with missing values. 2) Small gaps\n($\\le$ 25 min) are imputed with linear interpolation and larger gaps ($\\ge$ 30\nand $<$ 120 min) with Stineman interpolation. Based on a visual comparison,\nStineman interpolation provides more realistic glucose estimates than linear\ninterpolation for larger gaps. 3) After data cleaning, the correlation between\nglucose and heart rate is analyzed, yielding a moderate relation between 15 and\n60 minutes before hypoglycemia ($\\le$ 70 mg/dL). 4) Finally, a benchmark for\nhypoglycemia classification is provided with a state-of-the-art ResNet model.\nThe model is trained with the Maindatabase and Subdatabase II of DiaData to\nclassify hypoglycemia onset up to 2 hours in advance. Training with more data\nimproves performance by 7% while using quality-refined data yields a 2-3% gain\ncompared to raw data."}
{"id": "2511.02884", "categories": ["eess.SP", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.02884", "abs": "https://arxiv.org/abs/2511.02884", "authors": ["Dariush Salami", "Nima Bahmani", "Hüseyin Yiğitler", "Stephan Sigg"], "title": "Adaptive Internal Calibration for Temperature-Robust mmWave FMCW Radars", "comment": "Accepted to be published in ACM international joint conference on\n  Pervasive and Ubiquitous Computing (UbiComp)", "summary": "We present a novel internal calibration framework for Millimeter- Wave\n(mmWave) Frequency-Modulated Continuous-Wave (FMCW) radars to ensure robust\nperformance under internal temperature variations, tailored for deployment in\ndense wireless networks. Our approach mitigates the impact of\ntemperature-induced drifts in radar hardware, enhancing reliability. We propose\na temperature compensation model that leverages internal sensor data and signal\nprocessing techniques to maintain measurement accuracy. Experimental results\ndemonstrate improved robustness across a range of internal temperature\nconditions, with minimal computational overhead, ensuring scalability in dense\nnetwork environments. The framework also incorporates ethical design\nprinciples, avoiding reliance on sensitive external data. The proposed scheme\nreduces the Pearson correlation between the amplitude of the Intermediate\nFrequency (IF) signal and internal temperature drift up to 84%, significantly\nmitigating the temperature drift."}
{"id": "2511.02880", "categories": ["eess.SP", "cs.AI", "cs.CV", "eess.IV"], "pdf": "https://arxiv.org/pdf/2511.02880", "abs": "https://arxiv.org/abs/2511.02880", "authors": ["Zehui Zhan", "Yaojun Hu", "Jiajing Zhan", "Wanchen Lian", "Wanqing Wu", "Jintai Chen"], "title": "NEF-NET+: Adapting Electrocardio panorama in the wild", "comment": null, "summary": "Conventional multi-lead electrocardiogram (ECG) systems capture cardiac\nsignals from a fixed set of anatomical viewpoints defined by lead placement.\nHowever, certain cardiac conditions (e.g., Brugada syndrome) require\nadditional, non-standard viewpoints to reveal diagnostically critical patterns\nthat may be absent in standard leads. To systematically overcome this\nlimitation, Nef-Net was recently introduced to reconstruct a continuous\nelectrocardiac field, enabling virtual observation of ECG signals from\narbitrary views (termed Electrocardio Panorama). Despite its promise, Nef-Net\noperates under idealized assumptions and faces in-the-wild challenges, such as\nlong-duration ECG modeling, robustness to device-specific signal artifacts, and\nsuboptimal lead placement calibration. This paper presents NEF-NET+, an\nenhanced framework for realistic panoramic ECG synthesis that supports\narbitrary-length signal synthesis from any desired view, generalizes across ECG\ndevices, and compensates for operator-induced deviations in electrode\nplacement. These capabilities are enabled by a newly designed model\narchitecture that performs direct view transformation, incorporating a workflow\ncomprising offline pretraining, device calibration tuning steps as well as an\non-the-fly calibration step for patient-specific adaptation. To rigorously\nevaluate panoramic ECG synthesis, we construct a new Electrocardio Panorama\nbenchmark, called Panobench, comprising 5367 recordings with 48-view per\nsubject, capturing the full spatial variability of cardiac electrical activity.\nExperimental results show that NEF-NET+ delivers substantial improvements over\nNef-Net, yielding an increase of around 6 dB in PSNR in real-world setting. The\ncode and Panobench will be released in a subsequent publication."}
{"id": "2511.02938", "categories": ["eess.SP", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.02938", "abs": "https://arxiv.org/abs/2511.02938", "authors": ["Sepideh KhakzadGharamaleki", "Hassan Rivaz", "Brandon Helfield"], "title": "From Narrow to Wide: Autoencoding Transformers for Ultrasound Bandwidth Recovery", "comment": null, "summary": "Conventional pulse-echo ultrasound suffers when low-cost probes deliver only\nnarrow fractional bandwidths, elongating pulses and erasing high-frequency\ndetail. We address this limitation by learning a data-driven mapping from\nband-limited to broadband spectrogram of radio-frequency (RF) lines. To this\nend, a variation of Tiny Vision Transform (ViT) auto-encoder is trained on\nsimulation data using a curriculum-weighted loss. On heterogeneous speckle-cyst\nphantoms, the network reduces image-domain MSE by 90 percent, boosts PSNR by\n6.7 dB, and raises SSIM to 0.965 compared with the narrow-band input. It also\nsharpens point-target rows in a completely unseen resolution phantom,\ndemonstrating strong out-of-distribution generalisation without sacrificing\nframe rate or phase information. These results indicate that a purely software\nupgrade can endow installed narrow-band probes with broadband-like performance,\npotentially widening access to high-resolution ultrasound in\nresource-constrained settings."}
{"id": "2511.03130", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.03130", "abs": "https://arxiv.org/abs/2511.03130", "authors": ["Ved Prakash Dubey", "Shovan Bhaumik"], "title": "Consensus Tracking of an Underwater Vehicle Using Weighted Harmonic Mean Density", "comment": null, "summary": "This paper addresses an underwater target tracking problem in which a large\nnumber of sonobuoy sensors are deployed on a surveillance region. The region is\ndivided into several sub-regions, where a single tracker, capable of generating\ntrack is installed. Each sonobuoy can measure the direction of arrival of\nacoustic signals (known as bearing angles) and communicate the measurements\nwith the local tracker. Further, each local tracker can communicate with all\nother trackers, where each of them can exchange their estimate and finally a\nconsensus is reached. We propose a weighted harmonic mean density (HMD) based\ntracking to reach a consensus and provide a solution for the fusion of Gaussian\ndensities. In this approach, optimal weights are assigned by minimizing the\nKullback-Leibler divergence measure. Performance of the proposed method is\nmeasured using root mean square error, percentage of track divergence, and\nnormalized estimation error squared. Simulation results demonstrate that the\noptimized HMD-based fusion outperforms existing fusion methods during a\ndistributed tracking."}
{"id": "2511.03133", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.03133", "abs": "https://arxiv.org/abs/2511.03133", "authors": ["Ziheng Zhang", "Wen Chen", "Qingqing Wu", "Haoran Qin", "Zhendong Li", "Qiong Wu"], "title": "Analysis and Algorithm for Multi IRS Collaborative Localization via Hybrid Time Angle Estimation", "comment": null, "summary": "This paper proposes a novel multiple intelligent reflecting surfaces (IRSs)\ncollaborative hybrid localization system, which involves deploying multiple\nIRSs near the target area and achieving target localization through joint time\ndelay and angle estimation. Specifically, echo signals from all reflective\nelements are received by each sensor and jointly processed to estimate the time\ndelay and angle parameters. Based on the above model, we derive the Fisher\nInformation Matrix (FIM) for cascaded delay, Angle of Arrival (AOA), and Angle\nof Departure (AOD) estimation in semi passive passive models, along with the\ncorresponding Cramer Rao Bound (CRB). To achieve precise estimation close to\nthe CRB, we design efficient algorithms for angle and location estimation. For\nangle estimation, reflective signals are categorized into three cases based on\ntheir rank, with different signal preprocessing. By constructing an atomic norm\nset and minimizing the atomic norm, the joint angle estimation problem is\ntransformed into a convex optimization problem, and low-complexity estimation\nof multiple AOA and AOD pairs is achieved using the Alternating Direction\nMethod of Multipliers (ADMM). For location estimation, we propose a three-stage\nlocalization algorithm that combines weighted least squares, total least\nsquares, and quadratic correction to handle errors in the coefficient matrix\nand observation vector, thus improving accuracy. Numerical simulations validate\nthe superiority of the proposed system, demonstrating that the system's\ncollaboration, hybrid localization, and distributed deployment provide\nsubstantial benefits, as well as the accuracy of the proposed estimation\nalgorithms, particularly in low signal to noise ratio (SNR) condition."}
{"id": "2511.03220", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.03220", "abs": "https://arxiv.org/abs/2511.03220", "authors": ["Tianhao Mao", "Le Liang", "Jie Yang", "Hao Ye", "Shi Jin", "Geoffrey Ye Li"], "title": "Multimodal-Wireless: A Large-Scale Dataset for Sensing and Communication", "comment": null, "summary": "This paper presents Multimodal-Wireless, an open-source multimodal sensing\ndataset designed for wireless communication research. The dataset is generated\nthrough an integrated and customizable data pipeline built upon the CARLA\nsimulator and Sionna framework. It contains approximately 160,000 frames\ncollected across four virtual towns, sixteen communication scenarios, and three\nweather conditions, encompassing multiple sensing modalities--communication\nchannel, light detection and ranging, RGB and depth cameras, inertial\nmeasurement unit, and radar. This paper provides a comprehensive overview of\nthe dataset, outlining its key features, overall framework, and technical\nimplementation details. In addition, it explores potential research\napplications concerning communication and collaborative perception, exemplified\nby beam prediction using a multimodal large language model. The dataset is open\nin https://le-liang.github.io/mmw/."}
{"id": "2511.03283", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.03283", "abs": "https://arxiv.org/abs/2511.03283", "authors": ["Zhiyuan Zhai", "Wei Ni", "Xin Wang", "Dusit Niyato", "Ekram Hossain"], "title": "Integrated Sensing and Communication with UAV Swarms via Decentralized Consensus ADMM", "comment": null, "summary": "UAV swarms can form virtual antenna arrays to exploit additional spatial\ndegrees of freedom and enhance integrated sensing and communication (ISAC). The\noptimization of UAV positions is challenging due to the distributed nature of\nswarms and the lack of a global view at individual UAVs.\n  This paper presents a new decentralized optimization framework that allows\nUAVs to decide their locations in parallel and reach consensus on a globally\noptimal swarm geometry for ISAC.\n  Specifically, we derive the achievable uplink rate and Cram\\'er-Rao Bound\n(CRB) as tractable metrics for communication and sensing, respectively.\n  The UAV positions are optimized to balance maximizing the communication rate\nand minimizing the CRB.\n  To solve this non-convex problem with coupled variables, we develop a\ndecentralized consensus alternating direction method of multipliers (ADMM)\nalgorithm, which enables the UAVs to iteratively align their local updates and\nreach consensus.\n  The algorithm decomposes the global objective into local projection updates,\nproxy-assisted consensus coordination, and lightweight dual updates, ensuring\nscalability and consistency throughout the swarm.\n  Simulations demonstrate that the proposed consensus ADMM algorithm converges\nrapidly with strong scalability, and that the UAV swarm significantly\noutperforms fixed-array baselines in both communication and sensing\nperformance."}
{"id": "2511.03284", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.03284", "abs": "https://arxiv.org/abs/2511.03284", "authors": ["Zhiyuan Zhai", "Xiaojun Yuan", "Xin Wang", "Geoffrey Ye Li"], "title": "Decentralized Federated Learning with Distributed Aggregation Weight Optimization", "comment": null, "summary": "Decentralized federated learning (DFL) is an emerging paradigm to enable edge\ndevices collaboratively training a learning model using a device-to-device\n(D2D) communication manner without the coordination of a parameter server (PS).\nAggregation weights, also known as mixing weights, are crucial in DFL process,\nand impact the learning efficiency and accuracy. Conventional design relies on\na so-called central entity to collect all local information and conduct system\noptimization to obtain appropriate weights. In this paper, we develop a\ndistributed aggregation weight optimization algorithm to align with the\ndecentralized nature of DFL. We analyze convergence by quantitatively capturing\nthe impact of the aggregation weights over decentralized communication\nnetworks. Based on the analysis, we then formulate a learning performance\noptimization problem by designing the aggregation weights to minimize the\nderived convergence bound. The optimization problem is further transformed as\nan eigenvalue optimization problem and solved by our proposed subgradient-based\nalgorithm in a distributed fashion. In our algorithm, edge devices only need\nlocal information to obtain the optimal aggregation weights through local (D2D)\ncommunications, just like the learning itself. Therefore, the optimization,\ncommunication, and learning process can be all conducted in a distributed\nfashion, which leads to a genuinely distributed DFL system. Numerical results\ndemonstrate the superiority of the proposed algorithm in practical DFL\ndeployment."}
{"id": "2511.03290", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.03290", "abs": "https://arxiv.org/abs/2511.03290", "authors": ["Jinhao Yi", "Weijun Gao", "Chong Han"], "title": "Diffusion-Driven Terahertz Air-Ground Communications under Dynamic Atmospheric Turbulence", "comment": null, "summary": "The ever-increasing demand for ultra-high data rates in space-air-ground\nintegrated networks (SAGINs) has rendered terahertz THz communications a\npromising technology owing to its exceptionally broad and continuous spectrum\nresources. Nevertheless, in air-ground (AG) scenarios, the high mobility of\naircraft induces intense and rapidly fluctuating turbulence, leading to\nadditional propagation loss that is often overlooked in existing studies. To\nbridge this gap, this paper presents an AI-empowered THz AG communication\nframework that explicitly models turbulence-induced attenuation through fluid\ndynamics and integrates it into an adaptive optimization paradigm for\ncommunication performance enhancement. Specifically, a fluid-dynamics-informed\nattenuation model is established to characterize aircraft-generated turbulence\nand quantify its impact on THz signal propagation. Building upon this model, a\njoint power-attitude optimization problem is formulated to adaptively allocate\ntransmit power and adjust aircraft attitude for maximizing link capacity. The\noptimization problem is efficiently solved using a diffusion-based algorithm\nthat learns the nonlinear relationship between flight configuration and\nturbulence-induced attenuation. Comprehensive numerical evaluations demonstrate\nthat the turbulence-induced attenuation ranges from 18 to 28 dB under attacking\nangles between -10 degree and 10 degree at 0.7 Mach, verifying the pronounced\nimpact of aircraft-induced turbulence on THz propagation. Furthermore, the\nproposed framework attains an average capacity of 11.241 bps/Hz, substantially\noutperforming existing strategies by 22.8% and 66.5%, and approaching\napproximately 98% of the theoretical capacity limit."}
{"id": "2511.03291", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.03291", "abs": "https://arxiv.org/abs/2511.03291", "authors": ["Zhiyuan Zhai", "Shuyan Hu", "Wei Ni", "Xiaojun Yuan", "Xin Wang"], "title": "Spectral-Convergent Decentralized Machine Learning: Theory and Application in Space Networks", "comment": null, "summary": "Decentralized machine learning (DML) supports collaborative training in\nlarge-scale networks with no central server. It is sensitive to the quality and\nreliability of inter-device communications that result in time-varying and\nstochastic topologies. This paper studies the impact of unreliable\ncommunication on the convergence of DML and establishes a direct connection\nbetween the spectral properties of the mixing process and the global\nperformance. We provide rigorous convergence guarantees under random topologies\nand derive bounds that characterize the impact of the expected mixing matrix's\nspectral properties on learning. We formulate a spectral optimization problem\nthat minimizes the spectral radius of the expected second-order mixing matrix\nto enhance the convergence rate under probabilistic link failures. To solve\nthis non-smooth spectral problem in a fully decentralized manner, we design an\nefficient subgradient-based algorithm that integrates Chebyshev-accelerated\neigenvector estimation with local update and aggregation weight adjustment,\nwhile ensuring symmetry and stochasticity constraints without central\ncoordination. Experiments on a realistic low Earth orbit (LEO) satellite\nconstellation with time-varying inter-satellite link models and real-world\nremote sensing data demonstrate the feasibility and effectiveness of the\nproposed method. The method significantly improves classification accuracy and\nconvergence efficiency compared to existing baselines, validating its\napplicability in satellite and other decentralized systems."}
{"id": "2511.03292", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.03292", "abs": "https://arxiv.org/abs/2511.03292", "authors": ["Qiuyuan Yang", "Cunhua Pan", "Ruidong Li", "Zhenkun Zhang", "Hong Ren", "Changhong Wang", "Jiangzhou Wang"], "title": "UAV SAR Imaging with 5G NR OFDM Signals in NLOS Environments", "comment": null, "summary": "The integration of sensing and communication (ISAC) has significant potential\nfor future wireless systems, enabling efficient spectrum utilization and novel\napplication scenarios. In this paper, we propose a cooperative ISAC framework\nfor synthetic aperture radar (SAR) imaging by leveraging orthogonal frequency\ndivision multiplexing (OFDM) communication signals. We address the challenge of\nsevere imaging degradation in non-line-of-sight (NLOS) environments under the\nQUAsi Deterministic RadIo channel GenerAtor (QuaDRiGa). To detect weak signals\nand eliminate false points, we develop a two-stage compressed sensing-space\nalternating generalized expectation maximization (CS-SAGE) scheme for\nhigh-precision scatterer localization. In stage I, orthogonal matching pursuit\n(OMP) is employed for coarse estimation to identify the approximate locations\nof dominant scatterers. Then, the SAGE algorithm in stage II performs fine\nestimation to accurately extract scatterer parameters. Simulation results\nvalidate the effectiveness of the proposed cooperative ISAC framework, and\nprovide valuable insights for practical system design."}
{"id": "2511.03302", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.03302", "abs": "https://arxiv.org/abs/2511.03302", "authors": ["Xiaoyun Wang", "Yutong Zhang", "Sen Wang", "Sun Qi", "Hanning Wang", "Qixing Wang", "Jing Jin", "Jiwei He", "Nan Li"], "title": "C-RAN Advanced: From a Network Cooperation Perspective", "comment": null, "summary": "Future mobile networks in the sixth generation (6G) are poised for a paradigm\nshift from conventional communication services toward comprehensive information\nservices, driving the evolution of radio access network (RAN) architectures\ntoward enhanced cooperation, intelligence, and service orientation. Building\nupon the concept of centralized, collaborative, cloud, and clean RAN (C-RAN),\nthis article proposes a novel cooperative, intelligent, and service-based RAN\n(CIS-RAN) architecture. Focusing on cooperation, CIS-RAN extends the\ntraditional cooperative communication paradigm by further integrating\ncooperative sensing and cooperative artificial intelligence (AI). To improve\nboth performance and effectiveness across diverse application scenarios,\nCIS-RAN enhances network cooperation throughout the entire process of\nacquisition, transmission, and processing, thereby enabling efficient\ninformation acquisition, diverse cooperative interactions, and intelligent\nfusion decision-making. Key technologies are discussed, with network\ncooperative multiple-input multiple-output (MIMO) examined as a case study,\ndemonstrating superior performance over traditional architectures, as\ndemonstrated by numerical results. Future research directions are outlined,\nemphasizing the continued exploration and advancement of the CIS-RAN\narchitecture, particularly in enhancing network cooperation."}
{"id": "2511.03401", "categories": ["eess.SP", "H.1"], "pdf": "https://arxiv.org/pdf/2511.03401", "abs": "https://arxiv.org/abs/2511.03401", "authors": ["Kunrui Cao", "Jingyu Chen", "Panagiotis D. Diamantoulakis", "Lei Zhou", "Xingwang Li", "Yuanwei Liu", "George K. Karagiannidis"], "title": "Performance Analysis of Wireless-Powered Pinching Antenna Systems", "comment": "13 pages, 8 figures", "summary": "Pinching antenna system (PAS) serves as a groundbreaking paradigm that\nenhances wireless communications by flexibly adjusting the position of pinching\nantenna (PA) and establishing a strong line-of-sight (LoS) link, thereby\nreducing the free-space path loss. This paper introduces the concept of\nwireless-powered PAS, and investigates the reliability of wireless-powered PAS\nto explore the advantages of PA in improving the performance of\nwireless-powered communication (WPC) system. In addition, we derive the\nclosed-form expressions of outage probability and ergodic rate for the\npractical lossy waveguide case and ideal lossless waveguide case, respectively,\nand analyze the optimal deployment of waveguides and user to provide valuable\ninsights for guiding their deployments. The results show that an increase in\nthe absorption coefficient and in the dimensions of the user area leads to\nhigher in-waveguide and free-space propagation losses, respectively, which in\nturn increase the outage probability and reduce the ergodic rate of the\nwireless-powered PAS. However, the performance of wireless-powered PAS is\nseverely affected by the absorption coefficient and the waveguide length, e.g.,\nunder conditions of high absorption coefficient and long waveguide, the outage\nprobability of wireless-powered PAS is even worse than that of traditional WPC\nsystem. While the ergodic rate of wireless-powered PAS is better than that of\ntraditional WPC system under conditions of high absorption coefficient and long\nwaveguide. Interestingly, the wireless-powered PAS has the optimal time\nallocation factor and optimal distance between power station (PS) and access\npoint (AP) to minimize the outage probability or maximize the ergodic rate.\nMoreover, the system performance of PS and AP separated at the optimal distance\nbetween PS and AP is superior to that of PS and AP integrated into a hybrid\naccess point."}
{"id": "2511.03465", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.03465", "abs": "https://arxiv.org/abs/2511.03465", "authors": ["Javier Giménez", "José A. Cortés", "Francisco Javier Cañete", "Eduardo Martos-Naya", "Luis Díez"], "title": "A Modified Pulse and Design Framework to Halve the Complexity of OFDM Spectral Shaping Techniques", "comment": "5 pages, 1 figure, journal paper", "summary": "Orthogonal frequency division multiplexing (OFDM) is a widespread modulation\nbut suffers from high out-of-band emissions (OOBE). Spectral shaping strategies\nsuch as precoding, active interference cancellation (AIC) and time-domain\nmethods are effective at reducing the OOBE but entail optimization procedures\nand real-time implementation costs which might be considerable. This letter\nproposes a modification of the conventional OFDM waveform aimed at reducing the\ncost associated to many of the state-of-theart spectral shaping techniques and\nsets a framework for future works that want to benefit from the same reduction.\nThis approach may reduce both the number of coefficients involved in the\noptimization and the number of products of its implementation by up to 50%."}
{"id": "2511.03487", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.03487", "abs": "https://arxiv.org/abs/2511.03487", "authors": ["Yameng Liu", "Jianhua Zhang", "Yuxiang Zhang", "Zhiqiang Yuan", "Chuangxin Jiang", "Junchen Liu", "Wei Hong", "Yingyang Li", "Yan Li", "Guangyi Liu"], "title": "A Novel Multi-Reference-Point Modeling Framework for Monostatic Background Channel: Toward 3GPP ISAC Standardization", "comment": null, "summary": "Integrated Sensing and Communication (ISAC) has been identified as a key 6G\napplication by ITU and 3GPP. A realistic, standard-compatible channel model is\nessential for ISAC system design. To characterize the impact of Sensing Targets\n(STs), 3GPP defines ISAC channel as a combination of target and background\nchannels, comprising multipath components related to STs and those originating\nsolely from the environment, respectively. Although the background channel does\nnot carry direct ST information, its accurate modeling is critical for\nevaluating sensing performance, especially in complex environments. Existing\ncommunication standards characterize propagation between separated transmitter\n(Tx) and receiver (Rx). However, modeling background channels in the ISAC\nmonostatic mode, where the Tx and Rx are co-located, remains a pressing\nchallenge. In this paper, we firstly conduct ISAC monostatic background channel\nmeasurements for an indoor scenario at 28 GHz. Realistic channel parameters are\nextracted, revealing pronounced single-hop propagation and discrete multipath\ndistribution. Inspired by these properties, a novel stochastic model is\nproposed to characterizing the ISAC monostatic background channel as the\nsuperposition of sub-channels between the monostatic Tx&Rx and multiple\ncommunication Rx-like Reference Points (RPs). This model is compatible with\nstandardizations, and a 3GPP-extended implementation framework is introduced.\nFinally, a genetic algorithm-based method is proposed to extract the optimal\nnumber and placement of multi-RPs. The optimization approach and modeling\nframework are validated by comparing measured and simulated channel parameters.\nResults demonstrate that the proposed model effectively captures monostatic\nbackground channel characteristics, addresses a critical gap in ISAC channel\nmodeling, and supports 6G standardization."}
{"id": "2511.03612", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.03612", "abs": "https://arxiv.org/abs/2511.03612", "authors": ["Yingjie Xu", "Xuesong Cai", "Michiel Sandra", "Sara Willhammar", "Fredrik Tufvesson"], "title": "3D Cooperative User Tracking for Distributed Integrated Sensing and Communication", "comment": null, "summary": "As integrated sensing and communication (ISAC) becomes an integral part of 6G\nnetworks, distributed ISAC (DISAC) is expected to enhance both sensing and\ncommunication performance through its decentralized architecture. This paper\npresents a complete framework to address the challenge of cooperative user\ntracking in DISAC systems. By incorporating a global probability hypothesis\ndensity (PHD) filter and a field-of-view-aware access point (AP) management\nstrategy, the framework enables accurate user tracking using radio signals\nwhile optimizing AP scheduling. In addition, a real-world distributed MIMO\nchannel measurement campaign is performed to evaluate the effectiveness of the\nframework. The results demonstrate that a centimeter-level root mean-square\ntrajectory error can be achieved. Furthermore, the results show that it is not\nnecessary to keep APs active at all times to maintain high tracking accuracy,\nindicating the need for robust and efficient AP management. These findings\nprovide valuable insight into practical deployments and further development of\ncooperative user tracking techniques in DISAC systems."}
