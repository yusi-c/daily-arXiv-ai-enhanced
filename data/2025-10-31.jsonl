{"id": "2510.25936", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.25936", "abs": "https://arxiv.org/abs/2510.25936", "authors": ["Sen Yan", "Tianyu Hu", "Brahim Mefgouda", "Samson Lasaulce", "Merouane Debbah"], "title": "Reading Radio from Camera: Visually-Grounded, Lightweight, and Interpretable RSSI Prediction", "comment": "submitted to an IEEE conference", "summary": "Accurate, real-time wireless signal prediction is essential for\nnext-generation networks. However, existing vision-based frameworks often rely\non computationally intensive models and are also sensitive to environmental\ninterference. To overcome these limitations, we propose a novel, physics-guided\nand light-weighted framework that predicts the received signal strength\nindicator (RSSI) from camera images. By decomposing RSSI into its physically\ninterpretable components, path loss and shadow fading, we significantly reduce\nthe model's learning difficulty and exhibit interpretability. Our approach\nestablishes a new state-of-the-art by demonstrating exceptional robustness to\nenvironmental interference, a critical flaw in prior work. Quantitatively, our\nmodel reduces the prediction root mean squared error (RMSE) by 50.3% under\nconventional conditions and still achieves an 11.5% lower RMSE than the\nprevious benchmark's interference-eliminated results. This superior performance\nis achieved with a remarkably lightweight framework, utilizing a\nMobileNet-based model up to 19 times smaller than competing solutions. The\ncombination of high accuracy, robustness to interference, and computational\nefficiency makes our framework highly suitable for real-time, on-device\ndeployment in edge devices, paving the way for more intelligent and reliable\nwireless communication systems."}
{"id": "2510.26093", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.26093", "abs": "https://arxiv.org/abs/2510.26093", "authors": ["Qianchao Wang", "Chuanzhen Jia", "Yuxuan Ding", "Zhe Li", "Yaping Du"], "title": "Lightweight Ac Arc Fault Diagnosis via Fourier Transform Inspired Multi-frequency Neural Network", "comment": null, "summary": "Lightweight online detection of series arc faults is critically needed in\nresidential and industrial power systems to prevent electrical fires. Existing\ndiagnostic methods struggle to achieve both rapid response and robust accuracy\nunder resource-constrained conditions. To overcome the challenge, this work\nsuggests leveraging a multi-frequency neural network named MFNN, embedding\nprior physical knowledge into the network. Inspired by arcing current curve and\nthe Fourier decomposition analysis, we create an adaptive activation function\nwith super-expressiveness, termed EAS, and a novel network architecture with\nbranch networks to help MFNN extract features with multiple frequencies. In our\nexperiments, eight advanced arc fault diagnosis models across an experimental\ndataset with multiple sampling times and multi-level noise are used to\ndemonstrate the superiority of MFNN. The corresponding experiments show: 1) The\nMFNN outperforms other models in arc fault location, befitting from signal\ndecomposition of branch networks. 2) The noise immunity of MFNN is much better\nthan that of other models, achieving 14.51% over LCNN and 16.3% over BLS in\ntest accuracy when SNR=-9. 3) EAS and the network architecture contribute to\nthe excellent performance of MFNN."}
{"id": "2510.26097", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.26097", "abs": "https://arxiv.org/abs/2510.26097", "authors": ["Usman Akram", "Fan Zhang", "Yang Li", "Haris Vikalo"], "title": "Robust Super-Capacity SRS Channel Inpainting via Diffusion Models", "comment": null, "summary": "Accurate channel state information (CSI) is essential for reliable multiuser\nMIMO operation. In 5G NR, reciprocity-based beamforming via uplink Sounding\nReference Signals (SRS) face resource and coverage constraints, motivating\nsparse non-uniform SRS allocation. Prior masked-autoencoder (MAE) approaches\nimprove coverage but overfit to training masks and degrade under unseen\ndistortions (e.g., additional masking, interference, clipping, non-Gaussian\nnoise). We propose a diffusion-based channel inpainting framework that\nintegrates system-model knowledge at inference via a likelihood-gradient term,\nenabling a single trained model to adapt across mismatched conditions. On\nstandardized CDL channels, the score-based diffusion variant consistently\noutperforms a UNet score-model baseline and the one-step MAE under distribution\nshift, with improvements up to 14 dB NMSE in challenging settings (e.g.,\nLaplace noise, user interference), while retaining competitive accuracy under\nmatched conditions. These results demonstrate that diffusion-guided inpainting\nis a robust and generalizable approach for super-capacity SRS design in 5G NR\nsystems."}
{"id": "2510.26022", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.26022", "abs": "https://arxiv.org/abs/2510.26022", "authors": ["Xinqi Li", "Yi Zhang", "Li-Ting Huang", "Hsiao-Huang Chang", "Thoralf Niendorf", "Min-Chi Ku", "Qian Tao", "Hsin-Jung Yang"], "title": "Groupwise Registration with Physics-Informed Test-Time Adaptation on Multi-parametric Cardiac MRI", "comment": null, "summary": "Multiparametric mapping MRI has become a viable tool for myocardial tissue\ncharacterization. However, misalignment between multiparametric maps makes\npixel-wise analysis challenging. To address this challenge, we developed a\ngeneralizable physics-informed deep-learning model using test-time adaptation\nto enable group image registration across contrast weighted images acquired\nfrom multiple physical models (e.g., a T1 mapping model and T2 mapping model).\nThe physics-informed adaptation utilized the synthetic images from specific\nphysics model as registration reference, allows for transductive learning for\nvarious tissue contrast. We validated the model in healthy volunteers with\nvarious MRI sequences, demonstrating its improvement for multi-modal\nregistration with a wide range of image contrast variability."}
{"id": "2510.26150", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.26150", "abs": "https://arxiv.org/abs/2510.26150", "authors": ["Jiaying Di", "Kunlun Wang", "Jing Xu", "Wen Chen", "Dusit Niyato"], "title": "Virtual-Real Collaborated Split Learning via Model Partitioning in IRS-Assisted IoT Networks", "comment": null, "summary": "This paper investigates a novel computation and communication co-design\nframework for large-scale split learning in intelligent reflecting surface\n(IRS)-assisted internet of things (IoT) networks integrated with digital twin\n(DT) technique. The considered system consists of a multi-antenna access point\n(AP), multiple heterogeneous user devices (UDs), and an deployed IRS to enhance\nboth uplink and downlink transmission. The training process of a deep neural\nnetwork is partitioned between devices and the AP, where a DT replica is\nactivated to replace UDs with insufficient local computation capabilities. We\nformulate a delay-optimal split learning problem, which optimizes five key\nvariables: layer partitioning points, DT assignment decisions, IRS phase shift\nmatrix, AP downlink power allocation, and DT frequency adjustment, aiming to\nminimize the overall end-to-end delay under communication and computation. The\nproposed optimization problem is a highly coupled non-convex mixed-integer\nproblem. Therefore, we solve using an alternating optimization approach\ncombining closed-form updates, semidefinite relaxation (SDR), and\nlow-complexity heuristics. Extensive simulations demonstrate that the proposed\nscheme significantly reduces training delay compared to conventional baselines\nand achieves up to 35\\% delay improvement, especially under high UD density and\nstringent power constraints."}
{"id": "2510.26120", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2510.26120", "abs": "https://arxiv.org/abs/2510.26120", "authors": ["Yashaswini", "Sanjay Ghosh"], "title": "Functional Connectome Fingerprinting Using Convolutional and Dictionary Learning", "comment": "10 pages, 4 tables, and 11 figures", "summary": "Advances in data analysis and machine learning have revolutionized the study\nof brain signatures using fMRI, enabling non-invasive exploration of cognition\nand behavior through individual neural patterns. Functional connectivity (FC),\nwhich quantifies statistical relationships between brain regions, has emerged\nas a key metric for studying individual variability and developing biomarkers\nfor personalized medicine in neurological and psychiatric disorders. The\nconcept of subject fingerprinting, introduced by Finn et al. (2015), leverages\nneural connectivity variability to identify individuals based on their unique\npatterns. While traditional FC methods perform well on small datasets, machine\nlearning techniques are more effective with larger datasets, isolating\nindividual-specific features and maximizing inter-subject differences. In this\nstudy, we propose a framework combining convolutional autoencoders and sparse\ndictionary learning to enhance fingerprint accuracy. Autoencoders capture\nshared connectivity patterns while isolating subject-specific features in\nresidual FC matrices, which are analyzed using sparse coding to identify\ndistinctive features. Tested on the Human Connectome Project dataset, this\napproach achieved a 10% improvement over baseline group-averaged FC models. Our\nresults highlight the potential of integrating deep learning and sparse coding\ntechniques for scalable and robust functional connectome fingerprinting,\nadvancing personalized neuroscience applications and biomarker development."}
{"id": "2510.26166", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.26166", "abs": "https://arxiv.org/abs/2510.26166", "authors": ["Juncong Zhou", "Chao Hu", "Guanlin Wu", "Zixiang Ren", "Han Hu", "Juyong Zhang", "Rui Zhang", "Jie Xu"], "title": "6D Channel Knowledge Map Construction via Bidirectional Wireless Gaussian Splatting", "comment": null, "summary": "This paper investigates the construction of channel knowledge map (CKM) from\nsparse channel measurements. Dif ferent from conventional\ntwo-/three-dimensional (2D/3D) CKM approaches assuming fixed base station\nconfigurations, we present a six-dimensional (6D) CKM framework named\nbidirectional wireless Gaussian splatting (BiWGS), which is capable of mod\neling wireless channels across dynamic transmitter (Tx) and receiver (Rx)\npositions in 3D space. BiWGS uses Gaussian el lipsoids to represent virtual\nscatterer clusters and environmental obstacles in the wireless environment. By\nproperly learning the bidirectional scattering patterns and complex attenuation\nprofiles based on channel measurements, these ellipsoids inherently cap ture\nthe electromagnetic transmission characteristics of wireless environments,\nthereby accurately modeling signal transmission under varying transceiver\nconfigurations. Experiment results show that BiWGS significantly outperforms\nclassic multi-layer perception (MLP) for the construction of 6D channel power\ngain map with varying Tx-Rx positions, and achieves spatial spectrum prediction\naccuracy comparable to the state-of-the art wireless radiation field Gaussian\nsplatting (WRF-GS) for 3D CKM construction. This validates the capability of\nthe proposed BiWGS in accomplishing dimensional expansion of 6D CKM\nconstruction, without compromising fidelity."}
{"id": "2510.26225", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2510.26225", "abs": "https://arxiv.org/abs/2510.26225", "authors": ["Haoshuo Zhang", "Yufei Bo", "Jianhua Mo", "Meixia Tao"], "title": "BitSemCom: A Bit-Level Semantic Communication Framework with Learnable Probabilistic Mapping", "comment": null, "summary": "Most existing semantic communication systems employ analog modulation, which\nis incompatible with modern digital communication systems. Although several\ndigital transmission approaches have been proposed to address this issue, an\nend-to-end bit-level method that is compatible with arbitrary modulation\nformats, robust to channel noise, and free from quantization errors remains\nlacking. To this end, we propose BitSemCom, a novel bit-level semantic\ncommunication framework that realizes true joint source-channel coding (JSCC)\nat the bit level. Specifically, we introduce a modular learnable bit mapper\nthat establishes a probabilistic mapping between continuous semantic features\nand discrete bits, utilizing the Gumbel-Softmax trick to enable differentiable\nbit generation. Simulation results on image transmission demonstrate that\nBitSemCom achieves both competitive performance and superior robustness\ncompared to traditional separate source-channel coding (SSCC) schemes, and\noutperforms deep learning based JSCC with uniform 1-bit quantization,\nvalidating the effectiveness of the learnable bit mapper. Despite these\nimprovements, the bit mapper adds only 0.42% parameters and 0.09% computational\ncomplexity, making BitSemCom a lightweight and practical solution for\nreal-world semantic communication."}
{"id": "2510.26245", "categories": ["eess.SP", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.26245", "abs": "https://arxiv.org/abs/2510.26245", "authors": ["Juyeop Kim", "Hyejin Shin", "Sohee Kim", "Ilmu Byun"], "title": "Design of Orthogonal Phase of Arrival Positioning Scheme Based on 5G PRS and Optimization of TOA Performance", "comment": null, "summary": "This study analyzes the performance of positioning techniques based on\nconfiguration changes of 5G New Radio signals. In 5G networks, a terminal\nposition is determined from the Time of Arrival of Positioning Reference\nSignals transmitted by base stations. We propose an algorithm that improves TOA\naccuracy under low sampling rate constraints and implement 5G PRS for\npositioning in a software defined modem. We also examine how flexible time\nfrequency resource allocation of PRS affects TOA estimation accuracy and\ndiscuss optimal PRS configurations for a given signal environment."}
{"id": "2510.26390", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.26390", "abs": "https://arxiv.org/abs/2510.26390", "authors": ["Xizhi Tian", "Changjun Zhou", "Yulin. Yang"], "title": "SPG-CDENet: Spatial Prior-Guided Cross Dual Encoder Network for Multi-Organ Segmentation", "comment": null, "summary": "Multi-organ segmentation is a critical task in computer-aided diagnosis.\nWhile recent deep learning methods have achieved remarkable success in image\nsegmentation, huge variations in organ size and shape challenge their\neffectiveness in multi-organ segmentation. To address these challenges, we\npropose a Spatial Prior-Guided Cross Dual Encoder Network (SPG-CDENet), a novel\ntwo-stage segmentation paradigm designed to improve multi-organ segmentation\naccuracy. Our SPG-CDENet consists of two key components: a spatial prior\nnetwork and a cross dual encoder network. The prior network generates coarse\nlocalization maps that delineate the approximate ROI, serving as spatial\nguidance for the dual encoder network. The cross dual encoder network comprises\nfour essential components: a global encoder, a local encoder, a symmetric\ncross-attention module, and a flow-based decoder. The global encoder captures\nglobal semantic features from the entire image, while the local encoder focuses\non features from the prior network. To enhance the interaction between the\nglobal and local encoders, a symmetric cross-attention module is proposed\nacross all layers of the encoders to fuse and refine features. Furthermore, the\nflow-based decoder directly propagates high-level semantic features from the\nfinal encoder layer to all decoder layers, maximizing feature preservation and\nutilization. Extensive qualitative and quantitative experiments on two public\ndatasets demonstrate the superior performance of SPG-CDENet compared to\nexisting segmentation methods. Furthermore, ablation studies further validate\nthe effectiveness of the proposed modules in improving segmentation accuracy."}
{"id": "2510.26262", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.26262", "abs": "https://arxiv.org/abs/2510.26262", "authors": ["Francesco Verde", "Donatella Darsena", "Marco Di Renzo", "Vincenzo Galdi"], "title": "Optimal transmit field distribution for partially obstructed continuous radiating surfaces in near-field communication systems", "comment": "5 pages, 5 figures, conference", "summary": "This paper deals with the optimal synthesis of aperture fields for\n(radiating) near-field communications in obstructed environments. A physically\nconsistent model based on knife-edge diffraction is used to formulate the\nproblem as a maximization in Hilbert space. The optimal solution is obtained as\na matched filter that ``matches\" the shape of a diffraction-induced kernel,\nthus linking wave propagation with signal processing methods. The framework\nsupports hardware implementation using continuous apertures such as\nmetasurfaces or lens antennas. This approach bridges physically grounded\nmodeling, signal processing, and hardware design for efficient energy focusing\nin near-field obstructed channels."}
{"id": "2510.26573", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.26573", "abs": "https://arxiv.org/abs/2510.26573", "authors": ["Wondimagegn Abebe Demissie", "Stefano Roccella", "Rudy Rossetto", "Antonio Minnocci", "Andrea Vannini", "Luca Sebastiani"], "title": "Comparative Analysis of Deep Learning Models for Olive Tree Crown and Shadow Segmentation Towards Biovolume Estimation", "comment": "6 pages, 2025 IEEE International Workshop on Metrology for\n  Agriculture and Forestry (MetroAgriFor)", "summary": "Olive tree biovolume estimation is a key task in precision agriculture,\nsupporting yield prediction and resource management, especially in\nMediterranean regions severely impacted by climate-induced stress. This study\npresents a comparative analysis of three deep learning models U-Net,\nYOLOv11m-seg, and Mask RCNN for segmenting olive tree crowns and their shadows\nin ultra-high resolution UAV imagery. The UAV dataset, acquired over\nVicopisano, Italy, includes manually annotated crown and shadow masks. Building\non these annotations, the methodology emphasizes spatial feature extraction and\nrobust segmentation; per-tree biovolume is then estimated by combining crown\nprojected area with shadow-derived height using solar geometry. In testing,\nMask R-CNN achieved the best overall accuracy (F1 = 0.86; mIoU = 0.72), while\nYOLOv11m-seg provided the fastest throughput (0.12 second per image). The\nestimated biovolumes spanned from approximately 4 to 24 cubic meters,\nreflecting clear structural differences among trees. These results indicate\nMask R-CNN is preferable when biovolume accuracy is paramount, whereas\nYOLOv11m-seg suits large-area deployments where speed is critical; U-Net\nremains a lightweight, high-sensitivity option. The framework enables accurate,\nscalable orchard monitoring and can be further strengthened with DEM or DSM\nintegration and field calibration for operational decision support."}
{"id": "2510.26340", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.26340", "abs": "https://arxiv.org/abs/2510.26340", "authors": ["Shih-Kai Chou", "Mengran Zhao", "Cheng-Nan Hu", "Kuang-Chung Chou", "Carolina Fortuna", "Jernej Hribar"], "title": "SABER: Symbolic Regression-based Angle of Arrival and Beam Pattern Estimator", "comment": "12 pages, 11 figures", "summary": "Accurate Angle-of-arrival (AoA) estimation is essential for next-generation\nwireless communication systems to enable reliable beamforming, high-precision\nlocalization, and integrated sensing. Unfortunately, classical high-resolution\ntechniques require multi-element arrays and extensive snapshot collection,\nwhile generic Machine Learning (ML) approaches often yield black-box models\nthat lack physical interpretability. To address these limitations, we propose a\nSymbolic Regression (SR)-based ML framework. Namely, Symbolic Regression-based\nAngle of Arrival and Beam Pattern Estimator (SABER), a constrained\nsymbolic-regression framework that automatically discovers closed-form beam\npattern and AoA models from path loss measurements with interpretability. SABER\nachieves high accuracy while bridging the gap between opaque ML methods and\ninterpretable physics-driven estimators. First, we validate our approach in a\ncontrolled free-space anechoic chamber, showing that both direct inversion of\nthe known $\\cos^n$ beam and a low-order polynomial surrogate achieve sub-0.5\ndegree Mean Absolute Error (MAE). A purely unconstrained SR method can further\nreduce the error of the predicted angles, but produces complex formulas that\nlack physical insight. Then, we implement the same SR-learned inversions in a\nreal-world, Reconfigurable Intelligent Surface (RIS)-aided indoor testbed.\nSABER and unconstrained SR models accurately recover the true AoA with\nnear-zero error. Finally, we benchmark SABER against the Cram\\'er-Rao Lower\nBounds (CRLBs). Our results demonstrate that SABER is an interpretable and\naccurate alternative to state-of-the-art and black-box ML-based methods for AoA\nestimation."}
{"id": "2510.26635", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.26635", "abs": "https://arxiv.org/abs/2510.26635", "authors": ["Zhao Wang", "Wei Dai", "Thuy Thanh Dao", "Steffen Bollmann", "Hongfu Sun", "Craig Engstrom", "Shekhar S. Chandra"], "title": "SAMRI: Segment Anything Model for MRI", "comment": null, "summary": "Accurate magnetic resonance imaging (MRI) segmentation is crucial for\nclinical decision-making, but remains labor-intensive when performed manually.\nConvolutional neural network (CNN)-based methods can be accurate and efficient,\nbut often generalize poorly to MRI's variable contrast, intensity\ninhomogeneity, and protocols. Although the transformer-based Segment Anything\nModel (SAM) has demonstrated remarkable generalizability in natural images,\nexisting adaptations often treat MRI as another imaging modality, overlooking\nthese modality-specific challenges. We present SAMRI, an MRI-specialized SAM\ntrained and validated on 1.1 million labeled MR slices spanning whole-body\norgans and pathologies. We demonstrate that SAM can be effectively adapted to\nMRI by simply fine-tuning its mask decoder using a two-stage strategy, reducing\ntraining time by 94% and trainable parameters by 96% versus full-model\nretraining. Across diverse MRI segmentation tasks, SAMRI achieves a mean Dice\nof 0.87, delivering state-of-the-art accuracy across anatomical regions and\nrobust generalization on unseen structures, particularly small and clinically\nimportant structures."}
{"id": "2510.26532", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.26532", "abs": "https://arxiv.org/abs/2510.26532", "authors": ["Margarita Cabrera-Bean", "Josep Vidal", "Sergio Fernandez-Bertolin", "Albert Roso-Llorach", "Concepcion Violan"], "title": "HMM for short independent sequences: Multiple sequence Baum-Welch application", "comment": "18 pages Affiliation (1) Universitat Politecnica de Catalunya (UPC);\n  (2) IDIAP Jordi Gol", "summary": "In the classical setting, the training of a Hidden Markov Model (HMM)\ntypically relies on a single, sufficiently long observation sequence that can\nbe regarded as representative of the underlying stochastic process. In this\ncontext, the Expectation Maximization (EM) algorithm is applied in its\nspecialized form for HMMs, namely the Baum Welch algorithm, which has been\nextensively employed in applications such as speech recognition. The objective\nof this work is to present pseudocode formulations for both the training and\ndecoding procedures of HMMs in a different scenario, where the available data\nconsist of multiple independent temporal sequences generated by the same model,\neach of relatively short duration, i.e., containing only a limited number of\nsamples. Special emphasis is placed on the relevance of this formulation to\nlongitudinal studies in population health, where datasets are naturally\nstructured as collections of short trajectories across individuals with point\ndata at follow up."}
{"id": "2510.26661", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.26661", "abs": "https://arxiv.org/abs/2510.26661", "authors": ["Alya Almsouti", "Ainur Khamitova", "Darya Taratynova", "Mohammad Yaqub"], "title": "BRIQA: Balanced Reweighting in Image Quality Assessment of Pediatric Brain MRI", "comment": null, "summary": "Assessing the severity of artifacts in pediatric brain Magnetic Resonance\nImaging (MRI) is critical for diagnostic accuracy, especially in low-field\nsystems where the signal-to-noise ratio is reduced. Manual quality assessment\nis time-consuming and subjective, motivating the need for robust automated\nsolutions. In this work, we propose BRIQA (Balanced Reweighting in Image\nQuality Assessment), which addresses class imbalance in artifact severity\nlevels. BRIQA uses gradient-based loss reweighting to dynamically adjust\nper-class contributions and employs a rotating batching scheme to ensure\nconsistent exposure to underrepresented classes. Through experiments, no single\narchitecture performs best across all artifact types, emphasizing the\nimportance of architectural diversity. The rotating batching configuration\nimproves performance across metrics by promoting balanced learning when\ncombined with cross-entropy loss. BRIQA improves average macro F1 score from\n0.659 to 0.706, with notable gains in Noise (0.430), Zipper (0.098),\nPositioning (0.097), Contrast (0.217), Motion (0.022), and Banding (0.012)\nartifact severity classification. The code is available at\nhttps://github.com/BioMedIA-MBZUAI/BRIQA."}
{"id": "2510.26604", "categories": ["eess.SP", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.26604", "abs": "https://arxiv.org/abs/2510.26604", "authors": ["Shahab Moradi Torkashvand", "Arina Kharazi", "Emad Sadeghi", "Seyed Hossein Hesamedin Sadeghi", "Adel Nasiri"], "title": "Statistically Adaptive Differential Protection for AC Microgrids Based on Kullback-Leibler Divergence", "comment": null, "summary": "The proliferation of inverter-based resources challenges traditional\nmicrogrid protection by introducing variable fault currents and complex\ntransients. This paper presents a statistically adaptive differential\nprotection scheme based on Kullback-Leibler divergence, implemented via a\nBartlett-corrected G-statistic computed on logarithm-transformed current\nmagnitudes. The method is a multivariate fault detection engine that employs\nthe Mahalanobis distance to distinguish healthy and faulty states, enabling\nrobust detection even in noisy environments. Detection thresholds are\nstatistically derived from a chi-squared distribution for precise control over\nthe false alarm rate. Upon detection, a lightweight classifier identifies the\nfault type by assessing per-phase G-statistics against dedicated thresholds,\nenhanced by a temporal persistence filter for security. Extensive simulations\non a modified CIGRE 14-bus microgrid show high efficacy: sub-cycle average\ndetection delays, high detection and classification accuracy across operating\nmodes, resilience to high-impedance faults up to 250 Ohms, tolerance to 10 ms\ncommunication delay, and noise levels down to a 20 dB signal-to-noise ratio.\nThese findings demonstrate a reproducible and computationally efficient\nsolution for next-generation AC microgrid protection."}
{"id": "2510.26703", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.26703", "abs": "https://arxiv.org/abs/2510.26703", "authors": ["Paul F. R. Wilson", "Mohamed Harmanani", "Minh Nguyen Nhat To", "Amoon Jamzad", "Tarek Elghareb", "Zhuoxin Guo", "Adam Kinnaird", "Brian Wodlinger", "Purang Abolmaesumi", "Parvin Mousavi"], "title": "ProstNFound+: A Prospective Study using Medical Foundation Models for Prostate Cancer Detection", "comment": null, "summary": "Purpose: Medical foundation models (FMs) offer a path to build\nhigh-performance diagnostic systems. However, their application to prostate\ncancer (PCa) detection from micro-ultrasound ({\\mu}US) remains untested in\nclinical settings. We present ProstNFound+, an adaptation of FMs for PCa\ndetection from {\\mu}US, along with its first prospective validation. Methods:\nProstNFound+ incorporates a medical FM, adapter tuning, and a custom prompt\nencoder that embeds PCa-specific clinical biomarkers. The model generates a\ncancer heatmap and a risk score for clinically significant PCa. Following\ntraining on multi-center retrospective data, the model is prospectively\nevaluated on data acquired five years later from a new clinical site. Model\npredictions are benchmarked against standard clinical scoring protocols\n(PRI-MUS and PI-RADS). Results: ProstNFound+ shows strong generalization to the\nprospective data, with no performance degradation compared to retrospective\nevaluation. It aligns closely with clinical scores and produces interpretable\nheatmaps consistent with biopsy-confirmed lesions. Conclusion: The results\nhighlight its potential for clinical deployment, offering a scalable and\ninterpretable alternative to expert-driven protocols."}
{"id": "2510.26756", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.26756", "abs": "https://arxiv.org/abs/2510.26756", "authors": ["Soujanya Hazra", "Sanjay Ghosh"], "title": "Graph Guided Modulo Recovery of EEG Signals", "comment": "5 pages, 1 figure, and 2 tables", "summary": "Electroencephalography (EEG) often shows significant variability among\npeople. This fluctuation disrupts reliable acquisition and may result in\ndistortion or clipping. Modulo sampling is now a promising solution to this\nproblem, by folding signals instead of saturating them. Recovery of the\noriginal waveform from folded observations is a highly ill-posed problem. In\nthis work, we propose a method based on a graph neural network, referred to as\nGraphUnwrapNet, for the modulo recovery of EEG signals. Our core idea is to\nrepresent an EEG signal as an organized graph whose channels and temporal\nconnections establish underlying interdependence. One of our key contributions\nis in introducing a pre-estimation guided feature injection module to provide\ncoarse folding indicators that enhance stability during recovery at wrap\nboundaries. This design integrates structural information with folding priors\ninto an integrated framework. We performed comprehensive experiments on the\nSimultaneous Task EEG Workload (STEW) dataset. The results demonstrate\nconsistent enhancements over traditional optimization techniques and\ncompetitive accuracy relative to current deep learning models. Our findings\nemphasize the potential of graph-based methodology for robust modulo EEG\nrecovery."}
{"id": "2510.26759", "categories": ["eess.IV", "cs.CV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2510.26759", "abs": "https://arxiv.org/abs/2510.26759", "authors": ["Shaokai Wu", "Yapan Guo", "Yanbiao Ji", "Jing Tong", "Yuxiang Lu", "Mei Li", "Suizhi Huang", "Yue Ding", "Hongtao Lu"], "title": "MORE: Multi-Organ Medical Image REconstruction Dataset", "comment": "Accepted to ACMMM 2025", "summary": "CT reconstruction provides radiologists with images for diagnosis and\ntreatment, yet current deep learning methods are typically limited to specific\nanatomies and datasets, hindering generalization ability to unseen anatomies\nand lesions. To address this, we introduce the Multi-Organ medical image\nREconstruction (MORE) dataset, comprising CT scans across 9 diverse anatomies\nwith 15 lesion types. This dataset serves two key purposes: (1) enabling robust\ntraining of deep learning models on extensive, heterogeneous data, and (2)\nfacilitating rigorous evaluation of model generalization for CT reconstruction.\nWe further establish a strong baseline solution that outperforms prior\napproaches under these challenging conditions. Our results demonstrate that:\n(1) a comprehensive dataset helps improve the generalization capability of\nmodels, and (2) optimization-based methods offer enhanced robustness for unseen\nanatomies. The MORE dataset is freely accessible under CC-BY-NC 4.0 at our\nproject page https://more-med.github.io/"}
