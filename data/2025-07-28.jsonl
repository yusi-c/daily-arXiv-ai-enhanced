{"id": "2507.18850", "categories": ["eess.IV", "physics.med-ph", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2507.18850", "abs": "https://arxiv.org/abs/2507.18850", "authors": ["Nicholas Dwork", "Jeremy W. Gordon", "Shuyu Tang", "Peder E. Z. Larson"], "title": "Estimating Sensitivity Maps for X-Nuclei Magnetic Resonance Spectroscopic Imaging", "comment": null, "summary": "The purpose of this research is to estimate sensitivity maps when imaging\nX-nuclei that may not have a significant presence throughout the field of view.\nWe propose to estimate the coil's sensitivities by solving a least-squares\nproblem where each row corresponds to an individual estimate of the sensitivity\nfor a given voxel. Multiple estimates come from the multiple bins of the\nspectrum with spectroscopy, multiple times with dynamic imaging, or multiple\nfrequencies when utilizing spectral excitation. The method presented in this\nmanuscript, called the L2 optimal method, is compared to the commonly used\nRefPeak method which uses the spectral bin with the highest energy to estimate\nthe sensitivity maps. The L2 optimal method yields more accurate sensitivity\nmaps when imaging a numerical phantom and is shown to yield a higher\nsignal-to-noise ratio when imaging the brain, pancreas, and heart with\nhyperpolarized pyruvate as the contrast agent with hyperpolarized MRI. The L2\noptimal method is able to better estimate the sensitivity by extracting more\ninformation from the measurements."}
{"id": "2507.19138", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.19138", "abs": "https://arxiv.org/abs/2507.19138", "authors": ["Weisong Zhao", "Jingkai Zhou", "Xiangyu Zhu", "Weihua Chen", "Xiao-Yu Zhang", "Zhen Lei", "Fan Wang"], "title": "RealisVSR: Detail-enhanced Diffusion for Real-World 4K Video Super-Resolution", "comment": null, "summary": "Video Super-Resolution (VSR) has achieved significant progress through\ndiffusion models, effectively addressing the over-smoothing issues inherent in\nGAN-based methods. Despite recent advances, three critical challenges persist\nin VSR community: 1) Inconsistent modeling of temporal dynamics in foundational\nmodels; 2) limited high-frequency detail recovery under complex real-world\ndegradations; and 3) insufficient evaluation of detail enhancement and 4K\nsuper-resolution, as current methods primarily rely on 720P datasets with\ninadequate details. To address these challenges, we propose RealisVSR, a\nhigh-frequency detail-enhanced video diffusion model with three core\ninnovations: 1) Consistency Preserved ControlNet (CPC) architecture integrated\nwith the Wan2.1 video diffusion to model the smooth and complex motions and\nsuppress artifacts; 2) High-Frequency Rectified Diffusion Loss (HR-Loss)\ncombining wavelet decomposition and HOG feature constraints for texture\nrestoration; 3) RealisVideo-4K, the first public 4K VSR benchmark containing\n1,000 high-definition video-text pairs. Leveraging the advanced spatio-temporal\nguidance of Wan2.1, our method requires only 5-25% of the training data volume\ncompared to existing approaches. Extensive experiments on VSR benchmarks (REDS,\nSPMCS, UDM10, YouTube-HQ, VideoLQ, RealisVideo-720P) demonstrate our\nsuperiority, particularly in ultra-high-resolution scenarios."}
{"id": "2507.19155", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2507.19155", "abs": "https://arxiv.org/abs/2507.19155", "authors": ["Michal K. Grzeszczyk", "Tomasz Szczepański", "Pawel Renc", "Siyeop Yoon", "Jerome Charton", "Tomasz Trzciński", "Arkadiusz Sitek"], "title": "RegScore: Scoring Systems for Regression Tasks", "comment": "Accepted for the 28th International Conference on Medical Image\n  Computing and Computer Assisted Intervention (MICCAI) 2025", "summary": "Scoring systems are widely adopted in medical applications for their inherent\nsimplicity and transparency, particularly for classification tasks involving\ntabular data. In this work, we introduce RegScore, a novel, sparse, and\ninterpretable scoring system specifically designed for regression tasks. Unlike\nconventional scoring systems constrained to integer-valued coefficients,\nRegScore leverages beam search and k-sparse ridge regression to relax these\nrestrictions, thus enhancing predictive performance. We extend RegScore to\nbimodal deep learning by integrating tabular data with medical images. We\nutilize the classification token from the TIP (Tabular Image Pretraining)\ntransformer to generate Personalized Linear Regression parameters and a\nPersonalized RegScore, enabling individualized scoring. We demonstrate the\neffectiveness of RegScore by estimating mean Pulmonary Artery Pressure using\ntabular data and further refine these estimates by incorporating cardiac MRI\nimages. Experimental results show that RegScore and its personalized bimodal\nextensions achieve performance comparable to, or better than, state-of-the-art\nblack-box models. Our method provides a transparent and interpretable approach\nfor regression tasks in clinical settings, promoting more informed and\ntrustworthy decision-making. We provide our code at\nhttps://github.com/SanoScience/RegScore."}
{"id": "2507.19165", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.19165", "abs": "https://arxiv.org/abs/2507.19165", "authors": ["Kang Wang", "Chen Qin", "Zhang Shi", "Haoran Wang", "Xiwen Zhang", "Chen Chen", "Cheng Ouyang", "Chengliang Dai", "Yuanhan Mo", "Chenchen Dai", "Xutong Kuang", "Ruizhe Li", "Xin Chen", "Xiuzheng Yue", "Song Tian", "Alejandro Mora-Rubio", "Kumaradevan Punithakumar", "Shizhan Gong", "Qi Dou", "Sina Amirrajab", "Yasmina Al Khalil", "Cian M. Scannell", "Lexiaozi Fan", "Huili Yang", "Xiaowu Sun", "Rob van der Geest", "Tewodros Weldebirhan Arega", "Fabrice Meriaudeau", "Caner Özer", "Amin Ranem", "John Kalkhof", "İlkay Öksüz", "Anirban Mukhopadhyay", "Abdul Qayyum", "Moona Mazher", "Steven A Niederer", "Carles Garcia-Cabrera", "Eric Arazo", "Michal K. Grzeszczyk", "Szymon Płotka", "Wanqin Ma", "Xiaomeng Li", "Rongjun Ge", "Yongqing Kou", "Xinrong Chen", "He Wang", "Chengyan Wang", "Wenjia Bai", "Shuo Wang"], "title": "Extreme Cardiac MRI Analysis under Respiratory Motion: Results of the CMRxMotion Challenge", "comment": null, "summary": "Deep learning models have achieved state-of-the-art performance in automated\nCardiac Magnetic Resonance (CMR) analysis. However, the efficacy of these\nmodels is highly dependent on the availability of high-quality, artifact-free\nimages. In clinical practice, CMR acquisitions are frequently degraded by\nrespiratory motion, yet the robustness of deep learning models against such\nartifacts remains an underexplored problem. To promote research in this domain,\nwe organized the MICCAI CMRxMotion challenge. We curated and publicly released\na dataset of 320 CMR cine series from 40 healthy volunteers who performed\nspecific breathing protocols to induce a controlled spectrum of motion\nartifacts. The challenge comprised two tasks: 1) automated image quality\nassessment to classify images based on motion severity, and 2) robust\nmyocardial segmentation in the presence of motion artifacts. A total of 22\nalgorithms were submitted and evaluated on the two designated tasks. This paper\npresents a comprehensive overview of the challenge design and dataset, reports\nthe evaluation results for the top-performing methods, and further investigates\nthe impact of motion artifacts on five clinically relevant biomarkers. All\nresources and code are publicly available at: https://github.com/CMRxMotion"}
{"id": "2507.18673", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.18673", "abs": "https://arxiv.org/abs/2507.18673", "authors": ["Morriel Kasher", "Michael Tinston", "Predrag Spasojevic"], "title": "Design and Implementation of Parametrized Look-Up Tables for Post-Correction of Oversampling Low-Resolution ADCs", "comment": "13 pages, 20 figures. arXiv admin note: text overlap with\n  arXiv:2507.18370", "summary": "We propose a framework for the design, optimization, and implementation of\nLook-Up Tables (LUTs) used to recover noisy, oversampled, quantized signals\ngiven a parametric input model. The LUTs emulate the spectral effects of\npre-quantization dithering through an all-digital solution applied after\nquantization. This methodology decomposes the intractable LUT design problem\ninto four distinct stages, each of which is addressed analytically using a\nmodel-driven approach without reliance on training. Three dithering methods are\nstudied to improve spectral purity metrics. Two novel indexing schemes are\nproposed to limit the LUT memory overhead shown to compress the LUT size by\nover four orders of magnitude with marginal performance loss. The LUT design is\ntested with an oversampled noisy sinusoidal input quantized to 3 bits and shown\nto improve its Spurious-Free Dynamic Range (SFDR) by over 19 dBc with only 324\nbytes of memory while maintaining the same 3-bit fixed-point precision at the\ndigital output. This correction can be implemented using two-level\ncombinational logic ensuring ultra-low latency and, hence, suitable for\nlow-resolution wideband devices."}
{"id": "2507.19199", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.19199", "abs": "https://arxiv.org/abs/2507.19199", "authors": ["Abdul Hannan", "Zahid Mahmood", "Rizwan Qureshi", "Hazrat Ali"], "title": "Enhancing Diabetic Retinopathy Classification Accuracy through Dual Attention Mechanism in Deep Learning", "comment": "submitted to Computer Methods in Biomechanics and Biomedical\n  Engineering: Imaging & Visualization", "summary": "Automatic classification of Diabetic Retinopathy (DR) can assist\nophthalmologists in devising personalized treatment plans, making it a critical\ncomponent of clinical practice. However, imbalanced data distribution in the\ndataset becomes a bottleneck in the generalization of deep learning models\ntrained for DR classification. In this work, we combine global attention block\n(GAB) and category attention block (CAB) into the deep learning model, thus\neffectively overcoming the imbalanced data distribution problem in DR\nclassification. Our proposed approach is based on an attention mechanism-based\ndeep learning model that employs three pre-trained networks, namely,\nMobileNetV3-small, Efficientnet-b0, and DenseNet-169 as the backbone\narchitecture. We evaluate the proposed method on two publicly available\ndatasets of retinal fundoscopy images for DR. Experimental results show that on\nthe APTOS dataset, the DenseNet-169 yielded 83.20% mean accuracy, followed by\nthe MobileNetV3-small and EfficientNet-b0, which yielded 82% and 80%\naccuracies, respectively. On the EYEPACS dataset, the EfficientNet-b0 yielded a\nmean accuracy of 80%, while the DenseNet-169 and MobileNetV3-small yielded\n75.43% and 76.68% accuracies, respectively. In addition, we also compute the\nF1-score of 82.0%, precision of 82.1%, sensitivity of 83.0%, specificity of\n95.5%, and a kappa score of 88.2% for the experiments. Moreover, in our work,\nthe MobileNetV3-small has 1.6 million parameters on the APTOS dataset and 0.90\nmillion parameters on the EYEPACS dataset, which is comparatively less than\nother methods. The proposed approach achieves competitive performance that is\nat par with recently reported works on DR classification."}
{"id": "2507.18730", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.18730", "abs": "https://arxiv.org/abs/2507.18730", "authors": ["Yufeng Zhou", "Wen Chen", "Qingqing Wu", "Xusheng Zhu", "Zhendong Li", "Kunlun Wang", "Qiong Wu"], "title": "Exploiting Movable Antennas in NOMA Networks: Joint Beamforming, Power Allocation and Antenna Position Optimization", "comment": null, "summary": "This paper investigates the movable antenna (MA)- assisted downlink\nnon-orthogonal multiple access (NOMA) network to maximize system throughput. In\nthe considered scenario, both the base station (BS) and users are equipped with\nMA, and a predetermined successive interference cancellation (SIC) decoding\norder is adopted. Based on the field-response channel model, we formulate a\ncomplex, non-convex problem to jointly optimize the BS beamforming, power\nallocation, and MA positions at both the transmitter and receivers. To address\nthis, we propose an efficient algorithm based on an alternating optimization\n(AO) framework, which decomposes the original problem into three distinct\nsubproblems. By employing sequential parametric convex approximation (SPCA) and\nsuccessive convex approximation (SCA) techniques, the non-convex constraints\nwithin each subproblem are transformed into tractable. This methodology ensures\nthe algorithm converges to a stable, locally optimal solution. Numerical\nresults validate that the proposed system, which fully exploits the degrees of\nfreedom from antenna mobility at both ends, significantly outperforms\nbenchmarks in terms of throughput."}
{"id": "2507.19282", "categories": ["eess.IV", "cs.CV", "physics.med-ph"], "pdf": "https://arxiv.org/pdf/2507.19282", "abs": "https://arxiv.org/abs/2507.19282", "authors": ["Guoping Xu", "Yan Dai", "Hengrui Zhao", "Ying Zhang", "Jie Deng", "Weiguo Lu", "You Zhang"], "title": "SAM2-Aug: Prior knowledge-based Augmentation for Target Volume Auto-Segmentation in Adaptive Radiation Therapy Using Segment Anything Model 2", "comment": "26 pages, 10 figures", "summary": "Purpose: Accurate tumor segmentation is vital for adaptive radiation therapy\n(ART) but remains time-consuming and user-dependent. Segment Anything Model 2\n(SAM2) shows promise for prompt-based segmentation but struggles with tumor\naccuracy. We propose prior knowledge-based augmentation strategies to enhance\nSAM2 for ART.\n  Methods: Two strategies were introduced to improve SAM2: (1) using prior MR\nimages and annotations as contextual inputs, and (2) improving prompt\nrobustness via random bounding box expansion and mask erosion/dilation. The\nresulting model, SAM2-Aug, was fine-tuned and tested on the One-Seq-Liver\ndataset (115 MRIs from 31 liver cancer patients), and evaluated without\nretraining on Mix-Seq-Abdomen (88 MRIs, 28 patients) and Mix-Seq-Brain (86\nMRIs, 37 patients).\n  Results: SAM2-Aug outperformed convolutional, transformer-based, and\nprompt-driven models across all datasets, achieving Dice scores of 0.86(liver),\n0.89(abdomen), and 0.90(brain). It demonstrated strong generalization across\ntumor types and imaging sequences, with improved performance in\nboundary-sensitive metrics.\n  Conclusions: Incorporating prior images and enhancing prompt diversity\nsignificantly boosts segmentation accuracy and generalizability. SAM2-Aug\noffers a robust, efficient solution for tumor segmentation in ART. Code and\nmodels will be released at https://github.com/apple1986/SAM2-Aug."}
{"id": "2507.18733", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.18733", "abs": "https://arxiv.org/abs/2507.18733", "authors": ["Yuan Guo", "Wen Chen", "Qingqing Wu", "Yanze Zhu", "Yang Liu", "Zhendong Li", "Ying Wang"], "title": "Max-Min Rate Optimization for Multigroup Multicast MISO Systems Via Novel Transmissive RIS Transceiver", "comment": null, "summary": "This paper investigates a novel transmissive reconfigurable intelligent\nsurface (RIS) transceiver architectureenabled multigroup multicast downlink\ncommunication system. Under this setup, an optimization problem is formulated\nto maximize the minimum rate of users across all groups, subject to the maximum\navailable power of each RIS unit. Due to the nondifferentiable nature of the\nobjective function, the max-min rate problem is challenging to solve. To tackle\nthis difficult problem, we develop an iterative solution by leveraging the\nsuccessive convex approximation (SCA) and the penalty function method. However,\nthe above approach has high computational complexity and may lead to\ncompromised performance. To overcome these drawbacks, we design an efficient\nsecond-order cone programming (SOCP)-based method using the weighted minimum\nmean squared error (WMMSE) framework to reduce computational complexity.\nFurthermore, to further reduce the computational complexity, we also propose a\nlow-complexity and solver-free algorithm that analytically updates all\nvariables by combining the smooth approximation theory and the\nmajorization-minimization (MM) method. Numerical results are provided to verify\nthe convergence and effectiveness of our proposed three algorithms. It is also\ndemonstrated that the SOCP-based method outperforms the penalty-based algorithm\nin terms of both the achieved min rate and the computational complexity. In\ncontrast, the lowcomplexity design achieves significantly lower complexity with\nonly slightly degraded performance."}
{"id": "2507.19404", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2507.19404", "abs": "https://arxiv.org/abs/2507.19404", "authors": ["Chong Chen", "Marc Vornehm", "Preethi Chandrasekaran", "Muhammad A. Sultan", "Syed M. Arshad", "Yingmin Liu", "Yuchi Han", "Rizwan Ahmad"], "title": "A multi-dynamic low-rank deep image prior (ML-DIP) for real-time 3D cardiovascular MRI", "comment": null, "summary": "Purpose: To develop a reconstruction framework for 3D real-time cine\ncardiovascular magnetic resonance (CMR) from highly undersampled data without\nrequiring fully sampled training data.\n  Methods: We developed a multi-dynamic low-rank deep image prior (ML-DIP)\nframework that models spatial image content and temporal deformation fields\nusing separate neural networks. These networks are optimized per scan to\nreconstruct the dynamic image series directly from undersampled k-space data.\nML-DIP was evaluated on (i) a 3D cine digital phantom with simulated premature\nventricular contractions (PVCs), (ii) ten healthy subjects (including two\nscanned during both rest and exercise), and (iii) five patients with PVCs.\nPhantom results were assessed using peak signal-to-noise ratio (PSNR) and\nstructural similarity index measure (SSIM). In vivo performance was evaluated\nby comparing left-ventricular function quantification (against 2D real-time\ncine) and image quality (against 2D real-time cine and binning-based 5D-Cine).\n  Results: In the phantom study, ML-DIP achieved PSNR > 29 dB and SSIM > 0.90\nfor scan times as short as two minutes, while recovering cardiac motion,\nrespiratory motion, and PVC events. In healthy subjects, ML-DIP yielded\nfunctional measurements comparable to 2D cine and higher image quality than\n5D-Cine, including during exercise with high heart rates and bulk motion. In\nPVC patients, ML-DIP preserved beat-to-beat variability and reconstructed\nirregular beats, whereas 5D-Cine showed motion artifacts and information loss\ndue to binning.\n  Conclusion: ML-DIP enables high-quality 3D real-time CMR with acceleration\nfactors exceeding 1,000 by learning low-rank spatial and temporal\nrepresentations from undersampled data, without relying on external fully\nsampled training datasets."}
{"id": "2507.18764", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.18764", "abs": "https://arxiv.org/abs/2507.18764", "authors": ["Parisa Kanani", "Mohammad Javad Omidi", "Mahmoud Modarres-Hashemi", "Halim Yanikomeroglu"], "title": "Max-Min Fairness-Oriented Beamforming Design in HAPS-Enabled ISAC for 6G Networks", "comment": null, "summary": "This paper presents a high-altitude platform station (HAPS)-enabled\nintegrated sensing and communication (ISAC) system designed for\nsixth-generation (6G) networks. Positioned in the stratosphere, HAPS serves as\na super-macro base station, leveraging advanced beamforming techniques to\nenable communication and sensing simultaneously. This research addresses the\nneed for equitable service distribution in 6G networks by focusing on fairness\nwithin the HAPS-ISAC system. It tackles a non-convex optimization problem that\nbalances sensing beampattern gain and signal-to-interference-plus-noise ratio\n(SINR) requirements among communication users (CUs) using a max-min fairness\napproach while adhering to power constraints. The proposed HAPS-ISAC framework\nensures efficient resource allocation, reliable coverage, and improved sensing\naccuracy. Simulation results validate the potential of HAPS-ISAC as a pivotal\nenabler for 6G networks and integrated communication-sensing systems."}
{"id": "2507.18793", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.18793", "abs": "https://arxiv.org/abs/2507.18793", "authors": ["Kuranage Roche Rayan Ranasinghe", "Jiancheng An", "Iván Alexander Morales Sandoval", "Hyeon Seok Rou", "Giuseppe Thadeu Freitas de Abreu", "Chau Yuen", "Mérouane Debbah"], "title": "Flexible Intelligent Metasurfaces in High-Mobility MIMO Integrated Sensing and Communications", "comment": "Submitted to an IEEE journal", "summary": "We propose a novel doubly-dispersive (DD) multiple-input multiple-output\n(MIMO) channel model incorporating flexible intelligent metasurfaces (FIMs),\nwhich is suitable for integrated sensing and communications (ISAC) in\nhigh-mobility scenarios. We then discuss how the proposed FIM-parameterized DD\n(FPDD) channel model can be applied in a logical manner to ISAC waveforms that\nare known to perform well in DD environments, namely, orthogonal frequency\ndivision multiplexing (OFDM), orthogonal time frequency space (OTFS), and\naffine frequency division multiplexing (AFDM). Leveraging the proposed model,\nwe formulate an achievable rate maximization problem with a strong sensing\nconstraint for all the aforementioned waveforms, which we then solve via a\ngradient ascent algorithm with closed-form gradients presented as a bonus. Our\nnumerical results indicate that the achievable rate is significantly impacted\nby the emerging FIM technology with careful parametrization essential in\nobtaining strong ISAC performance across all waveforms suitable to mitigating\nthe effects of DD channels."}
{"id": "2507.18927", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.18927", "abs": "https://arxiv.org/abs/2507.18927", "authors": ["Xin Cheng", "Yu He", "Menglu Li", "Ruoguang Li", "Feng Shu", "Guangjie Han"], "title": "A Fingerprint Database Generation Method for RIS-Assisted Indoor Positioning", "comment": null, "summary": "Reconfigurable intelligent surface (RIS) has emerged as a promising\ntechnology to enhance indoor wireless communication and sensing performance.\nHowever, the construction of reliable received signal strength (RSS)-based\nfingerprint databases for RIS-assisted indoor positioning remains an open\nchallenge due to the lack of realistic and spatially consistent channel\nmodeling methods. In this paper, we propose a novel method with open-source\ncodes for generating RIS-assisted RSS fingerprint databases. Our method\ncaptures the complex RIS-assisted multipath behaviors by extended cluster-based\nchannel modeling and the physical and electromagnetic properties of RIS and\ntransmitter (Tx). And the spatial consistency is incorporated when simulating\nthe fingerprint data collection across neighboring positions. Furthermore, the\nproposed method offers exceptional flexibility in configuring RIS and Tx\nparameters. Extensive simulations are conducted to evaluate the fingerprint\ndatabase generated by the proposed method. Moreover, the positioning\nperformance on the database using K-nearest neighbors (KNN) and deep neural\nnetwork (DNN) is analyzed, providing valuable insights for the system design."}
{"id": "2507.18943", "categories": ["eess.SP", "cs.RO"], "pdf": "https://arxiv.org/pdf/2507.18943", "abs": "https://arxiv.org/abs/2507.18943", "authors": ["Abishek Shrestha", "Damith Herath", "Angie Fearon", "Maryam Ghahramani"], "title": "Assessing the Reliability and Validity of a Balance Mat for Measuring Postural Stability: A Combined Robot-Human Approach", "comment": null, "summary": "Postural sway assessment is important for detecting balance problems and\nidentifying people at risk of falls. Force plates (FP) are considered the gold\nstandard postural sway assessment method in laboratory conditions, but their\nlack of portability and requirement of high-level expertise limit their\nwidespread usage. This study evaluates the reliability and validity of a novel\nBalance Mat (BM) device, a low-cost portable alternative that uses optical\nfibre technology. The research includes two studies: a robot study and a human\nstudy. In the robot study, a UR10 robotic arm was used to obtain controlled\nsway patterns to assess the reliability and sensitivity of the BM. In the human\nstudy, 51 healthy young participants performed balance tasks on the BM in\ncombination with an FP to evaluate the BM's validity. Sway metrics such as sway\nmean, sway absolute mean, sway root mean square (RMS), sway path, sway range,\nand sway velocity were calculated from both BM and FP and compared. Reliability\nwas evaluated using the intra-class correlation coefficient (ICC), where values\ngreater than 0.9 were considered excellent and values between 0.75 and 0.9 were\nconsidered good. Results from the robot study demonstrated good to excellent\nICC values in both single and double-leg stances. The human study showed\nmoderate to strong correlations for sway path and range. Using Bland-Altman\nplots for agreement analysis revealed proportional bias between the BM and the\nFP where the BM overestimated sway metrics compared to the FP. Calibration was\nused to improve the agreement between the devices. The device demonstrated\nconsistent sway measurement across varied stance conditions, establishing both\nreliability and validity following appropriate calibration."}
{"id": "2507.18980", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.18980", "abs": "https://arxiv.org/abs/2507.18980", "authors": ["Bin Wang", "Jun Fang", "Yue Xiao", "Martin Haardt"], "title": "Max-Min Beamforming for Large-Scale Cell-Free Massive MIMO: A Randomized ADMM Algorithm", "comment": null, "summary": "We consider the problem of max-min beamforming (MMB) for cell-free massive\nmulti-input multi-output (MIMO) systems, where the objective is to maximize the\nminimum achievable rate among all users. Existing MMB methods are mainly based\non deterministic optimization methods, which are computationally inefficient\nwhen the problem size grows large. To address this issue, we, in this paper,\npropose a randomized alternating direction method of multiplier (ADMM)\nalgorithm for large-scale MMB problems. We first propose a novel formulation\nthat transforms the highly challenging feasibility-checking problem into a\nlinearly constrained optimization problem. An efficient randomized ADMM is then\ndeveloped for solving the linearly constrained problem. Unlike standard ADMM,\nrandomized ADMM only needs to solve a small number of subproblems at each\niteration to ensure convergence, thus achieving a substantial complexity\nreduction. Our theoretical analysis reveals that the proposed algorithm\nexhibits an O(1/\\bar{t}) convergence rate (\\bar{t} represents the number of\niterations), which is on the same order as its deterministic counterpart.\nNumerical results show that the proposed algorithm offers a significant\ncomplexity advantage over existing methods in solving the MMB problem."}
{"id": "2507.19149", "categories": ["eess.SP", "I.2.6; C.2.1; C.2.3; C.4"], "pdf": "https://arxiv.org/pdf/2507.19149", "abs": "https://arxiv.org/abs/2507.19149", "authors": ["Helena Serpi", "Christina", "Politi"], "title": "Machine Learning based Radio Environment Map Estimation for Indoor Visible Light Communication", "comment": "10 pages, 10 figures", "summary": "An innovative method for radio map estimation in optical wireless\ncommunications is proposed that is based on Machine Learning rather than\nsimulation techniques. Multi-Layer Perceptron (MLP) representation of indoor\nVisible Light Communication (VLC) systems is suggested, and signal propagation\nis estimated. The simulation and performance predictions are accurate, fast and\nrequire a reduced set of training sample size with respect to other\ncounterparts, making this solution very suitable for real time estimation of an\nindoor VLC system. It is shown that by tweaking MLP parameters, such as sample\nsize, number of epochs and batch size, one can balance the desired level of\ninference accuracy with training time and optimize the model's performance to\nmeet real-time requirements."}
{"id": "2507.19173", "categories": ["eess.SP", "cs.NI"], "pdf": "https://arxiv.org/pdf/2507.19173", "abs": "https://arxiv.org/abs/2507.19173", "authors": ["Lorenzo Cazzella", "Francesco Linsalata", "Damiano Badini", "Matteo Matteucci", "Maurizio Magarini", "Umberto Spagnolini"], "title": "High-Fidelity RF Mapping: Assessing Environmental Modeling in 6G Network Digital Twins", "comment": null, "summary": "The design of accurate Digital Twins (DTs) of electromagnetic environments\nstrictly depends on the fidelity of the underlying environmental modeling.\nEvaluating the differences among diverse levels of modeling accuracy is key to\ndetermine the relevance of the model features towards both efficient and\naccurate DT simulations. In this paper, we propose two metrics, the Hausdorff\nray tracing (HRT) and chamfer ray tracing (CRT) distances, to consistently\ncompare the temporal, angular and power features between two ray tracing\nsimulations performed on 3D scenarios featured by environmental changes. To\nevaluate the introduced metrics, we considered a high-fidelity digital twin\nmodel of an area of Milan, Italy and we enriched it with two different types of\nenvironmental changes: (i) the inclusion of parked vehicles meshes, and (ii)\nthe segmentation of the buildings facade faces to separate the windows mesh\ncomponents from the rest of the building. We performed grid-based and vehicular\nray tracing simulations at 28 GHz carrier frequency on the obtained scenarios\nintegrating the NVIDIA Sionna RT ray tracing simulator with the SUMO vehicular\ntraffic simulator. Both the HRT and CRT metrics highlighted the areas of the\nscenarios where the simulated radio propagation features differ owing to the\nintroduced mesh integrations, while the vehicular ray tracing simulations\nallowed to uncover the distance patterns arising along realistic vehicular\ntrajectories."}
{"id": "2507.19181", "categories": ["eess.SP", "cs.DM", "cs.IT", "cs.LG", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.19181", "abs": "https://arxiv.org/abs/2507.19181", "authors": ["Giacomo Elefante", "Gianluca Giacchi", "Michael Multerer", "Jacopo Quizi"], "title": "Bespoke multiresolution analysis of graph signals", "comment": null, "summary": "We present a novel framework for discrete multiresolution analysis of graph\nsignals. The main analytical tool is the samplet transform, originally defined\nin the Euclidean framework as a discrete wavelet-like construction, tailored to\nthe analysis of scattered data. The first contribution of this work is defining\nsamplets on graphs. To this end, we subdivide the graph into a fixed number of\npatches, embed each patch into a Euclidean space, where we construct samplets,\nand eventually pull the construction back to the graph. This ensures\northogonality, locality, and the vanishing moments property with respect to\nproperly defined polynomial spaces on graphs. Compared to classical Haar\nwavelets, this framework broadens the class of graph signals that can\nefficiently be compressed and analyzed. Along this line, we provide a\ndefinition of a class of signals that can be compressed using our construction.\nWe support our findings with different examples of signals defined on graphs\nwhose vertices lie on smooth manifolds. For efficient numerical implementation,\nwe combine heavy edge clustering, to partition the graph into meaningful\npatches, with landmark \\texttt{Isomap}, which provides low-dimensional\nembeddings for each patch. Our results demonstrate the method's robustness,\nscalability, and ability to yield sparse representations with controllable\napproximation error, significantly outperforming traditional Haar wavelet\napproaches in terms of compression efficiency and multiresolution fidelity."}
{"id": "2507.19327", "categories": ["eess.SP", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.19327", "abs": "https://arxiv.org/abs/2507.19327", "authors": ["Niklas Dieckow", "Katharina Ostaszewski", "Philip Heinisch", "Henriette Struckmann", "Hendrik Ranocha"], "title": "Real-time rail vehicle localisation using spatially resolved magnetic field measurements", "comment": null, "summary": "This work presents two complementary real-time rail vehicle localization\nmethods based on magnetic field measurements and a pre-recorded magnetic map.\nThe first uses a particle filter reweighted via magnetic similarity, employing\na heavy-tailed non-Gaussian kernel for enhanced stability. The second is a\nstateless sequence alignment technique that transforms real-time magnetic\nsignals into the spatial domain and matches them to the map using a similarity\nmeasure. Experiments with operational train data show that the particle filter\nachieves track-selective, sub-5-meter accuracy over 21.6 km, though its\nperformance degrades at low speeds and during cold starts. Accuracy tests were\nconstrained by the GNSS-based reference system. In contrast, the\nalignment-based method excels in cold-start scenarios, localizing within 30 m\nin 92 % of tests (100 % using top-3 matches). A hybrid approach combines both\nmethods$\\unicode{x2014}$alignment-based initialization followed by particle\nfilter tracking. Runtime analysis confirms real-time capability on\nconsumer-grade hardware. The system delivers accurate, robust localization\nsuitable for safety-critical rail applications."}
