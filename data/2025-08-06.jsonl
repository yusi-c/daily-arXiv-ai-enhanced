{"id": "2508.02726", "categories": ["eess.IV", "cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2508.02726", "abs": "https://arxiv.org/abs/2508.02726", "authors": ["Lucio Pinello", "Francesco Cadini", "Luca Lomazzi"], "title": "MPCA-based Domain Adaptation for Transfer Learning in Ultrasonic Guided Waves", "comment": null, "summary": "Ultrasonic Guided Waves (UGWs) represent a promising diagnostic tool for\nStructural Health Monitoring (SHM) in thin-walled structures, and their\nintegration with machine learning (ML) algorithms is increasingly being adopted\nto enable real-time monitoring capabilities. However, the large-scale\ndeployment of UGW-based ML methods is constrained by data scarcity and limited\ngeneralisation across different materials and sensor configurations. To address\nthese limitations, this work proposes a novel transfer learning (TL) framework\nbased on Multilinear Principal Component Analysis (MPCA). First, a\nConvolutional Neural Network (CNN) for regression is trained to perform damage\nlocalisation for a plated structure. Then, MPCA and fine-tuning are combined to\nhave the CNN work for a different plate. By jointly applying MPCA to the source\nand target domains, the method extracts shared latent features, enabling\neffective domain adaptation without requiring prior assumptions about\ndimensionality. Following MPCA, fine-tuning enables adapting the pre-trained\nCNN to a new domain without the need for a large training dataset. The proposed\nMPCA-based TL method was tested against 12 case studies involving different\ncomposite materials and sensor arrays. Statistical metrics were used to assess\ndomains alignment both before and after MPCA, and the results demonstrate a\nsubstantial reduction in localisation error compared to standard TL techniques.\nHence, the proposed approach emerges as a robust, data-efficient, and\nstatistically based TL framework for UGW-based SHM."}
{"id": "2508.02839", "categories": ["eess.IV", "eess.SP"], "pdf": "https://arxiv.org/pdf/2508.02839", "abs": "https://arxiv.org/abs/2508.02839", "authors": ["Zack Dewis", "Zhengsen Xu", "Yimin Zhu", "Motasem Alkayid", "Mabel Heffring", "Lincoln Linlin Xu"], "title": "Spatial-Temporal-Spectral Mamba with Sparse Deformable Token Sequence for Enhanced MODIS Time Series Classification", "comment": null, "summary": "Although MODIS time series data are critical for supporting dynamic,\nlarge-scale land cover land use classification, it is a challenging task to\ncapture the subtle class signature information due to key MODIS difficulties,\ne.g., high temporal dimensionality, mixed pixels, and spatial-temporal-spectral\ncoupling effect. This paper presents a novel spatial-temporal-spectral Mamba\n(STSMamba) with deformable token sequence for enhanced MODIS time series\nclassification, with the following key contributions. First, to disentangle\ntemporal-spectral feature coupling, a temporal grouped stem (TGS) module is\ndesigned for initial feature learning. Second, to improve Mamba modeling\nefficiency and accuracy, a sparse, deformable Mamba sequencing (SDMS) approach\nis designed, which can reduce the potential information redundancy in Mamba\nsequence and improve the adaptability and learnability of the Mamba sequencing.\nThird, based on SDMS, to improve feature learning, a novel\nspatial-temporal-spectral Mamba architecture is designed, leading to three\nmodules, i.e., a sparse deformable spatial Mamba module (SDSpaM), a sparse\ndeformable spectral Mamba module (SDSpeM), and a sparse deformable temporal\nMamba module (SDTM) to explicitly learn key information sources in MODIS. The\nproposed approach is tested on MODIS time series data in comparison with many\nstate-of-the-art approaches, and the results demonstrate that the proposed\napproach can achieve higher classification accuracy with reduced computational\ncomplexity."}
{"id": "2508.02880", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.02880", "abs": "https://arxiv.org/abs/2508.02880", "authors": ["Pengwei Sun", "Wei Peng", "Lun Yu Li", "Yixin Wang", "Kilian M. Pohl"], "title": "Evaluation of 3D Counterfactual Brain MRI Generation", "comment": null, "summary": "Counterfactual generation offers a principled framework for simulating\nhypothetical changes in medical imaging, with potential applications in\nunderstanding disease mechanisms and generating physiologically plausible data.\nHowever, generating realistic structural 3D brain MRIs that respect anatomical\nand causal constraints remains challenging due to data scarcity, structural\ncomplexity, and the lack of standardized evaluation protocols. In this work, we\nconvert six generative models into 3D counterfactual approaches by\nincorporating an anatomy-guided framework based on a causal graph, in which\nregional brain volumes serve as direct conditioning inputs. Each model is\nevaluated with respect to composition, reversibility, realism, effectiveness\nand minimality on T1-weighted brain MRIs (T1w MRIs) from the Alzheimer's\nDisease Neuroimaging Initiative (ADNI). In addition, we test the\ngeneralizability of each model with respect to T1w MRIs of the National\nConsortium on Alcohol and Neurodevelopment in Adolescence (NCANDA). Our results\nindicate that anatomically grounded conditioning successfully modifies the\ntargeted anatomical regions; however, it exhibits limitations in preserving\nnon-targeted structures. Beyond laying the groundwork for more interpretable\nand clinically relevant generative modeling of brain MRIs, this benchmark\nhighlights the need for novel architectures that more accurately capture\nanatomical interdependencies."}
{"id": "2508.02889", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.02889", "abs": "https://arxiv.org/abs/2508.02889", "authors": ["Farzad Beizaee", "Sina Hajimiri", "Ismail Ben Ayed", "Gregory Lodygensky", "Christian Desrosiers", "Jose Dolz"], "title": "REFLECT: Rectified Flows for Efficient Brain Anomaly Correction Transport", "comment": "Accepted in Medical Image Computing and Computer Assisted\n  Intervention Society (MICCAI 2025)", "summary": "Unsupervised anomaly detection (UAD) in brain imaging is crucial for\nidentifying pathologies without the need for labeled data. However, accurately\nlocalizing anomalies remains challenging due to the intricate structure of\nbrain anatomy and the scarcity of abnormal examples. In this work, we introduce\nREFLECT, a novel framework that leverages rectified flows to establish a\ndirect, linear trajectory for correcting abnormal MR images toward a normal\ndistribution. By learning a straight, one-step correction transport map, our\nmethod efficiently corrects brain anomalies and can precisely localize\nanomalies by detecting discrepancies between anomalous input and corrected\ncounterpart. In contrast to the diffusion-based UAD models, which require\niterative stochastic sampling, rectified flows provide a direct transport map,\nenabling single-step inference. Extensive experiments on popular UAD brain\nsegmentation benchmarks demonstrate that REFLECT significantly outperforms\nstate-of-the-art unsupervised anomaly detection methods. The code is available\nat https://github.com/farzad-bz/REFLECT."}
{"id": "2508.02687", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.02687", "abs": "https://arxiv.org/abs/2508.02687", "authors": ["Yijia Hao", "Maarten Strackx", "Miguel Gandara", "Sandy Cochran", "Bo Liu"], "title": "An AI-driven EDA Algorithm-Empowered VCO and LDO Co-Design Method", "comment": null, "summary": "Traditionally, the output noise and power supply rejection of low-dropout\nregulators (LDOs) are optimized to minimize power supply fluctuations, reducing\ntheir impact on the low-frequency noise of target voltage-controlled\noscillators (VCOs). However, this sequential design approach does not fully\naddress the trade-offs between high-frequency and LDO-induced low-frequency\nphase noise. To overcome this limitation, this paper presents a co-design\nmethod for low phase-noise LC-tank VCOs powered by LDOs. It is difficult to\ncarry out the co-design using traditional manual design techniques. Hence, an\nefficient AI-driven EDA algorithm is used. To validate the proposed method, a\n5.6 GHz LC-tank VCO with an integrated LDO is designed using a 65 nm CMOS\nprocess. Simulations show that the co-design method improves phase noise by 1.2\ndB at a 1 MHz offset and reduces dynamic power consumption by 28.8%, with FoM\nincreased by 2.4 dBc/Hz compared to the conventional sequential design method."}
{"id": "2508.02957", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.02957", "abs": "https://arxiv.org/abs/2508.02957", "authors": ["Puzhen Wu", "Mingquan Lin", "Qingyu Chen", "Emily Y. Chew", "Zhiyong Lu", "Yifan Peng", "Hexin Dong"], "title": "AMD-Mamba: A Phenotype-Aware Multi-Modal Framework for Robust AMD Prognosis", "comment": "Accepted at the MICCAI 2025 MIML Workshop", "summary": "Age-related macular degeneration (AMD) is a leading cause of irreversible\nvision loss, making effective prognosis crucial for timely intervention. In\nthis work, we propose AMD-Mamba, a novel multi-modal framework for AMD\nprognosis, and further develop a new AMD biomarker. This framework integrates\ncolor fundus images with genetic variants and socio-demographic variables. At\nits core, AMD-Mamba introduces an innovative metric learning strategy that\nleverages AMD severity scale score as prior knowledge. This strategy allows the\nmodel to learn richer feature representations by aligning learned features with\nclinical phenotypes, thereby improving the capability of conventional prognosis\nmethods in capturing disease progression patterns. In addition, unlike existing\nmodels that use traditional CNN backbones and focus primarily on local\ninformation, such as the presence of drusen, AMD-Mamba applies Vision Mamba and\nsimultaneously fuses local and long-range global information, such as vascular\nchanges. Furthermore, we enhance prediction performance through multi-scale\nfusion, combining image information with clinical variables at different\nresolutions. We evaluate AMD-Mamba on the AREDS dataset, which includes 45,818\ncolor fundus photographs, 52 genetic variants, and 3 socio-demographic\nvariables from 2,741 subjects. Our experimental results demonstrate that our\nproposed biomarker is one of the most significant biomarkers for the\nprogression of AMD. Notably, combining this biomarker with other existing\nvariables yields promising improvements in detecting high-risk AMD patients at\nearly stages. These findings highlight the potential of our multi-modal\nframework to facilitate more precise and proactive management of AMD."}
{"id": "2508.02689", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.02689", "abs": "https://arxiv.org/abs/2508.02689", "authors": ["Jiawei Wang", "Yu Guan", "Chen Chen", "Ligang Zhou", "Laurence T. Yang", "Sai Gu"], "title": "On Improving PPG-Based Sleep Staging: A Pilot Study", "comment": null, "summary": "Sleep monitoring through accessible wearable technology is crucial to\nimproving well-being in ubiquitous computing. Although\nphotoplethysmography(PPG) sensors are widely adopted in consumer devices,\nachieving consistently reliable sleep staging using PPG alone remains a\nnon-trivial challenge. In this work, we explore multiple strategies to enhance\nthe performance of PPG-based sleep staging. Specifically, we compare\nconventional single-stream model with dual-stream cross-attention strategies,\nbased on which complementary information can be learned via PPG and PPG-derived\nmodalities such as augmented PPG or synthetic ECG. To study the effectiveness\nof the aforementioned approaches in four-stage sleep monitoring task, we\nconducted experiments on the world's largest sleep staging dataset, i.e., the\nMulti-Ethnic Study of Atherosclerosis(MESA). We found that substantial\nperformance gain can be achieved by combining PPG and its auxiliary information\nunder the dual-stream cross-attention architecture. Source code of this project\ncan be found at https://github.com/DavyWJW/sleep-staging-models"}
{"id": "2508.03008", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.03008", "abs": "https://arxiv.org/abs/2508.03008", "authors": ["Meng Zhou", "Farzad Khalvati"], "title": "ClinicalFMamba: Advancing Clinical Assessment using Mamba-based Multimodal Neuroimaging Fusion", "comment": "Accepted at MICCAI MLMI 2025 Workshop", "summary": "Multimodal medical image fusion integrates complementary information from\ndifferent imaging modalities to enhance diagnostic accuracy and treatment\nplanning. While deep learning methods have advanced performance, existing\napproaches face critical limitations: Convolutional Neural Networks (CNNs)\nexcel at local feature extraction but struggle to model global context\neffectively, while Transformers achieve superior long-range modeling at the\ncost of quadratic computational complexity, limiting clinical deployment.\nRecent State Space Models (SSMs) offer a promising alternative, enabling\nefficient long-range dependency modeling in linear time through selective scan\nmechanisms. Despite these advances, the extension to 3D volumetric data and the\nclinical validation of fused images remains underexplored. In this work, we\npropose ClinicalFMamba, a novel end-to-end CNN-Mamba hybrid architecture that\nsynergistically combines local and global feature modeling for 2D and 3D\nimages. We further design a tri-plane scanning strategy for effectively\nlearning volumetric dependencies in 3D images. Comprehensive evaluations on\nthree datasets demonstrate the superior fusion performance across multiple\nquantitative metrics while achieving real-time fusion. We further validate the\nclinical utility of our approach on downstream 2D/3D brain tumor classification\ntasks, achieving superior performance over baseline methods. Our method\nestablishes a new paradigm for efficient multimodal medical image fusion\nsuitable for real-time clinical deployment."}
{"id": "2508.02693", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.02693", "abs": "https://arxiv.org/abs/2508.02693", "authors": ["Xinwei Yue", "Xinning Guo", "Xidong Mu", "Jingjing Zhao", "Peng Yang", "Junsheng Mu", "Zhiping Lu"], "title": "Federated Learning in Active STARS-Aided Uplink Networks", "comment": null, "summary": "Active simultaneously transmitting and reflecting surfaces (ASTARS) have\nattracted growing research interest due to its ability to alleviate\nmultiplicative fading and reshape the electromagnetic environment across the\nentire space. In this paper, we utilise ASTARS to assist the federated learning\n(FL) uplink model transfer and further reduce the number of uploaded parameter\ncounts through over-the-air (OTA) computing techniques. The impact of model\naggregation errors on ASTARS-aided FL uplink networks is characterized. We\nderive an upper bound on the aggregation error of the OTA-FL model and quantify\nthe training loss due to communication errors. Then, we define the performance\nof OTA-FL as a joint optimization problem that encompasses both the assignment\nof received beams and the phase shifting of ASTARS, aiming to achieve the\nmaximum learning efficiency and high-quality signal transmission. Numerical\nresults demonstrate that: i) The FL accuracy in ASTARS uplink networks are\nenhanced compared to that in state-of-the-art networks; ii) The ASTARS enabled\nFL system achieves the better learning accuracy using fewer active units than\nother baseline, especially when the dataset is more discrete; and iii) FL\naccuracy improves with higher amplification power, but excessive amplification\nmakes thermal noise the dominant source of error."}
{"id": "2508.03057", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.03057", "abs": "https://arxiv.org/abs/2508.03057", "authors": ["Tongxu Zhang", "Zhiming Liang", "Bei Wang"], "title": "A Survey of Medical Point Cloud Shape Learning: Registration, Reconstruction and Variation", "comment": null, "summary": "Point clouds have become an increasingly important representation for 3D\nmedical imaging, offering a compact, surface-preserving alternative to\ntraditional voxel or mesh-based approaches. Recent advances in deep learning\nhave enabled rapid progress in extracting, modeling, and analyzing anatomical\nshapes directly from point cloud data. This paper provides a comprehensive and\nsystematic survey of learning-based shape analysis for medical point clouds,\nfocusing on three fundamental tasks: registration, reconstruction, and\nvariation modeling. We review recent literature from 2021 to 2025, summarize\nrepresentative methods, datasets, and evaluation metrics, and highlight\nclinical applications and unique challenges in the medical domain. Key trends\ninclude the integration of hybrid representations, large-scale self-supervised\nmodels, and generative techniques. We also discuss current limitations, such as\ndata scarcity, inter-patient variability, and the need for interpretable and\nrobust solutions for clinical deployment. Finally, future directions are\noutlined for advancing point cloud-based shape learning in medical imaging."}
{"id": "2508.02698", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.02698", "abs": "https://arxiv.org/abs/2508.02698", "authors": ["Sameera Bharadwaja H.", "D. K. Mehra"], "title": "A Completely Blind Channel Estimation Technique for OFDM Using Constellation Splitting", "comment": null, "summary": "The problem of second-order statistics (SOS)-based blind channel estimation\nin OFDM systems is addressed in this paper. Almost all SOS-based methods\nproposed so far suffer from a complex-scalar estimation ambiguity, which is\nresolved by using pilots or reference symbols. We propose an algorithm to\nresolve this ambiguity in blind manner using frequency-domain linear\nnon-redundant precoding and constellation-splitting among the alternate\nsubcarriers. The performance of the proposed scheme is evaluated via numerical\nsimulations in MATLAB environment. Simulation results show that the proposed\napproach performs as good as its semi-blind counterpart for M-ary PAM systems."}
{"id": "2508.03073", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.03073", "abs": "https://arxiv.org/abs/2508.03073", "authors": ["Bo Zhang", "JianFei Huo", "Zheng Zhang", "Wufan Wang", "Hui Gao", "Xiangyang Gong", "Wendong Wang"], "title": "Nexus-INR: Diverse Knowledge-guided Arbitrary-Scale Multimodal Medical Image Super-Resolution", "comment": null, "summary": "Arbitrary-resolution super-resolution (ARSR) provides crucial flexibility for\nmedical image analysis by adapting to diverse spatial resolutions. However,\ntraditional CNN-based methods are inherently ill-suited for ARSR, as they are\ntypically designed for fixed upsampling factors. While INR-based methods\novercome this limitation, they still struggle to effectively process and\nleverage multi-modal images with varying resolutions and details. In this\npaper, we propose Nexus-INR, a Diverse Knowledge-guided ARSR framework, which\nemploys varied information and downstream tasks to achieve high-quality,\nadaptive-resolution medical image super-resolution. Specifically, Nexus-INR\ncontains three key components. A dual-branch encoder with an auxiliary\nclassification task to effectively disentangle shared anatomical structures and\nmodality-specific features; a knowledge distillation module using cross-modal\nattention that guides low-resolution modality reconstruction with\nhigh-resolution reference, enhanced by self-supervised consistency loss; an\nintegrated segmentation module that embeds anatomical semantics to improve both\nreconstruction quality and downstream segmentation performance. Experiments on\nthe BraTS2020 dataset for both super-resolution and downstream segmentation\ndemonstrate that Nexus-INR outperforms state-of-the-art methods across various\nmetrics."}
{"id": "2508.02703", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.02703", "abs": "https://arxiv.org/abs/2508.02703", "authors": ["Evangelos Sariyanidi", "John D. Herrington", "Lisa Yankowitz", "Pratik Chaudhari", "Theodore D. Satterthwaite", "Casey J. Zampella", "Robert T. Schultz", "Russell T. Shinohara", "Birkan Tunc"], "title": "Measuring Dependencies between Biological Signals with Temporal Self-supervision, and its Limitations", "comment": "To be submitted to NeurIPS 2025 AI for Science Workshop", "summary": "Measuring the statistical dependence between observed signals is a primary\ntool for scientific discovery. However, biological systems often exhibit\ncomplex non-linear interactions that currently cannot be captured without a\npriori knowledge regarding the nature of dependence. We introduce a\nself-supervised approach, concurrence, which is inspired by the observation\nthat if two signals are dependent, then one should be able to distinguish\nbetween temporally aligned vs. misaligned segments extracted from them.\nExperiments with fMRI, physiological and behavioral signals show that, to our\nknowledge, concurrence is the first approach that can expose relationships\nacross such a wide spectrum of signals and extract scientifically relevant\ndifferences without ad-hoc parameter tuning or reliance on a priori\ninformation, providing a potent tool for scientific discoveries across fields.\nHowever, depencencies caused by extraneous factors remain an open problem, thus\nresearchers should validate that exposed relationships truely pertain to the\nquestion(s) of interest."}
{"id": "2508.03357", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.03357", "abs": "https://arxiv.org/abs/2508.03357", "authors": ["Yifei Sun", "Zhanghao Chen", "Hao Zheng", "Yuqing Lu", "Lixin Duan", "Fenglei Fan", "Ahmed Elazab", "Xiang Wan", "Changmiao Wang", "Ruiquan Ge"], "title": "GL-LCM: Global-Local Latent Consistency Models for Fast High-Resolution Bone Suppression in Chest X-Ray Images", "comment": "11 pages, 3 figures, accepted by MICCAI 2025", "summary": "Chest X-Ray (CXR) imaging for pulmonary diagnosis raises significant\nchallenges, primarily because bone structures can obscure critical details\nnecessary for accurate diagnosis. Recent advances in deep learning,\nparticularly with diffusion models, offer significant promise for effectively\nminimizing the visibility of bone structures in CXR images, thereby improving\nclarity and diagnostic accuracy. Nevertheless, existing diffusion-based methods\nfor bone suppression in CXR imaging struggle to balance the complete\nsuppression of bones with preserving local texture details. Additionally, their\nhigh computational demand and extended processing time hinder their practical\nuse in clinical settings. To address these limitations, we introduce a\nGlobal-Local Latent Consistency Model (GL-LCM) architecture. This model\ncombines lung segmentation, dual-path sampling, and global-local fusion,\nenabling fast high-resolution bone suppression in CXR images. To tackle\npotential boundary artifacts and detail blurring in local-path sampling, we\nfurther propose Local-Enhanced Guidance, which addresses these issues without\nadditional training. Comprehensive experiments on a self-collected dataset\nSZCH-X-Rays, and the public dataset JSRT, reveal that our GL-LCM delivers\nsuperior bone suppression and remarkable computational efficiency,\nsignificantly outperforming several competitive methods. Our code is available\nat https://github.com/diaoquesang/GL-LCM."}
{"id": "2508.02710", "categories": ["eess.SP", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.02710", "abs": "https://arxiv.org/abs/2508.02710", "authors": ["Beatriz Macas Ordóñez", "Diego Vinicio Orellana Villavicencio", "José Manuel Ferrández", "Paula Bonomini"], "title": "Evaluation of Deep Learning Models for LBBB Classification in ECG Signals", "comment": "Accepted for presentation in the 47th Annual International Conference\n  of the IEEE Engineering in Medicine and Biology Society (EMBC 2025)", "summary": "This study explores different neural network architectures to evaluate their\nability to extract spatial and temporal patterns from electrocardiographic\n(ECG) signals and classify them into three groups: healthy subjects, Left\nBundle Branch Block (LBBB), and Strict Left Bundle Branch Block (sLBBB).\n  Clinical Relevance, Innovative technologies enable the selection of\ncandidates for Cardiac Resynchronization Therapy (CRT) by optimizing the\nclassification of subjects with Left Bundle Branch Block (LBBB)."}
{"id": "2508.03461", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.03461", "abs": "https://arxiv.org/abs/2508.03461", "authors": ["Gideon N. L. Rouwendaal", "Daniël Boeke", "Inge L. Cox", "Henk G. van der Poel", "Margriet C. van Dijk-de Haan", "Regina G. H. Beets-Tan", "Thierry N. Boellaard", "Wilson Silva"], "title": "Evaluating the Predictive Value of Preoperative MRI for Erectile Dysfunction Following Radical Prostatectomy", "comment": "13 pages, 5 figures, 2 tables. Accepted at PRedictive Intelligence in\n  MEdicine workshop @ MICCAI 2025 (PRIME-MICCAI). This is the submitted\n  manuscript with added link to github repo, funding acknowledgements and\n  authors' names and affiliations. No further post submission improvements or\n  corrections were integrated. Final version not published yet", "summary": "Accurate preoperative prediction of erectile dysfunction (ED) is important\nfor counseling patients undergoing radical prostatectomy. While clinical\nfeatures are established predictors, the added value of preoperative MRI\nremains underexplored. We investigate whether MRI provides additional\npredictive value for ED at 12 months post-surgery, evaluating four modeling\nstrategies: (1) a clinical-only baseline, representing current\nstate-of-the-art; (2) classical models using handcrafted anatomical features\nderived from MRI; (3) deep learning models trained directly on MRI slices; and\n(4) multimodal fusion of imaging and clinical inputs. Imaging-based models\n(maximum AUC 0.569) slightly outperformed handcrafted anatomical approaches\n(AUC 0.554) but fell short of the clinical baseline (AUC 0.663). Fusion models\noffered marginal gains (AUC 0.586) but did not exceed clinical-only\nperformance. SHAP analysis confirmed that clinical features contributed most to\npredictive performance. Saliency maps from the best-performing imaging model\nsuggested a predominant focus on anatomically plausible regions, such as the\nprostate and neurovascular bundles. While MRI-based models did not improve\npredictive performance over clinical features, our findings suggest that they\ntry to capture patterns in relevant anatomical structures and may complement\nclinical predictors in future multimodal approaches."}
{"id": "2508.02712", "categories": ["eess.SP", "cs.LG", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2508.02712", "abs": "https://arxiv.org/abs/2508.02712", "authors": ["Pallock Halder", "Satyajit Mojumder"], "title": "Physics-guided denoiser network for enhanced additive manufacturing data quality", "comment": "28 pages, 13 figures, 5 tables", "summary": "Modern engineering systems are increasingly equipped with sensors for\nreal-time monitoring and decision-making. However, the data collected by these\nsensors is often noisy and difficult to interpret, limiting its utility for\ncontrol and diagnostics. In this work, we propose a physics-informed denoising\nframework that integrates energy-based model and Fisher score regularization to\njointly reduce data noise and enforce physical consistency with a physics-based\nmodel. The approach is first validated on benchmark problems, including the\nsimple harmonic oscillator, Burgers' equation, and Laplace's equation, across\nvarying noise levels. We then apply the denoising framework to real thermal\nemission data from laser powder bed fusion (LPBF) additive manufacturing\nexperiments, using a trained Physics-Informed Neural Network (PINN) surrogate\nmodel of the LPBF process to guide denoising. Results show that the proposed\nmethod outperforms baseline neural network denoisers, effectively reducing\nnoise under a range of LPBF processing conditions. This physics-guided\ndenoising strategy enables robust, real-time interpretation of low-cost sensor\ndata, facilitating predictive control and improved defect mitigation in\nadditive manufacturing."}
{"id": "2508.03594", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.03594", "abs": "https://arxiv.org/abs/2508.03594", "authors": ["Ana Lawry Aguila", "Ayodeji Ijishakin", "Juan Eugenio Iglesias", "Tomomi Takenaga", "Yukihiro Nomura", "Takeharu Yoshikawa", "Osamu Abe", "Shouhei Hanaoka"], "title": "CADD: Context aware disease deviations via restoration of brain images using normative conditional diffusion models", "comment": null, "summary": "Applying machine learning to real-world medical data, e.g. from hospital\narchives, has the potential to revolutionize disease detection in brain images.\nHowever, detecting pathology in such heterogeneous cohorts is a difficult\nchallenge. Normative modeling, a form of unsupervised anomaly detection, offers\na promising approach to studying such cohorts where the ``normal'' behavior is\nmodeled and can be used at subject level to detect deviations relating to\ndisease pathology. Diffusion models have emerged as powerful tools for anomaly\ndetection due to their ability to capture complex data distributions and\ngenerate high-quality images. Their performance relies on image restoration;\ndifferences between the original and restored images highlight potential\nabnormalities. However, unlike normative models, these diffusion model\napproaches do not incorporate clinical information which provides important\ncontext to guide the disease detection process. Furthermore, standard\napproaches often poorly restore healthy regions, resulting in poor\nreconstructions and suboptimal detection performance. We present CADD, the\nfirst conditional diffusion model for normative modeling in 3D images. To guide\nthe healthy restoration process, we propose a novel inference inpainting\nstrategy which balances anomaly removal with retention of subject-specific\nfeatures. Evaluated on three challenging datasets, including clinical scans,\nwhich may have lower contrast, thicker slices, and motion artifacts, CADD\nachieves state-of-the-art performance in detecting neurological abnormalities\nin heterogeneous cohorts."}
{"id": "2508.02713", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.02713", "abs": "https://arxiv.org/abs/2508.02713", "authors": ["Pengxu Lin", "An-An Lu", "Xiqi Gao"], "title": "Precoder Design for User-Centric Network Massive MIMO: A Symplectic Optimization Approach", "comment": null, "summary": "In this paper, we utilize symplectic optimization to design a precoder for\nuser-centric network (UCN) massive multiple-input multiple-output (MIMO)\nsystems, where a subset of base stations (BSs) serves each user terminal (UT)\ninstead of using all BSs. In UCN massive MIMO systems, the dimension of the\nprecoders is reduced compared to conventional network massive MIMO. It\nsimplifies the implementation of precoders in practical systems. However, the\nmatrix inversion in traditional linear precoders still requires high\ncomputational complexity. To avoid the matrix inversion, we employ the\nsymplectic optimization framework, where optimization problems are solved based\non dissipative Hamiltonian dynamical systems. To better fit symplectic\noptimization, we transform the received model into the real field and\nreformulate the weighted sum-rate (WSR) maximization problem. The objective\nfunction of the optimization problem is viewed as the potential energy of the\ndynamical system. Due to energy dissipation, the continuous dynamical system\nalways converges to a state with minimal potential energy. By discretizing the\ncontinuous system while preserving the symplectic structure, we obtain an\niterative method for the precoder design. The complexity analysis of the\nproposed symplectic method is also provided to show its high computational\nefficiency. Simulation results demonstrate that the proposed precoder design\nbased on symplectic optimization outperforms the weighted minimum mean-square\nerror (WMMSE) precoder in the UCN massive MIMO system."}
{"id": "2508.02847", "categories": ["eess.SP", "cs.SY", "eess.IV", "eess.SY"], "pdf": "https://arxiv.org/pdf/2508.02847", "abs": "https://arxiv.org/abs/2508.02847", "authors": ["Ke Xu", "Chaitanya Krishna Prasad Vallabh", "Souran Manoochehri"], "title": "Integrating Machine Learning with Multimodal Monitoring System Utilizing Acoustic and Vision Sensing to Evaluate Geometric Variations in Laser Directed Energy Deposition", "comment": null, "summary": "Laser directed energy deposition (DED) additive manufacturing struggles with\nconsistent part quality due to complex melt pool dynamics and process\nvariations. While much research targets defect detection, little work has\nvalidated process monitoring systems for evaluating melt pool dynamics and\nprocess quality. This study presents a novel multimodal monitoring framework,\nsynergistically integrating contact-based acoustic emission (AE) sensing with\ncoaxial camera vision to enable layer-wise identification and evaluation of\ngeometric variations in DED parts. The experimental study used three part\nconfigurations: a baseline part without holes, a part with a 3mm diameter\nthrough-hole, and one with a 5mm through-hole to test the system's discerning\ncapabilities. Raw sensor data was preprocessed: acoustic signals were filtered\nfor time-domain and frequency-domain feature extraction, while camera data\nunderwent melt pool segmentation and morphological feature extraction. Multiple\nmachine learning algorithms (including SVM, random forest, and XGBoost) were\nevaluated to find the optimal model for classifying layer-wise geometric\nvariations. The integrated multimodal strategy achieved a superior\nclassification performance of 94.4%, compared to 87.8% for AE only and 86.7%\nfor the camera only. Validation confirmed the integrated system effectively\ncaptures both structural vibration signatures and surface morphological changes\ntied to the geometric variations. While this study focuses on specific\ngeometries, the demonstrated capability to discriminate between features\nestablishes a technical foundation for future applications in characterizing\npart variations like geometric inaccuracies and manufacturing-induced defects."}
{"id": "2508.02718", "categories": ["eess.SP", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.02718", "abs": "https://arxiv.org/abs/2508.02718", "authors": ["Zahra Mohammadi", "Siamak Mohammadi"], "title": "SleepLiteCNN: Energy-Efficient Sleep Apnea Subtype Classification with 1-Second Resolution Using Single-Lead ECG", "comment": null, "summary": "Apnea is a common sleep disorder characterized by breathing interruptions\nlasting at least ten seconds and occurring more than five times per hour.\nAccurate, high-temporal-resolution detection of sleep apnea subtypes -\nObstructive, Central, and Mixed - is crucial for effective treatment and\nmanagement. This paper presents an energy-efficient method for classifying\nthese subtypes using a single-lead electrocardiogram (ECG) with high temporal\nresolution to address the real-time needs of wearable devices. We evaluate a\nwide range of classical machine learning algorithms and deep learning\narchitectures on 1-second ECG windows, comparing their accuracy, complexity,\nand energy consumption. Based on this analysis, we introduce SleepLiteCNN, a\ncompact and energy-efficient convolutional neural network specifically designed\nfor wearable platforms. SleepLiteCNN achieves over 95% accuracy and a 92%\nmacro-F1 score, while requiring just 1.8 microjoules per inference after 8-bit\nquantization. Field Programmable Gate Array (FPGA) synthesis further\ndemonstrates significant reductions in hardware resource usage, confirming its\nsuitability for continuous, real-time monitoring in energy-constrained\nenvironments. These results establish SleepLiteCNN as a practical and effective\nsolution for wearable device sleep apnea subtype detection."}
{"id": "2508.02724", "categories": ["eess.SP", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.02724", "abs": "https://arxiv.org/abs/2508.02724", "authors": ["Yahia Dalbah", "Marcel Worring", "Yen-Chia Hsu"], "title": "Veli: Unsupervised Method and Unified Benchmark for Low-Cost Air Quality Sensor Correction", "comment": "Main content: 7 pages, 9 Figures, 3 Tables. Appendix: 4 pages, 6\n  Figures", "summary": "Urban air pollution is a major health crisis causing millions of premature\ndeaths annually, underscoring the urgent need for accurate and scalable\nmonitoring of air quality (AQ). While low-cost sensors (LCS) offer a scalable\nalternative to expensive reference-grade stations, their readings are affected\nby drift, calibration errors, and environmental interference. To address these\nchallenges, we introduce Veli (Reference-free Variational Estimation via Latent\nInference), an unsupervised Bayesian model that leverages variational inference\nto correct LCS readings without requiring co-location with reference stations,\neliminating a major deployment barrier. Specifically, Veli constructs a\ndisentangled representation of the LCS readings, effectively separating the\ntrue pollutant reading from the sensor noise. To build our model and address\nthe lack of standardized benchmarks in AQ monitoring, we also introduce the Air\nQuality Sensor Data Repository (AQ-SDR). AQ-SDR is the largest AQ sensor\nbenchmark to date, with readings from 23,737 LCS and reference stations across\nmultiple regions. Veli demonstrates strong generalization across both\nin-distribution and out-of-distribution settings, effectively handling sensor\ndrift and erratic sensor behavior. Code for model and dataset will be made\npublic when this paper is published."}
{"id": "2508.02742", "categories": ["eess.SP", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.02742", "abs": "https://arxiv.org/abs/2508.02742", "authors": ["Chunyu Liu", "Hao Zhang", "Wei Wu", "Fuhui Zhou", "Qihui Wu", "Derrick Wing Kwan Ng", "Chan-Byoung Chae"], "title": "SpectrumFM: A New Paradigm for Spectrum Cognition", "comment": "This paper has been accepted for presentation at the 2025 IEEE Global\n  Communications Conference (GLOBECOM 2025), Cognitive Radio and AI-Enabled\n  Network Symposium", "summary": "The enhancement of spectrum efficiency and the realization of secure spectrum\nutilization are critically dependent on spectrum cognition. However, existing\nspectrum cognition methods often exhibit limited generalization and suboptimal\naccuracy when deployed across diverse spectrum environments and tasks. To\novercome these challenges, we propose a spectrum foundation model, termed\nSpectrumFM, which provides a new paradigm for spectrum cognition. An innovative\nspectrum encoder that exploits the convolutional neural networks and the\nmulti-head self attention mechanisms is proposed to effectively capture both\nfine-grained local signal structures and high-level global dependencies in the\nspectrum data. To enhance its adaptability, two novel self-supervised learning\ntasks, namely masked reconstruction and next-slot signal prediction, are\ndeveloped for pre-training SpectrumFM, enabling the model to learn rich and\ntransferable representations. Furthermore, low-rank adaptation (LoRA)\nparameter-efficient fine-tuning is exploited to enable SpectrumFM to seamlessly\nadapt to various downstream spectrum cognition tasks, including spectrum\nsensing (SS), anomaly detection (AD), and wireless technology classification\n(WTC). Extensive experiments demonstrate the superiority of SpectrumFM over\nstate-of-the-art methods. Specifically, it improves detection probability in\nthe SS task by 30% at -4 dB signal-to-noise ratio (SNR), boosts the area under\nthe curve (AUC) in the AD task by over 10%, and enhances WTC accuracy by 9.6%."}
{"id": "2508.02799", "categories": ["eess.SP", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.02799", "abs": "https://arxiv.org/abs/2508.02799", "authors": ["Jessica Sanson", "Rahul C. Shah", "Maximilian Pinaroc", "Valerio Frascolla"], "title": "Extracting Range-Doppler Information of Moving Targets from Wi-Fi Channel State Information", "comment": null, "summary": "This paper presents, for the first time, a method to extract both range and\nDoppler information from commercial Wi-Fi Channel State Information (CSI) using\na monostatic (single transceiver) setup. Utilizing the CSI phase in Wi-Fi\nsensing from a Network Interface Card (NIC) not designed for full-duplex\noperation is challenging due to (1) Hardware asynchronization, which introduces\nsignificant phase errors, and (2) Proximity of transmit (Tx) and receive (Rx)\nantennas, which creates strong coupling that overwhelms the motion signal of\ninterest. We propose a new signal processing approach that addresses both\nchallenges via three key innovations: Time offset cancellation, Phase alignment\ncorrection, and Tx/Rx coupling mitigation. Our method achieves cm-level\naccuracy in range and Doppler estimation for moving targets, validated using a\ncommercial Intel Wi-Fi AX211 NIC. Our results show successful detection and\ntracking of moving objects in realistic environments, establishing the\nfeasibility of high-precision sensing using standard Wi-Fi packet\ncommunications and off-the-shelf hardware without requiring any modification or\nspecialized full-duplex capabilities."}
{"id": "2508.02847", "categories": ["eess.SP", "cs.SY", "eess.IV", "eess.SY"], "pdf": "https://arxiv.org/pdf/2508.02847", "abs": "https://arxiv.org/abs/2508.02847", "authors": ["Ke Xu", "Chaitanya Krishna Prasad Vallabh", "Souran Manoochehri"], "title": "Integrating Machine Learning with Multimodal Monitoring System Utilizing Acoustic and Vision Sensing to Evaluate Geometric Variations in Laser Directed Energy Deposition", "comment": null, "summary": "Laser directed energy deposition (DED) additive manufacturing struggles with\nconsistent part quality due to complex melt pool dynamics and process\nvariations. While much research targets defect detection, little work has\nvalidated process monitoring systems for evaluating melt pool dynamics and\nprocess quality. This study presents a novel multimodal monitoring framework,\nsynergistically integrating contact-based acoustic emission (AE) sensing with\ncoaxial camera vision to enable layer-wise identification and evaluation of\ngeometric variations in DED parts. The experimental study used three part\nconfigurations: a baseline part without holes, a part with a 3mm diameter\nthrough-hole, and one with a 5mm through-hole to test the system's discerning\ncapabilities. Raw sensor data was preprocessed: acoustic signals were filtered\nfor time-domain and frequency-domain feature extraction, while camera data\nunderwent melt pool segmentation and morphological feature extraction. Multiple\nmachine learning algorithms (including SVM, random forest, and XGBoost) were\nevaluated to find the optimal model for classifying layer-wise geometric\nvariations. The integrated multimodal strategy achieved a superior\nclassification performance of 94.4%, compared to 87.8% for AE only and 86.7%\nfor the camera only. Validation confirmed the integrated system effectively\ncaptures both structural vibration signatures and surface morphological changes\ntied to the geometric variations. While this study focuses on specific\ngeometries, the demonstrated capability to discriminate between features\nestablishes a technical foundation for future applications in characterizing\npart variations like geometric inaccuracies and manufacturing-induced defects."}
{"id": "2508.02856", "categories": ["eess.SP", "cs.AI", "cs.NI"], "pdf": "https://arxiv.org/pdf/2508.02856", "abs": "https://arxiv.org/abs/2508.02856", "authors": ["Seyed Bagher Hashemi Natanzi", "Hossein Mohammadi", "Bo Tang", "Vuk Marojevic"], "title": "Secure mmWave Beamforming with Proactive-ISAC Defense Against Beam-Stealing Attacks", "comment": null, "summary": "Millimeter-wave (mmWave) communication systems face increasing susceptibility\nto advanced beam-stealing attacks, posing a significant physical layer security\nthreat. This paper introduces a novel framework employing an advanced Deep\nReinforcement Learning (DRL) agent for proactive and adaptive defense against\nthese sophisticated attacks. A key innovation is leveraging Integrated Sensing\nand Communications (ISAC) capabilities for active, intelligent threat\nassessment. The DRL agent, built on a Proximal Policy Optimization (PPO)\nalgorithm, dynamically controls ISAC probing actions to investigate suspicious\nactivities. We introduce an intensive curriculum learning strategy that\nguarantees the agent experiences successful detection during training to\novercome the complex exploration challenges inherent to such a\nsecurity-critical task. Consequently, the agent learns a robust and adaptive\npolicy that intelligently balances security and communication performance.\nNumerical results demonstrate that our framework achieves a mean attacker\ndetection rate of 92.8% while maintaining an average user SINR of over 13 dB."}
{"id": "2508.02950", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.02950", "abs": "https://arxiv.org/abs/2508.02950", "authors": ["Sandesh Rao Mattu", "Nishant Mehrotra", "Robert Calderbank"], "title": "Zak-OTFS for Faster-Than-Nyquist Signaling in the Presence of Mobility & Delay Spread", "comment": "5 pages, 2 figures. Submitted to IEEE", "summary": "Orthogonal signaling limits the number of information symbols transmitted in\nbandwidth $B$ and time $T$ to be $BT$. This corresponds to the Nyquist\nsignaling and is achieved by mounting information symbols on $BT$-dimensional\nbasis spanning the $BT$-dimensional space spaced $\\frac{1}{B}$ and\n$\\frac{1}{T}$ apart. Faster-than-Nyquist signaling involves transmitting more\nthan $BT$ informational symbols in a $BT$-dimensional space. This leads to loss\nof orthogonality. This is achieved by time and/or bandwidth expansion resulting\nfrom packing more information symbols in the same $BT$-dimensional space\n(spacing less than $\\frac{1}{B}$ and/or $\\frac{1}{T}$). In this paper, we take\na different approach to faster-than-Nyquist signaling. We propose to\nsuperimpose the information symbols on one another maintaining the original\nspacing in the Nyquist signaling. We carry this out in the delay-Doppler (DD)\ndomain using Zak-transform based orthogonal time frequency space (Zak-OTFS)\nmodulation. In Zak-OTFS, the channel varies slowly. Further Zak-OTFS also\nallows construction of mutually unbiased bases the interference between which\nappear like Gaussian noise. The proposed scheme leverages the slow variation in\nthe DD channel to construct a precoder that mitigates the effect of the\ndoubly-spread channel. Further, in the proposed scheme we mount information\nsymbols on two mutually unbiased bases which allows superposition of\ninformation symbols. This simplifies receiver processing to detection in\nGaussian noise since each basis appears to the other as Gaussian noise. This\nreduction makes it possible to use trellis coded modulation to enhance\nbit-error performance. Numerical results demonstrate that the\nfaster-than-Nyquist signaling scheme achieves similar uncoded performance as\nthat of Nyquist signaling and with coding the performance is better than\nNyquist signaling at high signal-to-noise ratios."}
{"id": "2508.03011", "categories": ["eess.SP", "cs.RO", "I.2.9; C.3"], "pdf": "https://arxiv.org/pdf/2508.03011", "abs": "https://arxiv.org/abs/2508.03011", "authors": ["Hsun-Yu Lee", "Jie Lin", "Fang-Jing Wu"], "title": "Generating Light-based Fingerprints for Indoor Localization", "comment": "5 pages, 12 figures; presented at the 2024 MC & WASN Conference (Best\n  Paper Candidate)", "summary": "Accurate indoor localization underpins applications ranging from wayfinding\nand emergency response to asset tracking and smart-building services.\nRadio-frequency solutions (e.g. Wi-Fi, RFID, UWB) are widely adopted but remain\nvulnerable to multipath fading, interference, and uncontrollable coverage\nvariation. We explore an orthogonal modality -- visible light communication\n(VLC) -- and demonstrate that the spectral signatures captured by a low-cost\nAS7341 sensor can serve as robust location fingerprints.\n  We introduce a two-stage framework that (i) trains a multi-layer perceptron\n(MLP) on real spectral measurements and (ii) enlarges the training corpus with\nsynthetic samples produced by TabGAN. The augmented dataset reduces the mean\nlocalization error from 62.9cm to 49.3cm -- a 20% improvement -- while\nrequiring only 5% additional data-collection effort. Experimental results\nobtained on 42 reference points in a U-shaped laboratory confirm that GAN-based\naugmentation mitigates data-scarcity issues and enhances generalization."}
{"id": "2508.03021", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.03021", "abs": "https://arxiv.org/abs/2508.03021", "authors": ["Zhengyu Wang", "Tiebin Mi", "Gui Zhou", "Robert C. Qiu"], "title": "Metasurface-Enabled Extremely Large-Scale Antenna Systems: Transceiver Architecture, Physical Modeling, and Channel Estimation", "comment": null, "summary": "Extremely large-scale antenna arrays (ELAAs) have emerged as a pivotal\ntechnology for addressing the unprecedented performance demands of\nnext-generation wireless communication systems. To enhance their practicality,\nwe propose metasurface-enabled extremely large-scale antenna (MELA) systems --\nnovel transceiver architectures that employ reconfigurable transmissive\nmetasurfaces to facilitate efficient over-the-air RF-to-antenna coupling and\nphase control. This architecture eliminates the need for bulky switch matrices\nand costly phase-shifter networks typically required in conventional solutions.\nPhysically grounded models are developed to characterize electromagnetic field\npropagation through individual transmissive unit cells, capturing the\nfundamental physics of wave transformation and transmission. Additionally,\ndistance-dependent approximate models are introduced, exhibiting structural\nproperties conducive to efficient parameter estimation and signal processing.\nBased on the channel model, a two stage channel estimation framework is\nproposed for the scenarios comprising users in the hybrid near- and far-fields.\nIn the first stage, a dictionary-driven beamspace filtering technique enables\nrapid angular-domain scanning. In the refinement stage, the rotational symmetry\nof subarrays is exploited to design super-resolution estimators that jointly\nrecover angular and range parameters. An analytical expression for the\nhalf-power beamwidth of MELA is derived, revealing its near-optimal spatial\nresolution relative to conventional ELAA architectures. Numerical experiments\nfurther validate the high-resolution of the proposed channel estimation\nalgorithm and the fidelity of the electromagnetic model, positioning the MELA\narchitecture as a highly competitive and forward-looking solution for practical\nELAA deployment."}
{"id": "2508.03084", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.03084", "abs": "https://arxiv.org/abs/2508.03084", "authors": ["Lingyan Zhang", "Yuanfeng Qiu", "Dachuan Li", "Shaohua Wu", "Tingting Zhang", "Qinyu Zhang"], "title": "Scenario-Agnostic Deep-Learning-Based Localization with Contrastive Self-Supervised Pre-training", "comment": null, "summary": "Wireless localization has become a promising technology for offering\nintelligent location-based services. Although its localization accuracy is\nimproved under specific scenarios, the short of environmental dynamic\nvulnerability still hinders this approach from being fully practical\napplications. In this paper, we propose CSSLoc, a novel framework on\ncontrastive self-supervised pre-training to learn generic representations for\naccurate localization in various scenarios. Without the location information\nsupervision, CSSLoc attempts to learn an insightful metric on the similarity\ndiscrimination of radio data, in such a scenario-agnostic manner that the\nsimilar samples are closely clustered together and different samples are\nseparated in the representation space. Furthermore, the trained feature encoder\ncan be directly transferred for downstream localization tasks, and the location\npredictor is trained to estimate accurate locations with the robustness of\nenvironmental dynamics. With extensive experimental results, CSSLoc can\noutperform classical and state-of-the-art DNN-based localization schemes in\ntypical indoor scenarios, pushing deep-learning-based localization from\nspecificity to generality."}
{"id": "2508.03120", "categories": ["eess.SP", "cs.ET", "cs.RO"], "pdf": "https://arxiv.org/pdf/2508.03120", "abs": "https://arxiv.org/abs/2508.03120", "authors": ["Jiangyou Zhu", "Hongyu Deng", "He Chen"], "title": "Can Large Language Models Identify Materials from Radar Signals?", "comment": null, "summary": "Accurately identifying the material composition of objects is a critical\ncapability for AI robots powered by large language models (LLMs) to perform\ncontext-aware manipulation. Radar technologies offer a promising sensing\nmodality for material recognition task. When combined with deep learning, radar\ntechnologies have demonstrated strong potential in identifying the material of\nvarious objects. However, existing radar-based solutions are often constrained\nto closed-set object categories and typically require task-specific data\ncollection to train deep learning models, largely limiting their practical\napplicability. This raises an important question: Can we leverage the powerful\nreasoning capabilities of pre-trained LLMs to directly infer material\ncomposition from raw radar signals? Answering this question is non-trivial due\nto the inherent redundancy of radar signals and the fact that pre-trained LLMs\nhave no prior exposure to raw radar data during training. To address this, we\nintroduce LLMaterial, the first study to investigate the feasibility of using\nLLM to identify materials directly from radar signals. First, we introduce a\nphysics-informed signal processing pipeline that distills high-redundancy radar\nraw data into a set of compact intermediate parameters that encapsulate the\nmaterial's intrinsic characteristics. Second, we adopt a retrieval-augmented\ngeneration (RAG) strategy to provide the LLM with domain-specific knowledge,\nenabling it to interpret and reason over the extracted intermediate parameters.\nLeveraging this integration, the LLM is empowered to perform step-by-step\nreasoning on the condensed radar features, achieving open-set material\nrecognition directly from raw radar signals. Preliminary results show that\nLLMaterial can effectively distinguish among a variety of common materials,\nhighlighting its strong potential for real-world material identification\napplications."}
{"id": "2508.03131", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.03131", "abs": "https://arxiv.org/abs/2508.03131", "authors": ["Na Liu", "Chengliang Dai", "Qiuyue Wu", "Qiuqi Li", "Guoxiong Cai"], "title": "Model Order Reduction for Large-scale Circuits Using Higher Order Dynamic Mode Decomposition", "comment": null, "summary": "Model order reduction (MOR) has long been a mainstream strategy to accelerate\nlarge-scale transient circuit simulation. Dynamic Mode Decomposition (DMD)\nrepresents a novel data-driven characterization method, extracting dominant\ndynamical modes directly from time-domain simulation data without requiring\nexplicit system equations. This paper first deduces the DMD algorithm and then\nproposes high order dynamic mode decomposition (HODMD) incorporating delayed\nembedding technique, specifically targeting computational efficiency in\nlarge-scale circuit simulations. Compared with the DMD method, the HODMD method\novercomes the problem that the output signal cannot be reconstructed when the\nspatial resolution is insufficient. The proposed HODMD algorithm is applicable\nto general circuits and does not impose any constraints on the topology of the\npertinent circuit or type of the components. Three representative numerical\ntest cases are presented to systematically validate both the computational\nefficiency and accuracy of the proposed HODMD method."}
{"id": "2508.03248", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.03248", "abs": "https://arxiv.org/abs/2508.03248", "authors": ["Yoon Huh", "Bumjun Kim", "Wan Choi"], "title": "Federated Learning with Feature Reconstruction for Vector Quantization based Semantic Communication", "comment": null, "summary": "Recent advancements in semantic communication have primarily focused on image\ntransmission, where neural network (NN)-based joint source-channel coding\n(JSCC) modules play a central role. However, such systems often experience\nsemantic communication errors due to mismatched knowledge bases between users\nand performance degradation from outdated models, necessitating regular model\nupdates. To address these challenges in vector quantization (VQ)-based image\nsemantic communication systems, we propose FedSFR, a novel federated learning\n(FL) framework that incorporates semantic feature reconstruction (FR). FedSFR\nintroduces an FR step at the parameter server (PS) and allows a subset of\nclients to transmit compact feature vectors in lieu of sending full local model\nupdates, thereby improving training stability and communication efficiency. To\nenable effective FR learning, we design a loss function tailored for VQ-based\nimage semantic communication and demonstrate its validity as a surrogate for\nimage reconstruction error. Additionally, we provide a rigorous convergence\nanalysis and present a differentially private variant of FedSFR, along with\nformal privacy analysis. Experimental results on two benchmark datasets\nvalidate the superiority of FedSFR over existing baselines, especially in\ncapacity-constrained settings, confirming both its effectiveness and\nrobustness."}
{"id": "2508.03274", "categories": ["eess.SP", "cs.ET", "cs.HC", "cs.IR"], "pdf": "https://arxiv.org/pdf/2508.03274", "abs": "https://arxiv.org/abs/2508.03274", "authors": ["Ramaswamy Palaniappan", "Surej Mouli", "Howard Bowman", "Ian McLoughlin"], "title": "Investigating the Cognitive Response of Brake Lights in Initiating Braking Action Using EEG", "comment": "arXiv admin note: text overlap with arXiv:2010.10584", "summary": "Half of all road accidents result from either lack of driver attention or\nfrom maintaining insufficient separation between vehicles. Collision from the\nrear, in particular, has been identified as the most common class of accident\nin the UK, and its influencing factors have been widely studied for many years.\nRear-mounted stop lamps, illuminated when braking, are the primary mechanism to\nalert following drivers to the need to reduce speed or brake. This paper\ndevelops a novel brain response approach to measuring subject reaction to\ndifferent brake light designs. A variety of off-the-shelf brake light\nassemblies are tested in a physical simulated driving environment to assess the\ncognitive reaction times of 22 subjects. Eight pairs of LED-based and two pairs\nof incandescent bulb-based brake light assemblies are used and\nelectroencephalogram (EEG) data recorded. Channel Pz is utilised to extract the\nP3 component evoked during the decision making process that occurs in the brain\nwhen a participant decides to lift their foot from the accelerator and depress\nthe brake. EEG analysis shows that both incandescent bulb-based lights are\nstatistically slower to evoke cognitive responses than all tested LED-based\nlights. Between the LED designs, differences are evident, but not statistically\nsignificant, attributed to the significant amount of movement artifact in the\nEEG signal."}
{"id": "2508.03279", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.03279", "abs": "https://arxiv.org/abs/2508.03279", "authors": ["Vasileios Kouvakis", "Stylianos E. Trevlakis", "Ioannis Arapakis", "Alexandros-Apostolos A. Boulogeorgos"], "title": "Spiking Neural Networks for Resource Allocation in UAV-Enabled Wireless Networks", "comment": null, "summary": "This work presents a new spiking neural network (SNN)-based approach for user\nequipment-base station (UE-BS) association in non-terrestrial networks (NTNs).\nWith the introduction of UAV's in wireless networks, the system architecture\nbecomes heterogeneous, resulting in the need for dynamic and efficient\nmanagement to avoid congestion and sustain overall performance. The presented\nframework compares two SNN-based optimization strategies. Specifically, a\ntop-down centralized approach with complete network visibility and a bottom-up\ndistributed approach for individual network nodes. The SNN is based on leak\nintegrate-and-fire neurons with temporal components, which can perform fast and\nefficient event-driven inference. Realistic ray-tracing simulations are\nconducted, which showcase that the bottom-up model attains over 90\\% accuracy,\nwhile the top-down model maintains 80-100\\% accuracy. Both approaches reveal a\ntrade-off between individually optimal solutions and UE-BS association\nfeasibility, thus revealing the effectiveness of both approaches depending on\ndeployment scenarios."}
{"id": "2508.03327", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.03327", "abs": "https://arxiv.org/abs/2508.03327", "authors": ["Xingyu Huang", "Ruining Fan", "Mouli Chakraborty", "Avishek Nag", "Anshu Mukherjee"], "title": "Quantum Deep Learning for Massive MIMO User Scheduling", "comment": null, "summary": "We introduce a hybrid Quantum Neural Networks (QNN) architecture for the\nefficient user scheduling in 5G/Beyond 5G (B5G) massive Multiple Input Multiple\nOutput (MIMO) systems, addressing the scalability issues of traditional\nmethods. By leveraging statistical Channel State Information (CSI), our model\nreduces computational overhead and enhances spectral efficiency. It integrates\nclassical neural networks with a variational quantum circuit kernel,\noutperforming classical Convolutional Neural Networks (CNNs) and maintaining\nrobust performance in noisy channels. This demonstrates the potential of\nquantum-enhanced Machine Learning (ML) for wireless scheduling."}
{"id": "2508.03391", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.03391", "abs": "https://arxiv.org/abs/2508.03391", "authors": ["Seunghyeon Jeon", "Seonjung Kim", "Gyeongrae Im", "Yo-Seb Jeon"], "title": "Beam-Hopping Pattern Design for Grant-Free Random Access in LEO Satellite Communications", "comment": null, "summary": "Increasing demand for massive device connectivity in underserved regions\ndrives the development of advanced low Earth orbit (LEO) satellite\ncommunication systems. Beam-hopping LEO systems without connection\nestablishment provide a promising solution for achieving both demand-aware\nresource allocation and low access latency. This paper investigates\nbeam-hopping pattern design for the grant-free random access systems to\ndynamically allocate satellite resources according to traffic demands across\nserving cells. We formulate a binary optimization problem that aims to maximize\nthe minimum successful transmission probability across cells, given limited\nsatellite beam generation capacity. To solve this problem, we propose novel\nbeam-hopping design algorithms that alternately enhance the collision avoidance\nrate and decoding success probability within an alternating optimization\nframework. Specifically, the algorithms employ a bisection method to optimize\nillumination allocation for each cell based on demand, while using the\nalternating direction method of multipliers (ADMM) to optimize beam-hopping\npatterns for maximizing decoding success probability. Furthermore, we enhance\nthe ADMM by replacing the strict binary constraint with two equivalent\ncontinuous-valued constraints. Simulation results demonstrate the superiority\nof the proposed algorithms compared to other beam-hopping methods and verify\nrobustness in managing traffic demand imbalance."}
{"id": "2508.03423", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.03423", "abs": "https://arxiv.org/abs/2508.03423", "authors": ["Isabella W. G. da Silva", "Zahra Mobini", "Hien Q. Ngo", "Hyundong Shin", "Michail Matthaiou"], "title": "How to Proactively Monitor Untrusted Communications with Cell-Free Massive MIMO?", "comment": null, "summary": "This paper studies a cell-free massive multiple-input multiple-output\n(CF-mMIMO) proactive monitoring system in which multiple multi-antenna\nmonitoring nodes (MNs) are assigned to either observe the transmissions from an\nuntrusted transmitter (UT) or to jam the reception at the untrusted receiver\n(UR). We propose an effective channel state information (CSI) acquisition\nscheme for the monitoring system. In our approach, the MNs leverage the pilot\nsignals transmitted during the uplink and downlink phases of the untrusted link\nand estimate the effective channels corresponding to the UT and UR via a\nminimum mean-squared error (MMSE) estimation scheme. We derive new spectral\nefficiency (SE) expressions for the untrusted link and the monitoring system.\nFor the latter, the SE is derived for two CSI availability cases at the central\nprocessing unit (CPU); namely case-1: imperfect CSI knowledge at both MNs and\nCPU, case-2: imperfect CSI knowledge at the MNs and no CSI knowledge at the\nCPU. To improve the monitoring performance, we propose a novel joint mode\nassignment and jamming power control optimization method to maximize the\nmonitoring success probability (MSP) based on the Bayesian optimization\nframework. Numerical results show that (a) our CF-mMIMO proactive monitoring\nsystem relying on the proposed CSI acquisition and optimization approach\nsignificantly outperforms the considered benchmarks; (b) the MSP performance of\nour CF-mMIMO proactive monitoring system is greater than 0.8, regardless of the\nnumber of antennas at the untrusted nodes or the precoding scheme for the\nuntrusted transmission link."}
{"id": "2508.03460", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.03460", "abs": "https://arxiv.org/abs/2508.03460", "authors": ["Anubhab Chowdhury", "Sai Subramanyam Thoota", "Erik G. Larsson"], "title": "Joint Sensing and Bi-Directional Communication with Dynamic TDD Enabled Cell-Free MIMO", "comment": "Accepted for publication in the IEEE Transactions on Wireless\n  Communications 14 pages, 9 figures (one with two subfigures)", "summary": "This paper studies integrated sensing and communication (ISAC) with dynamic\ntime division duplex (DTDD) cell-free (CF) massive multiple-input\nmultiple-output~(mMIMO) systems. DTDD enables the CF mMIMO system to\nconcurrently serve both uplink~(UL) and downlink~(DL) users with spatially\nseparated \\emph{half-duplex~(HD)} access points~(APs) using the same\ntime-frequency resources. Further, to facilitate ISAC, the UL APs are utilized\nfor both UL data and target echo reception, while the DL APs jointly transmit\nthe precoded DL data streams and target signal. In this context, we present\ncentralized and distributed generalized likelihood-ratio tests~(GLRTs) for\ntarget detection treating UL users' signals as sensing interference. We then\nquantify the optimality and complexity trade-off between distributed and\ncentralized GLRTs and benchmark the respective estimators with the Bayesian\nCram\\'er-Rao lower bound for target radar-cross section~(RCS). Then, we present\na unified framework for joint UL users' data detection and RCS estimation.\nNext, for communication, we derive the signal-to-noise-plus-interference~(SINR)\noptimal combiner accounting for the cross-link and radar interference for UL\ndata processing. In DL, we use regularized zero-forcing for the users and\npropose two types of precoders for the target: one ``user-centric\" that\nnullifies the interference caused by the target signal to the DL users and one\n``target-centric\" based on the dominant eigenvector of the composite channel\nbetween the target and the APs. Finally, numerical studies corroborate with our\ntheoretical findings and reveal that the \\emph{GLRT is robust to inter-AP\ninterference, and DTDD doubles the $90\\%$-likely sum UL-DL SE compared to\ntraditional TDD-based CF-mMIMO ISAC systems}; while using HD hardware."}
{"id": "2508.03584", "categories": ["eess.SP", "cs.AI", "cs.ET", "cs.NI", "q-bio.MN"], "pdf": "https://arxiv.org/pdf/2508.03584", "abs": "https://arxiv.org/abs/2508.03584", "authors": ["Fatih Gulec", "Hamdan Awan", "Nigel Wallbridge", "Andrew W. Eckford"], "title": "Decoding and Engineering the Phytobiome Communication for Smart Agriculture", "comment": "Under revision for IEEE Communications Magazine", "summary": "Smart agriculture applications, integrating technologies like the Internet of\nThings and machine learning/artificial intelligence (ML/AI) into agriculture,\nhold promise to address modern challenges of rising food demand, environmental\npollution, and water scarcity. Alongside the concept of the phytobiome, which\ndefines the area including the plant, its environment, and associated\norganisms, and the recent emergence of molecular communication (MC), there\nexists an important opportunity to advance agricultural science and practice\nusing communication theory. In this article, we motivate to use the\ncommunication engineering perspective for developing a holistic understanding\nof the phytobiome communication and bridge the gap between the phytobiome\ncommunication and smart agriculture. Firstly, an overview of phytobiome\ncommunication via molecular and electrophysiological signals is presented and a\nmulti-scale framework modeling the phytobiome as a communication network is\nconceptualized. Then, how this framework is used to model electrophysiological\nsignals is demonstrated with plant experiments. Furthermore, possible smart\nagriculture applications, such as smart irrigation and targeted delivery of\nagrochemicals, through engineering the phytobiome communication are proposed.\nThese applications merge ML/AI methods with the Internet of Bio-Nano-Things\nenabled by MC and pave the way towards more efficient, sustainable, and\neco-friendly agricultural production. Finally, the implementation challenges,\nopen research issues, and industrial outlook for these applications are\ndiscussed."}
{"id": "2508.02726", "categories": ["eess.IV", "cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2508.02726", "abs": "https://arxiv.org/abs/2508.02726", "authors": ["Lucio Pinello", "Francesco Cadini", "Luca Lomazzi"], "title": "MPCA-based Domain Adaptation for Transfer Learning in Ultrasonic Guided Waves", "comment": null, "summary": "Ultrasonic Guided Waves (UGWs) represent a promising diagnostic tool for\nStructural Health Monitoring (SHM) in thin-walled structures, and their\nintegration with machine learning (ML) algorithms is increasingly being adopted\nto enable real-time monitoring capabilities. However, the large-scale\ndeployment of UGW-based ML methods is constrained by data scarcity and limited\ngeneralisation across different materials and sensor configurations. To address\nthese limitations, this work proposes a novel transfer learning (TL) framework\nbased on Multilinear Principal Component Analysis (MPCA). First, a\nConvolutional Neural Network (CNN) for regression is trained to perform damage\nlocalisation for a plated structure. Then, MPCA and fine-tuning are combined to\nhave the CNN work for a different plate. By jointly applying MPCA to the source\nand target domains, the method extracts shared latent features, enabling\neffective domain adaptation without requiring prior assumptions about\ndimensionality. Following MPCA, fine-tuning enables adapting the pre-trained\nCNN to a new domain without the need for a large training dataset. The proposed\nMPCA-based TL method was tested against 12 case studies involving different\ncomposite materials and sensor arrays. Statistical metrics were used to assess\ndomains alignment both before and after MPCA, and the results demonstrate a\nsubstantial reduction in localisation error compared to standard TL techniques.\nHence, the proposed approach emerges as a robust, data-efficient, and\nstatistically based TL framework for UGW-based SHM."}
{"id": "2508.02839", "categories": ["eess.IV", "eess.SP"], "pdf": "https://arxiv.org/pdf/2508.02839", "abs": "https://arxiv.org/abs/2508.02839", "authors": ["Zack Dewis", "Zhengsen Xu", "Yimin Zhu", "Motasem Alkayid", "Mabel Heffring", "Lincoln Linlin Xu"], "title": "Spatial-Temporal-Spectral Mamba with Sparse Deformable Token Sequence for Enhanced MODIS Time Series Classification", "comment": null, "summary": "Although MODIS time series data are critical for supporting dynamic,\nlarge-scale land cover land use classification, it is a challenging task to\ncapture the subtle class signature information due to key MODIS difficulties,\ne.g., high temporal dimensionality, mixed pixels, and spatial-temporal-spectral\ncoupling effect. This paper presents a novel spatial-temporal-spectral Mamba\n(STSMamba) with deformable token sequence for enhanced MODIS time series\nclassification, with the following key contributions. First, to disentangle\ntemporal-spectral feature coupling, a temporal grouped stem (TGS) module is\ndesigned for initial feature learning. Second, to improve Mamba modeling\nefficiency and accuracy, a sparse, deformable Mamba sequencing (SDMS) approach\nis designed, which can reduce the potential information redundancy in Mamba\nsequence and improve the adaptability and learnability of the Mamba sequencing.\nThird, based on SDMS, to improve feature learning, a novel\nspatial-temporal-spectral Mamba architecture is designed, leading to three\nmodules, i.e., a sparse deformable spatial Mamba module (SDSpaM), a sparse\ndeformable spectral Mamba module (SDSpeM), and a sparse deformable temporal\nMamba module (SDTM) to explicitly learn key information sources in MODIS. The\nproposed approach is tested on MODIS time series data in comparison with many\nstate-of-the-art approaches, and the results demonstrate that the proposed\napproach can achieve higher classification accuracy with reduced computational\ncomplexity."}
