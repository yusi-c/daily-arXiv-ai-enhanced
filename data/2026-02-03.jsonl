{"id": "2602.00042", "categories": ["eess.SP", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00042", "abs": "https://arxiv.org/abs/2602.00042", "authors": ["Zhihan Zeng", "Hongyuan Shu", "Kaihe Wang", "Lu Chen", "Amir Hussian", "Yanjun Huang", "Junchu Zhao", "Yue Xiu", "Zhongpei Zhang"], "title": "JSR-GFNet: Jamming-to-Signal Ratio-Aware Dynamic Gating for Interference Classification in future Cognitive Global Navigation Satellite Systems", "comment": null, "summary": "The transition toward cognitive global navigation satellite system (GNSS) receivers requires accurate interference classification to trigger adaptive mitigation strategies. However, conventional methods relying on Time-Frequency Analysis (TFA) and Convolutional Neural Networks (CNNs) face two fundamental limitations: severe performance degradation in low Jamming-to-Signal Ratio (JSR) regimes due to noise obscuration, and ``feature degeneracy'' caused by the loss of phase information in magnitude-only spectrograms. Consequently, spectrally similar signals -- such as high-order Quadrature Amplitude Modulation versus Band-Limited Gaussian Noise -- become indistinguishable. To overcome these challenges, this paper proposes the \\textbf{JSR-Guided Fusion Network (JSR-GFNet)}. This multi-modal architecture combines phase-sensitive complex In-Phase/Quadrature (IQ) samples with Short-Time Fourier Transform (STFT) spectrograms. Central to this framework is a physics-inspired dynamic gating mechanism driven by statistical signal descriptors. Acting as a conditional controller, it autonomously estimates signal reliability to dynamically reweight the contributions of a Complex-Valued ResNet (IQ stream) and an EfficientNet backbone (STFT stream). To validate the model, we introduce the Comprehensive GNSS Interference (CGI-21) dataset, simulating 21 jamming categories including software-defined waveforms from aerial platforms. Extensive experiments demonstrate that JSR-GFNet achieves higher accuracy across the full 10--50 dB JSR spectrum. Notably, interpretability analysis confirms that the model learns a physically intuitive strategy: prioritizing spectral energy integration in noise-limited regimes while shifting focus to phase precision in high-SNR scenarios to resolve modulation ambiguities. This framework provides a robust solution for next-generation aerospace navigation security."}
{"id": "2602.00100", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.00100", "abs": "https://arxiv.org/abs/2602.00100", "authors": ["Avinash Kadimisetty", "C. Oswald", "B. Sivalselvan"], "title": "Frequent Pattern Mining approach to Image Compression", "comment": null, "summary": "The paper focuses on Image Compression, explaining efficient approaches based on Frequent Pattern Mining(FPM). The proposed compression mechanism is based on clustering similar pixels in the image and thus using cluster identifiers in image compression. Redundant data in the image is effectively handled by replacing the DCT phase of conventional JPEG through a mixture of k-means Clustering and Closed Frequent Sequence Mining. To optimize the cardinality of pattern(s) in encoding, efficient pruning techniques have been used through the refinement of Conventional Generalized Sequential Pattern Mining(GSP) algorithm. We have proposed a mechanism for finding the frequency of a sequence which will yield significant reduction in the code table size. The algorithm is tested by compressing benchmark datasets yielding an improvement of 45% in compression ratios, often outperforming the existing alternatives. PSNR and SSIM, which are the image quality metrics, have been tested which show a negligible loss in visual quality."}
{"id": "2602.00054", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.00054", "abs": "https://arxiv.org/abs/2602.00054", "authors": ["Bixing Yan", "Kwadwo Mensah Obeng Afrane", "Achiel Colpaert", "Andre Kokkeler", "Sofie Pollin", "Yang Miao"], "title": "Experimental Validation of SBFD ISAC in an FR3 Distributed SIMO Testbed", "comment": "6 pages, 10 figures. Accepted by ICC 2026", "summary": "Integrated sensing and communication (ISAC) is a key enabler for future radio networks. This paper presents a sub-band full-duplex (SBFD) ISAC system that assigns non-overlapping OFDM subbands to sensing and communication, enabling simultaneous operation with minimal interference. A distributed testbed with three SIMO nodes is implemented using USRP X410 devices operating at 6.8 GHz with 20 MHz bandwidth per channel. A total of 2048 OFDM subcarriers are partitioned into three subbands: two for sensing using Zadoff-Chu sequences and one for communication using QPSK. Each USRP transmits one subband while receiving signals across all three, forming a 1 x 3 SIMO node. Time synchronization is achieved through host-server coordination without external clock distribution. Indoor measurements, validated against MOCAP ground truth, confirm the feasibility of the SBFD ISAC system. The results demonstrate monostatic sensing with a velocity resolution of 0.145 m/s, and communication under NLoS conditions with a BER of 3.63e-3. Compared with a multiband benchmark requiring three times more spectrum, the SBFD configuration achieves comparable velocity estimation accuracy while conserving resources. The sensing and communication performance trade-off is determined by subcarrier allocation strategy rather than mutual interference."}
{"id": "2602.00102", "categories": ["eess.IV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00102", "abs": "https://arxiv.org/abs/2602.00102", "authors": ["Fnu Neha", "Deepak kumar Shukla"], "title": "Radiomics in Medical Imaging: Methods, Applications, and Challenges", "comment": null, "summary": "Radiomics enables quantitative medical image analysis by converting imaging data into structured, high-dimensional feature representations for predictive modeling. Despite methodological developments and encouraging retrospective results, radiomics continue to face persistent challenges related to feature instability, limited reproducibility, validation bias, and restricted clinical translation. Existing reviews largely focus on application-specific outcomes or isolated pipeline components, with limited analysis of how interdependent design choices across acquisition, preprocessing, feature engineering, modeling, and evaluation collectively affect robustness and generalizability. This survey provides an end-to-end analysis of radiomics pipelines, examining how methodological decisions at each stage influence feature stability, model reliability, and translational validity. This paper reviews radiomic feature extraction, selection, and dimensionality reduction strategies; classical machine and deep learning-based modeling approaches; and ensemble and hybrid frameworks, with emphasis on validation protocols, data leakage prevention, and statistical reliability. Clinical applications are discussed with a focus on evaluation rigor rather than reported performance metrics. The survey identifies open challenges in standardization, domain shift, and clinical deployment, and outlines future directions such as hybrid radiomics-artificial intelligence models, multimodal fusion, federated learning, and standardized benchmarking."}
{"id": "2602.00431", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.00431", "abs": "https://arxiv.org/abs/2602.00431", "authors": ["Muddasir Rahim", "Soumaya Cherkaoui"], "title": "Dual-Tier IRS-Assisted Mid-Band 6G Mobile Networks: Robust Beamforming and User Association", "comment": null, "summary": "The rapid growth of Internet of Things (IoT) applications necessitates robust resource allocation in future sixth-generation (6G) networks, particularly at the upper mid-band (7-15 GHz, FR3). This paper presents a novel intelligent reconfigurable surface (IRS)-assisted framework combining terrestrial IRS (TIRS) and aerial IRS (AIRS) mounted on low-altitude platform stations, to ensure reliable connectivity under severe line-of-sight (LoS) blockages. Distinguishing itself from prior work restricted to terrestrial IRS and mmWave and THz bands, this work targets the FR3 spectrum, the so-called Golden Band for 6G. The joint beamforming and user association (JBUA) problem is formulated as a mixed-integer nonlinear program (MINLP), solved through problem decomposition, zero-forcing beamforming, and a stable matching algorithm. Comprehensive simulations show our method approaches exhaustive search performance with significantly lower complexity, outperforming existing greedy and random baselines. These results provide a scalable blueprint for real-world 6G deployments, supporting massive IoT connectivity in challenging environments."}
{"id": "2602.00136", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.00136", "abs": "https://arxiv.org/abs/2602.00136", "authors": ["Ti Ti Nguyen", "Thanh-Dung Le", "Vu Nguyen Ha", "Duc-Dung Tran", "Hung Nguyen-Kha", "Dinh-Hieu Tran", "Carlos L. Marcos-Rojas", "Juan C. Merlano-Duncan", "Symeon Chatzinotas"], "title": "Toward a Unified Semantic Loss Model for Deep JSCC-based Transmission of EO Imagery", "comment": "5 pages, 5 figures", "summary": "Modern Earth Observation (EO) systems increasingly rely on high-resolution imagery to support critical applications such as environmental monitoring, disaster response, and land-use analysis. Although these applications benefit from detailed visual data, the resulting data volumes impose significant challenges on satellite communication systems constrained by limited bandwidth, power, and dynamic link conditions. To address these limitations, this paper investigates Deep Joint Source-Channel Coding (DJSCC) as an effective source-channel paradigm for the transmission of EO imagery. We focus on two complementary aspects of semantic loss in DJSCC-based systems. First, a reconstruction-centric framework is evaluated by analyzing the semantic degradation of reconstructed images under varying compression ratios and channel signal-to-noise ratios (SNR). Second, a task-oriented framework is developed by integrating DJSCC with lightweight, application-specific models (e.g., EfficientViT), with performance measured using downstream task accuracy rather than pixel-level fidelity. Based on extensive empirical analysis, we propose a unified semantic loss framework that captures both reconstruction-centric and task-oriented performance within a single model. This framework characterizes the implicit relationship between JSCC compression, channel SNR, and semantic quality, offering actionable insights for the design of robust and efficient EO imagery transmission under resource-constrained satellite links."}
{"id": "2602.00438", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.00438", "abs": "https://arxiv.org/abs/2602.00438", "authors": ["Muddasir Rahim", "Soumaya Cherkaoui"], "title": "Reliable IoT Communications in 6G Non-Terrestrial Networks with Dual RIS", "comment": null, "summary": "The increasing demand for Internet of Things (IoT) applications has accelerated the need for robust resource allocation in sixth-generation (6G) networks. In this paper, we propose a reconfigurable intelligent surface (RIS)-assisted upper mid-band communication framework. To ensure robust connectivity under severe line-of-sight (LoS) blockages, we use a two-tier RIS structure comprising terrestrial RISs (TRISs) and high-altitude platform station (HAPS)-mounted RISs (HRISs). To maximize network sum rate, we formulate a joint beamforming, power allocation, and IoT device association (JBPDA) problem as a mixed-integer nonlinear program (MINLP). The formulated MINLP problem is challenging to solve directly; therefore, we tackle it via a decomposition approach. The zero-forcing (ZF) technique is used to optimize the beamforming matrix, a closed-form expression for power allocation is derived, and a stable matching-based algorithm is proposed for device-RIS association based on achievable data rates. Comprehensive simulations demonstrate that the proposed scheme approaches the performance of exhaustive search (ES) while exhibiting substantially lower complexity, and it consistently outperforms greedy search (GS) and random search (RS) baselines. Moreover, the proposed scheme converges much faster than the ES scheme."}
{"id": "2602.00184", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.00184", "abs": "https://arxiv.org/abs/2602.00184", "authors": ["Yiyang Wen", "Liu Shi", "Zekun Zhou", "WenZhe Shan", "Qiegen Liu"], "title": "Visible Singularities Guided Correlation Network for Limited-Angle CT Reconstruction", "comment": null, "summary": "Limited-angle computed tomography (LACT) offers the advantages of reduced radiation dose and shortened scanning time. Traditional reconstruction algorithms exhibit various inherent limitations in LACT. Currently, most deep learning-based LACT reconstruction methods focus on multi-domain fusion or the introduction of generic priors, failing to fully align with the core imaging characteristics of LACT-such as the directionality of artifacts and directional loss of structural information, which are caused by the absence of projection angles in certain directions. Inspired by the theory of visible and invisible singularities, taking into account the aforementioned core imaging characteristics of LACT, we propose a Visible Singularities Guided Correlation network for LACT reconstruction (VSGC). The design philosophy of VSGC consists of two core steps: First, extract VS edge features from LACT images and focus the model's attention on these VS. Second, establish correlations between the VS edge features and other regions of the image. Additionally, a multi-scale loss function with anisotropic constraint is employed to constrain the model to converge in multiple aspects. Finally, qualitative and quantitative validations are conducted on both simulated and real datasets to verify the effectiveness and feasibility of the proposed design. Particularly, in comparison with alternative methods, VSGC delivers more prominent performance in small angular ranges, with the PSNR improvement of 2.45 dB and the SSIM enhancement of 1.5\\%. The code is publicly available at https://github.com/yqx7150/VSGC."}
{"id": "2602.00664", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.00664", "abs": "https://arxiv.org/abs/2602.00664", "authors": ["Tong An", "Jiwei Zhao", "Jiayang Shi", "Bin Zheng", "Kai Yu", "Maged Elkashlan", "George K. Karagiannidis", "Hongsheng Chen"], "title": "Fronthaul-Efficient Distributed Cooperative 3D Positioning with Quantized Latent CSI Embeddings", "comment": "13 pages, 14 figures", "summary": "High-precision three-dimensional (3D) positioning in dense urban non-line-of-sight (NLOS) environments benefits significantly from cooperation among multiple distributed base stations (BSs). However, forwarding raw CSI from multiple BSs to a central unit (CU) incurs prohibitive fronthaul overhead, which limits scalable cooperative positioning in practice. This paper proposes a learning-based edge-cloud cooperative positioning framework under limited-capacity fronthaul constraints. In the proposed architecture, a neural network is deployed at each BS to compress the locally estimated CSI into a quantized representation subject to a fixed fronthaul payload. The quantized CSI is transmitted to the CU, which performs cooperative 3D positioning by jointly processing the compressed CSI received from multiple BSs. The proposed framework adopts a two-stage training strategy consisting of self-supervised local training at the BSs and end-to-end joint training for positioning at the CU. Simulation results based on a 3.5~GHz 5G NR compliant urban ray-tracing scenario with six BSs and 20~MHz bandwidth show that the proposed method achieves a mean 3D positioning error of 0.48~m and a 90th-percentile error of 0.83~m, while reducing the fronthaul payload to 6.25% of lossless CSI forwarding. The achieved performance is close to that of cooperative positioning with full CSI exchange."}
{"id": "2602.00186", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.00186", "abs": "https://arxiv.org/abs/2602.00186", "authors": ["Tingyu Fan", "Ran Gong", "Yueyu Hu", "Yao Wang"], "title": "SurfelSoup: Learned Point Cloud Geometry Compression With a Probablistic SurfelTree Representation", "comment": null, "summary": "This paper presents SurfelSoup, an end-to-end learned surface-based framework for point cloud geometry compression, with surface-structured primitives for representation. It proposes a probabilistic surface representation, pSurfel, which models local point occupancies using a bounded generalized Gaussian distribution. In addition, the pSurfels are organized into an octree-like hierarchy, pSurfelTree, with a Tree Decision module that adaptively terminates the tree subdivision for rate-distortion optimal Surfel granularity selection. This formulation avoids redundant point-wise compression in smooth regions and produces compact yet smooth surface reconstructions. Experimental results under the MPEG common test condition show consistent gain on geometry compression over voxel-based baselines and MPEG standard G-PCC-GesTM-TriSoup, while providing visually superior reconstructions with smooth and coherent surface structures."}
{"id": "2602.00696", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.00696", "abs": "https://arxiv.org/abs/2602.00696", "authors": ["Tong An", "Huan Lu", "Jiayang Shi", "Kai Yu", "Rongrong Zhu", "Bin Zheng", "Jiwei Zhao", "Haibo Zhou"], "title": "CMANet: Channel-Masked Attention Network for Cooperative Multi-Base-Station 3D Positioning", "comment": "6pages, 6 figures", "summary": "Achieving ubiquitous high-accuracy localization is crucial for next-generation wireless systems, yet remains challenging in multipath-rich urban environments. By exploiting the fine-grained multipath characteristics embedded in channel state information (CSI), more reliable and precise localization can be achieved. To address this, we present CMANet, a multi-BS cooperative positioning architecture that performs feature-level fusion of raw CSI using the proposed Channel Masked Attention (CMA) mechanism. The CMA encoder injects a physically grounded prior--per-BS channel gain--into the attention weights, thus emphasizing reliable links and suppressing spurious multipath. A lightweight LSTM decoder then treats subcarriers as a sequence to accumulate frequency-domain evidence into a final 3D position estimate. In a typical 5G NR-compliant urban simulation, CMANet achieves less than 0.5m median error and 1.0m 90th-percentile error, outperforming state-of-the-art benchmarks. Ablations verify the necessity of CMA and frequency accumulation. CMANet is edge-deployable and exemplifies an Integrated Sensing and Communication (ISAC)-aligned, cooperative paradigm for multi-BS CSI positioning."}
{"id": "2602.00198", "categories": ["eess.IV", "cs.AI", "cs.MM"], "pdf": "https://arxiv.org/pdf/2602.00198", "abs": "https://arxiv.org/abs/2602.00198", "authors": ["Esteban Pesnel", "Julien Le Tanou", "Michael Ropert", "Thomas Maugey", "Aline Roumy"], "title": "SCALED : Surrogate-gradient for Codec-Aware Learning of Downsampling in ABR Streaming", "comment": null, "summary": "The rapid growth in video consumption has introduced significant challenges to modern streaming architectures. Over-the-Top (OTT) video delivery now predominantly relies on Adaptive Bitrate (ABR) streaming, which dynamically adjusts bitrate and resolution based on client-side constraints such as display capabilities and network bandwidth. This pipeline typically involves downsampling the original high-resolution content, encoding and transmitting it, followed by decoding and upsampling on the client side. Traditionally, these processing stages have been optimized in isolation, leading to suboptimal end-to-end rate-distortion (R-D) performance. The advent of deep learning has spurred interest in jointly optimizing the ABR pipeline using learned resampling methods. However, training such systems end-to-end remains challenging due to the non-differentiable nature of standard video codecs, which obstructs gradient-based optimization. Recent works have addressed this issue using differentiable proxy models, based either on deep neural networks or hybrid coding schemes with differentiable components such as soft quantization, to approximate the codec behavior. While differentiable proxy codecs have enabled progress in compression-aware learning, they remain approximations that may not fully capture the behavior of standard, non-differentiable codecs. To our knowledge, there is no prior evidence demonstrating the inefficiencies of using standard codecs during training. In this work, we introduce a novel framework that enables end-to-end training with real, non-differentiable codecs by leveraging data-driven surrogate gradients derived from actual compression errors. It facilitates the alignment between training objectives and deployment performance. Experimental results show a 5.19\\% improvement in BD-BR (PSNR) compared to codec-agnostic training approaches, consistently across the entire rate-distortion convex hull spanning multiple downsampling ratios."}
{"id": "2602.00705", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.00705", "abs": "https://arxiv.org/abs/2602.00705", "authors": ["Mouli Chakraborty", "Subhash Chandra", "Avishek Nag", "Trung Q. Duong", "Merouane Debbah", "Anshu Mukherjee"], "title": "Comparative Analysis of Differential and Collision Entropy for Finite-Regime QKD in Hybrid Quantum Noisy Channels", "comment": null, "summary": "In this work, a comparative study between three fundamental entropic measures, differential entropy, quantum Renyi entropy, and quantum collision entropy for a hybrid quantum channel (HQC) was investigated, where hybrid quantum noise (HQN) is characterized by both discrete and continuous variables (CV) noise components. Using a Gaussian mixture model (GMM) to statistically model the HQN, we construct as well as visualize the corresponding pointwise entropic functions in a given 3D probabilistic landscape. When integrated over the relevant state space, these entropic surfaces yield values of the respective global entropy. Through analytical and numerical evaluation, it is demonstrated that the differential entropy approaches the quantum collision entropy under certain mixing conditions, which aligns with the Renyi entropy for order $α= 2$. Within the HQC framework, the results establish a theoretical and computational equivalence between these measures. This provides a unified perspective on quantifying uncertainty in hybrid quantum communication systems. Extending the analysis to the operational domain of finite key QKD, we demonstrated that the same $10\\%$ approximation threshold corresponds to an order-of-magnitude change in Eves success probability and a measurable reduction in the secure key rate."}
{"id": "2602.00215", "categories": ["eess.IV", "cs.CV", "eess.SP"], "pdf": "https://arxiv.org/pdf/2602.00215", "abs": "https://arxiv.org/abs/2602.00215", "authors": ["Abhinav V. Sambasivan", "Liam J. Coulter", "Richard G. Paxman", "Jarvis D. Haupt"], "title": "A Renderer-Enabled Framework for Computing Parameter Estimation Lower Bounds in Plenoptic Imaging Systems", "comment": null, "summary": "This work focuses on assessing the information-theoretic limits of scene parameter estimation in plenoptic imaging systems. A general framework to compute lower bounds on the parameter estimation error from noisy plenoptic observations is presented, with a particular focus on passive indirect imaging problems, where the observations do not contain line-of-sight information about the parameter(s) of interest. Using computer graphics rendering software to synthesize the often-complicated dependence among parameter(s) of interest and observations, i.e. the forward model, the proposed framework evaluates the Hammersley-Chapman-Robbins bound to establish lower bounds on the variance of any unbiased estimator of the unknown parameters. The effects of inexact rendering of the true forward model on the computed lower bounds are also analyzed, both theoretically and via simulations. Experimental evaluations compare the computed lower bounds with the performance of the Maximum Likelihood Estimator on a canonical object localization problem, showing that the lower bounds computed via the framework proposed here are indicative of the true underlying fundamental limits in several nominally representative scenarios."}
{"id": "2602.00790", "categories": ["eess.SP", "math.NA", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.00790", "abs": "https://arxiv.org/abs/2602.00790", "authors": ["H. Robert Frost"], "title": "Denoising deterministic networks using iterative Fourier transforms", "comment": null, "summary": "We detail a novel Fourier-based approach (IterativeFT) for identifying deterministic network structure in the presence of both edge pruning and Gaussian noise. This technique involves the iterative execution of forward and inverse 2D discrete Fourier transforms on a target network adjacency matrix. The denoising ability of the method is achieved via the application of a sparsification operation to both the real and frequency domain representations of the adjacency matrix with algorithm convergence achieved when the real domain sparsity pattern stabilizes. To demonstrate the effectiveness of the approach, we apply it to noisy versions of several deterministic models including Kautz, lattice, tree and bipartite networks. For contrast, we also evaluate preferential attachment networks to illustrate the behavior on stochastic graphs. We compare the performance of IterativeFT against simple real domain and frequency domain thresholding, reduced rank reconstruction and locally adaptive network sparsification. Relative to the comparison network denoising approaches, the proposed IterativeFT method provides the best overall performance for lattice and Kuatz networks with competitive performance on tree and bipartite networks. Importantly, the InterativeFT technique is effective at both filtering noisy edges and recovering true edges that are missing from the observed network."}
{"id": "2602.00220", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.00220", "abs": "https://arxiv.org/abs/2602.00220", "authors": ["Tomasz Les", "Tomasz Markiewicz", "Malgorzata Lorent", "Miroslaw Dziekiewicz", "Krzysztof Siwek"], "title": "Advanced Geometric Correction Algorithms for 3D Medical Reconstruction: Comparison of Computed Tomography and Macroscopic Imaging", "comment": "24 pages, 9 figures, submitted to Applied Sciences (MDPI)", "summary": "This paper introduces a hybrid two-stage registration framework for reconstructing three-dimensional (3D) kidney anatomy from macroscopic slices, using CT-derived models as the geometric reference standard. The approach addresses the data-scarcity and high-distortion challenges typical of macroscopic imaging, where fully learning-based registration (e.g., VoxelMorph) often fails to generalize due to limited training diversity and large nonrigid deformations that exceed the capture range of unconstrained convolutional filters. In the proposed pipeline, the Optimal Cross-section Matching (OCM) algorithm first performs constrained global alignment: translation, rotation, and uniform scaling to establish anatomically consistent slice initialization. Next, a lightweight deep-learning refinement network, inspired by VoxelMorph, predicts residual local deformations between consecutive slices. The core novelty of this architecture lies in its hierarchical decomposition of the registration manifold. This hybrid OCM+DL design integrates explicit geometric priors with the flexible learning capacity of neural networks, ensuring stable optimization and plausible deformation fields even with few training examples. Experiments on an original dataset of 40 kidneys demonstrated better results compared to single-stage baselines. The pipeline maintains physical calibration via Hough-based grid detection and employs Bezier-based contour smoothing for robust meshing and volume estimation. Although validated on kidney data, the proposed framework generalizes to other soft-tissue organs reconstructed from optical or photographic cross-sections. By decoupling interpretable global optimization from data-efficient deep refinement, the method advances the precision, reproducibility, and anatomical realism of multimodal 3D reconstructions for surgical planning, morphological assessment, and medical education."}
{"id": "2602.00817", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.00817", "abs": "https://arxiv.org/abs/2602.00817", "authors": ["Qiushi Guo", "Matthias Tschoepe", "Mengxi Liu", "Sizhen Bian", "Paul Lukowicz"], "title": "Calibration-Free Induced Magnetic Field Indoor and Outdoor Positioning via Data-Driven Modeling", "comment": null, "summary": "Induced magnetic field (IMF)-based localization offers a robust alternative to wave-based positioning technologies due to its resilience to non-line-of-sight conditions, environmental dynamics, and wireless interference. However, existing magnetic localization systems typically rely on analytical field inversion, manual calibration, or environment-specific fingerprinting, limiting their scalability and transferability. This paper presents a data-driven IMF localization framework that directly maps induced magnetic field measurements to spatial coordinates using supervised learning, eliminating explicit environment-specific calibration. By replacing explicit field modeling with learning-based inference, the proposed approach captures nonlinear field interactions and environmental effects. An orientation-invariant feature representation enables rotation-independent deployment. The system is evaluated across multiple indoor environments and an outdoor deployment. Benchmarking against classical and deep learning baselines shows that a Random Forest regressor achieves sub-20 cm accuracy in 2D and sub-30 cm in 3D localization. Cross-environment validation demonstrates that models trained indoors generalize to outdoor environments without retraining. We further analyze scalability by varying transmitter spacing, showing that coverage and accuracy can be balanced through deployment density. Overall, this work demonstrates that data-driven IMF localization is a scalable and transferable solution for real-world positioning."}
{"id": "2602.00221", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.00221", "abs": "https://arxiv.org/abs/2602.00221", "authors": ["Humaira Mehwish", "Hina Shakir", "Muneeba Rashid", "Asarim Aamir", "Reema Qaiser Khan"], "title": "Benchmarking Vanilla GAN, DCGAN, and WGAN Architectures for MRI Reconstruction: A Quantitative Analysis", "comment": "20 pages", "summary": "Magnetic Resonance Imaging (MRI) is a crucial imaging modality for viewing internal body structures. This research work analyses the performance of popular GAN models for accurate and precise MRI reconstruction by enhancing image quality and improving diagnostic accuracy. Three GAN architectures considered in this study are Vanilla GAN, Deep Convolutional GAN (DCGAN), and Wasserstein GAN (WGAN). They were trained and evaluated using knee, brain, and cardiac MRI datasets to assess their generalizability across body regions. While the Vanilla GAN operates on the fundamentals of the adversarial network setup, DCGAN advances image synthesis by securing the convolutional layers, giving a superior appearance to the prevalent spatial features. Training instability is resolved in WGAN through the Wasserstein distance to minimize an unstable regime, therefore, ensuring stable convergence and high-quality images. The GAN models were trained and tested using 1000 MR images of an anonymized knee, 805 images of Heart, 90 images of Brain MRI dataset. The Structural Similarity Index (SSIM) for Vanilla GAN is 0.84, DCGAN is 0.97, and WGAN is 0.99. The Peak Signal to Noise Ratio (PSNR) for Vanilla GAN is 26, DCGAN is 49.3, and WGAN is 43.5. The results were further statistically validated. This study shows that DCGAN and WGAN-based frameworks are promising in MR image reconstruction because of good image quality and superior accuracy. With the first cross-organ benchmark of baseline GANs under a common preprocessing pipeline, this work provides a reproducible benchmark for future hybrid GANs and clinical MRI applications."}
{"id": "2602.00917", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.00917", "abs": "https://arxiv.org/abs/2602.00917", "authors": ["Ali Kourani", "Naveed A. Abbasi", "Syeda Narjis Fatima", "Katsuyuki Haneda", "Andreas F. Molisch"], "title": "mmWave Sensing for Detecting Movement Through Thermoplastic Masks During Radiation Therapy Treatment", "comment": "5 pages, 6 figures. Conference paper", "summary": "Precision in radiation therapy relies on immobilization systems that limit patient motion. Thermoplastic masks are commonly used for this purpose, but subtle voluntary and involuntary movements such as jaw shifts, deep breathing, or eye squinting may still compromise treatment accuracy. Existing motion tracking methods are limited: optical systems require a clear line of sight and only detect surface motion, while X-ray-based tracking introduces additional ionizing radiation. This study explores the use of low-power, non-ionizing millimeter-wave (mmWave) sensing for through-mask motion detection. We characterize the RF properties of thermoplastic mask material in the 28-38 GHz range and perform motion detection using a 1 GHz bandwidth centered at 28 GHz. We use a frequency-domain system with horn antennas in a custom-built anechoic chamber to capture changes in the amplitude and phase of transmitted RF waves in response to subtle head and facial movements. These findings lay groundwork for future real-time through-mask motion tracking and future integration with multi-antenna systems and machine learning for error correction during radiotherapy."}
{"id": "2602.00483", "categories": ["eess.IV", "cs.CV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2602.00483", "abs": "https://arxiv.org/abs/2602.00483", "authors": ["Xihua Sheng", "Xiongzhuang Liang", "Chuanbo Tang", "Zhirui Zuo", "Yifan Bian", "Yutao Xie", "Zhuoyuan Li", "Yuqi Li", "Hui Xiang", "Li Li", "Dong Liu"], "title": "Recent Advances of End-to-End Video Coding Technologies for AVS Standard Development", "comment": null, "summary": "Video coding standards are essential to enable the interoperability and widespread adoption of efficient video compression technologies. In pursuit of greater video compression efficiency, the AVS video coding working group launched the standardization exploration of end-to-end intelligent video coding, establishing the AVS End-to-End Intelligent Video Coding Exploration Model (AVS-EEM) project. A core design principle of AVS-EEM is its focus on practical deployment, featuring inherently low computational complexity and requiring strict adherence to the common test conditions of conventional video coding. This paper details the development history of AVS-EEM and provides a systematic introduction to its key technical framework, covering model architectures, training strategies, and inference optimizations. These innovations have collectively driven the project's rapid performance evolution, enabling continuous and significant gains under strict complexity constraints. Through over two years of iterative refinement and collaborative effort, the coding performance of AVS-EEM has seen substantial improvement. Experimental results demonstrate that its latest model achieves superior compression efficiency compared to the conventional AVS3 reference software, marking a significant step toward a deployable intelligent video coding standard."}
{"id": "2602.01091", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.01091", "abs": "https://arxiv.org/abs/2602.01091", "authors": ["Ahmet B. Kilic", "Fatih E. Bilgen", "Ozgur B. Akan"], "title": "Channel Modeling and Experimental Validation of Odor-Based Molecular Communication Systems", "comment": "5 Pages, 4 Figures", "summary": "Odor-based Molecular Communication (OMC) employs odor molecules to convey information, contributing to the realization of the Internet of Everything (IoE) vision. Despite this, the practical deployment of OMC systems is currently limited by the lack of comprehensive channel models that accurately characterize particle propagation in diverse environments. While existing literature explores various aspects of molecular transport, a holistic approach that integrates theoretical modeling with experimental validation for bounded channels remains underdeveloped. In this paper, we address this gap by proposing mathematical frameworks for both bounded and unbounded OMC channels. To verify the accuracy of the proposed models, we develop a novel experimental testbed and conduct an extensive performance analysis. Our results demonstrate a strong correlation between the theoretical derivations and experimental data, providing a robust foundation for the design and analysis of future end-to-end OMC systems."}
{"id": "2602.00863", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2602.00863", "abs": "https://arxiv.org/abs/2602.00863", "authors": ["André F. R. Guarda", "Nuno M. M. Rodrigues", "Fernando Pereira"], "title": "Lightweight Super Resolution-enabled Coding Model for the JPEG Pleno Learning-based Point Cloud Coding Standard", "comment": "32 pages, 8 figures, submitted to Signal Processing: Image Communication", "summary": "While point cloud-based applications are gaining traction due to their ability to provide rich and immersive experiences, they critically need efficient coding solutions due to the large volume of data involved, often many millions of points per object. The JPEG Pleno Learning-based Point Cloud Coding standard, as the first learning-based coding standard for static point clouds, has set a foundational framework with very competitive compression performance regarding the relevant conventional and learning-based alternative point cloud coding solutions. This paper proposes a novel lightweight point cloud geometry coding model that significantly reduces the complexity of the standard, which is essential for the broad adoption of this coding standard, particularly in resource-constrained environments, while simultaneously achieving small average compression efficiency benefits. The novel coding model is based on the pioneering adoption of a compressed domain approach for the super-resolution model, in addition to a major reduction of the number of latent channels. A reduction of approximately 70% in the total number of model parameters is achieved while simultaneously offering slight average compression performance gains for the JPEG Pleno Point Cloud coding dataset."}
{"id": "2602.01121", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.01121", "abs": "https://arxiv.org/abs/2602.01121", "authors": ["Po-Chun Kang", "Ming-Chun Lee", "Tzu-Chien Chiu", "Ting-Yao Kuo", "Ta-Sung Lee"], "title": "Digital and Hybrid Precoding and RF Chain Selection Designs for Energy Efficient Multi-User MIMO-OFDM ISAC Systems", "comment": "14 pages", "summary": "Using multiple-input multiple-output (MIMO) with orthogonal frequency division multiplexing (OFDM) for integrated sensing and communication (ISAC) has attracted considerable attention in recent years. While most existing works focus on improving MIMO-OFDM ISAC performance, the impact of transmit power and radio-frequency (RF) circuit power consumption on energy efficiency (EE) remains relatively underexplored. To address this gap, this paper investigates joint precoding and RF chain selection for multi-user MIMO-OFDM ISAC systems, and develops energy-efficient designs for both fully digital and hybrid precoding architectures through the joint optimization of precoding and RF-chain activation. Specifically, we first formulate a novel EE maximization problem subject to sensing performance constraints. Then, efficient optimization algorithms are proposed for both architectures, together with analyses of their computational complexity and convergence behavior. Building on the proposed approaches, spectral efficiency-power consumption tradeoff designs are also provided. Simulation results demonstrate that, compared with existing schemes, the proposed approaches achieve significant improvements in the EE-sensing tradeoff for ISAC systems."}
{"id": "2602.00990", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2602.00990", "abs": "https://arxiv.org/abs/2602.00990", "authors": ["Jichen Yang", "Brian C. Allen", "Kirti Magudia", "Lisa M. Ho", "Chad M. Miller", "Maciej A. Mazurowski", "Benjamin Wildman-Tobriner"], "title": "Diagnostic Impact of Cine Clips for Thyroid Nodule Assessment on Ultrasound", "comment": "17 pages, 5 tables", "summary": "Background: Thyroid ultrasound is commonly performed using a combination of static images and cine clips (video recordings). However, the exact utility and impact of cine images remains unknown. This study aimed to evaluate the impact of cine imaging on accuracy and consistency of thyroid nodule assessment, using the American College of Radiology Thyroid Reporting and Data System (ACR TI-RADS). Methods: 50 benign and 50 malignant thyroid nodules with cytopathology results were included. A reader study with 4 specialty-trained radiologists was then conducted over 3 rounds, assessing only static images in the first two rounds and both static and cine images in the third round. TI-RADS scores and the consequent management recommendations were then evaluated by comparing them to the malignancy status of the nodules. Results: Mean sensitivity for malignancy detection was 0.65 for static images and 0.67 with both static and cine images (p>0.5). Specificity was 0.20 for static images and 0.22 with both static and cine images (p>0.5). Management recommendations were similar with and without cine images. Intrareader agreement on feature assignments remained consistent across all rounds, though TI-RADS point totals were slightly higher with cine images. Conclusion: The inclusion of cine imaging for thyroid nodule assessment on ultrasound did not significantly change diagnostic performance. Current practice guidelines, which do not mandate cine imaging, are sufficient for accurate diagnosis."}
{"id": "2602.01249", "categories": ["eess.SP", "eess.AS"], "pdf": "https://arxiv.org/pdf/2602.01249", "abs": "https://arxiv.org/abs/2602.01249", "authors": ["Muhammad Salman Khan", "Ahmad Ullah", "Siddique Latif", "Junaid Qadir"], "title": "Generative AI in Signal Processing Education: An Audio Foundation Model Based Approach", "comment": "accepted at IEEE EDUCON 2026", "summary": "Audio Foundation Models (AFMs), a specialized category of Generative AI (GenAI), have the potential to transform signal processing (SP) education by integrating core applications such as speech and audio enhancement, denoising, source separation, feature extraction, automatic classification, and real-time signal analysis into learning and research. This paper introduces SPEduAFM, a conceptual AFM tailored for SP education, bridging traditional SP principles with GenAI-driven innovations. Through an envisioned case study, we outline how AFMs can enable a range of applications, including automated lecture transcription, interactive demonstrations, and inclusive learning tools, showcasing their potential to transform abstract concepts into engaging, practical experiences. This paper also addresses challenges such as ethics, explainability, and customization by highlighting dynamic, real-time auditory interactions that foster experiential and authentic learning. By presenting SPEduAFM as a forward-looking vision, we aim to inspire broader adoption of GenAI in engineering education, enhancing accessibility, engagement, and innovation in the classroom and beyond."}
{"id": "2602.01065", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2602.01065", "abs": "https://arxiv.org/abs/2602.01065", "authors": ["Qianwan Yang", "Zhixiong Chen", "Jiaqi Zhang", "Ruipeng Guo", "Guorong Hu", "Lei Tian"], "title": "Coordinate-conditioned Deconvolution for Scalable Spatially Varying High-Throughput Imaging", "comment": null, "summary": "Wide-field fluorescence microscopy with compact optics often suffers from spatially varying blur due to field-dependent aberrations, vignetting, and sensor truncation, while finite sensor sampling imposes an inherent trade-off between field of view (FOV) and resolution. Computational Miniaturized Mesoscope (CM2) alleviate the sampling limit by multiplexing multiple sub-views onto a single sensor, but introduce view crosstalk and a highly ill-conditioned inverse problem compounded by spatially variant point spread functions (PSFs). Prior learning-based spatially varying (SV) reconstruction methods typically rely on global SV operators with fixed input sizes, resulting in memory and training costs that scale poorly with image dimensions. We propose SV-CoDe (Spatially Varying Coordinate-conditioned Deconvolution), a scalable deep learning framework that achieves uniform, high-resolution reconstruction across a 6.5 mm FOV. Unlike conventional methods, SV-CoDe employs coordinate-conditioned convolutions to locally adapt reconstruction kernels; this enables patch-based training that decouples parameter count from FOV size. SV-CoDe achieves the best image quality in both simulated and experimental measurements while requiring 10x less model size and 10x less training data than prior baselines. Trained purely on physics-based simulations, the network robustly generalizes to bead phantoms, weakly scattering brain slices, and freely moving C. elegans. SV-CoDe offers a scalable, physics-aware solution for correcting SV blur in compact optical systems and is readily extendable to a broad range of biomedical imaging applications."}
{"id": "2602.01293", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.01293", "abs": "https://arxiv.org/abs/2602.01293", "authors": ["Hui Chen", "Mengting Li", "Alireza Pourafzal", "Huiping Huang", "Yu Ge", "Sigurd Sandor Petersen", "Ming Shen", "George C. Alexandropoulos", "Henk Wymeersch"], "title": "Mismatch Analysis and Cooperative Calibration of Array Beam Patterns for ISAC Systems", "comment": null, "summary": "Integrated sensing and communication (ISAC) is a key technology for enabling a wide range of applications in future wireless systems. However, the sensing performance is often degraded by model mismatches caused by geometric errors (e.g., position and orientation) and hardware impairments (e.g., mutual coupling and amplifier non-linearity). This paper focuses on the angle estimation performance with antenna arrays and tackles the critical challenge of array beam pattern calibration for ISAC systems. To assess calibration quality from a sensing perspective, a novel performance metric that accounts for angle estimation error, rather than beam pattern similarity, is proposed and incorporated into a differentiable loss function. Additionally, a cooperative calibration framework is introduced, allowing multiple user equipments to iteratively optimize the beam pattern based on the proposed loss functions and local data, and collaboratively update global calibration parameters. The proposed models and algorithms are validated using real-world beam pattern measurements collected in an anechoic chamber. Experimental results show that the angle estimation error can be reduced from {$\\textbf{1.01}^\\circ$} to $\\textbf{0.11}^\\circ$ in 2D calibration scenarios, and from $\\textbf{5.19}^\\circ$ to $\\textbf{0.86}^\\circ$ in 3D calibration ones."}
{"id": "2602.01325", "categories": ["eess.IV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2602.01325", "abs": "https://arxiv.org/abs/2602.01325", "authors": ["Kai Hu", "Junfu Tan", "Fang Xu", "Ramy Samy", "Yu Liu"], "title": "Unified ROI-based Image Compression Paradigm with Generalized Gaussian Model", "comment": "14 pages, 18 figures,", "summary": "Region-of-Interest (ROI)-based image compression allocates bits unevenly according to the semantic importance of different regions. Such differentiated coding typically induces a sharp-peaked and heavy-tailed distribution. This distribution characteristic mathematically necessitates a probability model with adaptable shape parameters for accurate description. However, existing methods commonly use a Gaussian model to fit this distribution, resulting in a loss of coding performance. To systematically analyze the impact of this distribution on ROI coding, we develop a unified rate-distortion optimization theoretical paradigm. Building on this paradigm, we propose a novel Generalized Gaussian Model (GGM) to achieve flexible modeling of the latent variables distribution. To support stable optimization of GGM, we introduce effective differentiable functions and further propose a dynamic lower bound to alleviate train-test mismatch. Moreover, finite differences are introduced to solve the gradient computation after GGM fits the distribution. Experiments on COCO2017 demonstrate that our method achieves state-of-the-art in both ROI reconstruction and downstream tasks (e.g., Segmentation, Object Detection). Furthermore, compared to classical probability models, our GGM provides a more precise fit to feature distributions and achieves superior coding performance. The project page is at https://github.com/hukai-tju/ROIGGM."}
{"id": "2602.01377", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2602.01377", "abs": "https://arxiv.org/abs/2602.01377", "authors": ["Zilu Zhao", "Dirk Slock"], "title": "Approximating Univariate Factored Distributions via Message-Passing Algorithms", "comment": null, "summary": "Gaussian Mixture Models (GMMs) commonly arise in communication systems, particularly in bilinear joint estimation and detection problems. Although the product of GMMs is still a GMM, as the number of factors increases, the number of components in the resulting product GMM grows exponentially. To obtain a tractable approximation for a univariate factored probability density function (PDF), such as a product of GMMs, we investigate iterative message-passing algorithms. Based on Belief Propagation (BP), we propose a Variable Duplication and Gaussian Belief Propagation (VDBP)-based algorithm. The key idea of VDBP is to construct a multivariate measurement model whose marginal posterior is equal to the given univariate factored PDF. We then apply Gaussian BP (GaBP) to transform the global inference problem into local ones. Expectation propagation (EP) is another branch of message passing algorithms. In addition to converting the global approximation problem into local ones, it features a projection operation that ensures the intermediate functions (messages) belong to a desired family. Due to this projection, EP can be used to approximate the factored PDF directly. However, even if every factor is integrable, the division operation in EP may still cause the algorithm to fail when the mean and variance of a non-integrable belief are required. Therefore, this paper proposes two methods that combine EP with our previously proposed techniques for handling non-integrable beliefs to approximate univariate factored distributions."}
{"id": "2602.01444", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.01444", "abs": "https://arxiv.org/abs/2602.01444", "authors": ["Tal Grutman", "Carmel Shinar", "Tali Ilovitsh"], "title": "A texture-based framework for foundational ultrasound models", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Ultrasound is the most widely used medical imaging modality, yet the images it produces are fundamentally unique, arising from tissue-dependent scattering, reflection, and speed-of-sound variations that produce a constrained set of characteristic textures that differ markedly from natural-image statistics. These acoustically driven patterns make ultrasound challenging for algorithms originally designed for natural images. To bridge this gap, the field has increasingly turned to foundation models, hoping to leverage their generalization capabilities. However, these models often falter in ultrasound applications because they are not designed for ultrasound physics, they are merely trained on ultrasound data. Therefore, it is essential to integrate ultrasound-specific domain knowledge into established learning frameworks. We achieve this by reformulating self-supervised learning as a texture-analysis problem, introducing texture ultrasound semantic analysis (TUSA). Using TUSA, models learn to leverage highly scalable contrastive methods to extract true domain-specific representations directly from simple B-mode images. We train a TUSA model on a combination of open-source, simulated, and in vivo data. The latent space is compared to several larger foundation models, demonstrating that our approach gives TUSA models better generalizability for difficult downstream tasks on unique online datasets as well as a clinical eye dataset collected for this study. Our model achieves higher accuracy in detecting COVID (70%), spinal hematoma (100%) and vitreous hemorrhage (97%) and correlates more closely with quantitative parameters like liver steatosis (r = 0.83), ejection fraction (r = 0.63), and oxygen saturation (r = 0.38). We open-source the model weights and training script: https://github.com/talg2324/tusa"}
{"id": "2602.01577", "categories": ["eess.SP", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.01577", "abs": "https://arxiv.org/abs/2602.01577", "authors": ["Wenxuan Pan", "Yang Yang", "Dong Wei", "Zhiyu Zhu", "Jintao Wang", "Huan Wu", "Yao Nie"], "title": "Visible Light Positioning With Lamé Curve LEDs: A Generic Approach for Camera Pose Estimation", "comment": "Submitted to an IEEE journal for possible publication", "summary": "Camera-based visible light positioning (VLP) is a promising technique for accurate and low-cost indoor camera pose estimation (CPE). To reduce the number of required light-emitting diodes (LEDs), advanced methods commonly exploit LED shape features for positioning. Although interesting, they are typically restricted to a single LED geometry, leading to failure in heterogeneous LED-shape scenarios. To address this challenge, this paper investigates Lamé curves as a unified representation of common LED shapes and proposes a generic VLP algorithm using Lamé curve-shaped LEDs, termed LC-VLP. In the considered system, multiple ceiling-mounted Lamé curve-shaped LEDs periodically broadcast their curve parameters via visible light communication, which are captured by a camera-equipped receiver. Based on the received LED images and curve parameters, the receiver can estimate the camera pose using LC-VLP. Specifically, an LED database is constructed offline to store the curve parameters, while online positioning is formulated as a nonlinear least-squares problem and solved iteratively. To provide a reliable initialization, a correspondence-free perspective-\\textit{n}-points (FreeP\\textit{n}P) algorithm is further developed, enabling approximate CPE without any pre-calibrated reference points. The performance of LC-VLP is verified by both simulations and experiments. Simulations show that LC-VLP outperforms state-of-the-art methods in both circular- and rectangular-LED scenarios, achieving reductions of over 40% in position error and 25% in rotation error. Experiments further show that LC-VLP can achieve an average position accuracy of less than 4 cm."}
{"id": "2602.01513", "categories": ["eess.IV", "cs.AI", "cs.CR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.01513", "abs": "https://arxiv.org/abs/2602.01513", "authors": ["Xiaoxi Kong", "Jieyu Yuan", "Pengdi Chen", "Yuanlin Zhang", "Chongyi Li", "Bin Li"], "title": "MarkCleaner: High-Fidelity Watermark Removal via Imperceptible Micro-Geometric Perturbation", "comment": null, "summary": "Semantic watermarks exhibit strong robustness against conventional image-space attacks. In this work, we show that such robustness does not survive under micro-geometric perturbations: spatial displacements can remove watermarks by breaking the phase alignment. Motivated by this observation, we introduce MarkCleaner, a watermark removal framework that avoids semantic drift caused by regeneration-based watermark removal. Specifically, MarkCleaner is trained with micro-geometry-perturbed supervision, which encourages the model to separate semantic content from strict spatial alignment and enables robust reconstruction under subtle geometric displacements. The framework adopts a mask-guided encoder that learns explicit spatial representations and a 2D Gaussian Splatting-based decoder that explicitly parameterizes geometric perturbations while preserving semantic content. Extensive experiments demonstrate that MarkCleaner achieves superior performance in both watermark removal effectiveness and visual fidelity, while enabling efficient real-time inference. Our code will be made available upon acceptance."}
{"id": "2602.01646", "categories": ["eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.01646", "abs": "https://arxiv.org/abs/2602.01646", "authors": ["Minseok Kim", "Masato Yomoda"], "title": "Synthesized-Isotropic Narrowband Channel Parameter Extraction from Angle-Resolved Wideband Channel Measurements", "comment": null, "summary": "Angle-resolved channel sounding using antenna arrays or mechanically steered high-gain antennas is widely employed at millimeter-wave and terahertz bands. To extract antenna-independent large-scale channel parameters such as path loss, delay spread, and angular spread, the radiation-pattern effects embedded in the measured responses must be properly compensated. This paper revisits the technical challenges of path-gain calculation from angle-resolved wideband measurements, with emphasis on angular-domain power integration where the scan beams are inherently non-orthogonal and simple power summation leads to biased omni-equivalent power estimates. We first formulate the synthesized-isotropic narrowband power in a unified matrix form and introduce a beam-accumulation correction factor, including an offset-averaged variant to mitigate scalloping due to off-grid angles. The proposed framework is validated through simulations using channel models and 154~GHz corridor measurements."}
{"id": "2602.01681", "categories": ["eess.IV", "cs.CV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2602.01681", "abs": "https://arxiv.org/abs/2602.01681", "authors": ["Yu-Jie Liang", "Zihan Cao", "Liang-Jian Deng", "Yang Yang", "Malu Zhang"], "title": "Hyperspectral Image Fusion with Spectral-Band and Fusion-Scale Agnosticism", "comment": null, "summary": "Current deep learning models for Multispectral and Hyperspectral Image Fusion (MS/HS fusion) are typically designed for fixed spectral bands and spatial scales, which limits their transferability across diverse sensors. To address this, we propose SSA, a universal framework for MS/HS fusion with spectral-band and fusion-scale agnosticism. Specifically, we introduce Matryoshka Kernel (MK), a novel operator that enables a single model to adapt to arbitrary numbers of spectral channels. Meanwhile, we build SSA upon an Implicit Neural Representation (INR) backbone that models the HS signal as a continuous function, enabling reconstruction at arbitrary spatial resolutions. Together, these two forms of agnosticism enable a single MS/HS fusion model that generalizes effectively to unseen sensors and spatial scales. Extensive experiments demonstrate that our single model achieves state-of-the-art performance while generalizing well to unseen sensors and scales, paving the way toward future HS foundation models."}
{"id": "2602.01947", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.01947", "abs": "https://arxiv.org/abs/2602.01947", "authors": ["Baptiste Sambon", "Gilles Monnoyer", "Luc Vandendorpe", "Claude Oestges"], "title": "Resolution-Aliasing Trade-off in Near-Field Localisation", "comment": "Submitted to IEEE Open Journal of Signal Processing", "summary": "Extremely Large-scale MIMO (XL-MIMO) systems operating in Near-Field (NF) introduce new degrees of freedom for accurate source localisation, but make dense arrays impractical. Sparse or distributed arrays can reduce hardware complexity while maintaining high resolution, yet sub-Nyquist spatial sampling introduces aliasing artefacts in the localisation ambiguity function. This paper presents a unified framework to jointly characterise resolution and aliasing in NF localisation and study the trade-off between the two. Leveraging the concept of local chirp spatial frequency, we derive analytical expressions linking array geometry and sampling density to the spatial bandwidth of the received field. We introduce two geometric tools--Critical Antenna Elements (CAEs) and the Non-Contributive Zone (NCZ)--to intuitively identify how individual antennas contribute to resolution and/or aliasing. Our analysis reveals that resolution and aliasing are not always strictly coupled, e.g., increasing the array aperture can improve resolution without necessarily aggravating aliasing. These results provide practical guidelines for designing NF arrays that optimally balance resolution and aliasing, supporting efficient XL-MIMO deployment."}
{"id": "2602.02031", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2602.02031", "abs": "https://arxiv.org/abs/2602.02031", "authors": ["Martin Determann", "Elvira Fleig"], "title": "Edge-Aligned Initialization of Kernels for Steered Mixture-of-Experts", "comment": null, "summary": "Steered Mixture-of-Experts (SMoE) has recently emerged as a powerful framework for spatial-domain image modeling, enabling high-fidelity image representation using a remarkably small number of parameters. Its ability to steer kernel-based experts toward structural image features has led to successful applications in image compression, denoising, super-resolution, and light field processing. However, practical adoption is hindered by the reliance on gradient-based optimization to estimate model parameters on a per-image basis - a process that is computationally intensive and difficult to scale. Initialization strategies for SMoE are an essential component that directly affects convergence and reconstruction quality. In this paper, we propose a novel, edge-based initialization scheme that achieves good reconstruction qualities while reducing the need for stochastic optimization significantly. Through a method that leverages Canny edge detection to extract a sparse set of image contours, kernel positions and orientations are deterministically inferred. A separate approach enables the direct estimation of initial expert coefficients. This initialization reduces both memory consumption and computational cost."}
{"id": "2602.01961", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.01961", "abs": "https://arxiv.org/abs/2602.01961", "authors": ["Chenyang Yan", "Ruonan Yang", "Shunqiao Sun", "Mats Bengtsson"], "title": "Uncertainty-Weighted Multi-Task CNN for Joint DoA and Rain-Rate Estimation Under Rain-Induced Array Distortions", "comment": null, "summary": "We investigate joint direction-of-arrival (DoA) and rain-rate estimation for a uniform linear array operating under rain-induced multiplicative distortions. Building on a wavefront fluctuation model whose spatial correlation is governed by the rain-rate, we derive an angle-dependent covariance formulation and use it to synthesize training data. DoA estimation is cast as a multi-label classification problem on a discretized angular grid, while rain-rate estimation is formulated as a multi-class classification task. We then propose a multi-task deep CNN with a shared feature extractor and two task-specific heads, trained using an uncertainty-weighted objective to automatically balance the two losses. Numerical results in a two-source scenario show that the proposed network achieves lower DoA RMSE than classical baselines and provides accurate rain-rate classification at moderate-to-high SNRs."}
{"id": "2602.01974", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.01974", "abs": "https://arxiv.org/abs/2602.01974", "authors": ["Chenyang Yan", "Mats Bengtsson"], "title": "Obstacle Detection at Level Crossings under Adverse Weather Conditions -- A Survey", "comment": null, "summary": "Level crossing accidents remain a significant safety concern in modern railway systems, particularly under adverse weather conditions that degrade sensor performance. This review surveys state-of-the-art sensor technologies and fusion strategies for obstacle detection at railway level crossings, with a focus on robustness, detection accuracy, and environmental resilience. Individual sensors such as inductive loops, cameras, radar, and LiDAR offer complementary strengths but involve trade-offs, including material dependence, reduced visibility, and limited resolution in harsh environments. We analyze each modality's working principles, weather-induced vulnerabilities, and mitigation strategies, including signal enhancement and machine-learning-based denoising. We further review multi-sensor fusion approaches, categorized as data-level, feature-level, and decision-level architectures, that integrate complementary information to improve reliability and fault tolerance. The survey concludes with future research directions, including adaptive fusion algorithms, real-time processing pipelines, and weather-resilient datasets to support the deployment of intelligent, fail-safe detection systems for railway safety."}
{"id": "2602.02065", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.02065", "abs": "https://arxiv.org/abs/2602.02065", "authors": ["Xuan Yang", "Dongming Li", "Yi Lou", "Xianglin Fan"], "title": "Silhouette Score Efficient Radio Frequency Fingerprint Feature Extraction", "comment": null, "summary": "Radio frequency fingerprint (RFF) identification technology, which exploits relatively stable hardware imperfections, is highly susceptible to constantly changing channel effects. Although various channel-robust RFF feature extraction methods have been proposed, they predominantly rely on experimental comparisons rather than theoretical analyses. This limitation hinders the progress of channel-robust RFF feature extraction and impedes the establishment of theoretical guidance for its design. In this paper, we establish a unified theoretical performance analysis framework for different RFF feature extraction methods using the silhouette score as an evaluation metric, and propose a precoding-based channel-robust RFF feature extraction method that enhances the silhouette score without requiring channel estimation. First, we employ the silhouette score as an evaluation metric and obtain the theoretical performance of various RFF feature extraction methods using the Taylor series expansion. Next, we mitigate channel effects by computing the reciprocal of the received signal in the frequency domain at the device under authentication. We then compare these methods across three different scenarios: the deterministic channel scenario, the independent and identically distributed (i.i.d.) stochastic channel scenario, and the non-i.i.d. stochastic channel scenario. Finally, simulation and experimental results demonstrate that the silhouette score is an efficient metric to evaluate classification accuracy. Furthermore, the results indicate that the proposed precoding-based channel-robust RFF feature extraction method achieves the highest silhouette score and classification accuracy under channel variations."}
{"id": "2602.02086", "categories": ["eess.SP", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.02086", "abs": "https://arxiv.org/abs/2602.02086", "authors": ["Chen Feng", "Sébastien Lugan", "Karine Lasaracina", "Midori Sugaya", "Benoît Macq"], "title": "Neurophysiological effects of museum modalities on emotional engagement with real artworks", "comment": "7 pages, 4 figures - \\c{opyright}IEEE EmotionSense 2026/PerCom 2026", "summary": "Museums increasingly rely on digital content to support visitors' understanding of artworks, yet little is known about how these formats shape the emotional engagement that underlies meaningful art experiences. This research presents an in-situ EEG study on how digital interpretive content modulate engagement during art viewing. Participants experienced three modalities: direct viewing of a Bruegel painting, a 180° immersive interpretive projection, and a regular, display-based interpretive video. Frontal EEG markers of motivational orientation, internal involvement, perceptual drive, and arousal were extracted using eyes-open baselines and Z-normalized contrasts. Results show modality-specific engagement profiles: display-based interpretive video induced high arousal and fast-band activity, immersive projections promoted calm, presence-oriented absorption, and original artworks reflected internally regulated engagement. These findings, relying on lightweight EEG sensing in an operational cultural environment, suggest that digital interpretive content affects engagement style rather than quantity. This paves the way for new multimodal sensing approaches and enables museums to optimize the modalities and content of their interpretive media."}
{"id": "2602.02148", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.02148", "abs": "https://arxiv.org/abs/2602.02148", "authors": ["Yuhan Wang", "Haobo Zhang", "Qingyu Liu", "Hongliang Zhang", "Lingyang Song"], "title": "RIS-Aided Wireless Amodal Sensing for Single-View 3D Reconstruction", "comment": null, "summary": "Amodal sensing is critical for various real-world sensing applications because it can recover the complete shapes of partially occluded objects in complex environments. Among various amodal sensing paradigms, wireless amodal sensing is a potential solution due to its advantages of environmental robustness, privacy preservation, and low cost. However, the sensing data obtained by wireless system is sparse for shape reconstruction because of the low spatial resolution, and this issue is further intensified in complex environments with occlusion. To address this issue, we propose a Reconfigurable Intelligent Surface (RIS)-aided wireless amodal sensing scheme that leverages a large-scale RIS to enhance the spatial resolution and create reflection paths that can bypass the obstacles. A generative learning model is also employed to reconstruct the complete shape based on the sensing data captured from the viewpoint of the RIS. In such a system, it is challenging to optimize the RIS phase shifts because the relationship between RIS phase shifts and amodal sensing accuracy is complex and the closed-form expression is unknown. To tackle this challenge, we develop an error prediction model that learns the mapping from RIS phase shifts to amodal sensing accuracy, and optimizes RIS phase shifts based on this mapping. Experimental results on the benchmark dataset show that our method achieves at least a 56.73% reduction in reconstruction error compared to conventional schemes under the same number of RIS configurations."}
{"id": "2602.02167", "categories": ["eess.SP", "cs.CV", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.02167", "abs": "https://arxiv.org/abs/2602.02167", "authors": ["Soheil Behnam Roudsari", "Alexandre S. Brandão", "Felipe N. Martins"], "title": "Real-Time 2D LiDAR Object Detection Using Three-Frame RGB Scan Encoding", "comment": "6 pages, 6 figures, submitted to IEEE SAS 2026", "summary": "Indoor service robots need perception that is robust, more privacy-friendly than RGB video, and feasible on embedded hardware. We present a camera-free 2D LiDAR object detection pipeline that encodes short-term temporal context by stacking three consecutive scans as RGB channels, yielding a compact YOLOv8n input without occupancy-grid construction while preserving angular structure and motion cues. Evaluated in Webots across 160 randomized indoor scenarios with strict scenario-level holdout, the method achieves 98.4% mAP@0.5 (0.778 mAP@0.5:0.95) with 94.9% precision and 94.7% recall on four object classes. On a Raspberry Pi 5, it runs in real time with a mean post-warm-up end-to-end latency of 47.8ms per frame, including scan encoding and postprocessing. Relative to a closely related occupancy-grid LiDAR-YOLO pipeline reported on the same platform, the proposed representation is associated with substantially lower reported end-to-end latency. Although results are simulation-based, they suggest that lightweight temporal encoding can enable accurate and real-time LiDAR-only detection for embedded indoor robotics without capturing RGB appearance."}
{"id": "2602.02202", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.02202", "abs": "https://arxiv.org/abs/2602.02202", "authors": ["Zhixiong Chen", "Hyundong Shin", "Arumugam Nallanathan"], "title": "Sampling-Free Diffusion Transformers for Low-Complexity MIMO Channel Estimation", "comment": "13 pages", "summary": "Diffusion model-based channel estimators have shown impressive performance but suffer from high computational complexity because they rely on iterative reverse sampling. This paper proposes a sampling-free diffusion transformer (DiT) for low-complexity MIMO channel estimation, termed SF-DiT-CE. Exploiting angular-domain sparsity of MIMO channels, we train a lightweight DiT to directly predict the clean channels from their perturbed observations and noise levels. At inference, the least square (LS) estimate and estimation noise condition the DiT to recover the channel in a single forward pass, eliminating iterative sampling. Numerical results demonstrate that our method achieves superior estimation accuracy and robustness with significantly lower complexity than state-of-the-art baselines."}
{"id": "2602.02248", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2602.02248", "abs": "https://arxiv.org/abs/2602.02248", "authors": ["Kehan Huang", "Akram Shafie", "Min Qiu", "Elias Aboutanios", "Jinhong Yuan"], "title": "A Novel ISAC Waveform Based on Orthogonal Delay-Doppler Division Multiplexing with FMCW", "comment": "17 pages, 18 figures", "summary": "In this work, we propose the orthogonal delay-Doppler (DD) division multiplexing (ODDM) modulation with frequency modulated continuous wave (FMCW) (ODDM-FMCW) waveform to enable integrated sensing and communication (ISAC) with a low peak-to-average power ratio (PAPR). We first propose a square-root-Nyquist-filtered FMCW (SRN-FMCW) waveform to address limitations of conventional linear FMCW waveforms in ISAC systems. To better integrate with ODDM, we generate SRN-FMCW by embedding symbols in the DD domain, referred to as a DD-SRN-FMCW frame. A DD chirp compression receiver is designed to obtain the channel response efficiently. Next, we construct the proposed ODDM-FMCW waveform for ISAC by superimposing a DD-SRN-FMCW frame onto an ODDM data frame. A comprehensive performance analysis of the ODDM-FMCW waveform is presented, covering peak-to-average power ratio, spectrum, ambiguity function, and Cramer-Rao bound for delay and Doppler estimation. Numerical results show that the proposed ODDM-FMCW waveform delivers excellent ISAC performance in terms of root mean square error for sensing and bit error rate for communications."}
{"id": "2602.02312", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.02312", "abs": "https://arxiv.org/abs/2602.02312", "authors": ["Alfredo Pérez Vega-Leal", "Manuel G. Satué"], "title": "Flexible laboratory setup for DAC experimentation", "comment": null, "summary": "Analog multiplexing appears to be a promising solution for modern transmitters, where speed is the primary limitation. The objective is the development of a low-cost solution to compare different digital to analog (DAC) schemes. In particular, analog multiplexing techniques, high-speed single-DAC, Sigma-delta modulation, Dynamic element matching are considered. The work presents a review of these techniques and shows a prototype of a time interleaved sigma delta modulation based DAC based on a commercially available Field Programmable Gate Array system."}
{"id": "2602.02365", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.02365", "abs": "https://arxiv.org/abs/2602.02365", "authors": ["Sion Lynch", "Ángel F. García-Fernández", "Lee Devlin"], "title": "A Track-Before-Detect Trajectory Multi-Bernoulli Filter for Generalised Superpositional Measurements", "comment": "Submitted to IEEE Transactions on Signal Processing", "summary": "This paper proposes the Trajectory-Information Exchange Multi-Bernoulli (T-IEMB) filter to estimate sets of alive and all trajectories in track-before-detect applications with generalised superpositional measurements. This measurement model has superpositional hidden variables which are mapped to the conditional mean and covariance of the measurement, enabling it to describe a broad range of measurement models. This paper also presents a Gaussian implementation of the T-IEMB filter, which performs the update by approximating the conditional moments of the measurement model, and admits a computationally light filtering solution. Simulation results for a non-Gaussian radar-based tracking scenario demonstrate the performance of two Gaussian T-IEMB implementations, which provide improved tracking performance compared to a state-of-the-art particle filter based solution for track-before-detect, at a reduced computational cost."}
{"id": "2602.00215", "categories": ["eess.IV", "cs.CV", "eess.SP"], "pdf": "https://arxiv.org/pdf/2602.00215", "abs": "https://arxiv.org/abs/2602.00215", "authors": ["Abhinav V. Sambasivan", "Liam J. Coulter", "Richard G. Paxman", "Jarvis D. Haupt"], "title": "A Renderer-Enabled Framework for Computing Parameter Estimation Lower Bounds in Plenoptic Imaging Systems", "comment": null, "summary": "This work focuses on assessing the information-theoretic limits of scene parameter estimation in plenoptic imaging systems. A general framework to compute lower bounds on the parameter estimation error from noisy plenoptic observations is presented, with a particular focus on passive indirect imaging problems, where the observations do not contain line-of-sight information about the parameter(s) of interest. Using computer graphics rendering software to synthesize the often-complicated dependence among parameter(s) of interest and observations, i.e. the forward model, the proposed framework evaluates the Hammersley-Chapman-Robbins bound to establish lower bounds on the variance of any unbiased estimator of the unknown parameters. The effects of inexact rendering of the true forward model on the computed lower bounds are also analyzed, both theoretically and via simulations. Experimental evaluations compare the computed lower bounds with the performance of the Maximum Likelihood Estimator on a canonical object localization problem, showing that the lower bounds computed via the framework proposed here are indicative of the true underlying fundamental limits in several nominally representative scenarios."}
