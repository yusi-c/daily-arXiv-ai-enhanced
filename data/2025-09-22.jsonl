{"id": "2509.15363", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.15363", "abs": "https://arxiv.org/abs/2509.15363", "authors": ["Debasish Dutta", "Neeharika Sonowal", "Risheraj Barauh", "Deepjyoti Chetia", "Sanjib Kr Kalita"], "title": "Recent Advancements in Microscopy Image Enhancement using Deep Learning: A Survey", "comment": "7 pages, 3 figures and 1 table. 2024 IEEE International Conference on\n  Computer Vision and Machine Intelligence (CVMI). IEEE, 2024", "summary": "Microscopy image enhancement plays a pivotal role in understanding the\ndetails of biological cells and materials at microscopic scales. In recent\nyears, there has been a significant rise in the advancement of microscopy image\nenhancement, specifically with the help of deep learning methods. This survey\npaper aims to provide a snapshot of this rapidly growing state-of-the-art\nmethod, focusing on its evolution, applications, challenges, and future\ndirections. The core discussions take place around the key domains of\nmicroscopy image enhancement of super-resolution, reconstruction, and\ndenoising, with each domain explored in terms of its current trends and their\npractical utility of deep learning."}
{"id": "2509.15422", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.15422", "abs": "https://arxiv.org/abs/2509.15422", "authors": ["Edward P. Chandler", "Shirin Shoushtari", "Brendt Wohlberg", "Ulugbek S. Kamilov"], "title": "Analysis Plug-and-Play Methods for Imaging Inverse Problems", "comment": null, "summary": "Plug-and-Play Priors (PnP) is a popular framework for solving imaging inverse\nproblems by integrating learned priors in the form of denoisers trained to\nremove Gaussian noise from images. In standard PnP methods, the denoiser is\napplied directly in the image domain, serving as an implicit prior on natural\nimages. This paper considers an alternative analysis formulation of PnP, in\nwhich the prior is imposed on a transformed representation of the image, such\nas its gradient. Specifically, we train a Gaussian denoiser to operate in the\ngradient domain, rather than on the image itself. Conceptually, this is an\nextension of total variation (TV) regularization to learned TV regularization.\nTo incorporate this gradient-domain prior in image reconstruction algorithms,\nwe develop two analysis PnP algorithms based on half-quadratic splitting\n(APnP-HQS) and the alternating direction method of multipliers (APnP-ADMM). We\nevaluate our approach on image deblurring and super-resolution, demonstrating\nthat the analysis formulation achieves performance comparable to image-domain\nPnP algorithms."}
{"id": "2509.15595", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.15595", "abs": "https://arxiv.org/abs/2509.15595", "authors": ["Kaniz Fatema", "Vaibhav Thakur", "Emad A. Mohammed"], "title": "Prostate Capsule Segmentation from Micro-Ultrasound Images using Adaptive Focal Loss", "comment": null, "summary": "Micro-ultrasound (micro-US) is a promising imaging technique for cancer\ndetection and computer-assisted visualization. This study investigates prostate\ncapsule segmentation using deep learning techniques from micro-US images,\naddressing the challenges posed by the ambiguous boundaries of the prostate\ncapsule. Existing methods often struggle in such cases, motivating the\ndevelopment of a tailored approach. This study introduces an adaptive focal\nloss function that dynamically emphasizes both hard and easy regions, taking\ninto account their respective difficulty levels and annotation variability. The\nproposed methodology has two primary strategies: integrating a standard focal\nloss function as a baseline to design an adaptive focal loss function for\nproper prostate capsule segmentation. The focal loss baseline provides a robust\nfoundation, incorporating class balancing and focusing on examples that are\ndifficult to classify. The adaptive focal loss offers additional flexibility,\naddressing the fuzzy region of the prostate capsule and annotation variability\nby dilating the hard regions identified through discrepancies between expert\nand non-expert annotations. The proposed method dynamically adjusts the\nsegmentation model's weights better to identify the fuzzy regions of the\nprostate capsule. The proposed adaptive focal loss function demonstrates\nsuperior performance, achieving a mean dice coefficient (DSC) of 0.940 and a\nmean Hausdorff distance (HD) of 1.949 mm in the testing dataset. These results\nhighlight the effectiveness of integrating advanced loss functions and adaptive\ntechniques into deep learning models. This enhances the accuracy of prostate\ncapsule segmentation in micro-US images, offering the potential to improve\nclinical decision-making in prostate cancer diagnosis and treatment planning."}
{"id": "2509.15689", "categories": ["eess.IV", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2509.15689", "abs": "https://arxiv.org/abs/2509.15689", "authors": ["Jay Park", "Hong Nguyen", "Sean Foley", "Jihwan Lee", "Yoonjeong Lee", "Dani Byrd", "Shrikanth Narayanan"], "title": "Interpretable Modeling of Articulatory Temporal Dynamics from real-time MRI for Phoneme Recognition", "comment": null, "summary": "Real-time Magnetic Resonance Imaging (rtMRI) visualizes vocal tract action,\noffering a comprehensive window into speech articulation. However, its signals\nare high dimensional and noisy, hindering interpretation. We investigate\ncompact representations of spatiotemporal articulatory dynamics for phoneme\nrecognition from midsagittal vocal tract rtMRI videos. We compare three feature\ntypes: (1) raw video, (2) optical flow, and (3) six linguistically-relevant\nregions of interest (ROIs) for articulator movements. We evaluate models\ntrained independently on each representation, as well as multi-feature\ncombinations. Results show that multi-feature models consistently outperform\nsingle-feature baselines, with the lowest phoneme error rate (PER) of 0.34\nobtained by combining ROI and raw video. Temporal fidelity experiments\ndemonstrate a reliance on fine-grained articulatory dynamics, while ROI\nablation studies reveal strong contributions from tongue and lips. Our findings\nhighlight how rtMRI-derived features provide accuracy and interpretability, and\nestablish strategies for leveraging articulatory data in speech processing."}
{"id": "2509.15475", "categories": ["eess.SP", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2509.15475", "abs": "https://arxiv.org/abs/2509.15475", "authors": ["Lioz Berman", "Sharon Gannot", "Tom Tirer"], "title": "(SP)$^2$-Net: A Neural Spatial Spectrum Method for DOA Estimation", "comment": "Code can be found at https://github.com/Liozb/SP2-Net", "summary": "We consider the problem of estimating the directions of arrival (DOAs) of\nmultiple sources from a single snapshot of an antenna array, a task with many\npractical applications. In such settings, the classical Bartlett beamformer is\ncommonly used, as maximum likelihood estimation becomes impractical when the\nnumber of sources is unknown or large, and spectral methods based on the sample\ncovariance are not applicable due to the lack of multiple snapshots. However,\nthe accuracy and resolution of the Bartlett beamformer are fundamentally\nlimited by the array aperture. In this paper, we propose a deep learning\ntechnique, comprising a novel architecture and training strategy, for\ngenerating a high-resolution spatial spectrum from a single snapshot.\nSpecifically, we train a deep neural network that takes the measurements and a\nhypothesis angle as input and learns to output a score consistent with the\ncapabilities of a much wider array. At inference time, a heatmap can be\nproduced by scanning an arbitrary set of angles. We demonstrate the advantages\nof our trained model, named (SP)$^2$-Net, over the Bartlett beamformer and\nsparsity-based DOA estimation methods."}
{"id": "2509.15758", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.15758", "abs": "https://arxiv.org/abs/2509.15758", "authors": ["Yue Zhang", "Jiahua Dong", "Chengtao Peng", "Qiuli Wang", "Dan Song", "Guiduo Duan"], "title": "Uncertainty-Gated Deformable Network for Breast Tumor Segmentation in MR Images", "comment": "5 pages, 2 figures", "summary": "Accurate segmentation of breast tumors in magnetic resonance images (MRI) is\nessential for breast cancer diagnosis, yet existing methods face challenges in\ncapturing irregular tumor shapes and effectively integrating local and global\nfeatures. To address these limitations, we propose an uncertainty-gated\ndeformable network to leverage the complementary information from CNN and\nTransformers. Specifically, we incorporates deformable feature modeling into\nboth convolution and attention modules, enabling adaptive receptive fields for\nirregular tumor contours. We also design an Uncertainty-Gated Enhancing Module\n(U-GEM) to selectively exchange complementary features between CNN and\nTransformer based on pixel-wise uncertainty, enhancing both local and global\nrepresentations. Additionally, a Boundary-sensitive Deep Supervision Loss is\nintroduced to further improve tumor boundary delineation. Comprehensive\nexperiments on two clinical breast MRI datasets demonstrate that our method\nachieves superior segmentation performance compared with state-of-the-art\nmethods, highlighting its clinical potential for accurate breast tumor\ndelineation."}
{"id": "2509.15564", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.15564", "abs": "https://arxiv.org/abs/2509.15564", "authors": ["Jeongjae Lee", "Wonseok Choi", "Songnam Hong"], "title": "CSIT-Free Downlink Transmission for mmWave MU-MISO Systems in High-Mobility Scenario", "comment": "Submitted to IEEE Conference", "summary": "This paper investigates the downlink (DL) transmission in millimeter-wave\n(mmWave) multi-user multiple-input single-output (MU-MISO) systems especially\nfocusing on a high speed mobile scenario. To complete the DL transmission\nwithin an extremely short channel coherence time, we propose a novel DL\ntransmission framework that eliminates the need for channel state information\nat the transmitter (CSIT), of which acquisition process requires a substantial\noverhead, instead fully exploiting the given channel coherence time. Harnessing\nthe characteristic of mmWave channel and uniquely designed CSIT-free unitary\nprecoding, we propose a symbol detection method along with the simultaneous CSI\nat the receiver (CSIR) and Doppler shift estimation method to completely cancel\nthe interferences while achieving a full combining gain. Via simulations, we\ndemonstrate the effectiveness of the proposed method comparing with the\nexisting baselines."}
{"id": "2509.15802", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.15802", "abs": "https://arxiv.org/abs/2509.15802", "authors": ["Qijun Yang", "Boyang Wang", "Hujun Yin"], "title": "DPC-QA Net: A No-Reference Dual-Stream Perceptual and Cellular Quality Assessment Network for Histopathology Images", "comment": null, "summary": "Reliable whole slide imaging (WSI) hinges on image quality,yet staining\nartefacts, defocus, and cellular degradations are common. We present DPC-QA\nNet, a no-reference dual-stream network that couples wavelet-based global\ndifference perception with cellular quality assessment from nuclear and\nmembrane embeddings via an Aggr-RWKV module. Cross-attention fusion and\nmulti-term losses align perceptual and cellular cues. Across different\ndatasets, our model detects staining, membrane, and nuclear issues with >92%\naccuracy and aligns well with usability scores; on LIVEC and KonIQ it\noutperforms state-of-the-art NR-IQA. A downstream study further shows strong\npositive correlations between predicted quality and cell recognition accuracy\n(e.g., nuclei PQ/Dice, membrane boundary F-score), enabling practical\npre-screening of WSI regions for computational pathology."}
{"id": "2509.15601", "categories": ["eess.SP", "physics.app-ph"], "pdf": "https://arxiv.org/pdf/2509.15601", "abs": "https://arxiv.org/abs/2509.15601", "authors": ["Wanghan Lv", "Kumar Vijay Mishra", "Jinsong Hu"], "title": "Twisting Signals for Joint Radar-Communications: An OAM Vortex Beam Approach", "comment": "13 pages, 12 figures, 1 table", "summary": "Orbital angular momentum (OAM) technology has attracted much research\ninterest in recent years because of its characteristic helical phase front\ntwisting around the propagation axis and natural orthogonality among different\nOAM states to encode more degrees of freedom than classical planar beams.\nLeveraging upon these features, OAM technique has been applied to wireless\ncommunication systems to enhance spectral efficiency and radar systems to\ndistinguish spatial targets without beam scanning. Leveraging upon these unique\nproperties, we propose an OAM-based millimeter-wave joint radar-communications\n(JRC) system comprising a bi-static automotive radar and vehicle-to-vehicle\n(V2V) communications. Different from existing uniform circular array (UCA)\nbased OAM systems where each element is an isotropic antenna, an OAM spatial\nmodulation scheme utilizing a uniform linear array (ULA) is adopted with each\nelement being a traveling-wave antenna, producing multiple Laguerre-Gaussian\n(LG) vortex beams simultaneously. Specifically, we first build a novel\nbi-static automotive OAM-JRC model that embeds communication messages in a\nradar signal, following which a target position and velocity parameters\nestimation algorithm is designed with only radar frames. Then, an OAM-based\nmode-division multiplexing (MDM) strategy between radar and JRC frames is\npresented to ensure the JRC parameters identifiability and recovery.\nFurthermore, we analyze the performance of the JRC system through deriving\nrecovery guarantees and Cram\\'er-Rao lower bound (CRLB) of radar target\nparameters and evaluating the bit error rate (BER) of communication,\nrespectively. Our numerical experiments validate the effectiveness of the\nproposed OAM-based JRC system and parameter estimation method."}
{"id": "2509.15814", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.15814", "abs": "https://arxiv.org/abs/2509.15814", "authors": ["Qijun Yang", "Yating Huang", "Lintao Xiang", "Hujun Yin"], "title": "QWD-GAN: Quality-aware Wavelet-driven GAN for Unsupervised Medical Microscopy Images Denoising", "comment": null, "summary": "Image denoising plays a critical role in biomedical and microscopy imaging,\nespecially when acquiring wide-field fluorescence-stained images. This task\nfaces challenges in multiple fronts, including limitations in image acquisition\nconditions, complex noise types, algorithm adaptability, and clinical\napplication demands. Although many deep learning-based denoising techniques\nhave demonstrated promising results, further improvements are needed in\npreserving image details, enhancing algorithmic efficiency, and increasing\nclinical interpretability. We propose an unsupervised image denoising method\nbased on a Generative Adversarial Network (GAN) architecture. The approach\nintroduces a multi-scale adaptive generator based on the Wavelet Transform and\na dual-branch discriminator that integrates difference perception feature maps\nwith original features. Experimental results on multiple biomedical microscopy\nimage datasets show that the proposed model achieves state-of-the-art denoising\nperformance, particularly excelling in the preservation of high-frequency\ninformation. Furthermore, the dual-branch discriminator is seamlessly\ncompatible with various GAN frameworks. The proposed quality-aware,\nwavelet-driven GAN denoising model is termed as QWD-GAN."}
{"id": "2509.15603", "categories": ["eess.SP", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2509.15603", "abs": "https://arxiv.org/abs/2509.15603", "authors": ["Sven Hinderer"], "title": "Blind Source Separation of Radar Signals in Time Domain Using Deep Learning", "comment": null, "summary": "Identification and further analysis of radar emitters in a contested\nenvironment requires detection and separation of incoming signals. If they\narrive from the same direction and at similar frequencies, deinterleaving them\nremains challenging. A solution to overcome this limitation becomes\nincreasingly important with the advancement of emitter capabilities. We propose\ntreating the problem as blind source separation in time domain and apply\nsupervisedly trained neural networks to extract the underlying signals from the\nreceived mixture. This allows us to handle highly overlapping and also\ncontinuous wave (CW) signals from both radar and communication emitters. We\nmake use of advancements in the field of audio source separation and extend a\ncurrent state-of-the-art model with the objective of deinterleaving arbitrary\nradio frequency (RF) signals. Results show, that our approach is capable of\nseparating two unknown waveforms in a given frequency band with a single\nchannel receiver."}
{"id": "2509.15947", "categories": ["eess.IV", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.15947", "abs": "https://arxiv.org/abs/2509.15947", "authors": ["Katharina Eckstein", "Constantin Ulrich", "Michael Baumgartner", "Jessica Kächele", "Dimitrios Bounias", "Tassilo Wald", "Ralf Floca", "Klaus H. Maier-Hein"], "title": "The Missing Piece: A Case for Pre-Training in 3D Medical Object Detection", "comment": "MICCAI 2025", "summary": "Large-scale pre-training holds the promise to advance 3D medical object\ndetection, a crucial component of accurate computer-aided diagnosis. Yet, it\nremains underexplored compared to segmentation, where pre-training has already\ndemonstrated significant benefits. Existing pre-training approaches for 3D\nobject detection rely on 2D medical data or natural image pre-training, failing\nto fully leverage 3D volumetric information. In this work, we present the first\nsystematic study of how existing pre-training methods can be integrated into\nstate-of-the-art detection architectures, covering both CNNs and Transformers.\nOur results show that pre-training consistently improves detection performance\nacross various tasks and datasets. Notably, reconstruction-based\nself-supervised pre-training outperforms supervised pre-training, while\ncontrastive pre-training provides no clear benefit for 3D medical object\ndetection. Our code is publicly available at:\nhttps://github.com/MIC-DKFZ/nnDetection-finetuning."}
{"id": "2509.15627", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.15627", "abs": "https://arxiv.org/abs/2509.15627", "authors": ["Ziyuan Zheng", "Qingqing Wu", "Yanze Zhu", "Wen Chen", "Ying Gao", "Honghao Wang"], "title": "Wireless Sensing with Movable Intelligent Surface", "comment": "13 pages, 11 figures, submitted to an IEEE Journal for possible\n  publications", "summary": "Future wireless networks are envisioned to deliver not only gigabit\ncommunications but also ubiquitous sensing. Reconfigurable intelligent surfaces\n(RISs) have emerged to reshape radio propagation, recently showing considerable\npromise for wireless sensing. Still, their per-element electronic tuning incurs\nprohibitive hardware cost and power consumption. Motivated by the concept of\nfluid antenna system (FAS), this paper introduces a low-cost movable\nintelligent surface (MIS) for wireless sensing, which replaces element-wise\nelectronic phase tuning with panel-wise mechanical reconfiguration. The MIS\nstacks a large fixed and a smaller movable pre-phased metasurface layers, whose\ndifferential position shifts synthesize distinct composite phase patterns,\nenabling multiple beam patterns for multi-target detection. We characterize a\nMIS-enabled multi-hop echo signal model with multi-target interference and then\nformulate a worst-case sensing signal-to-interference-plus-noise ratio (SINR)\nmaximization problem that jointly designs MIS phase shifts and schedules MS2's\nposition. A Riemannian Augmented Lagrangian Method (RALM)-based algorithm is\ndeveloped to solve the formulated mixed-integer non-convex problem. We also\nderive a heuristic MIS beam steering design with closed-form phase distribution\nand position scheduling. Simulations validate MIS's beam pattern\nreconfiguration capability, show that the RALM-based scheme significantly\noutperforms the closed-form scheme in improving sensing SINR, and uncover a\ngain-diversity trade-off in beam patterns that informs the optimal choice of\nMIS configuration."}
{"id": "2509.16019", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.16019", "abs": "https://arxiv.org/abs/2509.16019", "authors": ["Bhavesh Sandbhor", "Bheeshm Sharma", "Balamurugan Palaniappan"], "title": "SLaM-DiMM: Shared Latent Modeling for Diffusion Based Missing Modality Synthesis in MRI", "comment": null, "summary": "Brain MRI scans are often found in four modalities, consisting of T1-weighted\nwith and without contrast enhancement (T1ce and T1w), T2-weighted imaging\n(T2w), and Flair. Leveraging complementary information from these different\nmodalities enables models to learn richer, more discriminative features for\nunderstanding brain anatomy, which could be used in downstream tasks such as\nanomaly detection. However, in clinical practice, not all MRI modalities are\nalways available due to various reasons. This makes missing modality generation\na critical challenge in medical image analysis. In this paper, we propose\nSLaM-DiMM, a novel missing modality generation framework that harnesses the\npower of diffusion models to synthesize any of the four target MRI modalities\nfrom other available modalities. Our approach not only generates high-fidelity\nimages but also ensures structural coherence across the depth of the volume\nthrough a dedicated coherence enhancement mechanism. Qualitative and\nquantitative evaluations on the BraTS-Lighthouse-2025 Challenge dataset\ndemonstrate the effectiveness of the proposed approach in synthesizing\nanatomically plausible and structurally consistent results. Code is available\nat https://github.com/BheeshmSharma/SLaM-DiMM-MICCAI-BraTS-Challenge-2025."}
{"id": "2509.15636", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.15636", "abs": "https://arxiv.org/abs/2509.15636", "authors": ["Tobias Lafer", "Erik Leitinger", "Klaus Witrisal"], "title": "Optimizing Sparse Antenna Arrays for Localization and Sensing using Vector Spherical Wave Functions", "comment": null, "summary": "In increasing number of electronic devices implement wideband radio\ntechnologies for localization and sensing purposes, like ultra-wideband (UWB).\nSuch radio technologies benefit from a large number of antennas, but space for\nantennas is often limited, especially in devices for mobile and IoT\napplications. A common challenge is therefore to optimize the placement and\norientations of a small number of antenna elements inside a device, leading to\nthe best localization performance. We propose a method for systematically\napproaching the optimization of such sparse arrays by means of Cram\\'er-Rao\nlower bounds (CRLBs) and vector spherical wave functions (VSWFs). The VSWFs\nform the basis of a wideband signal model considering frequency, direction and\npolarization-dependent characteristics of the antenna array under test (AUT),\ntogether with mutual coupling and distortions from surrounding obstacles. We\nderive the CRLBs for localization parameters like delay and angle-of-arrival\nfor this model under additive white Gaussian noise channel conditions, and\nformulate optimization problems for determining optimal antenna positions and\norientations via minimization of the CRLBs. The proposed optimization procedure\nis demonstrated by means of an exemplary arrangement of three Crossed\nExponentially Tapered Slot (XETS) antennas."}
{"id": "2509.16044", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.16044", "abs": "https://arxiv.org/abs/2509.16044", "authors": ["Fang Lu", "Jingyu Xu", "Qinxiu Sun", "Qiong Lou"], "title": "FMD-TransUNet: Abdominal Multi-Organ Segmentation Based on Frequency Domain Multi-Axis Representation Learning and Dual Attention Mechanisms", "comment": null, "summary": "Accurate abdominal multi-organ segmentation is critical for clinical\napplications. Although numerous deep learning-based automatic segmentation\nmethods have been developed, they still struggle to segment small, irregular,\nor anatomically complex organs. Moreover, most current methods focus on\nspatial-domain analysis, often overlooking the synergistic potential of\nfrequency-domain representations. To address these limitations, we propose a\nnovel framework named FMD-TransUNet for precise abdominal multi-organ\nsegmentation. It innovatively integrates the Multi-axis External Weight Block\n(MEWB) and the improved dual attention module (DA+) into the TransUNet\nframework. The MEWB extracts multi-axis frequency-domain features to capture\nboth global anatomical structures and local boundary details, providing\ncomplementary information to spatial-domain representations. The DA+ block\nutilizes depthwise separable convolutions and incorporates spatial and channel\nattention mechanisms to enhance feature fusion, reduce redundant information,\nand narrow the semantic gap between the encoder and decoder. Experimental\nvalidation on the Synapse dataset shows that FMD-TransUNet outperforms other\nrecent state-of-the-art methods, achieving an average DSC of 81.32\\% and a HD\nof 16.35 mm across eight abdominal organs. Compared to the baseline model, the\naverage DSC increased by 3.84\\%, and the average HD decreased by 15.34 mm.\nThese results demonstrate the effectiveness of FMD-TransUNet in improving the\naccuracy of abdominal multi-organ segmentation."}
{"id": "2509.15650", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.15650", "abs": "https://arxiv.org/abs/2509.15650", "authors": ["Sven Hinderer", "Zheming Yin", "Athanasios Papanikolaou", "Jan Hesselbarth", "Bin Yang"], "title": "Hybrid Baseband Simulation for Single-Channel Radar-Based Indoor Localization System", "comment": null, "summary": "Indoor localization with chirp sequence radar at millimeter wavelength offers\nhigh localization accuracy at low system cost. We propose a hybrid radar\nbaseband signal simulator for our novel single-channel radar-based indoor\nlocalization system consisting of an active radar and passive reflectors as\nreferences. By combining ray tracing channel simulations with real measurements\nof the two-way antenna gain of the radar and accurate simulation of the radar\ncross section of chosen reflectors, realistic modeling of the baseband receive\nsignal in complex scenarios is achieved."}
{"id": "2509.16106", "categories": ["eess.IV", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.16106", "abs": "https://arxiv.org/abs/2509.16106", "authors": ["Yuanyun Hu", "Evan Bell", "Guijin Wang", "Yu Sun"], "title": "PRISM: Probabilistic and Robust Inverse Solver with Measurement-Conditioned Diffusion Prior for Blind Inverse Problems", "comment": null, "summary": "Diffusion models are now commonly used to solve inverse problems in\ncomputational imaging. However, most diffusion-based inverse solvers require\ncomplete knowledge of the forward operator to be used. In this work, we\nintroduce a novel probabilistic and robust inverse solver with\nmeasurement-conditioned diffusion prior (PRISM) to effectively address blind\ninverse problems. PRISM offers a technical advancement over current methods by\nincorporating a powerful measurement-conditioned diffusion model into a\ntheoretically principled posterior sampling scheme. Experiments on blind image\ndeblurring validate the effectiveness of the proposed method, demonstrating the\nsuperior performance of PRISM over state-of-the-art baselines in both image and\nblur kernel recovery."}
{"id": "2509.15681", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.15681", "abs": "https://arxiv.org/abs/2509.15681", "authors": ["Jiahuan Wu", "Xinchun Yu", "Xiao-Ping Zhang"], "title": "Extended k-u Fading Model in mmWave Communication: Statistical Properties and Performance Evaluations", "comment": null, "summary": "This study proposes a small-scale fading model, named the extended k-u model,\nwhich incorporates the imbalance of multipath clusters by adding a new\nparameter based on the original k-u model. The extended k-u model outperforms\nthe k-u model in characterizing small-scale fading in the millimeter-wave\n(mmWave) band and has more accurate modeling capability than the extended n-u\nmodel in scenarios with line-of-sight (LoS) paths. And it is mathematically\nmore tractable than the a-k-n-u model. Experiments are conducted for mmWave\ncommunication scenarios with LoS paths, covering the outdoor 28 GHz band, the\nindoor 65 GHz band, and the indoor 92 GHz band. The results demonstrate that\nthe extended k-u model achieves a smaller mean square error in fitting the\nmeasured data compared to both the k-u model and the extended n-u model across\nall scenarios. In addition, through theoretical derivations, closed-form\nexpressions are obtained for the key statistical characteristics of the\nextended k-u model, including the probability density function, cumulative\ndistribution function, moments of arbitrary order, and moment generating\nfunction. Based on these statistics, this study further derives and analyzes\nthe expressions for some performance metrics of the communication system,\nincluding the amount of fading, the probability of outage, and the average bit\nerror rate."}
{"id": "2509.15718", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.15718", "abs": "https://arxiv.org/abs/2509.15718", "authors": ["Hao Zhang", "Fuhui Zhou", "Qihui Wu", "Chau Yuen"], "title": "Distributed Multi-Task Learning for Joint Wireless Signal Enhancement and Recognition", "comment": "accepted by Transactions on Cognitive Communications and Networking", "summary": "Wireless signal recognition (WSR) is crucial in modern and future wireless\ncommunication networks since it aims to identify the properties of the received\nsignal in a no-collaborative manner. However, it is challenging to accurately\nclassify signals in low signal-to-noise ratio (SNR) conditions and distributed\nnetwork settings. In this paper, we propose a novel distributed multi-task\nlearning framework for joint wireless signal enhancement and recognition\n(WSER), addressing the crucial need for non-collaborative signal identification\nin modern wireless networks. Our approach integrates a wireless signal\nenhancement and recognition network (WSERNet) with FedProx+, an enhanced\nfederated learning algorithm designed for heterogeneous data distributions.\nSpecifically, WSERNet leverages an asymmetric convolution block (ACBlock) to\ncapture long-range dependencies in the input signal and improve the performance\nof the deep learning model. FedProx+ introduces a proximal term to the loss\nfunction to encourage the model updates to be closer to the previous model,\nenhancing the convergence speed and robustness of federated learning. Extensive\nexperiments demonstrate the effectiveness of the proposed framework for joint\nWSER, achieving superior performance compared to state-of-the-art methods under\nboth centralized and distributed settings including independent and identically\ndistributed (IID) and non-IID data distributions."}
{"id": "2509.15766", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.15766", "abs": "https://arxiv.org/abs/2509.15766", "authors": ["Peihao Dong", "Jingchun Wang", "Shen Gao", "Fuhui Zhou", "Qihui Wu"], "title": "Explainable Deep Learning Based Adversarial Defense for Automatic Modulation Classification", "comment": "Accepted by IEEE Internet of Things Journal", "summary": "Deep learning (DL) has been widely applied to enhance automatic modulation\nclassification (AMC). However, the elaborate AMC neural networks are\nsusceptible to various adversarial attacks, which are challenging to handle due\nto the generalization capability and computational cost. In this article, an\nexplainable DL based defense scheme, called SHapley Additive exPlanation\nenhanced Adversarial Fine-Tuning (SHAP-AFT), is developed in the perspective of\ndisclosing the attacking impact on the AMC network. By introducing the concept\nof cognitive negative information, the motivation of using SHAP for defense is\ntheoretically analyzed first. The proposed scheme includes three stages, i.e.,\nthe attack detection, the information importance evaluation, and the AFT. The\nfirst stage indicates the existence of the attack. The second stage evaluates\ncontributions of the received data and removes those data positions using\nnegative Shapley values corresponding to the dominating negative information\ncaused by the attack. Then the AMC network is fine-tuned based on adversarial\nadaptation samples using the refined received data pattern. Simulation results\nshow the effectiveness of the Shapley value as the key indicator as well as the\nsuperior defense performance of the proposed SHAP-AFT scheme in face of\ndifferent attack types and intensities."}
{"id": "2509.15902", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.15902", "abs": "https://arxiv.org/abs/2509.15902", "authors": ["Haofan Dong", "Ozgur B. Akan"], "title": "Fundamental Limits of THz Inter-Satellite ISAC Under Hardware Impairments", "comment": null, "summary": "This paper establishes a theoretical framework for analyzing the fundamental\nperformance limits of terahertz (THz) Low Earth Orbit (LEO) inter-satellite\nlink (ISL) Integrated Sensing and Communications (ISAC) systems. We develop a\nunified, end-to-end signal model that, jointly captures the effects of extreme\norbital dynamics, cascaded non-ideal hardware impairments, and micro-radian\nbeam pointing errors. Through Bayesian Cram\\'er-Rao Lower Bound (BCRLB)\nanalysis, we derive the ultimate sensing accuracy for range and range-rate,\nrevealing a quadratic ($1/f_c^2$) improvement in estimation variance with\ncarrier frequency, which is ultimately floored by signal-dependent hardware\ndistortion. For communication, we show that system performance is not\npower-limited but hardware-limited, deriving a closed-form capacity ceiling\nunder the joint effect of phase noise and PA nonlinearity: $C_{\\text{sat}} =\n\\log_2(1 + e^{-\\sigma_\\phi^2}/\\Gamma_{\\text{eff}})$, where\n$\\Gamma_{\\text{eff}}$ is a proposed hardware quality factor. Our numerical\nresults, based on state-of-the-art component data and the identified\ntrade-offs, suggest that favorable operational conditions may exist in the\nsub-THz frequency range (200-600 GHz) where the quadratic sensing gain with\nfrequency is balanced against hardware quality degradation. Power Amplifier\n(PA) nonlinearity emerges as the dominant performance bottleneck, exceeding\nother impairments by one to two orders of magnitude."}
{"id": "2509.15964", "categories": ["eess.SP", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.15964", "abs": "https://arxiv.org/abs/2509.15964", "authors": ["Tianyu Li", "Yan Xin", "Jianzhong", "Zhang"], "title": "MoE-CE: Enhancing Generalization for Deep Learning based Channel Estimation via a Mixture-of-Experts Framework", "comment": null, "summary": "Reliable channel estimation (CE) is fundamental for robust communication in\ndynamic wireless environments, where models must generalize across varying\nconditions such as signal-to-noise ratios (SNRs), the number of resource blocks\n(RBs), and channel profiles. Traditional deep learning (DL)-based methods\nstruggle to generalize effectively across such diverse settings, particularly\nunder multitask and zero-shot scenarios. In this work, we propose MoE-CE, a\nflexible mixture-of-experts (MoE) framework designed to enhance the\ngeneralization capability of DL-based CE methods. MoE-CE provides an\nappropriate inductive bias by leveraging multiple expert subnetworks, each\nspecialized in distinct channel characteristics, and a learned router that\ndynamically selects the most relevant experts per input. This architecture\nenhances model capacity and adaptability without a proportional rise in\ncomputational cost while being agnostic to the choice of the backbone model and\nthe learning algorithm. Through extensive experiments on synthetic datasets\ngenerated under diverse SNRs, RB numbers, and channel profiles, including\nmultitask and zero-shot evaluations, we demonstrate that MoE-CE consistently\noutperforms conventional DL approaches, achieving significant performance gains\nwhile maintaining efficiency."}
{"id": "2509.15973", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.15973", "abs": "https://arxiv.org/abs/2509.15973", "authors": ["Yiming Zhou", "Wei Dai"], "title": "Scalable Hessian-free Proximal Conjugate Gradient Method for Nonconvex and Nonsmooth Optimization", "comment": "Manuscript for ICASSP 2026 Submission", "summary": "This work studies a composite minimization problem involving a differentiable\nfunction q and a nonsmooth function h, both of which may be nonconvex. This\nproblem is ubiquitous in signal processing and machine learning yet remains\nchallenging to solve efficiently, particularly when large-scale instances, poor\nconditioning, and nonconvexity coincide. To address these challenges, we\npropose a proximal conjugate gradient method (PCG) that matches the fast\nconvergence of proximal (quasi-)Newton algorithms while reducing computation\nand memory complexity, and is especially effective for spectrally clustered\nHessians. Our key innovation is to form, at each iteration, an approximation to\nthe Newton direction based on CG iterations to build a majorization surrogate.\nWe define this surrogate in a curvature-aware manner and equip it with a\nCG-derived isotropic weight, guaranteeing majorization of a local second-order\nmodel of q along the given direction. To better preserve majorization after the\nproximal step and enable further approximation refinement, we scale the CG\ndirection by the ratio between the Cauchy step length and a step size derived\nfrom the largest Ritz value of the CG tridiagonal. All curvature is accessed\nvia Hessian-vector products computed by automatic differentiation, keeping the\nmethod Hessian-free. Convergence to first-order critical points is established.\nNumerical experiments on CS-MRI with nonconvex regularization and on dictionary\nlearning, against benchmark methods, demonstrate the efficiency of the proposed\napproach."}
{"id": "2509.15993", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.15993", "abs": "https://arxiv.org/abs/2509.15993", "authors": ["Yuwei Wang", "Li Sun", "Tingting Yang"], "title": "Wireless Channel Foundation Model with Embedded Noise-Plus-Interference Suppression Structure", "comment": null, "summary": "Wireless channel foundation model (WCFM) is a task-agnostic AI model that is\npretrained on large-scale wireless channel datasets to learn a universal\nchannel feature representation that can be used for a wide range of downstream\ntasks related to communications and sensing. While existing works on WCFM have\ndemonstrated its great potentials in various tasks including beam prediction,\nchannel prediction, localization, etc, the models are all trained using perfect\n(i.e., error-free and complete) channel information state (CSI) data which are\ngenerated with simulation tools. However, in practical systems where the WCFM\nis deployed, perfect CSI is not available. Instead, channel estimation needs to\nbe first performed based on pilot signals over a subset of the resource\nelements (REs) to acquire a noisy version of the CSI (termed as degraded CSI),\nwhich significantly differs from the perfect CSI in some real-world\nenvironments with severe noise and interference. As a result, the feature\nrepresentation generated by the WCFM is unable to reflect the characteristics\nof the true channel, yielding performance degradation in downstream tasks. To\naddress this issue, in this paper we propose an enhanced wireless channel\nfoundation model architecture with noise-plus-interference (NPI) suppression\ncapability. In our approach, coarse estimates of the CSIs are first obtained.\nWith these information, two projection matrices are computed to extract the NPI\nterms in the received signals, which are further processed by a NPI estimation\nand subtraction module. Finally, the resultant signal is passed through a CSI\ncompletion network to get a clean version of the CSI, which is used for feature\nextraction. Simulation results demonstrated that compared to the\nstate-of-the-art solutions, WCFM with NPI suppression structure achieves\nimproved performance on channel prediction task."}
{"id": "2509.16045", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.16045", "abs": "https://arxiv.org/abs/2509.16045", "authors": ["Shan Shan", "Chongjun Ouyang", "Yong Li", "Yuanwei Liu"], "title": "Secure Multicast Communications with Pinching-Antenna Systems (PASS)", "comment": null, "summary": "This article investigates secure multicast communications in pinching-antenna\nsystems (PASS), where pinching beamforming is enabled by adaptively adjusting\npinching antenna (PAs) positions along waveguides to improve multicast\nsecurity. Specifically, a PASS-based secure multicast framework is proposed, in\nwhich joint optimization of transmit and pinching beamforming is conducted to\nmaximize the secrecy multicast rate. i) For the single-group multicast\nscenario, an alternating optimization (AO) framework is employed, where the\npinching beamformer is updated via an element-wise sequential optimization\nmethod. The transmit beamformer is designed via a semidefinite relaxation (SDR)\nformulation for an upper-bound solution, while a Dinkelbach-alternating\ndirection method of multipliers (ADMM) offers a low-complexity alternative. ii)\nFor the multi-group multicast scenario, transmit and pinching beamformers are\nalternately optimized under a majorization-minimization (MM) framework. The\ntransmit beamformer is obtained via SDR or an efficient second-order cone\nprogramming (SOCP) method, while the pinching beamformer is updated through\nMM-based element-wise sequential update strategy. Numerical results are\nprovided to demonstrate that: (i) PASS consistently outperform conventional\nfixed-location antenna architectures in terms of secrecy performance across\nvarious configurations; and (ii) the performance advantage of PASS over\nfixed-location architectures becomes more significant with increased service\nregion, larger antenna arrays, and higher user and eavesdropper densities."}
{"id": "2509.16086", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.16086", "abs": "https://arxiv.org/abs/2509.16086", "authors": ["Sahil P. Wankhede", "Xiangdong Xie", "Ali H. Alshehri", "Keith W Brashler", "Mohammad Ba'adani", "Doru C Turcan", "Kamal Youcef-Toumi", "Xian Du"], "title": "In-Situ Fault Detection of Submerged Pump Impellers Using Encapsulated Accelerometers and Machine Learning", "comment": "Under review", "summary": "Vertical turbine pumps in oil and gas operations rely on motor-mounted\naccelerometers for condition monitoring. However, these sensors cannot detect\nfaults at submerged impellers exposed to harsh downhole environments. We\npresent the first study deploying encapsulated accelerometers mounted directly\non submerged impeller bowls, enabling in-situ vibration monitoring. Using a\nlab-scale pump setup with 1-meter oil submergence, we collected vibration data\nunder normal and simulated fault conditions. The data were analyzed using a\nsuite of machine learning models -- spanning traditional and deep learning\nmethods -- to evaluate sensor effectiveness. Impeller-mounted sensors achieved\n91.3% average accuracy and 0.973 AUC-ROC, outperforming the best non-submerged\nsensor. Crucially, encapsulation caused no statistically significant\nperformance loss in sensor performance, confirming its viability for\noil-submerged environments. While the lab setup used shallow submergence,\nreal-world pump impellers operate up to hundreds of meters underground -- well\nbeyond the range of surface-mounted sensors. This first-of-its-kind in-situ\nmonitoring system demonstrates that impeller-mounted sensors -- encapsulated\nfor protection while preserving diagnostic fidelity -- can reliably detect\nfaults in critical submerged pump components. By capturing localized vibration\nsignatures that are undetectable from surface-mounted sensors, this approach\nenables earlier fault detection, reduces unplanned downtime, and optimizes\nmaintenance for downhole systems in oil and gas operations."}
{"id": "2509.16183", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.16183", "abs": "https://arxiv.org/abs/2509.16183", "authors": ["Tyler G. R. Reid", "Matteo Gala", "Mathieu Favreau", "Argyris Kriezis", "Michael O'Meara", "Andre Pant", "Paul Tarantino", "Christina Youn"], "title": "Xona Pulsar Compatibility with GNSS", "comment": "15 pages, 12 figures", "summary": "At least ten emerging providers are developing satellite navigation systems\nfor low Earth orbit (LEO). Compatibility with existing GNSS in L-band is\ncritical to their successful deployment and for the larger ecosystem. Xona is\ndeploying Pulsar, a near 260-satellite LEO constellation offering dual L-band\nnavigation services near L1 and L5. Designed for interoperability, Pulsar\nprovides centimeter-level accuracy, resilience, and authentication, while\nmaintaining a format that existing GNSS receivers can support through a\nfirmware update. This study examines Pulsar's compatibility with GPS and\nGalileo by evaluating C/N0 degradation caused by the introduction of its X1 and\nX5 signals. Using spectrally compact QPSK modulation, Pulsar minimizes\ninterference despite higher signal power. Theoretical analysis is supported by\nhardware testing across a range of commercial GNSS receivers in both lab-based\nsimulation and in-orbit live-sky conditions. The study confirms Pulsar causes\nno adverse interference effects to existing GNSS, supporting coexistence and\nintegration within the global PNT ecosystem."}
