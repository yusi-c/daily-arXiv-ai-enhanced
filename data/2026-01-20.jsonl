{"id": "2601.10762", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2601.10762", "abs": "https://arxiv.org/abs/2601.10762", "authors": ["Siheon Joo", "Hongjo Kim"], "title": "An Implementation of the Crack Topology Score with Extensions", "comment": null, "summary": "The Crack Topology Score (CTS) is a recently proposed metric that focuses on evaluating the topological correctness of crack segmentation outputs. While pixel-wise metrics such as IoU or F1-score fail to capture structural validity, CTS offers a skeleton-based matching framework to measure the preservation of connectivity. This paper presents a faithful implementation of the CTS metric, along with optional preprocessing extensions designed to handle common prediction artifacts (e.g., small holes and edge noise) found in deep learning outputs. All extensions are disabled by default to ensure strict comparability with the original definition. The implementation supports PyTorch-based workflows and includes visualization tools for transparency. Code and archival resources will be made available at https://github.com/SH-Joo/crack-topology-score."}
{"id": "2601.11045", "categories": ["eess.IV", "cs.CV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2601.11045", "abs": "https://arxiv.org/abs/2601.11045", "authors": ["Mayesha Maliha R. Mithila", "Mylene C. Q. Farias"], "title": "Convolutions Need Registers Too: HVS-Inspired Dynamic Attention for Video Quality Assessment", "comment": "Accepted at ACM MMSys 2026. 12 pages, 8 figures. No supplementary material", "summary": "No-reference video quality assessment (NR-VQA) estimates perceptual quality without a reference video, which is often challenging. While recent techniques leverage saliency or transformer attention, they merely address global context of the video signal by using static maps as auxiliary inputs rather than embedding context fundamentally within feature extraction of the video sequence. We present Dynamic Attention with Global Registers for Video Quality Assessment (DAGR-VQA), the first framework integrating register-token directly into a convolutional backbone for spatio-temporal, dynamic saliency prediction. By embedding learnable register tokens as global context carriers, our model enables dynamic, HVS-inspired attention, producing temporally adaptive saliency maps that track salient regions over time without explicit motion estimation. Our model integrates dynamic saliency maps with RGB inputs, capturing spatial data and analyzing it through a temporal transformer to deliver a perceptually consistent video quality assessment. Comprehensive tests conducted on the LSVQ, KonVid-1k, LIVE-VQC, and YouTube-UGC datasets show that the performance is highly competitive, surpassing the majority of top baselines. Research on ablation studies demonstrates that the integration of register tokens promotes the development of stable and temporally consistent attention mechanisms. Achieving an efficiency of 387.7 FPS at 1080p, DAGR-VQA demonstrates computational performance suitable for real-time applications like multimedia streaming systems."}
{"id": "2601.11075", "categories": ["eess.IV", "cs.CV", "physics.med-ph"], "pdf": "https://arxiv.org/pdf/2601.11075", "abs": "https://arxiv.org/abs/2601.11075", "authors": ["Maiko Nagao", "Kaito Urata", "Atsushi Teramoto", "Kazuyoshi Imaizumi", "Masashi Kondo", "Hiroshi Fujita"], "title": "Visual question answering-based image-finding generation for pulmonary nodules on chest CT from structured annotations", "comment": null, "summary": "Interpretation of imaging findings based on morphological characteristics is important for diagnosing pulmonary nodules on chest computed tomography (CT) images. In this study, we constructed a visual question answering (VQA) dataset from structured data in an open dataset and investigated an image-finding generation method for chest CT images, with the aim of enabling interactive diagnostic support that presents findings based on questions that reflect physicians' interests rather than fixed descriptions. In this study, chest CT images included in the Lung Image Database Consortium and Image Database Resource Initiative (LIDC-IDRI) datasets were used. Regions of interest surrounding the pulmonary nodules were extracted from these images, and image findings and questions were defined based on morphological characteristics recorded in the database. A dataset comprising pairs of cropped images, corresponding questions, and image findings was constructed, and the VQA model was fine-tuned on it. Language evaluation metrics such as BLEU were used to evaluate the generated image findings. The VQA dataset constructed using the proposed method contained image findings with natural expressions as radiological descriptions. In addition, the generated image findings showed a high CIDEr score of 3.896, and a high agreement with the reference findings was obtained through evaluation based on morphological characteristics. We constructed a VQA dataset for chest CT images using structured information on the morphological characteristics from the LIDC-IDRI dataset. Methods for generating image findings in response to these questions have also been investigated. Based on the generated results and evaluation metric scores, the proposed method was effective as an interactive diagnostic support system that can present image findings according to physicians' interests."}
{"id": "2601.11085", "categories": ["eess.IV", "cs.CV", "physics.med-ph"], "pdf": "https://arxiv.org/pdf/2601.11085", "abs": "https://arxiv.org/abs/2601.11085", "authors": ["Kaito Urata", "Maiko Nagao", "Atsushi Teramoto", "Kazuyoshi Imaizumi", "Masashi Kondo", "Hiroshi Fujita"], "title": "Generation of Chest CT pulmonary Nodule Images by Latent Diffusion Models using the LIDC-IDRI Dataset", "comment": null, "summary": "Recently, computer-aided diagnosis systems have been developed to support diagnosis, but their performance depends heavily on the quality and quantity of training data. However, in clinical practice, it is difficult to collect the large amount of CT images for specific cases, such as small cell carcinoma with low epidemiological incidence or benign tumors that are difficult to distinguish from malignant ones. This leads to the challenge of data imbalance. In this study, to address this issue, we proposed a method to automatically generate chest CT nodule images that capture target features using latent diffusion models (LDM) and verified its effectiveness. Using the LIDC-IDRI dataset, we created pairs of nodule images and finding-based text prompts based on physician evaluations. For the image generation models, we used Stable Diffusion version 1.5 (SDv1) and 2.0 (SDv2), which are types of LDM. Each model was fine-tuned using the created dataset. During the generation process, we adjusted the guidance scale (GS), which indicates the fidelity to the input text. Both quantitative and subjective evaluations showed that SDv2 (GS = 5) achieved the best performance in terms of image quality, diversity, and text consistency. In the subjective evaluation, no statistically significant differences were observed between the generated images and real images, confirming that the quality was equivalent to real clinical images. We proposed a method for generating chest CT nodule images based on input text using LDM. Evaluation results demonstrated that the proposed method could generate high-quality images that successfully capture specific medical features."}
{"id": "2601.10727", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.10727", "abs": "https://arxiv.org/abs/2601.10727", "authors": ["Sanghyun Kim", "Jiwon Seo"], "title": "Zonotope Shadow and Reflection Matching: A Novel GNSS Reflection-Based Framework for Enhanced Positioning Accuracy in Urban Areas", "comment": "Submitted to IEEE T-ITS", "summary": "In urban areas, signal reception conditions are often poor due to reflections from buildings, resulting in inaccurate global navigation satellite system (GNSS)-based positioning. Various 3D-mapping-aided (3DMA) GNSS techniques, including shadow matching, have been proposed to address this issue. However, conventional shadow matching estimates positions in a discretized manner. The accuracy of this approach is limited by the resolution of the grid points representing the candidate receiver positions, making it difficult to achieve robust urban positioning and to ensure that the position estimate satisfies user-specified protection levels or safety bounds. To overcome these limitations, zonotope shadow matching (ZSM) has been proposed, which utilizes a set-based position estimate rather than grid-based estimates. ZSM calculates the GNSS shadow--an area on the ground where the line-of-sight (LOS) is blocked and only non-line-of-sight (NLOS) signals can be received--to estimate the receiver's position set. ZSM distinguishes between LOS and NLOS satellites, determining that the receiver is inside the GNSS shadow if the satellite is NLOS and outside if the satellite is LOS. However, relying solely on GNSS shadows limits the ability to sufficiently reduce the size of the receiver position set and to precisely estimate the receiver's location. To address this, we propose zonotope shadow and reflection matching (ZSRM) to enhance positioning accuracy in urban areas. The proposed ZSRM technique is validated through field tests using GNSS signals collected in an urban environment. Consequently, the RMS horizontal position error of ZSRM improved by 10.0% to 53.6% compared with ZSM, while the RMS cross-street and along-street position bounds improved by 18.0% to 50.1% and 30.7% to 59.3%, respectively."}
{"id": "2601.10733", "categories": ["eess.SP", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10733", "abs": "https://arxiv.org/abs/2601.10733", "authors": ["Jakob Struye", "Nabeel Nisar Bhat", "Siddhartha Kumar", "Mohammad Hossein Moghaddam", "Jeroen Famaey"], "title": "Millimeter-Wave Gesture Recognition in ISAC: Does Reducing Sensing Airtime Hamper Accuracy?", "comment": null, "summary": "Most Integrated Sensing and Communications (ISAC) systems require dividing airtime across their two modes. However, the specific impact of this decision on sensing performance remains unclear and underexplored. In this paper, we therefore investigate the impact on a gesture recognition system using a Millimeter-Wave (mmWave) ISAC system. With our dataset of power per beam pair gathered with two mmWave devices performing constant beam sweeps while test subjects performed distinct gestures, we train a gesture classifier using Convolutional Neural Networks. We then subsample these measurements, emulating reduced sensing airtime, showing that a sensing airtime of 25 % only reduces classification accuracy by 0.15 percentage points from full-time sensing. Alongside this high-quality sensing at low airtime, mmWave systems are known to provide extremely high data throughputs, making mmWave ISAC a prime enabler for applications such as truly wireless Extended Reality."}
{"id": "2601.10735", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10735", "abs": "https://arxiv.org/abs/2601.10735", "authors": ["Lizy Abraham", "Siobhan Coughlan", "Kritika Rajain", "Changhong Li", "Saji Philip", "Adam James"], "title": "SSC-UNet: UNet with Self-Supervised Contrastive Learning for Phonocardiography Noise Reduction", "comment": "Accepted by IEEE Healthcom 2025", "summary": "Congenital Heart Disease (CHD) remains a significant global health concern affecting approximately 1\\% of births worldwide. Phonocardiography has emerged as a supplementary tool to diagnose CHD cost-effectively. However, the performance of these diagnostic models highly depends on the quality of the phonocardiography, thus, noise reduction is particularly critical. Supervised UNet effectively improves noise reduction capabilities, but limited clean data hinders its application. The complex time-frequency characteristics of phonocardiography further complicate finding the balance between effectively removing noise and preserving pathological features. In this study, we proposed a self-supervised phonocardiography noise reduction model based on Noise2Noise to enable training without clean data. Augmentation and contrastive learning are applied to enhance its performance. We obtained an average SNR of 12.98 dB after filtering under 10~dB of hospital noise. Classification sensitivity after filtering was improved from 27\\% to 88\\%, indicating its promising pathological feature retention capabilities in practical noisy environments."}
{"id": "2601.10737", "categories": ["eess.SP", "cond-mat.mtrl-sci", "cs.CV", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.10737", "abs": "https://arxiv.org/abs/2601.10737", "authors": ["Giuseppe Romano", "Rodrigo Arrieta", "Steven G. Johnson"], "title": "Differentiating through binarized topology changes: Second-order subpixel-smoothed projection", "comment": null, "summary": "A key challenge in topology optimization (TopOpt) is that manufacturable structures, being inherently binary, are non-differentiable, creating a fundamental tension with gradient-based optimization. The subpixel-smoothed projection (SSP) method addresses this issue by smoothing sharp interfaces at the subpixel level through a first-order expansion of the filtered field. However, SSP does not guarantee differentiability under topology changes, such as the merging of two interfaces, and therefore violates the convergence guarantees of many popular gradient-based optimization algorithms. We overcome this limitation by regularizing SSP with the Hessian of the filtered field, resulting in a twice-differentiable projected density during such transitions, while still guaranteeing an almost-everywhere binary structure. We demonstrate the effectiveness of our second-order SSP (SSP2) methodology on both thermal and photonic problems, showing that SSP2 has faster convergence than SSP for connectivity-dominant cases -- where frequent topology changes occur -- while exhibiting comparable performance otherwise. Beyond improving convergence guarantees for CCSA optimizers, SSP2 enables the use of a broader class of optimization algorithms with stronger theoretical guarantees, such as interior-point methods. Since SSP2 adds minimal complexity relative to SSP or traditional projection schemes, it can be used as a drop-in replacement in existing TopOpt codes."}
{"id": "2601.10743", "categories": ["eess.SP", "cs.LG", "cs.NI"], "pdf": "https://arxiv.org/pdf/2601.10743", "abs": "https://arxiv.org/abs/2601.10743", "authors": ["Ayesh Abu Lehyeh", "Anastassia Gharib", "Tian Xia", "Dryver Huston", "Safwan Wshah"], "title": "UBiGTLoc: A Unified BiLSTM-Graph Transformer Localization Framework for IoT Sensor Networks", "comment": "Accepted and published in IEEE Internet of Things Journal", "summary": "Sensor nodes localization in wireless Internet of Things (IoT) sensor networks is crucial for the effective operation of diverse applications, such as smart cities and smart agriculture. Existing sensor nodes localization approaches heavily rely on anchor nodes within wireless sensor networks (WSNs). Anchor nodes are sensor nodes equipped with global positioning system (GPS) receivers and thus, have known locations. These anchor nodes operate as references to localize other sensor nodes. However, the presence of anchor nodes may not always be feasible in real-world IoT scenarios. Additionally, localization accuracy can be compromised by fluctuations in Received Signal Strength Indicator (RSSI), particularly under non-line-of-sight (NLOS) conditions. To address these challenges, we propose UBiGTLoc, a Unified Bidirectional Long Short-Term Memory (BiLSTM)-Graph Transformer Localization framework. The proposed UBiGTLoc framework effectively localizes sensor nodes in both anchor-free and anchor-presence WSNs. The framework leverages BiLSTM networks to capture temporal variations in RSSI data and employs Graph Transformer layers to model spatial relationships between sensor nodes. Extensive simulations demonstrate that UBiGTLoc consistently outperforms existing methods and provides robust localization across both dense and sparse WSNs while relying solely on cost-effective RSSI data."}
{"id": "2601.10745", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.10745", "abs": "https://arxiv.org/abs/2601.10745", "authors": ["Shivam Kumar", "Himanshu Singh"], "title": "An IoT-Based Controlled Environment Storage for Prevention of Spoilage of Onion (Allium Cepa) During Post-Harvest with UV-C Disinfection", "comment": "8 pages, 7 figures. Undergraduate Research Project", "summary": "India is the second largest producer of onions in the world, contributing over 26 million tonnes annually. However, during storage, approximately 30-40% of onions are lost due to rotting, sprouting, and weight loss. Despite being a major producer, conventional storage methods are either low-cost but ineffective (traditional storage with 40% spoilage) or highly effective but prohibitively expensive for small farmers (cold storage). This paper presents a low-cost IoT-based smart onion storage system that monitors and automatically regulates environmental parameters including temperature, humidity, and spoilage gases using ESP32 microcontroller, DHT22 sensor, MQ-135 gas sensor, and UV-C disinfection technology. The proposed system aims to reduce onion spoilage to 15-20% from the current 40-45% wastage rate while remaining affordable for small and marginal farmers who constitute the majority in India. The system is designed to be cost-effective (estimated 60k-70k INR), energy-efficient, farmer-friendly, and solar-powered."}
{"id": "2601.10746", "categories": ["eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.10746", "abs": "https://arxiv.org/abs/2601.10746", "authors": ["Yuxin Yang", "Hang Zhou", "Hourong Song", "Branislav Hredzak"], "title": "On the static and small signal analysis of DAB converter", "comment": null, "summary": "This document develops a method to solve the periodic operating point of Dual-Active-Bridge (DAB)."}
{"id": "2601.10747", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10747", "abs": "https://arxiv.org/abs/2601.10747", "authors": ["Silke K. Kaiser"], "title": "Sensor Placement for Urban Traffic Interpolation: A Data-Driven Evaluation to Inform Policy", "comment": null, "summary": "Data on citywide street-segment traffic volumes are essential for urban planning and sustainable mobility management. Yet such data are available only for a limited subset of streets due to the high costs of sensor deployment and maintenance. Traffic volumes on the remaining network are therefore interpolated based on existing sensor measurements. However, current sensor locations are often determined by administrative priorities rather than by data-driven optimization, leading to biased coverage and reduced estimation performance. This study provides a large-scale, real-world benchmarking of easily implementable, data-driven strategies for optimizing the placement of permanent and temporary traffic sensors, using segment-level data from Berlin (Strava bicycle counts) and Manhattan (taxi counts). It compares spatial placement strategies based on network centrality, spatial coverage, feature coverage, and active learning. In addition, the study examines temporal deployment schemes for temporary sensors. The findings highlight that spatial placement strategies that emphasize even spatial coverage and employ active learning achieve the lowest prediction errors. With only 10 sensors, they reduce the mean absolute error by over 60% in Berlin and 70% in Manhattan compared to alternatives. Temporal deployment choices further improve performance: distributing measurements evenly across weekdays reduces error by an additional 7% in Berlin and 21% in Manhattan. Together, these spatial and temporal principles allow temporary deployments to closely approximate the performance of optimally placed permanent deployments. From a policy perspective, the results indicate that cities can substantially improve data usefulness by adopting data-driven sensor placement strategies, while retaining flexibility in choosing between temporary and permanent deployments."}
{"id": "2601.10748", "categories": ["eess.SP", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10748", "abs": "https://arxiv.org/abs/2601.10748", "authors": ["Jun Li", "Hongling Zhu", "Yujie Xiao", "Qinghao Zhao", "Yalei Ke", "Gongzheng Tang", "Guangkun Nie", "Deyun Zhang", "Jin Li", "Canqing Yu", "Shenda Hong"], "title": "AnyECG: Evolved ECG Foundation Model for Holistic Health Profiling", "comment": "in progress", "summary": "Background: Artificial intelligence enabled electrocardiography (AI-ECG) has demonstrated the ability to detect diverse pathologies, but most existing models focus on single disease identification, neglecting comorbidities and future risk prediction. Although ECGFounder expanded cardiac disease coverage, a holistic health profiling model remains needed.\n  Methods: We constructed a large multicenter dataset comprising 13.3 million ECGs from 2.98 million patients. Using transfer learning, ECGFounder was fine-tuned to develop AnyECG, a foundation model for holistic health profiling. Performance was evaluated using external validation cohorts and a 10-year longitudinal cohort for current diagnosis, future risk prediction, and comorbidity identification.\n  Results: AnyECG demonstrated systemic predictive capability across 1172 conditions, achieving an AUROC greater than 0.7 for 306 diseases. The model revealed novel disease associations, robust comorbidity patterns, and future disease risks. Representative examples included high diagnostic performance for hyperparathyroidism (AUROC 0.941), type 2 diabetes (0.803), Crohn disease (0.817), lymphoid leukemia (0.856), and chronic obstructive pulmonary disease (0.773).\n  Conclusion: The AnyECG foundation model provides substantial evidence that AI-ECG can serve as a systemic tool for concurrent disease detection and long-term risk prediction."}
{"id": "2601.10761", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.10761", "abs": "https://arxiv.org/abs/2601.10761", "authors": ["Junseok Lee", "Jihye Shin", "Sangyong Lee", "Chang-Jae Chun"], "title": "LSR-Net: A Lightweight and Strong Robustness Network for Bearing Fault Diagnosis in Noise Environment", "comment": null, "summary": "Rotating bearings play an important role in modern industries, but have a high probability of occurrence of defects because they operate at high speed, high load, and poor operating environments. Therefore, if a delay time occurs when a bearing is diagnosed with a defect, this may cause economic loss and loss of life. Moreover, since the vibration sensor from which the signal is collected is highly affected by the operating environment and surrounding noise, accurate defect diagnosis in a noisy environment is also important. In this paper, we propose a lightweight and strong robustness network (LSR-Net) that is accurate in a noisy environment and enables real-time fault diagnosis. To this end, first, a denoising and feature enhancement module (DFEM) was designed to create a 3-channel 2D matrix by giving several nonlinearity to the feature-map that passed through the denoising module (DM) block composed of convolution-based denoising (CD) blocks. Moreover, adaptive pruning was applied to DM to improve denoising ability when the power of noise is strong. Second, for lightweight model design, a convolution-based efficiency shuffle (CES) block was designed using group convolution (GConv), group pointwise convolution (GPConv) and channel split that can design the model while maintaining low parameters. In addition, the trade-off between the accuracy and model computational complexity that can occur due to the lightweight design of the model was supplemented using attention mechanisms and channel shuffle. In order to verify the defect diagnosis performance of the proposed model, performance verification was conducted in a noisy environment using a vibration signal. As a result, it was confirmed that the proposed model had the best anti-noise ability compared to the benchmark models, and the computational complexity of the model was also the lowest."}
{"id": "2601.10771", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10771", "abs": "https://arxiv.org/abs/2601.10771", "authors": ["Nay Klaimi", "Clément Elvira", "Philippe Mary", "Luc Le Magoarou"], "title": "Physically constrained unfolded multi-dimensional OMP for large MIMO systems", "comment": null, "summary": "Sparse recovery methods are essential for channel estimation and localization in modern communication systems, but their reliability relies on accurate physical models, which are rarely perfectly known. Their computational complexity also grows rapidly with the dictionary dimensions in large MIMO systems. In this paper, we propose MOMPnet, a novel unfolded sparse recovery framework that addresses both the reliability and complexity challenges of traditional methods. By integrating deep unfolding with data-driven dictionary learning, MOMPnet mitigates hardware impairments while preserving interpretability. Instead of a single large dictionary, multiple smaller, independent dictionaries are employed, enabling a low-complexity multidimensional Orthogonal Matching Pursuit algorithm. The proposed unfolded network is evaluated on realistic channel data against multiple baselines, demonstrating its strong performance and potential."}
{"id": "2601.10780", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.10780", "abs": "https://arxiv.org/abs/2601.10780", "authors": ["Nursultan Daupayev", "Christian Engel", "Ricky Bendyk", "Soeren Hirsch"], "title": "Adaptive algorithm for microsensor in sustainable environmental monitoring", "comment": null, "summary": "Traditional data collection from sensors produce a lot of data, which lead to constant power consumption and require more storage space. This study proposes an algorithm for a data acquisition and processing method based on Fourier transform (DFT), which extracts dominant frequency components using harmonic analysis (HA) to identify frequency peaks. This algorithm allows sensors to activate only when an event occurs, while preserving critical information for detecting defects, such as those in the surface structures of buildings and ensuring accuracy for further predictions."}
{"id": "2601.10846", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.10846", "abs": "https://arxiv.org/abs/2601.10846", "authors": ["Fabiola Colone", "Filippo Costa", "Yiding Gao", "Chengpeng Hao", "Linjie Yan", "Giuliano Manara", "Danilo Orlando"], "title": "RIS-aided Radar Detection Architectures with Application to Low-RCS Targets", "comment": null, "summary": "In this paper, we address the radar detection of low observable targets with the assistance of a reconfigurable intelligent surface (RIS). Instead of using a multistatic radar network as counter-stealth strategy with its synchronization, costs, phase coherence, and energy consumption issues, we exploit a RIS to form a joint monostatic and bistatic configuration that can intercept the energy backscattered by the target along irrelevant directions different from the line-of-sight of the radar. Then, this energy is redirected towards the radar that capitalizes all the backscattered energy to detect the low observable target. To this end, five different detection architectures are devised that jointly process monostatic and bistatic echoes and exhibit the constant false alarm rate property at least with respect to the clutter power. To support the practical implementation, we also provide a guideline for the design of a RIS that satisfies the operating requirements of the considered application. The performance analysis is carried out in comparison with conventional detectors and shows that the proposed strategy leads to effective solutions to the detection of low observable targets."}
{"id": "2601.10963", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.10963", "abs": "https://arxiv.org/abs/2601.10963", "authors": ["Xiang Cheng", "Boxun Liu", "Xuanyu Liu", "Xuesong Cai"], "title": "Large Wireless Foundation Models: Stronger over Bigger", "comment": null, "summary": "AI-communication integration is widely regarded as a core enabling technology for 6G. Most existing AI-based physical-layer designs rely on task-specific models that are separately tailored to individual modules, resulting in poor generalization. In contrast, communication systems are inherently general-purpose and should support broad applicability and robustness across diverse scenarios. Foundation models offer a promising solution through strong reasoning and generalization, yet wireless-system constraints hinder a direct transfer of large language model (LLM)-style success to the wireless domain. Therefore, we introduce the concept of large wireless foundation models (LWFMs) and present a novel framework for empowering the physical layer with foundation models under wireless constraints. Specifically, we propose two paradigms for realizing LWFMs, including leveraging existing general-purpose foundation models and building novel wireless foundation models. Based on recent progress, we distill two roadmaps for each paradigm and formulate design principles under wireless constraints. We further provide case studies of LWFM-empowered wireless systems to intuitively validate their advantages. Finally, we characterize the notion of \"large\" in LWFMs through a multidimensional analysis of existing work and outline promising directions for future research."}
{"id": "2601.10972", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.10972", "abs": "https://arxiv.org/abs/2601.10972", "authors": ["Mengning Li", "Wenye Wang"], "title": "DuTrack: Long-Term Indoor Human Tracking with Dual-Channel Sensing and Inference", "comment": null, "summary": "Wi-Fi tracking technology demonstrates promising potential for future smart home and intelligent family care. Currently, accurate Wi-Fi tracking methods rely primarily on fine-grained velocity features. However, such velocity-based approaches suffer from the problem of accumulative errors, making it challenging to stably track users' trajectories over a long period of time. This paper presents DuTrack, a fusion-based tracking system for stable human tracking. The fundamental idea is to leverage the ubiquitous acoustic signals in households to rectify the accumulative Wi-Fi tracking error. Theoretically, Wi-Fi sensing in line-of-sight (LoS) and non-line-of-sight (NLoS) scenarios can be modeled as elliptical Fresnel zones and hyperbolic zones, respectively. By designing acoustic sensing signals, we are able to model the acoustic sensing zones as a series of hyperbolic clusters. We reveal how to fuse the fields of electromagnetic waves and mechanical waves, and establish the optimization equation. Next, we design a data-driven architecture to solve the aforementioned optimization equation. Experimental results show that the proposed multimodal tracking scheme exhibits superior performance. We achieve a 89.37% reduction in median tracking error compared to model-based methods and a 65.02% reduction compared to data-driven methods."}
{"id": "2601.10978", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.10978", "abs": "https://arxiv.org/abs/2601.10978", "authors": ["Nan An", "Hongyi He", "Fang Yang", "Chang Liu", "Jian Song", "Zhu Han", "Binbin Zhu"], "title": "Delay-Aware Task Offloading for Heterogeneous VLC-RF-based Vehicular Fog Computing", "comment": null, "summary": "Vehicular fog computing (VFC) is a promising paradigm for reducing the computation burden of vehicles, thus supporting delay-sensitive services in next-generation transportation networks. However, traditional VFC schemes rely on radio frequency (RF) communications, which limits their adaptability for dense vehicular environments. In this paper, a heterogeneous visible light communication (VLC)-RF architecture is designed for VFC systems to facilitate efficient task offloading. Specifically, computing tasks are dynamically partitioned and offloaded to idle vehicles via both VLC and RF links, thereby fully exploiting the interference resilience of VLC and the coverage advantage of RF. To minimize the average task processing delay (TPD), an optimization problem of task offloading and computing resource allocation is formulated, and then solved by the developed residual-based majorization-minimization (RBMM) algorithm. Simulation results confirm that the heterogeneous VLC-RF architecture with the proposed algorithm achieves a 15% average TPD reduction compared to VFC systems relying solely on VLC or RF."}
{"id": "2601.10980", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.10980", "abs": "https://arxiv.org/abs/2601.10980", "authors": ["Mengning Li", "Wenye Wang"], "title": "Uni-Fi: Integrated Multi-Task Wi-Fi Sensing", "comment": null, "summary": "Wi-Fi sensing technology enables non-intrusive, continuous monitoring of user locations and activities, which supports diverse smart home applications. Since different sensing tasks exhibit contextual relationships, their integration can enhance individual module performance. However, integrating sensing tasks across different research efforts faces challenges due to the absence of two key elements. The first is a unified architecture that captures the fundamental nature shared across diverse sensing tasks. The second is an extensible pipeline that can integrate sensing methodologies proposed in potential future research. This paper presents Uni-Fi, an extensible framework for multi-task Wi-Fi sensing integration. This paper makes the following contributions. First, we propose a unified theoretical framework that reveals the fundamental differences between single-task and multi-task sensing. Second, we develop a scalable sensing pipeline that automatically generates multi-task sensing solvers, enabling seamless integration of multiple sensing models. Experimental results show that Uni-Fi achieves robust performance across tasks, with a localization error of approximately 0.54 meters, 98.34 percent accuracy for activity classification, and 98.57 percent accuracy for presence detection."}
{"id": "2601.11110", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.11110", "abs": "https://arxiv.org/abs/2601.11110", "authors": ["Marcus Henninger", "Lucas Giroto", "Ahmed Elkelesh", "Silvio Mandelli"], "title": "Hybrid Resource Allocation Scheme for Bistatic ISAC with Data Channels", "comment": "6 pages, 5 figures. This work has been submitted to the IEEE for possible publication", "summary": "Bistatic integrated sensing and communication (ISAC) enables efficient reuse of the existing cellular infrastructure and is likely to play an important role in future sensing networks. In this context, ISAC using the data channel is a promising approach to improve the bistatic sensing performance compared to relying solely on pilots. One of the challenges associated with this approach is resource allocation: the communication link aims to transmit higher modulation order (MO) symbols to maximize the throughput, whereas a lower MO is preferable for sensing to achieve a higher signal-to-noise ratio in the radar image. To address this conflict, this paper introduces a hybrid resource allocation scheme. By placing lower MO symbols as pseudo-pilots on a suitable sensing grid, we enhance the bistatic sensing performance while only slightly reducing the spectral efficiency of the communication link. Simulation results validate our approach against different baselines and provide practical insights into how decoding errors affect the sensing performance."}
{"id": "2601.11116", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11116", "abs": "https://arxiv.org/abs/2601.11116", "authors": ["Yuki Nakamura", "Shingo Takemoto", "Shunsuke Ono"], "title": "Comprehensive Robust Dynamic Mode Decomposition from Mode Extraction to Dimensional Reduction", "comment": "Submitted to IEEE Transactions on Signal Processing. The source code is available at https://github.com/MDI-TokyoTech/Comprehensive-Robust-Dynamic-Mode-Decomposition. The project page is https://www.mdi.c.titech.ac.jp/publications/cr-dmd", "summary": "We propose Comprehensive Robust Dynamic Mode Decomposition (CR-DMD), a novel framework that robustifies the entire DMD process - from mode extraction to dimensional reduction - against mixed noise. Although standard DMD widely used for uncovering spatio-temporal patterns and constructing low-dimensional models of dynamical systems, it suffers from significant performance degradation under noise due to its reliance on least-squares estimation for computing the linear time evolution operator. Existing robust variants typically modify the least-squares formulation, but they remain unstable and fail to ensure faithful low-dimensional representations. First, we introduce a convex optimization-based preprocessing method designed to effectively remove mixed noise, achieving accurate and stable mode extraction. Second, we propose a new convex formulation for dimensional reduction that explicitly links the robustly extracted modes to the original noisy observations, constructing a faithful representation of the original data via a sparse weighted sum of the modes. Both stages are efficiently solved by a preconditioned primal-dual splitting method. Experiments on fluid dynamics datasets demonstrate that CR-DMD consistently outperforms state-of-the-art robust DMD methods in terms of mode accuracy and fidelity of low-dimensional representations under noisy conditions."}
{"id": "2601.11307", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.11307", "abs": "https://arxiv.org/abs/2601.11307", "authors": ["Julia Schwarzbeck", "Robin Neuder", "Marc Späth", "Alejandro Jiménez-Sáez"], "title": "Scalable mm-Wave Liquid Crystal Reconfigurable Intelligent Surfaces based on the Delay Line Architecture", "comment": null, "summary": "This paper presents the design, fabrication, and characterization of broadband liquid crystal (LC) reconfigurable intelligent surfaces (RIS) operating around 60 GHz and scaling up to 750 radiating elements. The RISs employ a delay line architecture (DLA) that decouples the phase shifting and radiating layer, enabling wide bandwidth, continuous phase control exceeding 360°, and fast response times with a micrometer-thin LC layer of 4.6 micrometer. Two prototypes with 120 and 750 elements are realized using identical unit cells and column-wise biasing. Measurements demonstrate beam steering over +-60° and -3 dB bandwidths exceeding 9% for both apertures, confirming the scalability of the proposed architecture. On top of a measured nanowatt power consumption per unit cell, aperture efficiencies above 20% are predicted by simulations. While the measured efficiencies are reduced to 9.2% and 2.6%, a detailed analysis verifies that this reduction can be attributed to technological challenges in a laboratory environment. Finally, a comprehensive comparison between the applied DLA-based LC-RIS and a conventional approach highlights the superior potential of applied architecture."}
{"id": "2601.11351", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.11351", "abs": "https://arxiv.org/abs/2601.11351", "authors": ["Ruifeng Zheng", "Pengjie Zhou", "Pit Hofmann", "Martín Schottlender", "Fatima Rani", "Juan A. Cabrera", "Frank H. P. Fitzek"], "title": "Modulation, ISI, and Detection for Langmuir Adsorption-Based Microfluidic Molecular Communication", "comment": "5 pages", "summary": "This paper studies microfluidic molecular communication receivers with finite-capacity Langmuir adsorption driven by an effective surface concentration. In the reaction-limited regime, we derive a closed-form single-pulse response kernel and a symbol-rate recursion for on-off keying that explicitly exposes channel memory and inter-symbol interference. We further develop short-pulse and long-pulse approximations, revealing an interference asymmetry in the long-pulse regime due to saturation. To account for stochasticity, we adopt a finite-receptor binomial counting model, employ pulse-end sampling, and propose a low-complexity midpoint-threshold detector that reduces to a fixed threshold when interference is negligible. Numerical results corroborate the proposed characterization and quantify detection performance versus pulse and symbol durations."}
{"id": "2601.11438", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.11438", "abs": "https://arxiv.org/abs/2601.11438", "authors": ["Qiaosen Zhang", "Matteo Nerini", "Bruno Clerckx"], "title": "Channel Estimation in MIMO Systems Aided by Microwave Linear Analog Computers (MiLACs)", "comment": "Submitted to IEEE for publication", "summary": "Microwave linear analog computers (MiLACs) have recently emerged as a promising solution for future gigantic multiple-input multiple-output (MIMO) systems, enabling beamforming with greatly reduced hardware and computational cost. However, channel estimation for MiLAC-aided systems remains an open problem. Conventional least squares (LS) and minimum mean square error (MMSE) estimation rely on intensive digital computation, which undermines the benefits offered by MiLACs. In this letter, we propose efficient LS and MMSE channel estimation schemes for MiLAC-aided MIMO systems. By designing training precoders and combiners implemented by MiLACs, both LS and MMSE estimation are performed fully in the analog domain, achieving identical performance to their digital counterparts while significantly reducing computational complexity, transmit RF chains, analog-to-digital/digital-to-analog converters (ADCs/DACs) resolution requirements, and peak-to-average power ratio (PAPR). Numerical results verify the effectiveness and advantages of the proposed schemes."}
