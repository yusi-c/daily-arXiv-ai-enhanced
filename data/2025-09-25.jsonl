{"id": "2509.19304", "categories": ["eess.SP", "cs.CR"], "pdf": "https://arxiv.org/pdf/2509.19304", "abs": "https://arxiv.org/abs/2509.19304", "authors": ["M. Andrecut"], "title": "Raspberry Pi Pico as a Radio Transmitter", "comment": "13 pages, 3 figures", "summary": "In this paper we discuss several surprisingly simple methods for transforming\nthe Raspberry Pi Pico (RP2) microcontroller into a radio transmitter, by using\nonly cheap off the shelf electronic components, and open source software. While\ninitially this transformation may look as a harmless curiosity, in some extreme\ncases it can also pose security risks, since it can be used to open a large\nnumber of local stealth radio communication channels."}
{"id": "2509.19306", "categories": ["eess.SP", "cs.AI", "cs.IT", "cs.NI", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.19306", "abs": "https://arxiv.org/abs/2509.19306", "authors": ["Jingyi Wang", "Zhongyuan Zhao", "Qingtian Wang", "Zexu Li", "Yue Wang", "Tony Q. S. Quek"], "title": "A Federated Fine-Tuning Paradigm of Foundation Models in Heterogenous Wireless Networks", "comment": null, "summary": "Edge intelligence has emerged as a promising strategy to deliver low-latency\nand ubiquitous services for mobile devices. Recent advances in fine-tuning\nmechanisms of foundation models have enabled edge intelligence by integrating\nlow-rank adaptation (LoRA) with federated learning. However, in wireless\nnetworks, the device heterogeneity and resource constraints on edge devices\npose great threats to the performance of federated fine-tuning. To tackle these\nissues, we propose to optimize federated fine-tuning in heterogenous wireless\nnetworks via online learning. First, the framework of switching-based federated\nfine-tuning in wireless networks is provided. The edge devices switches to LoRA\nmodules dynamically for federated fine-tuning with base station to jointly\nmitigate the impact of device heterogeneity and transmission unreliability.\nSecond, a tractable upper bound on the inference risk gap is derived based on\ntheoretical analysis. To improve the generalization capability, we formulate a\nnon-convex mixed-integer programming problem with long-term constraints, and\ndecouple it into model switching, transmit power control, and bandwidth\nallocation subproblems. An online optimization algorithm is developed to solve\nthe problems with polynomial computational complexity. Finally, the simulation\nresults on the SST-2 and QNLI data sets demonstrate the performance gains in\ntest accuracy and energy efficiency."}
{"id": "2509.19307", "categories": ["eess.SP", "math.PR", "60E05 (primary), 33E20 (secondary)"], "pdf": "https://arxiv.org/pdf/2509.19307", "abs": "https://arxiv.org/abs/2509.19307", "authors": ["Anthony LoPrete", "Johannes Burge"], "title": "Bandwidth of Gamma-Distribution-Shaped Functions via Lambert W Function", "comment": null, "summary": "The full width at half maximum (FWHM) is a useful quantity for characterizing\nthe bandwidth of unimodal functions. However, a closed-form expression for the\nFWHM of gamma-shaped functions-i.e. functions that are shaped like the gamma\ndistribution probability density function (PDF)-is not widely available. Here,\nwe derive and present just such an expression. To do so, we use the Lambert W\nfunction to compute the inverse of the gamma PDF. We use this inverse to derive\nan exact analytic expression for the width of a gamma distribution at an\narbitrary proportion of the maximum, from which the FWHM follows trivially. (An\nexpression for the octave bandwidth of gamma-shaped functions is also\nprovided.) The FWHM is then compared to the Gaussian approximation of\ngamma-shaped functions. A few other related issues are discussed."}
{"id": "2509.19308", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.19308", "abs": "https://arxiv.org/abs/2509.19308", "authors": ["Chang Wang", "Ming Zhu", "Shahram Latifi", "Buddhadeb Dawn", "Shengjie Zhai"], "title": "Graph-Based Spatio-temporal Attention and Multi-Scale Fusion for Clinically Interpretable, High-Fidelity Fetal ECG Extraction", "comment": "6 pages, ACM BCB 2025", "summary": "Congenital Heart Disease (CHD) is the most common neonatal anomaly,\nhighlighting the urgent need for early detection to improve outcomes. Yet,\nfetal ECG (fECG) signals in abdominal ECG (aECG) are often masked by maternal\nECG and noise, challenging conventional methods under low signal-to-noise ratio\n(SNR) conditions. We propose FetalHealthNet (FHNet), a deep learning framework\nthat integrates Graph Neural Networks with a multi-scale enhanced transformer\nto dynamically model spatiotemporal inter-lead correlations and extract clean\nfECG signals. On benchmark aECG datasets, FHNet consistently outperforms long\nshort-term memory (LSTM) models, standard transformers, and state-of-the-art\nmodels, achieving R2>0.99 and RMSE = 0.015 even under severe noise.\nInterpretability analyses highlight physiologically meaningful temporal and\nlead contributions, supporting model transparency and clinical trust. FHNet\nillustrates the potential of AI-driven modeling to advance fetal monitoring and\nenable early CHD screening, underscoring the transformative impact of\nnext-generation biomedical signal processing."}
{"id": "2509.19353", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.19353", "abs": "https://arxiv.org/abs/2509.19353", "authors": ["Yuxiao Yi", "Qingyao Zhuang", "Zhi-Qin John Xu"], "title": "Frequency-Aware Ensemble Learning for BraTS 2025 Pediatric Brain Tumor Segmentation", "comment": "11 pages, 3 figures, conference, miccai brats challenge", "summary": "Pediatric brain tumor segmentation presents unique challenges due to the\nrarity and heterogeneity of these malignancies, yet remains critical for\nclinical diagnosis and treatment planning. We propose an ensemble approach\nintegrating nnU-Net, Swin UNETR, and HFF-Net for the BraTS-PED 2025 challenge.\nOur method incorporates three key extensions: adjustable initialization scales\nfor optimal nnU-Net complexity control, transfer learning from BraTS 2021\npre-trained models to enhance Swin UNETR's generalization on pediatric dataset,\nand frequency domain decomposition for HFF-Net to separate low-frequency tissue\ncontours from high-frequency texture details. Our final ensemble combines\nnnU-Net ($\\gamma=0.7$), fine-tuned Swin UNETR, and HFF-Net, achieving Dice\nscores of 72.3% (ET), 95.6% (NET), 68.9% (CC), 89.5% (ED), 92.3% (TC), and\n92.3% (WT), respectively."}
{"id": "2509.19310", "categories": ["eess.SP", "cs.IT", "math.FA", "math.IT", "42B10, 42A38, 44A35, 65R10, 81S30"], "pdf": "https://arxiv.org/pdf/2509.19310", "abs": "https://arxiv.org/abs/2509.19310", "authors": ["Mukul Chauhan", "Waseem Z. Lone", "Amit K. Verma"], "title": "A Novel Two-Dimensional Wigner Distribution Framework via the Quadratic Phase Fourier Transform with a Non-Separable Kernel", "comment": null, "summary": "This paper introduces a novel time-frequency distribution, referred to as the\nTwo-Dimensional Non-Separable Quadratic Phase Wigner Distribution (2D-NSQPWD),\nformulated within the framework of the Two-Dimensional Non-Separable Quadratic\nPhase Fourier Transform (2D-NSQPFT). By replacing the classical Fourier kernel\nwith the NSQPFT kernel, the proposed distribution generalizes the classical\nWigner distribution and effectively captures complex, non-separable signal\nstructures. We rigorously establish several key properties of the 2D-NSQPWD,\nincluding time and frequency shift invariance, marginal behavior, conjugate\nsymmetry, convolution relations, and Moyal's identity. Furthermore, the\nconnection between the 2D-NSQPWD and the two-dimensional short-time Fourier\ntransform (2D-STFT) is explored. The distribution's effectiveness is\ndemonstrated through its application to single-, bi-, and tri-component\ntwo-dimensional linear frequency modulated (2D-LFM) signals, where it shows\nsuperior performance in cross-term suppression and signal localization."}
{"id": "2509.19616", "categories": ["eess.IV", "cs.MM", "cs.NI", "quant-ph", "C.2.1; I.1.2; H.5.1"], "pdf": "https://arxiv.org/pdf/2509.19616", "abs": "https://arxiv.org/abs/2509.19616", "authors": ["Animesh Rajpurohit", "Michael Kelley", "Wei Wang", "Krishna Murthy Kattiyan Ramamoorthy"], "title": "BALANCE: Bitrate-Adaptive Limit-Aware Netcast Content Enhancement Utilizing QUBO and Quantum Annealing", "comment": "6 pages, 4 figures, 2 tables. Accepted at 2025 IEEE Wireless\n  Communications and Networking Conference (WCNC)", "summary": "In an era of increasing data cap constraints, optimizing video streaming\nquality while adhering to user-defined data caps remains a significant\nchallenge. This paper introduces Bitrate-Adaptive Limit-Aware Netcast Content\nEnhancement (BALANCE), a novel Quantum framework aimed at addressing this\nissue. BALANCE intelligently pre-selects video segments based on visual\ncomplexity and anticipated data consumption, utilizing the Video Multimethod\nAssessment Fusion (VMAF) metric to enhance Quality of Experience (QoE). We\ncompare our method against traditional bitrate ladders used in Adaptive Bitrate\n(ABR) streaming, demonstrating a notable improvement in QoE under equivalent\ndata constraints. We compare the Slack variable approach with the Dynamic\nPenalization Approach (DPA) by framing the bitrate allocation problem through\nQuadratic Unconstrained Binary Optimization (QUBO) to effectively enforce data\nlimits. Our results indicate that the DPA consistently outperforms the Slack\nVariable Method, delivering more valid and optimal solutions as data limits\nincrease. This new quantum approach significantly enhances streaming\nsatisfaction for users with limited data plans."}
{"id": "2509.19312", "categories": ["eess.SP", "cs.AI", "cs.IT", "cs.LG", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.19312", "abs": "https://arxiv.org/abs/2509.19312", "authors": ["Minghui Wu", "Zhen Gao"], "title": "E2E Learning Massive MIMO for Multimodal Semantic Non-Orthogonal Transmission and Fusion", "comment": null, "summary": "Massive multiple-input multiple-output (MIMO) promises high spectral\nefficiency but also leads to high-dimensional downlink channel state\ninformation (CSI), which complicates real-time channel acquisition and\nprecoding. To address this, we propose an end-to-end (E2E) uplink-downlink CSI\nfusion precoding network that jointly models downlink CSI reference signal\n(CSI-RS) design, CSI feedback, and base-station (BS) precoding within a single\nE2E neural architecture. Concretely, a projection network built on the MAXIM\narchitecture takes uplink sounding reference signals (SRS) as input and outputs\nfrequency-, beam-, and port-domain projection matrices for designing downlink\nCSI-RS. User equipment (UE) then compresses/quantizes the resulting CSI-RS\nobservations and feeds back a compact representation. At the base station (BS),\ntwo complementary branches produce candidate precoders: one is a feedback-only\nprecoding network driven by quantized downlink observations, and the other is\nan SRS-only precoding network driven by uplink SRS. These candidate precoders\nare subsequently combined by a fusion precoding network to yield the final\ntransmit precoder. All the modules are trained with a\nspectral-efficiency-oriented loss under a three-stage schedule. Simulation\nresults show that the proposed approach effectively harnesses both SRS-derived\ninformation and UE feedback, achieving markedly better performance than\nconventional baselines."}
{"id": "2509.20001", "categories": ["eess.IV", "cs.CV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2509.20001", "abs": "https://arxiv.org/abs/2509.20001", "authors": ["Babak Naderi", "Ross Cutler"], "title": "Ensuring Reliable Participation in Subjective Video Quality Tests Across Platforms", "comment": null, "summary": "Subjective video quality assessment (VQA) is the gold standard for measuring\nend-user experience across communication, streaming, and UGC pipelines. Beyond\nhigh-validity lab studies, crowdsourcing offers accurate, reliable, faster, and\ncheaper evaluation-but suffers from unreliable submissions by workers who\nignore instructions or game rewards. Recent tests reveal sophisticated exploits\nof video metadata and rising use of remote-desktop (RD) connections, both of\nwhich bias results. We propose objective and subjective detectors for RD users\nand compare two mainstream crowdsourcing platforms on their susceptibility and\nmitigation under realistic test conditions and task designs."}
{"id": "2509.19313", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.19313", "abs": "https://arxiv.org/abs/2509.19313", "authors": ["Huipeng Liu", "Zhichao Zhu", "Yuan Zhou", "Changlu Li"], "title": "STL-FFT-STFT-TCN-LSTM: An Effective Wave Height High Accuracy Prediction Model Fusing Time-Frequency Domain Features", "comment": "17 page, 13 figures; references added", "summary": "As the consumption of traditional energy sources intensifies and their\nadverse environmental impacts become more pronounced, wave energy stands out as\na highly promising member of the renewable energy family due to its high energy\ndensity, stability, widespread distribution, and environmental friendliness.\nThe key to its development lies in the precise prediction of Significant Wave\nHeight (WVHT). However, wave energy signals exhibit strong nonlinearity, abrupt\nchanges, multi-scale periodicity, data sparsity, and high-frequency noise\ninterference; additionally, physical models for wave energy prediction incur\nextremely high computational costs. To address these challenges, this study\nproposes a hybrid model combining STL-FFT-STFT-TCN-LSTM. This model exploits\nthe Seasonal-Trend Decomposition Procedure based on Loess (STL), Fast Fourier\nTransform (FFT), Short-Time Fourier Transform (STFT), Temporal Convolutional\nNetwork (TCN), and Long Short-Term Memory (LSTM) technologies. The model aims\nto optimize multi-scale feature fusion, capture extreme wave heights, and\naddress issues related to high-frequency noise and periodic signals, thereby\nachieving efficient and accurate prediction of significant wave height.\nExperiments were conducted using hourly data from NOAA Station 41008 and 41047\nspanning 2019 to 2022. The results showed that compared with other single\nmodels and hybrid models, the STL-FFT-STFT-TCN-LSTM model achieved\nsignificantly higher prediction accuracy in capturing extreme wave heights and\nsuppressing high-frequency noise, with MAE reduced by 15.8\\%-40.5\\%, SMAPE\nreduced by 8.3\\%-20.3\\%, and R increased by 1.31\\%-2.9\\%; in ablation\nexperiments, the model also demonstrated the indispensability of each component\nstep, validating its superiority in multi-scale feature fusion."}
{"id": "2509.19315", "categories": ["eess.SP", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.19315", "abs": "https://arxiv.org/abs/2509.19315", "authors": ["Yiqiao Chen", "Zijian Huang", "Zhenghui Feng"], "title": "Advancing Few-Shot Pediatric Arrhythmia Classification with a Novel Contrastive Loss and Multimodal Learning", "comment": "12pages, 10 figures", "summary": "Pediatric arrhythmias are a major risk factor for disability and sudden\ncardiac death, yet their automated classification remains challenging due to\nclass imbalance, few-shot categories, and complex signal characteristics, which\nseverely limit the efficiency and reliability of early screening and clinical\nintervention. To address this problem, we propose a multimodal end-to-end deep\nlearning framework that combines dual-branch convolutional encoders for ECG and\nIEGM, semantic attention for cross-modal feature alignment, and a lightweight\nTransformer encoder for global dependency modeling. In addition, we introduce a\nnew contrastive loss fucntion named Adaptive Global Class-Aware Contrastive\nLoss (AGCACL) to enhance intra-class compactness and inter-class separability\nthrough class prototypes and a global similarity matrix. To the best of our\nknowledge, this is the first systematic study based on the Leipzig Heart Center\npediatric/congenital ECG+IEGM dataset, for which we also provide a complete and\nreproducible preprocessing pipeline. Experimental results demonstrate that the\nproposed method achieves the overall best performance on this dataset,\nincluding 97.76\\% Top-1 Accuracy, 94.08\\% Macro Precision, 91.97\\% Macro\nRecall, 92.97\\% Macro F1, and 92.36\\% Macro F2, with improvements of +13.64,\n+15.96, +19.82, and +19.44 percentage points over the strongest baseline in\nMacro Precision/Recall/F1/F2, respectively. These findings indicate that the\nframework significantly improves the detectability and robustness for minority\narrhythmia classes, offering potential clinical value for rhythm screening,\npre-procedural assessment, and postoperative follow-up in pediatric and\ncongenital heart disease populations."}
{"id": "2509.19316", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.19316", "abs": "https://arxiv.org/abs/2509.19316", "authors": ["Ammar Kamoona", "Hui Song", "Ali Moradi Amani", "Mahdi Jalili", "Xinghuo Yu", "Peter McTaggart"], "title": "Electric Vehicle Identification from Behind Smart Meter Data", "comment": "27 pages,", "summary": "Electric vehicle (EV) charging loads identification from behind smart meter\nrecordings is an indispensable aspect that enables effective decision-making\nfor energy distributors to reach an informed and intelligent decision about the\npower grid's reliability. When EV charging happens behind the meter (BTM), the\ncharging occurs on the customer side of the meter, which measures the overall\nelectricity consumption. In other words, the charging of the EV is considered\npart of the customer's load and not separately measured by the Distribution\nNetwork Operators (DNOs). DNOs require complete knowledge about the EV presence\nin their network. Identifying the EV charging demand is essential to better\nplan and manage the distribution grid. Unlike supervised methods, this paper\naddresses the problem of EV charging load identification in a non-nonintrusive\nmanner from low-frequency smart meter using an unsupervised learning approach\nbased on anomaly detection technique. Our approach does not require prior\nknowledge of EV charging profiles. It only requires real power consumption data\nof non-EV users, which are abundant in practice. We propose a deep temporal\nconvolution encoding decoding (TAE) network. The TAE is applied to power\nconsumption from smart BTM from Victorian households in Australia, and the TAE\nshows superior performance in identifying households with EVs."}
{"id": "2509.19318", "categories": ["eess.SP", "cs.RO"], "pdf": "https://arxiv.org/pdf/2509.19318", "abs": "https://arxiv.org/abs/2509.19318", "authors": ["Yanbaihui Liu", "Erica Babusci", "Claudia K. Gunsch", "Boyuan Chen"], "title": "Scensory: Automated Real-Time Fungal Identification and Spatial Mapping", "comment": "Our project website is at: http://generalroboticslab.com/Scensory", "summary": "Indoor fungal contamination poses significant risks to public health, yet\nexisting detection methods are slow, costly, and lack spatial resolution.\nConventional approaches rely on laboratory analysis or high-concentration\nsampling, making them unsuitable for real-time monitoring and scalable\ndeployment. We introduce \\textbf{\\textit{Scensory}}, a robot-enabled olfactory\nsystem that simultaneously identifies fungal species and localizes their\nspatial origin using affordable volatile organic compound (VOC) sensor arrays\nand deep learning. Our key idea is that temporal VOC dynamics encode both\nchemical and spatial signatures, which we decode through neural architectures\ntrained on robot-automated data collection. We demonstrate two operational\nmodes: a passive multi-array configuration for environmental monitoring, and a\nmobile single-array configuration for active source tracking. Across five\nfungal species, our system achieves up to 89.85\\% accuracy in species detection\nand 87.31\\% accuracy in localization under ambient conditions, where each\nprediction only takes 3--7\\,s sensor inputs. Additionally, by computationally\nanalyzing model behavior, we can uncover key biochemical signatures without\nadditional laboratory experiments. Our approach enables real-time, spatially\naware fungal monitoring and establishes a scalable and affordable framework for\nautonomous environmental sensing."}
{"id": "2509.19328", "categories": ["eess.SP", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.19328", "abs": "https://arxiv.org/abs/2509.19328", "authors": ["Sina Montazeri", "Waltenegus Dargie", "Yunhe Feng", "Kewei Sha"], "title": "Human Activity Recognition Based on Electrocardiogram Data Only", "comment": "This is a preprint version. Content may change before final\n  publication", "summary": "Human activity recognition is critical for applications such as early\nintervention and health analytics. Traditional activity recognition relies on\ninertial measurement units (IMUs), which are resource intensive and require\ncalibration. Although electrocardiogram (ECG)-based methods have been explored,\nthese have typically served as supplements to IMUs or have been limited to\nbroad categorical classification such as fall detection or active vs. inactive\nin daily activities. In this paper, we advance the field by demonstrating, for\nthe first time, robust recognition of activity only with ECG in six distinct\nactivities, which is beyond the scope of previous work. We design and evaluate\nthree new deep learning models, including a CNN classifier with\nSqueeze-and-Excitation blocks for channel-wise feature recalibration, a ResNet\nclassifier with dilated convolutions for multiscale temporal dependency\ncapture, and a novel CNNTransformer hybrid combining convolutional feature\nextraction with attention mechanisms for long-range temporal relationship\nmodeling. Tested on data from 54 subjects for six activities, all three models\nachieve over 94% accuracy for seen subjects, while CNNTransformer hybrid\nreaching the best accuracy of 72% for unseen subjects, a result that can be\nfurther improved by increasing the training population. This study demonstrates\nthe first successful ECG-only activity classification in multiple physical\nactivities, offering significant potential for developing next-generation\nwearables capable of simultaneous cardiac monitoring and activity recognition\nwithout additional motion sensors."}
{"id": "2509.19330", "categories": ["eess.SP", "cs.AI", "cs.HC", "cs.LG", "cs.MM"], "pdf": "https://arxiv.org/pdf/2509.19330", "abs": "https://arxiv.org/abs/2509.19330", "authors": ["Zejun Liu", "Yunshan Chen", "Chengxi Xie", "Huan Liu"], "title": "LibEMER: A novel benchmark and algorithms library for EEG-based Multimodal Emotion Recognition", "comment": "5 pages, 2 figures", "summary": "EEG-based multimodal emotion recognition(EMER) has gained significant\nattention and witnessed notable advancements, the inherent complexity of human\nneural systems has motivated substantial efforts toward multimodal approaches.\nHowever, this field currently suffers from three critical limitations: (i) the\nabsence of open-source implementations. (ii) the lack of standardized and\ntransparent benchmarks for fair performance analysis. (iii) in-depth discussion\nregarding main challenges and promising research directions is a notable\nscarcity. To address these challenges, we introduce LibEMER, a unified\nevaluation framework that provides fully reproducible PyTorch implementations\nof curated deep learning methods alongside standardized protocols for data\npreprocessing, model realization, and experimental setups. This framework\nenables unbiased performance assessment on three widely-used public datasets\nacross two learning tasks. The open-source library is publicly accessible at:\nhttps://anonymous.4open.science/r/2025ULUIUBUEUMUEUR485384"}
{"id": "2509.19331", "categories": ["eess.SP", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.19331", "abs": "https://arxiv.org/abs/2509.19331", "authors": ["Enhao Huang", "Zhiyu Zhang", "Tianxiang Xu", "Chunshu Xia", "Kaichun Hu", "Yuchen Yang", "Tongtong Pan", "Dong Dong", "Zhan Qin"], "title": "Holographic Transformers for Complex-Valued Signal Processing: Integrating Phase Interference into Self-Attention", "comment": null, "summary": "Complex-valued signals encode both amplitude and phase, yet most deep models\ntreat attention as real-valued correlation, overlooking interference effects.\nWe introduce the Holographic Transformer, a physics-inspired architecture that\nincorporates wave interference principles into self-attention. Holographic\nattention modulates interactions by relative phase and coherently superimposes\nvalues, ensuring consistency between amplitude and phase. A dual-headed decoder\nsimultaneously reconstructs the input and predicts task outputs, preventing\nphase collapse when losses prioritize magnitude over phase. We demonstrate that\nholographic attention implements a discrete interference operator and maintains\nphase consistency under linear mixing. Experiments on PolSAR image\nclassification and wireless channel prediction show strong performance,\nachieving high classification accuracy and F1 scores, low regression error, and\nincreased robustness to phase perturbations. These results highlight that\nenforcing physical consistency in attention leads to generalizable improvements\nin complex-valued learning and provides a unified, physics-based framework for\ncoherent signal modeling. The code is available at\nhttps://github.com/EonHao/Holographic-Transformers."}
{"id": "2509.19334", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.19334", "abs": "https://arxiv.org/abs/2509.19334", "authors": ["Shangqing Yuan", "Wenshuang Zhai", "Shengwen Guo"], "title": "A Spatio-Temporal Feature Fusion EEG Virtual Channel Signal Generation Network and Its Application in Anxiety Assessment", "comment": null, "summary": "To address the issue of limited channels and insufficient information\ncollection in portable EEG devices, this study explores an EEG virtual channel\nsignal generation network using a novel spatio-temporal feature fusion\nstrategy. Based on the EEG signals from four frontal lobe channels, the network\naims to generate virtual channel EEG signals for other 13 important brain\nregions. The architecture of the network is a two-dimensional convolutional\nneural network and it includes a parallel module for temporal and spatial\ndomain feature extraction, followed by a feature fusion module. The public\nPRED+CT database, which includes multi-channel EEG signals from 119 subjects,\nwas selected to verify the constructed network. The results showed that the\naverage correlation coefficient between the generated virtual channel EEG\nsignals and the original real signals was 0.6724, with an average absolute\nerror of 3.9470. Furthermore, the 13 virtual channel EEG signals were combined\nwith the original EEG signals of four brain regions and then used for anxiety\nclassification with a support vector machine. The results indicate that the\nvirtual EEG signals generated by the constructed network not only have a high\ndegree of consistency with the real channel EEG signals but also significantly\nenhance the performance of machine learning algorithms for anxiety\nclassification. This study effectively alleviates the problem of insufficient\ninformation acquisition by portable EEG devices with few channels."}
{"id": "2509.19335", "categories": ["eess.SP", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.19335", "abs": "https://arxiv.org/abs/2509.19335", "authors": ["Xudong Zhang", "Jingbo Tan", "Zhizhen Ren", "Jintao Wang", "Yihua Ma", "Jian Song"], "title": "CSIYOLO: An Intelligent CSI-based Scatter Sensing Framework for Integrated Sensing and Communication Systems", "comment": "13 pages, 16 figures, 3 tables. This work has been submitted to the\n  IEEE for possible publication", "summary": "ISAC is regarded as a promising technology for next-generation communication\nsystems, enabling simultaneous data transmission and target sensing. Among\nvarious tasks in ISAC, scatter sensing plays a crucial role in exploiting the\nfull potential of ISAC and supporting applications such as autonomous driving\nand low-altitude economy. However, most existing methods rely on either\nwaveform and hardware modifications or traditional signal processing schemes,\nleading to poor compatibility with current communication systems and limited\nsensing accuracy. To address these challenges, we propose CSIYOLO, a framework\nthat performs scatter localization only using estimated CSI from a single base\nstation-user equipment pair. This framework comprises two main components:\nanchor-based scatter parameter detection and CSI-based scatter localization.\nFirst, by formulating scatter parameter extraction as an image detection\nproblem, we propose an anchor-based scatter parameter detection method inspired\nby You Only Look Once architectures. After that, a CSI-based localization\nalgorithm is derived to determine scatter locations with extracted parameters.\nMoreover, to improve localization accuracy and implementation efficiency, we\ndesign an extendable network structure with task-oriented optimizations,\nenabling multi-scale anchor detection and better adaptation to CSI\ncharacteristics. A noise injection training strategy is further designed to\nenhance robustness against channel estimation errors. Since the proposed\nframework operates solely on estimated CSI without modifying waveforms or\nsignal processing pipelines, it can be seamlessly integrated into existing\ncommunication systems as a plugin. Experiments show that our proposed method\ncan significantly outperform existing methods in scatter localization accuracy\nwith relatively low complexities under varying numbers of scatters and\nestimation errors."}
{"id": "2509.19340", "categories": ["eess.SP", "cs.AI", "cs.IT", "cs.NI", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.19340", "abs": "https://arxiv.org/abs/2509.19340", "authors": ["Ying Ju", "Mingdong Li", "Haoyu Wang", "Lei Liu", "Youyang Qu", "Mianxiong Dong", "Victor C. M. Leung", "Chau Yuen"], "title": "Joint Channel Estimation and Computation Offloading in Fluid Antenna-assisted MEC Networks", "comment": null, "summary": "With the emergence of fluid antenna (FA) in wireless communications, the\ncapability to dynamically adjust port positions offers substantial benefits in\nspatial diversity and spectrum efficiency, which are particularly valuable for\nmobile edge computing (MEC) systems. Therefore, we propose an FA-assisted MEC\noffloading framework to minimize system delay. This framework faces two severe\nchallenges, which are the complexity of channel estimation due to dynamic port\nconfiguration and the inherent non-convexity of the joint optimization problem.\nFirstly, we propose Information Bottleneck Metric-enhanced Channel Compressed\nSensing (IBM-CCS), which advances FA channel estimation by integrating\ninformation relevance into the sensing process and capturing key features of FA\nchannels effectively. Secondly, to address the non-convex and high-dimensional\noptimization problem in FA-assisted MEC systems, which includes FA port\nselection, beamforming, power control, and resource allocation, we propose a\ngame theory-assisted Hierarchical Twin-Dueling Multi-agent Algorithm (HiTDMA)\nbased offloading scheme, where the hierarchical structure effectively decouples\nand coordinates the optimization tasks between the user side and the base\nstation side. Crucially, the game theory effectively reduces the dimensionality\nof power control variables, allowing deep reinforcement learning (DRL) agents\nto achieve improved optimization efficiency. Numerical results confirm that the\nproposed scheme significantly reduces system delay and enhances offloading\nperformance, outperforming benchmarks. Additionally, the IBM-CCS channel\nestimation demonstrates superior accuracy and robustness under varying port\ndensities, contributing to efficient communication under imperfect CSI."}
{"id": "2509.19342", "categories": ["eess.SP", "cs.IT", "cs.LG", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.19342", "abs": "https://arxiv.org/abs/2509.19342", "authors": ["Xinyu Qin", "Ye Xue", "Qi Yan", "Shutao Zhang", "Bingsheng Peng", "Tsung-Hui Chang"], "title": "A Measurement Report Data-Driven Framework for Localized Statistical Channel Modeling", "comment": null, "summary": "Localized statistical channel modeling (LSCM) is crucial for effective\nperformance evaluation in digital twin-assisted network optimization. Solely\nrelying on the multi-beam reference signal receiving power (RSRP), LSCM aims to\nmodel the localized statistical propagation environment by estimating the\nchannel angular power spectrum (APS). However, existing methods rely heavily on\ndrive test data with high collection costs and limited spatial coverage. In\nthis paper, we propose a measurement report (MR) data-driven framework for\nLSCM, exploiting the low-cost and extensive collection of MR data. The\nframework comprises two novel modules. The MR localization module addresses the\nissue of missing locations in MR data by introducing a semi-supervised method\nbased on hypergraph neural networks, which exploits multi-modal information via\ndistance-aware hypergraph modeling and hypergraph convolution for location\nextraction. To enhance the computational efficiency and solution robustness,\nLSCM operates at the grid level. Compared to independently constructing\ngeographically uniform grids and estimating channel APS, the joint grid\nconstruction and channel APS estimation module enhances robustness in complex\nenvironments with spatially non-uniform data by exploiting their correlation.\nThis module alternately optimizes grid partitioning and APS estimation using\nclustering and improved sparse recovery for the ill-conditioned measurement\nmatrix and incomplete observations. Through comprehensive experiments on a\nreal-world MR dataset, we demonstrate the superior performance and robustness\nof our framework in localization and channel modeling."}
{"id": "2509.19367", "categories": ["eess.SP", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2509.19367", "abs": "https://arxiv.org/abs/2509.19367", "authors": ["Borhan Uddin Chowdhury", "Damian Valles", "Md Raf E Ul Shougat"], "title": "Low-Cost Sensor Fusion Framework for Organic Substance Classification and Quality Control Using Classification Methods", "comment": "Copyright 2025 IEEE. This is the author's version of the work\n  accepted for publication in FMLDS 2025. The final version will be published\n  by IEEE and available via DOI (to be inserted when available). Accepted at\n  FMLDS 2025, to appear in IEEE Xplore. 8 pages, 17 figures, 3 tables", "summary": "We present a sensor-fusion framework for rapid, non-destructive\nclassification and quality control of organic substances, built on a standard\nArduino Mega 2560 microcontroller platform equipped with three commercial\nenvironmental and gas sensors. All data used in this study were generated\nin-house: sensor outputs for ten distinct classes - including fresh and expired\nsamples of apple juice, onion, garlic, and ginger, as well as cinnamon and\ncardamom - were systematically collected and labeled using this hardware setup,\nresulting in a unique, application-specific dataset. Correlation analysis was\nemployed as part of the preprocessing pipeline for feature selection. After\npreprocessing and dimensionality reduction (PCA/LDA), multiple supervised\nlearning models - including Support Vector Machine (SVM), Decision Tree (DT),\nand Random Forest (RF), each with hyperparameter tuning, as well as an\nArtificial Neural Network (ANN) and an ensemble voting classifier - were\ntrained and cross-validated on the collected dataset. The best-performing\nmodels, including tuned Random Forest, ensemble, and ANN, achieved test\naccuracies in the 93 to 94 percent range. These results demonstrate that\nlow-cost, multisensory platforms based on the Arduino Mega 2560, combined with\nadvanced machine learning and correlation-driven feature engineering, enable\nreliable identification and quality control of organic compounds."}
{"id": "2509.19374", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.19374", "abs": "https://arxiv.org/abs/2509.19374", "authors": ["Oscar A. Oviedo"], "title": "Short-Term Regional Electricity Demand Forecasting in Argentina Using LSTM Networks", "comment": "44 pages, 13 figures", "summary": "This study presents the development and optimization of a deep learning model\nbased on Long Short-Term Memory (LSTM) networks to predict short-term hourly\nelectricity demand in C\\'ordoba, Argentina. Integrating historical consumption\ndata with exogenous variables (climatic factors, temporal cycles, and\ndemographic statistics), the model achieved high predictive precision, with a\nmean absolute percentage error of 3.20\\% and a determination coefficient of\n0.95. The inclusion of periodic temporal encodings and weather variables proved\ncrucial to capture seasonal patterns and extreme consumption events, enhancing\nthe robustness and generalizability of the model. In addition to the design and\nhyperparameter optimization of the LSTM architecture, two complementary\nanalyses were carried out: (i) an interpretability study using Random Forest\nregression to quantify the relative importance of exogenous drivers, and (ii)\nan evaluation of model performance in predicting the timing of daily demand\nmaxima and minima, achieving exact-hour accuracy in more than two-thirds of the\ntest days and within abs(1) hour in over 90\\% of cases. Together, these results\nhighlight both the predictive accuracy and operational relevance of the\nproposed framework, providing valuable insights for grid operators seeking\noptimized planning and control strategies under diverse demand scenarios."}
{"id": "2509.19382", "categories": ["eess.SP", "cs.IT", "cs.LG", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.19382", "abs": "https://arxiv.org/abs/2509.19382", "authors": ["Xiaolong Li", "Zhi-qin John Xu", "Peiting You", "Yifei Zhu"], "title": "Neural Network Based Framework for Passive Intermodulation Cancellation in MIMO Systems", "comment": null, "summary": "Passive intermodulation (PIM) has emerged as a critical source of\nself-interference in modern MIMO-OFDM systems, especially under the stringent\nrequirements of 5G and beyond. Conventional cancellation methods often rely on\ncomplex nonlinear models with limited scalability and high computational cost.\nIn this work, we propose a lightweight deep learning framework for PIM\ncancellation that leverages depthwise separable convolutions and dilated\nconvolutions to efficiently capture nonlinear dependencies across antennas and\nsubcarriers. To further enhance convergence, we adopt a cyclic learning rate\nschedule and gradient clipping. In a controlled MIMO experimental setup, the\nmethod effectively suppresses third-order passive intermodulation (PIM)\ndistortion, achieving up to 29dB of average power error (APE) with only 11k\ntrainable parameters. These results highlight the potential of compact neural\narchitectures for scalable interference mitigation in future wireless\ncommunication systems."}
{"id": "2509.19383", "categories": ["eess.SP", "cs.IT", "cs.PF", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.19383", "abs": "https://arxiv.org/abs/2509.19383", "authors": ["Qianqian Li", "Hua Li", "Shiya Hao", "Lintao Li", "Xiaoming Dai"], "title": "Impact of RHIs and ipSIC on Active RIS-NOMA Systems with Low-Precision ADCs", "comment": null, "summary": "This study evaluates the performance of an active reconfigurable intelligent\nsurface (ARIS)-assisted non-orthogonal multiple access (NOMA) system employing\nlow-precision analog-to-digital converters (ADCs). Analytical approximations\nfor the outage probability (OP) are derived, considering residual hardware\nimpairments (RHIs) and imperfect successive interference cancellation (ipSIC).\nAdditionally, we analyze the asymptotic OP, system throughput, and diversity\norder at high signal-to-noise ratios (SNRs). Simulation results demonstrate\nthat the proposed quantized ARIS-NOMA system outperforms its passive\ncounterpart (PRIS-NOMA), achieving lower OP and higher throughput with reduced\ntransmit power requirements and fewer reflecting elements. Moreover, the outage\nperformance of both quantized ARIS-NOMA and PRIS-NOMA systems demonstrates\nsignificant improvement as the number of reflecting elements increases. The\nnegative impacts of low-precision ADCs can be effectively mitigated by\noptimizing transmit power and scaling the number of reflecting elements."}
{"id": "2509.19384", "categories": ["eess.SP", "cs.AI", "cs.LG", "physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2509.19384", "abs": "https://arxiv.org/abs/2509.19384", "authors": ["Hongyuan Shi", "Yilin Zhai", "Ping Dong", "Zaijin You", "Chao Zhan", "Qing Wang"], "title": "Data-Driven Reconstruction of Significant Wave Heights from Sparse Observations", "comment": null, "summary": "Reconstructing high-resolution regional significant wave height fields from\nsparse and uneven buoy observations remains a core challenge for ocean\nmonitoring and risk-aware operations. We introduce AUWave, a hybrid deep\nlearning framework that fuses a station-wise sequence encoder (MLP) with a\nmulti-scale U-Net enhanced by a bottleneck self-attention layer to recover\n32$\\times$32 regional SWH fields. A systematic Bayesian hyperparameter search\nwith Optuna identifies the learning rate as the dominant driver of\ngeneralization, followed by the scheduler decay and the latent dimension. Using\nNDBC buoy observations and ERA5 reanalysis over the Hawaii region, AUWave\nattains a minimum validation loss of 0.043285 and a slightly right-skewed RMSE\ndistribution. Spatial errors are lowest near observation sites and increase\nwith distance, reflecting identifiability limits under sparse sampling.\nSensitivity experiments show that AUWave consistently outperforms a\nrepresentative baseline in data-richer configurations, while the baseline is\nonly marginally competitive in the most underdetermined single-buoy cases. The\narchitecture's multi-scale and attention components translate into accuracy\ngains when minimal but non-trivial spatial anchoring is available. Error maps\nand buoy ablations reveal key anchor stations whose removal disproportionately\ndegrades performance, offering actionable guidance for network design. AUWave\nprovides a scalable pathway for gap filling, high-resolution priors for data\nassimilation, and contingency reconstruction."}
{"id": "2509.19385", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.19385", "abs": "https://arxiv.org/abs/2509.19385", "authors": ["Benjamin J. Choi", "Griffin Milsap", "Clara A. Scholl", "Francesco Tenore", "Mattson Ogg"], "title": "A Statistical Mixture-of-Experts Framework for EMG Artifact Removal in EEG: Empirical Insights and a Proof-of-Concept Application", "comment": null, "summary": "Effective control of neural interfaces is limited by poor signal quality.\nWhile neural network-based electroencephalography (EEG) denoising methods for\nelectromyogenic (EMG) artifacts have improved in recent years, current\nstate-of-the-art (SOTA) models perform suboptimally in settings with high\nnoise. To address the shortcomings of current machine learning (ML)-based\ndenoising algorithms, we present a signal filtration algorithm driven by a new\nmixture-of-experts (MoE) framework. Our algorithm leverages three new\nstatistical insights into the EEG-EMG denoising problem: (1) EMG artifacts can\nbe partitioned into quantifiable subtypes to aid downstream MoE classification,\n(2) local experts trained on narrower signal-to-noise ratio (SNR) ranges can\nachieve performance increases through specialization, and (3) correlation-based\nobjective functions, in conjunction with rescaling algorithms, can enable\nfaster convergence in a neural network-based denoising context. We empirically\ndemonstrate these three insights into EMG artifact removal and use our findings\nto create a new downstream MoE denoising algorithm consisting of convolutional\n(CNN) and recurrent (RNN) neural networks. We tested all results on a major\nbenchmark dataset (EEGdenoiseNet) collected from 67 subjects. We found that our\nMoE denoising model achieved competitive overall performance with SOTA ML\ndenoising algorithms and superior lower bound performance in high noise\nsettings. These preliminary results highlight the promise of our MoE framework\nfor enabling advances in EMG artifact removal for EEG processing, especially in\nhigh noise settings. Further research and development will be necessary to\nassess our MoE framework on a wider range of real-world test cases and explore\nits downstream potential to unlock more effective neural interfaces."}
{"id": "2509.19387", "categories": ["eess.SP", "cs.LG", "stat.AP", "stat.ML"], "pdf": "https://arxiv.org/pdf/2509.19387", "abs": "https://arxiv.org/abs/2509.19387", "authors": ["Antonio Quintero Rincon", "Nicolas Masino", "Veronica Marsico", "Hadj Batatia"], "title": "Hybrid Pipeline SWD Detection in Long-Term EEG Signals", "comment": "11 pages, 8 figures, 4 tables, SABI 2025 CLIC 2025", "summary": "Spike-and-wave discharges (SWDs) are the electroencephalographic hallmark of\nabsence epilepsy, yet their manual identification in multi-day recordings\nremains labour-intensive and error-prone. We present a lightweight hybrid\npipeline that couples analytical features with a shallow artificial neural\nnetwork (ANN) for accurate, patient-specific SWD detection in long-term,\nmonopolar EEG. A two-sided moving-average (MA) filter first suppresses the\nhigh-frequency components of normal background activity. The residual signal is\nthen summarised by the mean and the standard deviation of its normally\ndistributed samples, yielding a compact, two-dimensional feature vector for\nevery 20s window. These features are fed to a single-hidden-layer ANN trained\nvia back-propagation to classify each window as SWD or non-SWD. The method was\nevaluated on 780 channels sampled at 256 Hz from 12 patients, comprising 392\nannotated SWD events. It correctly detected 384 events (sensitivity: 98%) while\nachieving a specificity of 96.2 % and an overall accuracy of 97.2%. Because\nfeature extraction is analytic, and the classifier is small, the pipeline runs\nin real-time and requires no manual threshold tuning. These results indicate\nthat normal-distribution descriptors combined with a modest ANN provide an\neffective and computationally inexpensive solution for automated SWD screening\nin extended EEG recordings."}
{"id": "2509.19397", "categories": ["eess.SP", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.19397", "abs": "https://arxiv.org/abs/2509.19397", "authors": ["Jiarui Jin", "Xiaocheng Fang", "Haoyu Wang", "Jun Li", "Che Liu", "Donglin Xie", "Hongyan Li", "Shenda Hong"], "title": "Self-Alignment Learning to Improve Myocardial Infarction Detection from Single-Lead ECG", "comment": null, "summary": "Myocardial infarction is a critical manifestation of coronary artery disease,\nyet detecting it from single-lead electrocardiogram (ECG) remains challenging\ndue to limited spatial information. An intuitive idea is to convert single-lead\ninto multiple-lead ECG for classification by pre-trained models, but generative\nmethods optimized at the signal level in most cases leave a large latent space\ngap, ultimately degrading diagnostic performance. This naturally raises the\nquestion of whether latent space alignment could help. However, most prior ECG\nalignment methods focus on learning transformation invariance, which mismatches\nthe goal of single-lead detection. To address this issue, we propose SelfMIS, a\nsimple yet effective alignment learning framework to improve myocardial\ninfarction detection from single-lead ECG. Discarding manual data\naugmentations, SelfMIS employs a self-cutting strategy to pair multiple-lead\nECG with their corresponding single-lead segments and directly align them in\nthe latent space. This design shifts the learning objective from pursuing\ntransformation invariance to enriching the single-lead representation,\nexplicitly driving the single-lead ECG encoder to learn a representation\ncapable of inferring global cardiac context from the local signal.\nExperimentally, SelfMIS achieves superior performance over baseline models\nacross nine myocardial infarction types while maintaining a simpler\narchitecture and lower computational overhead, thereby substantiating the\nefficacy of direct latent space alignment. Our code and checkpoint will be\npublicly available after acceptance."}
{"id": "2509.19401", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.19401", "abs": "https://arxiv.org/abs/2509.19401", "authors": ["Jiazhen Hong", "Geoff Mackellar", "Soheila Ghane"], "title": "SpellerSSL: Self-Supervised Learning with P300 Aggregation for Speller BCIs", "comment": null, "summary": "Electroencephalogram (EEG)-based P300 speller brain-computer interfaces\n(BCIs) face three main challenges: low signal-to-noise ratio (SNR), poor\ngeneralization, and time-consuming calibration. We propose SpellerSSL, a\nframework that combines self-supervised learning (SSL) with P300 aggregation to\naddress these issues. First, we introduce an aggregation strategy to enhance\nSNR. Second, to achieve generalization in training, we employ a customized 1D\nU-Net backbone and pretrain the model on both cross-domain and in-domain EEG\ndata. The pretrained model is subsequently fine-tuned with a lightweight\nERP-Head classifier for P300 detection, which adapts the learned\nrepresentations to subject-specific data. Our evaluations on calibration time\ndemonstrate that combining the aggregation strategy with SSL significantly\nreduces the calibration burden per subject and improves robustness across\nsubjects. Experimental results show that SSL learns effective EEG\nrepresentations in both in-domain and cross-domain, with in-domain achieving a\nstate-of-the-art character recognition rate of 94% with only 7 repetitions and\nthe highest information transfer rate (ITR) of 21.86 bits/min on the public\nII-B dataset. Moreover, in-domain SSL with P300 aggregation reduces the\nrequired calibration size by 60% while maintaining a comparable character\nrecognition rate. To the best of our knowledge, this is the first study to\napply SSL to P300 spellers, highlighting its potential to improve both\nefficiency and generalization in speller BCIs and paving the way toward an EEG\nfoundation model for P300 speller BCIs."}
{"id": "2509.19403", "categories": ["eess.SP", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.19403", "abs": "https://arxiv.org/abs/2509.19403", "authors": ["Sheng-Bin Duan", "Jian-Long Hao", "Tian-Yu Xiang", "Xiao-Hu Zhou", "Mei-Jiang Gui", "Xiao-Liang Xie", "Shi-Qi Liu", "Zeng-Guang Hou"], "title": "Online Adaptation via Dual-Stage Alignment and Self-Supervision for Fast-Calibration Brain-Computer Interfaces", "comment": null, "summary": "Individual differences in brain activity hinder the online application of\nelectroencephalogram (EEG)-based brain computer interface (BCI) systems. To\novercome this limitation, this study proposes an online adaptation algorithm\nfor unseen subjects via dual-stage alignment and self-supervision. The\nalignment process begins by applying Euclidean alignment in the EEG data space\nand then updates batch normalization statistics in the representation space.\nMoreover, a self-supervised loss is designed to update the decoder. The loss is\ncomputed by soft pseudo-labels derived from the decoder as a proxy for the\nunknown ground truth, and is calibrated by Shannon entropy to facilitate\nself-supervised training. Experiments across five public datasets and seven\ndecoders show the proposed algorithm can be integrated seamlessly regardless of\nBCI paradigm and decoder architecture. In each iteration, the decoder is\nupdated with a single online trial, which yields average accuracy gains of 4.9%\non steady-state visual evoked potentials (SSVEP) and 3.6% on motor imagery.\nThese results support fast-calibration operation and show that the proposed\nalgorithm has great potential for BCI applications."}
{"id": "2509.19551", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.19551", "abs": "https://arxiv.org/abs/2509.19551", "authors": ["Jrme Leclre", "Thyagaraja Marathe", "Tyler G. R. Reid"], "title": "Insights into Xona Pulsar LEO PNT: Constellation, Signals, and Receiver Design", "comment": "ION GNSS+ 2025 Conference", "summary": "The landscape of global navigation satellite systems (GNSS) is expanding with\nthe emergence of low Earth orbit (LEO) constellations such as Pulsar, which are\nexpected to play a key role in the future of positioning, navigation, and\ntiming (PNT). LEO-based systems provide advantages including stronger signals\nfor greater robustness, faster dynamics that aid convergence and multipath\nmitigation, and shorter time to first fix (TTFF) enabled by high data rates.\nThese benefits, however, come with changes in signal behavior and constellation\ngeometry that require careful consideration in receiver design. This paper\ninvestigates Pulsar properties using a GNSS simulator, analyzing parameters\nsuch as satellite pass duration, elevation, Doppler shift, Doppler rate, range,\nand number of satellites in view. Comparisons with GPS highlight the\ndifferences introduced by LEO operation. The analysis examines temporal\nevolution, statistical distributions, and maximum and minimum values. Beyond\nthese statistical insights, the study explores interdependencies between\nparameters and differences across satellites, providing additional perspective.\nEvaluations are performed at multiple latitudes to ensure a worldwide\nperspective, and the impact of applying different elevation masks is discussed\nwhere relevant. Building on these findings, the paper assesses Pulsar's impact\non receiver design from two standpoints: design considerations, addressing\nexpanded Doppler ranges, higher Doppler rates, and unique constellation\nstructure; and design optimizations, exploiting parameter analyses and\ninterdependencies (e.g., Doppler rate vs Doppler) to refine acquisition\nstrategies and applying prediction and prioritization techniques to avoid\nunnecessary computations. Together, these optimizations can reduce acquisition\ntime and lower receiver power consumption."}
{"id": "2509.19594", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.19594", "abs": "https://arxiv.org/abs/2509.19594", "authors": ["Mohammadhossein Karimi", "Yuanzhe Gong", "Tho Le-Ngoc"], "title": "DNN-Based Nulling Control Beam Focusing for Near-Field Multi-User Interference Mitigation", "comment": "6 pages, 4 figures, submitted to IEEE WCNC 2026", "summary": "This paper proposes a deep learning-based framework for near-field nulling\ncontrol beam focusing (NCBF) in extra-large MIMO (XL-MIMO) systems to mitigate\nmulti-user interference (MUI). A dual-estimator architecture comprising two\nfully connected deep neural networks (FCDNNs) is developed to separately\npredict the phase and magnitude components of NCBF weights, using locations of\nboth desired and interfering users. The models are trained on a large dataset\ngenerated via a Linearly Constrained Minimum Variance (LCMV) beamforming\nalgorithm to accommodate diverse user configurations, including both collinear\nand non-collinear scenarios. Illustrative results demonstrate that the proposed\nDNN models achieve high prediction accuracy, with test errors of only 0.067\nradians for phase estimation and 0.206 dB for magnitude estimation. Full-wave\nsimulations incorporating realistic element radiation patterns and\ninter-element coupling confirm the close agreement between the beam patterns\nproduced by the DNN-predicted and LCMV-based NCBF schemes under practical\ndeployment conditions. An average MUI suppression of 36.7 dB is achieved, with\ninterference mitigation exceeding 17.5 dB across all tested cases. The proposed\napproach enables scalable and real-time beam focusing with effective\ninterference suppression, offering a promising solution for future near-field\nmulti-user wireless communications."}
{"id": "2509.19686", "categories": ["eess.SP", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2509.19686", "abs": "https://arxiv.org/abs/2509.19686", "authors": ["Gabriel J. Griswold", "Mark A. Griswold"], "title": "Non-locally averaged pruned reassigned spectrograms: a tool for glottal pulse visualization and analysis", "comment": "Submitted to Speech Communications. 16 pages, 7 figs, 1 table", "summary": "Reassigned spectrograms have shown advantages in precise formant measuring\nand inter-speaker differentiation. However, reassigned spectrograms suffer from\ntheir inability to visualize larger amounts of data in an easily comprehensible\nand reproducible manner. Utilizing the techniques and tools developed by Fulop\nand Fitz, a variation of the reassigned spectrogram is proposed. Non-locally\nAveraged Pruned Reassigned Spectrograms (NAPReS) provide a simplified view into\nthe characteristics of a speaker's glottal pulsation patterns throughout the\ncentroid of a vowel through the stacking, summing, and pruning of large numbers\nof glottal pulses. In this exploratory study, NAPReS has been shown to display\na large amount of data in an easily comprehensible and quantifiable manner,\nwhile also making the observation of low-amplitude cyclical structures more\naccessible. NAPReS also allows for alternative formant fitting methods such as\nGaussian mixture modeling. In this study, NAPReS with GMM was compared against\nconventional LPC fitting of formant values and was shown to be more\nreproducible than conventional LPC fitting in high-noise situations."}
{"id": "2509.19754", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.19754", "abs": "https://arxiv.org/abs/2509.19754", "authors": ["Xiaolei Yang", "Zijing Wang", "Zhijin Qin", "Xiaoming Tao"], "title": "Timeliness-Aware Joint Source and Channel Coding for Adaptive Image Transmission", "comment": "6 pages, 7 figures, accepted at IEEE GLOBECOM Workshops 2025", "summary": "Accurate and timely image transmission is critical for emerging\ntime-sensitive applications such as remote sensing in satellite-assisted\nInternet of Things. However, the bandwidth limitation poses a significant\nchallenge in existing wireless systems, making it difficult to fulfill the\nrequirements of both high-fidelity and low-latency image transmission. Semantic\ncommunication is expected to break through the performance bottleneck by\nfocusing on the transmission of goal-oriented semantic information rather than\nraw data. In this paper, we employ a new timeliness metric named the value of\ninformation (VoI) and propose an adaptive joint source and channel coding\n(JSCC) method for image transmission that simultaneously considers both\nreconstruction quality and timeliness. Specifically, we first design a JSCC\nframework for image transmission with adaptive code length. Next, we formulate\na VoI maximization problem by optimizing the transmission code length of the\nadaptive JSCC under the reconstruction quality constraint. Then, a deep\nreinforcement learning-based algorithm is proposed to solve the optimization\nproblem efficiently. Experimental results show that the proposed method\nsignificantly outperforms baseline schemes in terms of reconstruction quality\nand timeliness, particularly in low signal-to-noise ratio conditions, offering\na promising solution for efficient and robust image transmission in\ntime-sensitive wireless networks."}
{"id": "2509.19801", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.19801", "abs": "https://arxiv.org/abs/2509.19801", "authors": ["Ioannis Gavras", "George C. Alexandropoulos"], "title": "Electromagnetics-Compliant Optimization of Dynamic Metasurface Antennas for Bistatic Sensing", "comment": "13 pages, 7 figures", "summary": "Dynamic Metasurface Antennas (DMAs) are recently attracting considerable\nresearch interests due to their potential to enable low-cost, reconfigurable,\nand highly scalable antenna array architectures for next generation wireless\nsystems. However, most of the existing literature relies on idealized models\nfor the DMA operation, often overlooking critical structural and physical\nconstraints inherent to their constituent metamaterials. In this paper,\nleveraging a recently proposed model for this antenna architecture\nincorporating physically consistent modeling of mutual coupling and waveguide\npropagation losses, we optimize DMA-based transmission for bistatic sensing. A\ntractable approximation for the DMA response is first presented, which enables\nefficient optimization of the dynamically reconfigurable Lorentzian-constrained\nresponses of the array's metamaterials. In particular, we formulate a robust\nbeamforming optimization problem with the objective to minimize the worst-case\nposition error bound, in the presence of spatial uncertainties for the\nenvironment's scatterers as well as synchronization uncertainties at the analog\ncombining multi-antenna receiver. To address the resulting high computational\ncomplexity due to the possibly excessive number of metamaterial-based antennas\nand their operation constraints, two low complexity beamforming design\napproaches are presented that perform offline searching over a novel beam\ncodebook. The accuracy of all presented DMA designs is assessed by means of\nMonte Carlo simulations for various system parameters, confirming that\naccurately modeling mutual coupling is essential for maintaining increased\nlocalization performance. It is also shown that, even under positioning and\nsynchronization uncertainties, the proposed designs yield accuracy comparable\nto their fully digital and analog counterparts, while adhering to the\nstructural DMA constraints."}
{"id": "2509.19900", "categories": ["eess.SP", "stat.AP", "stat.ML"], "pdf": "https://arxiv.org/pdf/2509.19900", "abs": "https://arxiv.org/abs/2509.19900", "authors": ["Xinjue Wang", "Esa Ollila", "Sergiy A. Vorobyov", "Ammar Mian"], "title": "Generalized Nonnegative Structured Kruskal Tensor Regression", "comment": null, "summary": "This paper introduces Generalized Nonnegative Structured Kruskal Tensor\nRegression (NS-KTR), a novel tensor regression framework that enhances\ninterpretability and performance through mode-specific hybrid regularization\nand nonnegativity constraints. Our approach accommodates both linear and\nlogistic regression formulations for diverse response variables while\naddressing the structural heterogeneity inherent in multidimensional tensor\ndata. We integrate fused LASSO, total variation, and ridge regularizers, each\ntailored to specific tensor modes, and develop an efficient alternating\ndirection method of multipliers (ADMM) based algorithm for parameter\nestimation. Comprehensive experiments on synthetic signals and real\nhyperspectral datasets demonstrate that NS-KTR consistently outperforms\nconventional tensor regression methods. The framework's ability to preserve\ndistinct structural characteristics across tensor dimensions while ensuring\nphysical interpretability makes it especially suitable for applications in\nsignal processing and hyperspectral image analysis."}
{"id": "2509.19912", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.19912", "abs": "https://arxiv.org/abs/2509.19912", "authors": ["Xingxiang Peng", "Qingqing Wu", "Ziyuan Zheng", "Wen Chen", "Yanze Zhu", "Ying Gao"], "title": "Rotatable Antenna Enabled Spectrum Sharing: Joint Antenna Orientation and Beamforming Design", "comment": "13 pages, 10 figures. Submitted to an IEEE journal for possible\n  publication", "summary": "Conventional antenna arrays rely primarily on digital beamforming for spatial\ncontrol. While adding more elements can narrow beamwidth and suppress\ninterference, such scaling incurs prohibitive hardware and power costs.\nRotatable antennas (RAs), which allow mechanical or electronic adjustment of\nelement orientations, introduce a new degree of freedom to exploit spatial\nflexibility without enlarging the array. By dynamically optimizing\norientations, RAs can substantially improve desired link alignment and\ninterference suppression. This paper investigates RA-enabled multiple-input\nsingle-output (MISO) interference channels under co-channel spectrum sharing\nand formulates a weighted sum-rate maximization problem that jointly optimizes\ntransmit beamforming and antenna orientations. To tackle this nonconvex\nproblem, we develop an alternating optimization (AO) framework that integrates\nweighted minimum mean-square error (WMMSE)-based beamforming with\nFrank-Wolfe-based orientation updates. To reduce complexity, we further study\norientation optimization under maximum-ratio transmission (MRT) and\nzero-forcing (ZF) beamforming schemes. For finite-resolution actuators, we\nconstruct spherical Fibonacci codebooks and design a cross-entropy method\n(CEM)-based algorithm for discrete orientation selection. Simulations show that\nintegrating RAs with conventional beamforming markedly increases weighted\nsum-rate, with gains rising with element directivity. Under discrete\norientation control, the proposed CEM algorithm consistently outperforms the\nnearest-projection baseline."}
{"id": "2509.19974", "categories": ["eess.SP", "eess.AS"], "pdf": "https://arxiv.org/pdf/2509.19974", "abs": "https://arxiv.org/abs/2509.19974", "authors": ["Natsuki Ueno", "Ryotaro Sato", "Nobutaka Ono"], "title": "On the Invariance of Cross-Correlation Peak Positions Under Monotonic Signal Transformations, with Application to Fast Time Difference Estimation", "comment": null, "summary": "We present a theorem concerning the invariance of cross-correlation peak\npositions, which provides a foundation for a new method for time difference\nestimation that is potentially faster than the conventional fast Fourier\ntransform (FFT) approach for real/complex sequences. This theoretical result\nshows that the peak position of the cross-correlation function between two\nshifted discrete-time signals remains unchanged under arbitrary monotonic\ntransformations of the input signals. By exploiting this property, we design an\nefficient estimation algorithm based on the cross-correlation function between\nsignals quantized into low-bit integers. The proposed method requires only\ninteger arithmetic instead of real-valued operations, and further computational\nefficiency can be achieved through number-theoretic algorithms. Numerical\nexperiments demonstrate that the proposed method achieves a shorter processing\ntime than conventional FFT-based approaches."}
{"id": "2509.20026", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.20026", "abs": "https://arxiv.org/abs/2509.20026", "authors": ["Jiayi Lu", "Jiayi Zhang", "Hao Lei", "Huahua Xiao", "Bo Ai", "Derrick Wing Kwan Ng"], "title": "Near-field Spatial-domain Channel Extrapolation for XL-MIMO Systems", "comment": "This paper has been accepted by IEEE Transactions on Wireless\n  Communications", "summary": "Extremely large-scale multiple-input multiple-output (XL-MIMO) systems are\npivotal to next-generation wireless communications, where dynamic RF chain\narchitectures offer enhanced performance. However, efficient precoding in such\nsystems requires accurate channel state information (CSI) obtained with low\ncomplexity. To address this challenge, spatial-domain channel extrapolation has\nattracted growing interest. Existing methods often overlook near-field\nspherical wavefronts or rely heavily on sparsity priors, leading to performance\ndegradation. In this paper, we propose an adaptive near-field channel\nextrapolation framework for multi-subcarrier XL-MIMO systems, leveraging a\nstrategically selected subset of antennas. Subsequently, we develop both\non-grid and off-grid algorithms, where the latter refines the former's\nestimates for improved accuracy. To further reduce complexity, a\ncross-validation (CV)-based scheme is introduced. Additionally, we analytically\nformulate the mutual coherence of the sensing matrix and propose a\ncoherence-minimizing-based random pattern to ensure robust extrapolation.\nNumerical results validate that the proposed algorithms significantly\noutperform existing methods in both extrapolation accuracy and achievable rate,\nwhile maintaining low computational complexity. In particular, our proposed CV\nratio offers a flexible trade-off between accuracy and efficiency, and the\ncorresponding off-grid algorithm achieves high accuracy with complexity\ncomparable to conventional on-grid methods."}
{"id": "2509.20030", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.20030", "abs": "https://arxiv.org/abs/2509.20030", "authors": ["Renzhi Yuan", "Zhixing Wang", "Shouye Miao", "Mufei Zhao", "Haifeng Yao", "Bin Cao", "Mugen Peng"], "title": "Multi-Stage CD-Kennedy Receiver for QPSK Modulated CV-QKD in Turbulent Channels", "comment": "25pages,7 figures", "summary": "Continuous variable-quantum key distribution (CV-QKD) protocols attract\nincreasing attentions in recent years because they enjoy high secret key rate\n(SKR) and good compatibility with existing optical communication\ninfrastructure. Classical coherent receivers are widely employed in coherent\nstates based CV-QKD protocols, whose detection performance is bounded by the\nstandard quantum limit (SQL). Recently, quantum receivers based on displacement\noperators are experimentally demonstrated with detection performance\noutperforming the SQL in various practical conditions. However, potential\napplications of quantum receivers in CV-QKD protocols under turbulent channels\nare still not well explored, while practical CV-QKD protocols must survive from\nthe atmospheric turbulence in satellite-to-ground optical communication links.\nIn this paper, we consider the possibility of using a quantum receiver called\nmulti-stage CD-Kennedy receiver to enhance the SKR performance of a quadrature\nphase shift keying (QPSK) modulated CV-QKD protocol in turbulent channels. We\nfirst derive the error probability of the multi-stage CD-Kennedy receiver for\ndetecting QPSK signals in turbulent channels and further propose three types of\nmulti-stage CD-Kennedy receiver with different displacement choices, i.e., the\nType-I, Type-II, and Type-III receivers. Then we derive the SKR of a QPSK\nmodulated CV-QKD protocol using the multi-stage CD-Kennedy receiver and\npost-selection strategy in turbulent channels. Numerical results show that the\nmulti-stage CD-Kennedy receiver can outperform the classical coherent receiver\nin turbulent channels in terms of both error probability and SKR performance\nand the Type-II receiver can tolerate worse channel conditions compared with\nType-I and Type-III receivers in terms of error probability performance."}
{"id": "2509.20034", "categories": ["eess.SP", "math.OC", "stat.AP"], "pdf": "https://arxiv.org/pdf/2509.20034", "abs": "https://arxiv.org/abs/2509.20034", "authors": ["Etienne Lasalle", "Barbara Pascal"], "title": "Reproduction Number and Spatial Connectivity Structure Estimation via Graph Sparsity-Promoting Penalized Functional", "comment": "11 pages, 3 figures", "summary": "During an epidemic outbreak, decision makers crucially need accurate and\nrobust tools to monitor the pathogen propagation. The effective reproduction\nnumber, defined as the expected number of secondary infections stemming from\none contaminated individual, is a state-of-the-art indicator quantifying the\nepidemic intensity. Numerous estimators have been developed to precisely track\nthe reproduction number temporal evolution. Yet, COVID-19 pandemic surveillance\nraised unprecedented challenges due to the poor quality of worldwide reported\ninfection counts. When monitoring the epidemic in different territories\nsimultaneously, leveraging the spatial structure of data significantly enhances\nboth the accuracy and robustness of reproduction number estimates. However,\nthis requires a good estimate of the spatial structure. To tackle this major\nlimitation, the present work proposes a joint estimator of the reproduction\nnumber and connectivity structure. The procedure is assessed through intensive\nnumerical simulations on carefully designed synthetic data and illustrated on\nreal COVID-19 spatiotemporal infection counts."}
{"id": "2509.20046", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.20046", "abs": "https://arxiv.org/abs/2509.20046", "authors": ["Knut H. Grythe", "Jan Erik Hkegrd"], "title": "A dual bistatic optical forward transceiver configuration for determining the position of an acoustic communication source detected by optical communication fibers", "comment": "18 pages, 17 figures", "summary": "Optical fibers have long been employed as sensors in a wide range of\ncommercial systems. Distributed Acoustic Sensing (DAS) extends this concept by\nenabling the detection and localization of acoustic sources along the fiber,\nusing backscattered light from small segments to achieve spatial resolution on\nthe order of meters. Recently, DAS has also been explored as a component in\nunderwater acoustic communication systems. Emerging interest in bidirectional\nconfigurations where both transmitter and receiver are placed at opposite ends\nof the fiber has opened new possibilities. However, in such setups, source\nlocalization is not inherently integrated into the signal decoding process. For\nscenarios where source positioning is valuable, we propose an approach inspired\nby bi-static radar principles. This configuration utilizes acoustic signals\nreceived at both ends of the fiber to estimate source position based on\npropagation delay differences. Although the localization accuracy is lower than\nthat of DAS due to reduced sampling rates, the method offers a viable\nalternative for integrated communication and positioning. We present the system\ntopology and configuration for a dual-fiber layout, each end equipped with\noptical transmitters and receivers. The position estimation is derived from the\ntime difference of arrival (TDOA) between the two receivers. The Cram\\'er-Rao\nBound is derived to characterize the theoretical limits of localization\naccuracy, highlighting dependencies on system parameters such as optical power\nloss. Our analysis shows that increased acoustic bandwidth and higher carrier\nfrequencies enhance spatial resolution. We formulate the Cross Ambiguity\nFunction as a maximum likelihood estimator for TDOA and provide simulation\nresults illustrating its performance under varying system conditions. Finally,\nwe discuss key challenges that must be addressed for practical implementation."}
{"id": "2509.20059", "categories": ["eess.SP", "cs.NI"], "pdf": "https://arxiv.org/pdf/2509.20059", "abs": "https://arxiv.org/abs/2509.20059", "authors": ["Koki Kanzaki", "Koya Sato"], "title": "Joint Ex-Post Location Calibration and Radio Map Construction under Biased Positioning Errors", "comment": "6 pages, 8 figures. Accepted for presentation at 2025 IEEE GLOBECOM\n  Workshops: Workshop on The Interplay of Digital Twins and Pervasive\n  Artificial Intelligence for Next-Generation IoT", "summary": "This paper proposes a high-accuracy radio map construction method tailored\nfor environments where location information is affected by bursty errors. Radio\nmaps are an effective tool for visualizing wireless environments. Although\nextensive research has been conducted on accurate radio map construction, most\nexisting approaches assume noise-free location information during sensing. In\npractice, however, positioning errors ranging from a few to several tens of\nmeters can arise due to device-based positioning systems (e.g., GNSS). Ignoring\nsuch errors during inference can lead to significant degradation in radio map\naccuracy. This study highlights that these errors often tend to be biased when\nusing mobile devices as sensors. We introduce a novel framework that models\nthese errors together with spatial correlation in radio propagation by\nembedding them as tunable parameters in the marginal log-likelihood function.\nThis enables ex-post calibration of location uncertainty during radio map\nconstruction. Numerical results based on practical human mobility data\ndemonstrate that the proposed method can limit RMSE degradation to\napproximately 0.25-0.29 dB, compared with Gaussian process regression using\nnoise-free location data, whereas baseline methods suffer performance losses\nexceeding 1 dB."}
{"id": "2509.20246", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.20246", "abs": "https://arxiv.org/abs/2509.20246", "authors": ["Marko Fidanovski", "Ivn Alexander Morales Sandoval", "Hyeon Seok Rou", "Giuseppe Thadeu Freitas de Abreu", "Emil Bjrnson"], "title": "Reciprocal Beyond-Diagonal Reconfigurable Intelligent Surface (BD-RIS): Scattering Matrix Design via Manifold Optimization", "comment": null, "summary": "Beyond-diagonal reconfigurable intelligent surfaces (BD-RISs) are emerging as\na transformative technology in wireless communications, enabling enhanced\nperformance and quality of service (QoS) of wireless systems in harsh urban\nenvironments due to their relatively low cost and advanced signal processing\ncapabilities. Generally, BD-RIS systems are employed to improve robustness,\nincrease achievable rates, and enhance energy efficiency of wireless systems in\nboth direct and indirect ways. The direct way is to produce a favorable\npropagation environment via the design of optimized scattering matrices, while\nthe indirect way is to reap additional improvements via the design of\nmultiple-input multiple-output (MIMO) beamformers that further exploit the\nlatter \"engineered\" medium. In this article, the problem of sum-rate\nmaximization via BD-RIS is examined, with a focus on feasibility, namely\nlow-complexity physical implementation, by enforcing reciprocity in the BD-RIS\ndesign. We begin by outlining the system model and formulating an optimization\nproblem that aims to enhance the system's sum-rate by designing a symmetric\nscattering matrix. In particular, the approach leverages a manifold\noptimization framework, where a penalty term is added to the objective function\nto ensure that the symmetry constraint is upheld, with reciprocity further\nenforced by projecting the obtained solution onto a set of feasible scattering\nmatrices. Simulation results demonstrate the effectiveness of the proposed\nmethod in outperforming current state-of-the-art (SotA) approaches in terms of\nsum-rate maximization."}
{"id": "2509.20299", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.20299", "abs": "https://arxiv.org/abs/2509.20299", "authors": ["Chenguang Rao", "Kai-Kit Wong", "Mohd Hamza Naim Shaikh", "Hanjiang Hong", "Hyundong Shin", "Yangyang Zhang"], "title": "Geometric Port Selection in CUMA Systems", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Compact ultra-massive antenna-array (CUMA) is a novel multiple access\ntechnology built on the fluid antenna system (FAS) concept, offering an\nimproved scheme over fluid antenna multiple access (FAMA) that can support\nmassive connectivity on the same physical channel without the need of precoding\nand interference cancellation. By employing a simple port-selection mechanism\nthat leverages random channel superposition, CUMA can suppress inter-user\ninterference while keeping hardware costs low. Nevertheless, its ad-hoc\nport-selection strategy leaves considerable room for optimization. In this\nwork, we revisit CUMA and propose two adaptive single-RF port-selection schemes\nthat retain its simplicity while significantly enhancing performance. The first\none, referred to as exact optimal half-space (EOHS), dynamically selects the\nprojection direction that maximizes the instantaneous signal build-up across\nactive ports. To reduce complexity while preserving most of the gains, we\nfurthermore introduce a principal component analysis (PCA)-based scheme, which\naligns port partitioning with the dominant statistical direction of per-port\nchannel vectors. This method yields a closed-form low-complexity solution,\ncomplemented by a tractable analytical framework that provides a closed-form\nexpression for the signal-to-interference ratio (SIR) probability density\nfunction (PDF). Simulation results corroborate the analysis, demonstrating that\nboth EOHS and PCA consistently outperform conventional CUMA across diverse user\ndensities, port counts, and FAS aperture sizes. Notably, PCA achieves\nperformance close to EOHS at a fraction of the computational cost. The proposed\nschemes scale effectively to large-user regimes, offering a compelling\ncomplexity-performance trade-off for next-generation multiple access systems."}
