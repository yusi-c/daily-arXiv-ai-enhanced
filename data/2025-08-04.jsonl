{"id": "2508.00093", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.00093", "abs": "https://arxiv.org/abs/2508.00093", "authors": ["Lucas Alves Zischler", "Chiara Lasagni", "Paolo Serena", "Alberto Bononi", "Giammarco Di Sciullo", "Divya A. Shaji", "Antonio Mecozzi", "Cristian Antonelli"], "title": "Closed-form Expression for the Power Profile in Wideband Systems with Inter-channel Stimulated Raman Scattering", "comment": "Submitted for the Journal of Lightwave Technology", "summary": "Wideband systems experience significant inter-channel stimulated Raman\nscattering (ISRS) and channel-dependent losses. Due to the non-uniform\nattenuation profile, the combined effects of ISRS and fiber loss can only be\naccurately estimated using numerical methods. In this work, we present an\napproximate closed-form expression for the channels' power profile accounting\nfor these combined effects. We validate the proposed expression against\nnumerical solutions in the case of CLU transmission, showing high accuracy for\nboth single-span and multi-span fiber-optic links. Additionally, we derive an\ninverse expression, formulated as a function of the output power, which can be\nutilized to target a desired optical signal-to-noise ratio (OSNR) profile\nthrough pre-emphasis of the launched channel powers."}
{"id": "2508.00274", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.00274", "abs": "https://arxiv.org/abs/2508.00274", "authors": ["Yunfei Liu", "Mingxuan Liu", "Wupeng Xie", "Xinzhu Liu", "Wenxue Liu", "Yangang Sun", "Xin Qiu", "Cui Yuan", "Jinhai Li"], "title": "RIS-MAE: A Self-Supervised Modulation Classification Method Based on Raw IQ Signals and Masked Autoencoder", "comment": null, "summary": "Automatic modulation classification (AMC) is a basic technology in\nintelligent wireless communication systems. It is important for tasks such as\nspectrum monitoring, cognitive radio, and secure communications. In recent\nyears, deep learning methods have made great progress in AMC. However,\nmainstream methods still face two key problems. First, they often use\ntime-frequency images instead of raw signals. This causes loss of key\nmodulation features and reduces adaptability to different communication\nconditions. Second, most methods rely on supervised learning. This needs a\nlarge amount of labeled data, which is hard to get in real-world environments.\nTo solve these problems, we propose a self-supervised learning framework called\nRIS-MAE. RIS-MAE uses masked autoencoders to learn signal features from\nunlabeled data. It takes raw IQ sequences as input. By applying random masking\nand reconstruction, it captures important time-domain features such as\namplitude, phase, etc. This helps the model learn useful and transferable\nrepresentations. RIS-MAE is tested on four datasets. The results show that it\nperforms better than existing methods in few-shot and cross-domain tasks.\nNotably, it achieves high classification accuracy on previously unseen datasets\nwith only a small number of fine-tuning samples, confirming its generalization\nability and potential for real-world deployment."}
{"id": "2508.00326", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.00326", "abs": "https://arxiv.org/abs/2508.00326", "authors": ["Chengwang Ji", "Kehui Li", "Haiquan Lu", "Qiaoyan Peng", "Jintao Wang", "Shaodan Ma"], "title": "Model-Driven Deep Learning Enhanced Joint Beamforming and Mode Switching for RDARS-Aided MIMO Systems", "comment": null, "summary": "Reconfigurable distributed antenna and reflecting surface (RDARS) is a\npromising architecture for future sixth-generation (6G) wireless networks. In\nparticular, the dynamic working mode configuration for the RDARS-aided system\nbrings an extra selection gain compared to the existing reconfigurable\nintelligent surface (RIS)-aided system and distributed antenna system (DAS). In\nthis paper, we consider the RDARS-aided downlink multiple-input multiple-output\n(MIMO) system and aim to maximize the weighted sum rate (WSR) by jointly\noptimizing the beamforming matrices at the based station (BS) and RDARS, as\nwell as mode switching matrix at RDARS. The optimization problem is challenging\nto be solved due to the non-convex objective function and mixed integer binary\nconstraint. To this end, a penalty term-based weight minimum mean square error\n(PWM) algorithm is proposed by integrating the majorization-minimization (MM)\nand weight minimum mean square error (WMMSE) methods. To further escape the\nlocal optimum point in the PWM algorithm, a model-driven DL method is\nintegrated into this algorithm, where the key variables related to the\nconvergence of PWM algorithm are trained to accelerate the convergence speed\nand improve the system performance. Simulation results are provided to show\nthat the PWM-based beamforming network (PWM-BFNet) can reduce the number of\niterations by half and achieve performance improvements of 26.53% and 103.2% at\nthe scenarios of high total transmit power and a large number of RDARS transmit\nelements (TEs), respectively."}
{"id": "2508.00409", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.00409", "abs": "https://arxiv.org/abs/2508.00409", "authors": ["Mohammad Soleymani", "Ignacio Santamaria", "Eduard Jorswieck", "Robert Schober", "Lajos Hanzo"], "title": "STAR-RIS-aided RSMA for the URLLC multi-user MIMO Downlink", "comment": "Accepted at 28th International Workshop on Smart Antennas 2025", "summary": "Rate splitting multiple access (RSMA) is intrinsically amalgamated with\nsimultaneously transmitting and reflecting (STAR) reconfigurable intelligent\nsurfaces (RIS) to enhance energy efficiency (EE) of the finite block length\n(FBL) multiple-input multiple-output (MIMO) downlink. An alternating\noptimization-based algorithm is proposed to jointly optimize the transmit\nbeamforming matrices, STAR-RIS configurations, and rate-splitting parameters.\nSTAR-RIS attains 360-degree full-plane coverage, while RSMA provides a\nprominent gain by efficiently managing interference. Numerical results reveal a\nstrong synergy between RSMA and STAR-RIS, demonstreating significant EE gains\nover reflective RIS and spatial division multiple access (SDMA)."}
{"id": "2508.00155", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00155", "abs": "https://arxiv.org/abs/2508.00155", "authors": ["Tomasz Szczepański", "Szymon Płotka", "Michal K. Grzeszczyk", "Arleta Adamowicz", "Piotr Fudalej", "Przemysław Korzeniowski", "Tomasz Trzciński", "Arkadiusz Sitek"], "title": "GEPAR3D: Geometry Prior-Assisted Learning for 3D Tooth Segmentation", "comment": "Accepted for the 28th International Conference on Medical Image\n  Computing and Computer Assisted Intervention (MICCAI) 2025", "summary": "Tooth segmentation in Cone-Beam Computed Tomography (CBCT) remains\nchallenging, especially for fine structures like root apices, which is critical\nfor assessing root resorption in orthodontics. We introduce GEPAR3D, a novel\napproach that unifies instance detection and multi-class segmentation into a\nsingle step tailored to improve root segmentation. Our method integrates a\nStatistical Shape Model of dentition as a geometric prior, capturing anatomical\ncontext and morphological consistency without enforcing restrictive adjacency\nconstraints. We leverage a deep watershed method, modeling each tooth as a\ncontinuous 3D energy basin encoding voxel distances to boundaries. This\ninstance-aware representation ensures accurate segmentation of narrow, complex\nroot apices. Trained on publicly available CBCT scans from a single center, our\nmethod is evaluated on external test sets from two in-house and two public\nmedical centers. GEPAR3D achieves the highest overall segmentation performance,\naveraging a Dice Similarity Coefficient (DSC) of 95.0% (+2.8% over the\nsecond-best method) and increasing recall to 95.2% (+9.5%) across all test\nsets. Qualitative analyses demonstrated substantial improvements in root\nsegmentation quality, indicating significant potential for more accurate root\nresorption assessment and enhanced clinical decision-making in orthodontics. We\nprovide the implementation and dataset at https://github.com/tomek1911/GEPAR3D."}
{"id": "2508.00456", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.00456", "abs": "https://arxiv.org/abs/2508.00456", "authors": ["Ji Wang", "Bin Tang", "Jian Xiao", "Qimei Cui", "Xingwang Li", "Tony Q. S. Quek"], "title": "When Vision-Language Model (VLM) Meets Beam Prediction: A Multimodal Contrastive Learning Framework", "comment": null, "summary": "As the real propagation environment becomes in creasingly complex and\ndynamic, millimeter wave beam prediction faces huge challenges. However, the\npowerful cross modal representation capability of vision-language model (VLM)\nprovides a promising approach. The traditional methods that rely on real-time\nchannel state information (CSI) are computationally expensive and often fail to\nmaintain accuracy in such environments. In this paper, we present a VLM-driven\ncontrastive learning based multimodal beam prediction framework that integrates\nmultimodal data via modality-specific encoders. To enforce cross-modal\nconsistency, we adopt a contrastive pretraining strategy to align image and\nLiDAR features in the latent space. We use location information as text prompts\nand connect it to the text encoder to introduce language modality, which\nfurther improves cross-modal consistency. Experiments on the DeepSense-6G\ndataset show that our VLM backbone provides additional semantic grounding.\nCompared with existing methods, the overall distance-based accuracy score\n(DBA-Score) of 0.9016, corresponding to 1.46% average improvement."}
{"id": "2508.00164", "categories": ["eess.IV", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2508.00164", "abs": "https://arxiv.org/abs/2508.00164", "authors": ["Sourya Sengupta", "Jianquan Xu", "Phuong Nguyen", "Frank J. Brooks", "Yang Liu", "Mark A. Anastasio"], "title": "On the Utility of Virtual Staining for Downstream Applications as it relates to Task Network Capacity", "comment": null, "summary": "Virtual staining, or in-silico-labeling, has been proposed to computationally\ngenerate synthetic fluorescence images from label-free images by use of deep\nlearning-based image-to-image translation networks. In most reported studies,\nvirtually stained images have been assessed only using traditional image\nquality measures such as structural similarity or signal-to-noise ratio.\nHowever, in biomedical imaging, images are typically acquired to facilitate an\nimage-based inference, which we refer to as a downstream biological or clinical\ntask. This study systematically investigates the utility of virtual staining\nfor facilitating clinically relevant downstream tasks (like segmentation or\nclassification) with consideration of the capacity of the deep neural networks\nemployed to perform the tasks. Comprehensive empirical evaluations were\nconducted using biological datasets, assessing task performance by use of\nlabel-free, virtually stained, and ground truth fluorescence images. The\nresults demonstrated that the utility of virtual staining is largely dependent\non the ability of the segmentation or classification task network to extract\nmeaningful task-relevant information, which is related to the concept of\nnetwork capacity. Examples are provided in which virtual staining does not\nimprove, or even degrades, segmentation or classification performance when the\ncapacity of the associated task network is sufficiently large. The results\ndemonstrate that task network capacity should be considered when deciding\nwhether to perform virtual staining."}
{"id": "2508.00494", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.00494", "abs": "https://arxiv.org/abs/2508.00494", "authors": ["Youngsun Kong", "Farnoush Baghestani", "I-Ping Chen", "Ki Chon"], "title": "Feasibility of Extracting Skin Nerve Activity from Electrocardiogram Recorded at A Low Sampling Frequency", "comment": "Accepted and presented at the 47th Annual International Conference of\n  the IEEE Engineering in Medicine and Biology Society (EMBC 2025)", "summary": "Skin nerve activity (SKNA) derived from electrocardiogram (ECG) signals has\nbeen a promising non-invasive surrogate for accurate and effective assessment\nof the sympathetic nervous system (SNS). Typically, SKNA extraction requires a\nhigher sampling frequency than the typical ECG recording requirement (> 2 kHz)\nbecause analysis tools extract SKNA from the 0.5-1 kHz frequency band. However,\nECG recording systems commonly provide a sampling frequency of 1 kHz or lower,\nparticularly for wearable devices. Our recent power spectral analysis exhibited\nthat 150-500 Hz frequency bands are dominant during sympathetic stimulation.\nTherefore, we hypothesize that SKNA can be extracted from ECG sampled at a\nlower sampling frequency. We collected ECG signals from 16 participants during\nSNS stimulation and resampled the signals at 0.5, 1, and 4 kHz. Our statistical\nanalyses of significance, classification performance, and reliability indicate\nno significant difference between SKNA indices derived from ECG signals sampled\nat 0.5, 1, and 4 kHz. Our findings indicate that conventional ECG devices,\nwhich are limited to low sampling rates due to resource constraints or outdated\nguidelines, can be used to reliably collect SKNA if muscle artifact\ncontamination is minimal."}
{"id": "2508.00235", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.00235", "abs": "https://arxiv.org/abs/2508.00235", "authors": ["Erin Rainville", "Amirhossein Rasoulian", "Hassan Rivaz", "Yiming Xiao"], "title": "Weakly Supervised Intracranial Aneurysm Detection and Segmentation in MR angiography via Multi-task UNet with Vesselness Prior", "comment": "Accepted to ICCV 2025 Workshop CVAMD", "summary": "Intracranial aneurysms (IAs) are abnormal dilations of cerebral blood vessels\nthat, if ruptured, can lead to life-threatening consequences. However, their\nsmall size and soft contrast in radiological scans often make it difficult to\nperform accurate and efficient detection and morphological analyses, which are\ncritical in the clinical care of the disorder. Furthermore, the lack of large\npublic datasets with voxel-wise expert annotations pose challenges for\ndeveloping deep learning algorithms to address the issues. Therefore, we\nproposed a novel weakly supervised 3D multi-task UNet that integrates\nvesselness priors to jointly perform aneurysm detection and segmentation in\ntime-of-flight MR angiography (TOF-MRA). Specifically, to robustly guide IA\ndetection and segmentation, we employ the popular Frangi's vesselness filter to\nderive soft cerebrovascular priors for both network input and an attention\nblock to conduct segmentation from the decoder and detection from an auxiliary\nbranch. We train our model on the Lausanne dataset with coarse ground truth\nsegmentation, and evaluate it on the test set with refined labels from the same\ndatabase. To further assess our model's generalizability, we also validate it\nexternally on the ADAM dataset. Our results demonstrate the superior\nperformance of the proposed technique over the SOTA techniques for aneurysm\nsegmentation (Dice = 0.614, 95%HD =1.38mm) and detection (false positive rate =\n1.47, sensitivity = 92.9%)."}
{"id": "2508.00603", "categories": ["eess.SP", "cs.SY", "eess.AS", "eess.SY"], "pdf": "https://arxiv.org/pdf/2508.00603", "abs": "https://arxiv.org/abs/2508.00603", "authors": ["Hong-Cheng Liang", "Man-Wai Mak", "Kong Aik Lee"], "title": "Subband Architecture Aided Selective Fixed-Filter Active Noise Control", "comment": null, "summary": "The feedforward selective fixed-filter method selects the most suitable\npre-trained control filter based on the spectral features of the detected\nreference signal, effectively avoiding slow convergence in conventional\nadaptive algorithms. However, it can only handle limited types of noises, and\nthe performance degrades when the input noise exhibits non-uniform power\nspectral density. To address these limitations, this paper devises a novel\nselective fixed-filter scheme based on a delayless subband structure. In the\noff-line training stage, subband control filters are pre-trained for different\nfrequency ranges and stored in a dedicated sub-filter database. During the\non-line control stage, the incoming noise is decomposed using a polyphase FFT\nfilter bank, and a frequency-band-matching mechanism assigns each subband\nsignal the most appropriate control filter. Subsequently, a weight stacking\ntechnique is employed to combine all subband weights into a fullband filter,\nenabling real-time noise suppression. Experimental results demonstrate that the\nproposed scheme provides fast convergence, effective noise reduction, and\nstrong robustness in handling more complicated noisy environments."}
{"id": "2508.00438", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.00438", "abs": "https://arxiv.org/abs/2508.00438", "authors": ["Sumin Seo", "In Kyu Lee", "Hyun-Woo Kim", "Jaesik Min", "Chung-Hwan Jung"], "title": "Diffusion-Based User-Guided Data Augmentation for Coronary Stenosis Detection", "comment": "Accepted at MICCAI 2025. Dataset available at\n  https://github.com/medipixel/DiGDA", "summary": "Coronary stenosis is a major risk factor for ischemic heart events leading to\nincreased mortality, and medical treatments for this condition require\nmeticulous, labor-intensive analysis. Coronary angiography provides critical\nvisual cues for assessing stenosis, supporting clinicians in making informed\ndecisions for diagnosis and treatment. Recent advances in deep learning have\nshown great potential for automated localization and severity measurement of\nstenosis. In real-world scenarios, however, the success of these competent\napproaches is often hindered by challenges such as limited labeled data and\nclass imbalance. In this study, we propose a novel data augmentation approach\nthat uses an inpainting method based on a diffusion model to generate realistic\nlesions, allowing user-guided control of severity. Extensive evaluation on\nlesion detection and severity classification across various synthetic dataset\nsizes shows superior performance of our method on both a large-scale in-house\ndataset and a public coronary angiography dataset. Furthermore, our approach\nmaintains high detection and classification performance even when trained with\nlimited data, highlighting its clinical importance in improving the assessment\nof severity of stenosis and optimizing data utilization for more reliable\ndecision support."}
{"id": "2508.00800", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.00800", "abs": "https://arxiv.org/abs/2508.00800", "authors": ["Rui Chen", "Wen-Xuan Long", "Bing-Qian Wang", "Yuan He", "Rui-Jin Sun", "Nan Cheng", "Gan Zheng", "Dusit Niyato"], "title": "Multibeam High Throughput Satellite: Hardware Foundation, Resource Allocation, and Precoding", "comment": "38 pages, 18 figures", "summary": "With its wide coverage and uninterrupted service, satellite communication is\na critical technology for next-generation 6G communications. High throughput\nsatellite (HTS) systems, utilizing multipoint beam and frequency multiplexing\ntechniques, enable satellite communication capacity of up to Tbps to meet the\ngrowing traffic demand. Therefore, it is imperative to review\nthe-state-of-the-art of multibeam HTS systems and identify their associated\nchallenges and perspectives. Firstly, we summarize the multibeam HTS hardware\nfoundations, including ground station systems, on-board payloads, and user\nterminals. Subsequently, we review the flexible on-board radio resource\nallocation approaches of bandwidth, power, time slot, and joint allocation\nschemes of HTS systems to optimize resource utilization and cater to\nnon-uniform service demand. Additionally, we survey multibeam precoding methods\nfor the HTS system to achieve full-frequency reuse and interference\ncancellation, which are classified according to different deployments such as\nsingle gateway precoding, multiple gateway precoding, on-board precoding, and\nhybrid on-board/on-ground precoding. Finally, we disscuss the challenges\nrelated to Q/V band link outage, time and frequency synchronization of\ngateways, the accuracy of channel state information (CSI), payload light-weight\ndevelopment, and the application of deep learning (DL). Research on these\ntopics will contribute to enhancing the performance of HTS systems and finally\ndelivering high-speed data to areas underserved by terrestrial networks."}
{"id": "2508.00721", "categories": ["eess.IV", "cs.CV", "cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2508.00721", "abs": "https://arxiv.org/abs/2508.00721", "authors": ["Yuxiang Wan", "Ryan Devera", "Wenjie Zhang", "Ju Sun"], "title": "FMPlug: Plug-In Foundation Flow-Matching Priors for Inverse Problems", "comment": null, "summary": "We present FMPlug, a novel plug-in framework that enhances foundation\nflow-matching (FM) priors for solving ill-posed inverse problems. Unlike\ntraditional approaches that rely on domain-specific or untrained priors, FMPlug\nsmartly leverages two simple but powerful insights: the similarity between\nobserved and desired objects and the Gaussianity of generative flows. By\nintroducing a time-adaptive warm-up strategy and sharp Gaussianity\nregularization, FMPlug unlocks the true potential of domain-agnostic foundation\nmodels. Our method beats state-of-the-art methods that use foundation FM priors\nby significant margins, on image super-resolution and Gaussian deblurring."}
{"id": "2508.00721", "categories": ["eess.IV", "cs.CV", "cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2508.00721", "abs": "https://arxiv.org/abs/2508.00721", "authors": ["Yuxiang Wan", "Ryan Devera", "Wenjie Zhang", "Ju Sun"], "title": "FMPlug: Plug-In Foundation Flow-Matching Priors for Inverse Problems", "comment": null, "summary": "We present FMPlug, a novel plug-in framework that enhances foundation\nflow-matching (FM) priors for solving ill-posed inverse problems. Unlike\ntraditional approaches that rely on domain-specific or untrained priors, FMPlug\nsmartly leverages two simple but powerful insights: the similarity between\nobserved and desired objects and the Gaussianity of generative flows. By\nintroducing a time-adaptive warm-up strategy and sharp Gaussianity\nregularization, FMPlug unlocks the true potential of domain-agnostic foundation\nmodels. Our method beats state-of-the-art methods that use foundation FM priors\nby significant margins, on image super-resolution and Gaussian deblurring."}
{"id": "2508.00755", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.00755", "abs": "https://arxiv.org/abs/2508.00755", "authors": ["Peng Hu", "Wenxuan Zhang"], "title": "AI-Driven Collaborative Satellite Object Detection for Space Sustainability", "comment": "Submitted to the 13th Annual IEEE International Conference on\n  Wireless for Space and Extreme Environments (WiSEE 2025)", "summary": "The growing density of satellites in low-Earth orbit (LEO) presents serious\nchallenges to space sustainability, primarily due to the increased risk of\nin-orbit collisions. Traditional ground-based tracking systems are constrained\nby latency and coverage limitations, underscoring the need for onboard,\nvision-based space object detection (SOD) capabilities. In this paper, we\npropose a novel satellite clustering framework that enables the collaborative\nexecution of deep learning (DL)-based SOD tasks across multiple satellites. To\nsupport this approach, we construct a high-fidelity dataset simulating imaging\nscenarios for clustered satellite formations. A distance-aware viewpoint\nselection strategy is introduced to optimize detection performance, and recent\nDL models are used for evaluation. Experimental results show that the\nclustering-based method achieves competitive detection accuracy compared to\nsingle-satellite and existing approaches, while maintaining a low size, weight,\nand power (SWaP) footprint. These findings underscore the potential of\ndistributed, AI-enabled in-orbit systems to enhance space situational awareness\nand contribute to long-term space sustainability."}
