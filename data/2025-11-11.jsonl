{"id": "2511.05522", "categories": ["eess.SP", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05522", "abs": "https://arxiv.org/abs/2511.05522", "authors": ["Ali Saeizadeh", "Miead Tehrani-Moayyed", "Davide Villa", "J. Gordon Beattie", "Pedram Johari", "Stefano Basagni", "Tommaso Melodia"], "title": "AIRMap - AI-Generated Radio Maps for Wireless Digital Twins", "comment": "13 pages, 17 figures, This paper has been submitted to the IEEE Transactions for possible publication", "summary": "Accurate, low-latency channel modeling is essential for real-time wireless network simulation and digital-twin applications. Traditional modeling methods like ray tracing are however computationally demanding and unsuited to model dynamic conditions. In this paper, we propose AIRMap, a deep-learning framework for ultra-fast radio-map estimation, along with an automated pipeline for creating the largest radio-map dataset to date. AIRMap uses a single-input U-Net autoencoder that processes only a 2D elevation map of terrain and building heights. Trained and evaluated on 60,000 Boston-area samples, spanning coverage areas from 500 m to 3 km per side, AIRMap predicts path gain with under 5 dB RMSE in 4 ms per inference on an NVIDIA L40S -over 7000x faster than GPU-accelerated ray tracing based radio maps. A lightweight transfer learning calibration using just 20% of field measurements reduces the median error to approximately 10%, significantly outperforming traditional simulators, which exceed 50% error. Integration into the Colosseum emulator and the Sionna SYS platform demonstrate near-zero error in spectral efficiency and block-error rate compared to measurement-based channels. These findings validate AIRMap's potential for scalable, accurate, and real-time radio map estimation in wireless digital twins."}
{"id": "2511.05537", "categories": ["eess.SP", "cs.LG", "eess.IV", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2511.05537", "abs": "https://arxiv.org/abs/2511.05537", "authors": ["Soujanya Hazra", "Sanjay Ghosh"], "title": "Bridging Accuracy and Explainability in EEG-based Graph Attention Network for Depression Detection", "comment": "13 pages, 3 tables, and 7 fugures", "summary": "Depression is a major cause of global mental illness and significantly influences suicide rates. Timely and accurate diagnosis is essential for effective intervention. Electroencephalography (EEG) provides a non-invasive and accessible method for examining cerebral activity and identifying disease-associated patterns. We propose a novel graph-based deep learning framework, named Edge-gated, axis-mixed Pooling Attention Network (ExPANet), for differentiating major depressive disorder (MDD) patients from healthy controls (HC). EEG recordings undergo preprocessing to eliminate artifacts and are segmented into short periods of activity. We extract 14 features from each segment, which include time, frequency, fractal, and complexity domains. Electrodes are represented as nodes, whereas edges are determined by the phase-locking value (PLV) to represent functional connectivity. The generated brain graphs are examined utilizing an adapted graph attention network. This architecture acquires both localized electrode characteristics and comprehensive functional connectivity patterns. The proposed framework attains superior performance relative to current EEG-based approaches across two different datasets. A fundamental advantage of our methodology is its explainability. We evaluated the significance of features, channels, and edges, in addition to intrinsic attention weights. These studies highlight features, cerebral areas, and connectivity associations that are especially relevant to MDD, many of which correspond with clinical data. Our findings demonstrate a reliable and transparent method for EEG-based screening of MDD, using deep learning with clinically relevant results."}
{"id": "2511.06424", "categories": ["eess.IV", "cs.AI", "cs.CV", "eess.SP", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.06424", "abs": "https://arxiv.org/abs/2511.06424", "authors": ["Amit Vaisman", "Guy Ohayon", "Hila Manor", "Michael Elad", "Tomer Michaeli"], "title": "Turbo-DDCM: Fast and Flexible Zero-Shot Diffusion-Based Image Compression", "comment": "Code is available at https://amitvaisman.github.io/turbo_ddcm/", "summary": "While zero-shot diffusion-based compression methods have seen significant progress in recent years, they remain notoriously slow and computationally demanding. This paper presents an efficient zero-shot diffusion-based compression method that runs substantially faster than existing methods, while maintaining performance that is on par with the state-of-the-art techniques. Our method builds upon the recently proposed Denoising Diffusion Codebook Models (DDCMs) compression scheme. Specifically, DDCM compresses an image by sequentially choosing the diffusion noise vectors from reproducible random codebooks, guiding the denoiser's output to reconstruct the target image. We modify this framework with Turbo-DDCM, which efficiently combines a large number of noise vectors at each denoising step, thereby significantly reducing the number of required denoising operations. This modification is also coupled with an improved encoding protocol. Furthermore, we introduce two flexible variants of Turbo-DDCM, a priority-aware variant that prioritizes user-specified regions and a distortion-controlled variant that compresses an image based on a target PSNR rather than a target BPP. Comprehensive experiments position Turbo-DDCM as a compelling, practical, and flexible image compression scheme."}
{"id": "2511.05912", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.05912", "abs": "https://arxiv.org/abs/2511.05912", "authors": ["Sajjad Hussain", "Conor Brennan"], "title": "RadioSim Agent: Combining Large Language Models and Deterministic EM Simulators for Interactive Radio Map Analysis", "comment": "Submitted to EuCAP 2026", "summary": "Deterministic electromagnetic (EM) simulators provide accurate radio propagation modeling but often require expert configuration and lack interactive flexibility. We present RadioSim Agent, an agentic framework that integrates large language models (LLMs) with physics-based EM solvers and vision-enabled reasoning to enable interactive and explainable radio map generation. The framework encapsulates ray-tracing models as callable simulation tools, orchestrated by an LLM capable of interpreting natural language objectives, managing simulation workflows, and visually analyzing resulting radio maps. Demonstrations in urban UAV communication scenarios show that the agent autonomously selects appropriate propagation mechanisms, executes deterministic simulations, and provides semantic and visual summaries of pathloss behavior. The results indicate that RadioSim Agent provides multimodal interpretability and intuitive user interaction, paving the way for intelligent EM simulation assistants in next-generation wireless system design."}
{"id": "2511.06035", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.06035", "abs": "https://arxiv.org/abs/2511.06035", "authors": ["Vincenzo Mottola", "Alessandro Sardellitti", "Filippo Milano", "Luigi Ferrigno", "Marco Laracca", "Antonello Tamburrino"], "title": "Invariants in Eddy Current Testing via Dimensional Analysis", "comment": null, "summary": "The Buckingham's $π$, theorem has been recently introduced in the context of Non destructive Testing \\& Evaluation (NdT\\&E) , giving a theoretical basis for developing simple but effective methods for multi-parameter estimation via dimensional analysis. Dimensional groups, or $π-$groups, allow for the reduction of the number of parameters affecting the dimensionless measured quantities.\n  In many real-world applications, the main interest is in estimating only a subset of the variables affecting the measurements. An example is estimating the thickness and electrical conductivity of a plate from Eddy Current Testing data, regardless of the lift-off of the probe, which may be either uncertain and/or variable. Alternatively, one may seek to estimate thickness and lift-off while neglecting the influence of the electrical conductivity, or to estimate the electrical conductivity and the lift-off, neglecting the thickness.\n  This is where the concept of invariants becomes crucial. An invariant transformation is a mathematical mapping that makes the measured signal independent of one or more of these uncertain parameters. Invariant transformations provide a way to isolate useful signals from uncertain ones, improving the accuracy and reliability of the NdT results.\n  The main contribution of this paper is a systematic method to derive \\emph{invariant} transformations for frequency domain Eddy Current Testing data, via dimensional analysis. The proposed method is compatible with real-time and in-line operations.\n  After its theoretical foundation is introduced, the method is validated by means of experimental data, with reference to configurations consisting of plates with different thicknesses, electrical conductivity, and lift-off. The experimental validation proves the effectiveness of the method in achieving excellent accuracy on a wide range of parameters of interest."}
{"id": "2511.07057", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.07057", "abs": "https://arxiv.org/abs/2511.07057", "authors": ["Zidong Chen", "Fadratul Hafinaz Hassan"], "title": "TauFlow: Dynamic Causal Constraint for Complexity-Adaptive Lightweight Segmentation", "comment": "42 pages and 9 figures", "summary": "Deploying lightweight medical image segmentation models on edge devices presents two major challenges: 1) efficiently handling the stark contrast between lesion boundaries and background regions, and 2) the sharp drop in accuracy that occurs when pursuing extremely lightweight designs (e.g., <0.5M parameters). To address these problems, this paper proposes TauFlow, a novel lightweight segmentation model. The core of TauFlow is a dynamic feature response strategy inspired by brain-like mechanisms. This is achieved through two key innovations: the Convolutional Long-Time Constant Cell (ConvLTC), which dynamically regulates the feature update rate to \"slowly\" process low-frequency backgrounds and \"quickly\" respond to high-frequency boundaries; and the STDP Self-Organizing Module, which significantly mitigates feature conflicts between the encoder and decoder, reducing the conflict rate from approximately 35%-40% to 8%-10%."}
{"id": "2511.06036", "categories": ["eess.SP", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.06036", "abs": "https://arxiv.org/abs/2511.06036", "authors": ["Hassan Hizeh", "Rim Chighri", "Muhammad Mahboob Ur Rahman", "Mohamed A. Bahloul", "Ali Muqaibel", "Tareq Y. Al-Naffouri"], "title": "Towards Human-AI-Robot Collaboration and AI-Agent based Digital Twins for Parkinson's Disease Management: Review and Outlook", "comment": "20 pages, 5 figures, 4 tables, under review with a journal", "summary": "The current body of research on Parkinson's disease (PD) screening, monitoring, and management has evolved along two largely independent trajectories. The first research community focuses on multimodal sensing of PD-related biomarkers using noninvasive technologies such as inertial measurement units (IMUs), force/pressure insoles, electromyography (EMG), electroencephalography (EEG), speech and acoustic analysis, and RGB/RGB-D motion capture systems. These studies emphasize data acquisition, feature extraction, and machine learning-based classification for PD screening, diagnosis, and disease progression modeling. In parallel, a second research community has concentrated on robotic intervention and rehabilitation, employing socially assistive robots (SARs), robot-assisted rehabilitation (RAR) systems, and virtual reality (VR)-integrated robotic platforms for improving motor and cognitive function, enhancing social engagement, and supporting caregivers. Despite the complementary goals of these two domains, their methodological and technological integration remains limited, with minimal data-level or decision-level coupling between the two. With the advent of advanced artificial intelligence (AI), including large language models (LLMs), agentic AI systems, a unique opportunity now exists to unify these research streams. We envision a closed-loop sensor-AI-robot framework in which multimodal sensing continuously guides the interaction between the patient, caregiver, humanoid robot (and physician) through AI agents that are powered by a multitude of AI models such as robotic and wearables foundation models, LLM-based reasoning, reinforcement learning, and continual learning. Such closed-loop system enables personalized, explainable, and context-aware intervention, forming the basis for digital twin of the PD patient that can adapt over time to deliver intelligent, patient-centered PD care."}
{"id": "2511.07088", "categories": ["eess.IV", "physics.med-ph"], "pdf": "https://arxiv.org/pdf/2511.07088", "abs": "https://arxiv.org/abs/2511.07088", "authors": ["Yu-Tzu Kuo", "Anum S. Kazerouni", "Vivian Y. Park", "Wesley Surento", "Suleeporn Sujichantararat", "Daniel S. Hippe", "Habib Rahbar", "Savannah C. Partridge"], "title": "Validation of Fully-Automated Deep Learning-Based Fibroglandular Tissue Segmentation for Efficient and Reliable Quantitation of Background Parenchymal Enhancement in Breast MRI", "comment": null, "summary": "Background parenchymal enhancement (BPE) on breast dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI) shows potential as a breast cancer risk marker. Clinically, BPE is qualitatively assessed by radiologists, but quantitative BPE measures offer potential for more precise risk evaluation. This study evaluated an existing open-source, fully-automated deep learning-based (DL-based) method for segmenting fibroglandular tissue (FGT) to quantify BPE and compared it to a semi-automated fuzzy c-means method. Using breast MRI examinations from 100 women, we evaluated segmentation agreement, concordance across quantitative BPE metrics, and associations with qualitative BPE. The quality of FGT segmentations from both methods was scored by a radiologist. While the DL-based and semi-automated methods showed good agreement for quantitative BPE measurements, DL-based measures more strongly correlated with qualitative BPE assessments and DL-based segmentations were scored as higher quality by the radiologist. Our findings suggest that DL-based FGT segmentation enhances efficiency for objective BPE quantification and may improve standardized breast cancer risk assessment."}
{"id": "2511.06045", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2511.06045", "abs": "https://arxiv.org/abs/2511.06045", "authors": ["Yakov Gusakov", "Osvaldo Simeone", "Tirza Routtenberg", "Nir Shlezinger"], "title": "Online Learning of Modular Bayesian Deep Receivers: Single-Step Adaptation with Streaming Data", "comment": "Under review for publication in the IEEE", "summary": "Deep neural network (DNN)-based receivers offer a powerful alternative to classical model-based designs for wireless communication, especially in complex and nonlinear propagation environments. However, their adoption is challenged by the rapid variability of wireless channels, which makes pre-trained static DNN-based receivers ineffective, and by the latency and computational burden of online stochastic gradient descent (SGD)-based learning. In this work, we propose an online learning framework that enables rapid low-complexity adaptation of DNN-based receivers. Our approach is based on two main tenets. First, we cast online learning as Bayesian tracking in parameter space, enabling a single-step adaptation, which deviates from multi-epoch SGD . Second, we focus on modular DNN architectures that enable parallel, online, and localized variational Bayesian updates. Simulations with practical communication channels demonstrate that our proposed online learning framework can maintain a low error rate with markedly reduced update latency and increased robustness to channel dynamics as compared to traditional gradient descent based method."}
{"id": "2511.07094", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.07094", "abs": "https://arxiv.org/abs/2511.07094", "authors": ["Necati Sefercioglu", "Mehmet Ozan Unal", "Metin Ertas", "Isa Yildirim"], "title": "Task-Adaptive Low-Dose CT Reconstruction", "comment": null, "summary": "Deep learning-based low-dose computed tomography reconstruction methods already achieve high performance on standard image quality metrics like peak signal-to-noise ratio and structural similarity index measure. Yet, they frequently fail to preserve the critical anatomical details needed for diagnostic tasks. This fundamental limitation hinders their clinical applicability despite their high metric scores. We propose a novel task-adaptive reconstruction framework that addresses this gap by incorporating a frozen pre-trained task network as a regularization term in the reconstruction loss function. Unlike existing joint-training approaches that simultaneously optimize both reconstruction and task networks, and risk diverging from satisfactory reconstructions, our method leverages a pre-trained task model to guide reconstruction training while still maintaining diagnostic quality. We validate our framework on a liver and liver tumor segmentation task. Our task-adaptive models achieve Dice scores up to 0.707, approaching the performance of full-dose scans (0.874), and substantially outperforming joint-training approaches (0.331) and traditional reconstruction methods (0.626). Critically, our framework can be integrated into any existing deep learning-based reconstruction model through simple loss function modification, enabling widespread adoption for task-adaptive optimization in clinical practice. Our codes are available at: https://github.com/itu-biai/task_adaptive_ct"}
{"id": "2511.06060", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.06060", "abs": "https://arxiv.org/abs/2511.06060", "authors": ["Jie Ma", "Pinjun Zheng", "Xing Liu", "Yuchen Zhang", "Ali A. Nasir", "Tareq Y. Al-Naffouri"], "title": "Positioning Using LEO Satellite Communication Signals Under Orbital Errors", "comment": null, "summary": "Low Earth orbit (LEO) satellites offer a promising alternative to global navigation satellite systems for precise positioning; however, their relatively low altitudes make them more susceptible to orbital perturbations, which in turn degrade positioning accuracy. In this work, we study LEO-based positioning under orbital errors within a signal-of-opportunity framework. First, we introduce a LEO orbit model that accounts for Earth's non-sphericity and derive a wideband communication model that captures fast- and slow-time Doppler effects and multipath propagation. Subsequently, we perform a misspecified Cramér-Rao bound (MCRB) analysis to evaluate the impact of orbital errors on positioning performance. Then, we propose a two-stage positioning method starting with a (i) MCRB-based weighted orbit calibration, followed by (ii) least-squares user positioning using the corrected orbit. The MCRB analysis indicates that orbital errors can induce kilometer-level position biases. Extensive simulations show that the proposed estimator can considerably enhance the positioning accuracy relative to the orbit-mismatched baseline, yielding errors on the order of a few meters."}
{"id": "2511.07290", "categories": ["eess.IV", "cs.CV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2511.07290", "abs": "https://arxiv.org/abs/2511.07290", "authors": ["Xinyi Wang", "Angeliki Katsenou", "Junxiao Shen", "David Bull"], "title": "CAMP-VQA: Caption-Embedded Multimodal Perception for No-Reference Quality Assessment of Compressed Video", "comment": "14 pages, 6 figures", "summary": "The prevalence of user-generated content (UGC) on platforms such as YouTube and TikTok has rendered no-reference (NR) perceptual video quality assessment (VQA) vital for optimizing video delivery. Nonetheless, the characteristics of non-professional acquisition and the subsequent transcoding of UGC video on sharing platforms present significant challenges for NR-VQA. Although NR-VQA models attempt to infer mean opinion scores (MOS), their modeling of subjective scores for compressed content remains limited due to the absence of fine-grained perceptual annotations of artifact types. To address these challenges, we propose CAMP-VQA, a novel NR-VQA framework that exploits the semantic understanding capabilities of large vision-language models. Our approach introduces a quality-aware prompting mechanism that integrates video metadata (e.g., resolution, frame rate, bitrate) with key fragments extracted from inter-frame variations to guide the BLIP-2 pretraining approach in generating fine-grained quality captions. A unified architecture has been designed to model perceptual quality across three dimensions: semantic alignment, temporal characteristics, and spatial characteristics. These multimodal features are extracted and fused, then regressed to video quality scores. Extensive experiments on a wide variety of UGC datasets demonstrate that our model consistently outperforms existing NR-VQA methods, achieving improved accuracy without the need for costly manual fine-grained annotations. Our method achieves the best performance in terms of average rank and linear correlation (SRCC: 0.928, PLCC: 0.938) compared to state-of-the-art methods. The source code and trained models, along with a user-friendly demo, are available at: https://github.com/xinyiW915/CAMP-VQA."}
{"id": "2511.06173", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.06173", "abs": "https://arxiv.org/abs/2511.06173", "authors": ["Liyang Lu", "Haochen Wu", "Wenbo Xu", "Zhaocheng Wang", "H. Vincent Poor"], "title": "Hierarchically Block-Sparse Recovery With Prior Support Information", "comment": "This manuscript has been accepted by IEEE Transactions on Information Theory (IEEE TIT) in Nov. 2025", "summary": "We provide new recovery bounds for hierarchical compressed sensing (HCS) based on prior support information (PSI). A detailed PSI-enabled reconstruction model is formulated using various forms of PSI. The hierarchical block orthogonal matching pursuit with PSI (HiBOMP-P) algorithm is designed in a recursive form to reliably recover hierarchically block-sparse signals. We derive exact recovery conditions (ERCs) measured by the mutual incoherence property (MIP), wherein hierarchical MIP concepts are proposed, and further develop reconstructible sparsity levels to reveal sufficient conditions for ERCs. Leveraging these MIP analyses, we present several extended insights, including reliable recovery conditions in noisy scenarios and the optimal hierarchical structure for cases where sparsity is not equal to zero. Our results further confirm that HCS offers improved recovery performance even when the prior information does not overlap with the true support set, whereas existing methods heavily rely on this overlap, thereby compromising performance if it is absent."}
{"id": "2511.05537", "categories": ["eess.SP", "cs.LG", "eess.IV", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2511.05537", "abs": "https://arxiv.org/abs/2511.05537", "authors": ["Soujanya Hazra", "Sanjay Ghosh"], "title": "Bridging Accuracy and Explainability in EEG-based Graph Attention Network for Depression Detection", "comment": "13 pages, 3 tables, and 7 fugures", "summary": "Depression is a major cause of global mental illness and significantly influences suicide rates. Timely and accurate diagnosis is essential for effective intervention. Electroencephalography (EEG) provides a non-invasive and accessible method for examining cerebral activity and identifying disease-associated patterns. We propose a novel graph-based deep learning framework, named Edge-gated, axis-mixed Pooling Attention Network (ExPANet), for differentiating major depressive disorder (MDD) patients from healthy controls (HC). EEG recordings undergo preprocessing to eliminate artifacts and are segmented into short periods of activity. We extract 14 features from each segment, which include time, frequency, fractal, and complexity domains. Electrodes are represented as nodes, whereas edges are determined by the phase-locking value (PLV) to represent functional connectivity. The generated brain graphs are examined utilizing an adapted graph attention network. This architecture acquires both localized electrode characteristics and comprehensive functional connectivity patterns. The proposed framework attains superior performance relative to current EEG-based approaches across two different datasets. A fundamental advantage of our methodology is its explainability. We evaluated the significance of features, channels, and edges, in addition to intrinsic attention weights. These studies highlight features, cerebral areas, and connectivity associations that are especially relevant to MDD, many of which correspond with clinical data. Our findings demonstrate a reliable and transparent method for EEG-based screening of MDD, using deep learning with clinically relevant results."}
{"id": "2511.06188", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.06188", "abs": "https://arxiv.org/abs/2511.06188", "authors": ["Zhihao Tao", "Athina P. Petropulu"], "title": "Meta-Learning-Driven GFlowNets for 3D Directional Modulation in Mobile Wireless Systems", "comment": "Submitted to IEEE ICC 2026", "summary": "In our prior work we have proposed the use of GFlowNets, a generative AI (GenAI) framework, for designing a secure communication system comprising a time-modulated intelligent reflecting surface (TM-IRS). However, GFlowNet-based approaches assume static environments, limiting their applicability in mobile wireless networks. In this paper, we proposes a novel Meta-GFlowNet framework that achieves rapid adaptation to dynamic conditions using model-agnostic meta-learning. As the communication user is moving, the framework learns a direction-general prior across user directions via inner trajectory-balance updates and outer meta-updates, enabling quick convergence to new user directions. The approach requires no labeled data, employing a pseudo-supervised consistency objective derived from the learned reward by GFlowNet and the actual sum-rate reward of the TM-IRS system. Simulation results show that the proposed method attains faster adaptation and higher secrecy performance than retrained GFlowNets, offering an efficient GenAI framework for dynamic wireless environments. Although the scenario considered here focuses on directional modulation-based physical-layer security, the proposed framework can also be applied to other mobile wireless systems, such as joint sensing-communication networks, that utilize GFlowNets."}
{"id": "2511.06257", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.06257", "abs": "https://arxiv.org/abs/2511.06257", "authors": ["Yimeng Lin", "Nan Wang", "Daniel Abraham", "Daniel Polak", "Xiaozhi Cao", "Stephen Cauley", "Kawin Setsompop"], "title": "Fast Reconstruction of Motion-Corrupted Data with Mobile-GRAPPA: Motion and dB0 Inhomogeneity Correction Leveraging Efficient GRAPPA", "comment": "8 pages, 5 figures", "summary": "Advanced motion navigations now enable rapid tracking of subject motion and dB0-induced phase, but accurately incorporating this high-temporal-resolution information into SENSE (Aligned-SENSE) is often computationally prohibitive. We propose \"Mobile-GRAPPA\", a k-space \"cleaning\" approach that uses local GRAPPA operators to remove motion and dB0 related corruption so that the resulting data can be reconstructed with standard SENSE. We efficiently train a family of k-space-position-specific Mobile-GRAPPA kernels via a lightweight multilayer perceptron (MLP) and apply them across k-space to generate clean data. In experiments on highly motion-corrupted 1-mm whole-brain GRE (Tacq = 10 min; 1,620 motion/dB0 trackings) and EPTI (Tacq = 2 min; 544 trackings), Mobile-GRAPPA enabled accurate reconstruction with negligible time penalty, whereas full Aligned-SENSE was impractical (reconstruction times > 10 h for GRE and > 10 days for EPTI). These results show that Mobile-GRAPPA incorporates detailed motion and dB0 tracking into SENSE with minimal computational overhead, enabling fast, high-quality reconstructions of challenging data."}
{"id": "2511.06270", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.06270", "abs": "https://arxiv.org/abs/2511.06270", "authors": ["Abdulahi Abiodun Badrudeen", "Nakyung Lee", "Adam Dubs", "Sunwoo Kim"], "title": "Blocker-Aware Beamforming and Dynamic Power Allocation for Multicarrier ISAC-NOMA Systems", "comment": "6 pages, 5 figures, conference", "summary": "This paper proposes a blocker-aware multicarrier integrated sensing and communication (ISAC)-non orthogonal multiple access (NOMA) system, leveraging hybrid beamforming and dynamic power allocation to enhance spectrum efficiency in 6G networks. Recognizing the performance degradation caused by environmental blockers, the system introduces a joint waveform design that ensures robust operation under varying channel conditions. A channel switching mechanism is deployed to reroute communication through alternative non-line-of-sight paths when the primary line-of-sight links are obstructed. Moreover, a dynamic power allocation strategy enforces a minimum rate constraint for the weak NOMA user, ensuring consistent quality of service. Extensive simulations over multiple blockage scenarios and signal to noise (SNR) conditions validate the effectiveness of the proposed solution. Notably, under severe blockage, the system achieves up to a 400% sensing rate enhancement at 15 dB SNR, with only a 20% reduction in communication rate. These results corroborate the system's ability to adapt and optimize joint sensing-communication performance in practical deployment environments."}
{"id": "2511.06339", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.06339", "abs": "https://arxiv.org/abs/2511.06339", "authors": ["Shasha Liu", "Hayssam Dahrouj", "Abla Kammoun", "Mohamed-Slim Alouini"], "title": "Sum Rate and Worst Case SINR Optimization in Multi HAPS Ground Integrated Networks", "comment": null, "summary": "Balancing throughput and fairness promises to be a key enabler for achieving large-scale digital inclusion in future vertical heterogeneous networks (VHetNets). In an attempt to address the global digital divide problem, this paper explores a multi-high-altitude platform system (HAPS)-ground integrated network, in which multiple HAPSs collaborate with ground base stations (BSs) to enhance the users' quality of service on the ground to achieve the highly sought-after digital equity. To this end, this paper considers maximizing both the network-wide weighted sum rate function and the worst-case signal-to-interference-plus-noise ratio (SINR) function subject to the same system level constraints. More specifically, the paper tackles the two different optimization problems so as to balance throughput and fairness, by accounting for the individual HAPS payload connectivity constraints, HAPS and BS distinct power limitations, and per-user rate requirements. This paper solves the considered problems using techniques from optimization theory by adopting a generalized assignment problem (GAP)-based methodology to determine the user association variables, jointly with successive convex approximation (SCA)-based iterative algorithms for optimizing the corresponding beamforming vectors. One of the main advantages of the proposed algorithms is their amenability for distributed implementation across the multiple HAPSs and BSs. The simulation results particularly validate the performance of the presented algorithms, demonstrating the capability of multi-HAPS networks to boost-up the overall network digital inclusion toward democratizing future digital services."}
{"id": "2511.06359", "categories": ["eess.SP", "cs.GT"], "pdf": "https://arxiv.org/pdf/2511.06359", "abs": "https://arxiv.org/abs/2511.06359", "authors": ["Jiacheng Wang", "Changyuan Zhao", "Dusit Niyato", "Geng Sun", "Weijie Yuan", "Abbas Jamalipour", "Tao Xiang"], "title": "Stackelberg Game-Driven Defense for ISAC Against Channel Attacks in Low-Altitude Networks", "comment": "6 pages, 4 figures", "summary": "The increasing saturation of terrestrial resources has driven economic activities into low-altitude airspace. These activities, such as air taxis, rely on low-altitude wireless networks, and one key enabling technology is integrated sensing and communication (ISAC). However, in low-altitude airspace, ISAC is vulnerable to channel-access attacks, thereby degrading performance and threatening safety. To address this, we propose a defense framework based on a Stackelberg game. Specifically, we first model the system under attack, deriving metrics for the communication and the sensing to quantify performance. Then, we formulate the interaction as a three-player game where a malicious attacker acts as the leader, while the legitimate drone and ground base station act as followers. Using a backward induction algorithm, we obtain the Stackelberg equilibrium, allowing the defenders to dynamically adjust their strategies to mitigate the attack. Simulation results verify that the proposed algorithm converges to a stable solution and outperforms existing baselines, ensuring reliable ISAC performance for critical low-altitude applications."}
{"id": "2511.06369", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.06369", "abs": "https://arxiv.org/abs/2511.06369", "authors": ["Wonseok Choi", "Jeongjae Lee", "Songnam Hong"], "title": "CSIT-Free Multi-Group Multicast Transmission in Overloaded mmWave Systems", "comment": "Submitted to IEEE ICC 2026", "summary": "In this paper, we investigate the downlink multi-group multicast (MGM) transmission problem in overloaded mmWave systems. In particular, the conventional MGM beamforming requires substantial computational complexity and feedback (or pilot) overhead for acquisition of channel state information at the transmitter (CSIT), while simultaneous interference management and multicast beamforming optimization across multi-group inevitably incurs a significant rate loss. To address this, we propose a CSIT-free MGM (CF-MGM) transmission that eliminates the need for a complex CSIT acquisition. A deterministic CSIT-free precoding and proposed closed-form power allocation based on max-min fairness (MMF) allow each user to detect the common multicast stream completely canceling the inter-group interference with a significantly low complexity. Simulation results demonstrate the superiority and scalability of the proposed CF-MGM for the achievable rate and increase of users in a group outperforming the existing CSIT-based methods."}
{"id": "2511.06383", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.06383", "abs": "https://arxiv.org/abs/2511.06383", "authors": ["Khalid A. Alshumayri", "Mudassir Masood", "Ali. A. Nasir"], "title": "Near-Field Velocity Estimation and Predictive Beamforming with Modular Linear Array", "comment": "7 pages, 6 figures", "summary": "Velocity estimation is a cornerstone of recently introduced near-field predictive beamforming. This paper derives the closed-form Cramer-Rao bounds (CRBs) for joint velocity estimation using a modular linear array (MLA) within a predictive-beamforming framework. The analysis shows that increasing inter-module separation enlarges the effective aperture and reduces the transverse-velocity CRB, whereas the radial-velocity CRB is largely insensitive to separation. We further obtain a simple closed-form relation linking the achievable antenna savings to the inter-module separation while preserving the same transverse accuracy of a uniform linear array (ULA). We further investigate how velocity mismatch affects array gain and show that transverse-velocity errors cause more severe performance degradation than radial-velocity errors. Simulations show that predictive beamforming with MLAs maintains high localization accuracy for target tracking."}
{"id": "2511.06395", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.06395", "abs": "https://arxiv.org/abs/2511.06395", "authors": ["Hung D. Nguyen", "Jeongseok Ha"], "title": "UAV-Assisted Downlink Satellite Covert Communication", "comment": null, "summary": "This paper investigates the use of an unmanned aerial vehicle (UAV) to assist covert communication between a low-Earth orbit (LEO) satellite and a ground user under the surveillance of a passive warden. The UAV simultaneously serves its own ground network and acts as a friendly jammer to enhance the covertness of satellite transmissions. We derive a closed-form lower bound on the warden's average minimum detection error probability which is then used to define the covert constraint. Building on this, we formulate an optimization problem to jointly design the UAV's 3D placement, its power allocation, and the satellite's transmit power to maximize the system's covert rate. To solve the resulting non-convex problem, we propose an algorithm based on the block coordinate descent (BCD) and successive convex approximation (SCA) techniques, and further develop a Dinkelbach's algorithm for a special case. Numerical results validate the tightness of the derived bound and demonstrate the effectiveness of the proposed algorithms in configuring optimal system parameters."}
{"id": "2511.06440", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.06440", "abs": "https://arxiv.org/abs/2511.06440", "authors": ["Yingjie Xu", "Xuesong Cai", "Ali Al-Ameri", "Sara Willhammar", "Fredrik Tufvesson"], "title": "Distributed MIMO Positioning: Fundamental Limit Analysis and User Tracking Framework Design", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "This paper presents a comprehensive study on the 3D positioning capabilities of users in distributed multiple-input multiple-output (MIMO) systems. Unlike previous studies that mainly rely on idealized isotropic antenna models, we adopt a polarimetric model that takes advantage of effective aperture distribution functions to characterize realistic antenna patterns, placements, and polarization effects. Based on this model, we analyze the fundamental limits of UE positioning using the Fisher information matrix (FIM) and the position error bound (PEB). The FIM is shown to be expressed as a weighted sum of the information contributions from individual access point (AP)-UE pairs, with each contribution interpreted geometrically across distance, azimuth, and elevation dimensions. The impact of the UE tilt and the spatial distribution of APs on the PEBs is further analyzed. As a further advancement, we propose a complete positioning framework from a UE tracking perspective. By integrating a global probability hypothesis density filter and a PEB-aware AP management strategy, the framework enables accurate tracking while optimizing AP scheduling. Finally, we present a distributed MIMO channel measurement campaign to validate the proposed framework. The results demonstrate a centimeter-level tracking accuracy. In addition, the PEB-aware AP management strategy is shown to maintain robust tracking performance while significantly reducing the number of concurrently active APs, thus lowering the overall system overhead."}
{"id": "2511.06621", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.06621", "abs": "https://arxiv.org/abs/2511.06621", "authors": ["Antonina Kosikova", "Apostolos Psaros", "Andrew Smyth"], "title": "Spectrum and Physics-Informed Neural Networks (SaPINNs) for Input-State-Parameter Estimation in Dynamic Systems Subjected to Natural Hazards-Induced Excitation", "comment": "Preprint submitted to Mechanical Systems and Signal Processing", "summary": "System identification under unknown external excitation is an inherently ill-posed problem, typically requiring additional knowledge or simplifying assumptions to enable reliable state and parameter estimation. The difficulty of the problem is further amplified in structural systems subjected to natural hazards such as earthquakes or windstorms, where responses are often highly transient, nonlinear, and spatially distributed. To address this challenge, we introduce Spectrum and Physics-Informed Neural Networks (SaPINNs) for efficient input--state--parameter estimation in systems under complex excitations characteristic of natural hazards. The proposed model enhances the neural network with governing physics of the system dynamics and incorporates spectral information of natural hazards by using empirically derived spectra as priors on the unknown excitations. This integration improves inference of unmeasured inputs, system states, and parameters without imposing restrictive assumptions on their dynamics. The performance of the proposed framework is demonstrated through comparative studies on both linear and nonlinear systems under various types of excitation, including the El Centro earthquake, where the seismic spectrum is assumed to be not precisely known. To account for predictive uncertainty, the proposed architecture is embedded within a Deep Ensemble (DEns) networks architecture, providing distributions over possible solutions. The results demonstrate that the proposed approach outperforms conventional PINNs, as the incorporation of spectral information introduces an inductive bias that guides the network more effectively through the solution space and enhances its ability to recover physically consistent state and parameter estimates with realistic uncertainty levels."}
{"id": "2511.06710", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.06710", "abs": "https://arxiv.org/abs/2511.06710", "authors": ["Hao Sun", "Xianghao Yu", "Junting Chen"], "title": "Structure-Aware Near-Field Radio Map Recovery via RBF-Assisted Matrix Completion", "comment": null, "summary": "This paper proposes a novel structure-aware matrix completion framework assisted by radial basis function (RBF) interpolation for near-field radio map construction in extremely large multiple-input multiple-output (XL-MIMO) systems. Unlike the far-field scenario, near-field wavefronts exhibit strong dependencies on both angle and distance due to spherical wave propagation, leading to complicated variations in received signal strength (RSS). To effectively capture the intricate spatial variations structure inherent in near-field environments, a regularized RBF interpolation method is developed to enhance radio map reconstruction accuracy. Leveraging theoretical insights from interpolation error analysis of RBF, an inverse μ-law-inspired nonuniform sampling strategy is introduced to allocate measurements adaptively, emphasizing regions with rapid RSS variations near the transmitter. To further exploit the global low-rank structure in the near-field radio map, we integrate RBF interpolation with nuclear norm minimization (NNM)-based matrix completion. A robust Huberized leave-one-out cross-validation (LOOCV) scheme is then proposed for adaptive selection of the tolerance parameter, facilitating optimal fusion between RBF interpolation and matrix completion. The integration of local variation structure modeling via RBF interpolation and global low-rank structure exploitation via matrix completion yields a structure-aware framework that substantially improves the accuracy of near-field radio map reconstruction. Extensive simulations demonstrate that the proposed approach achieves over 10% improvement in normalized mean squared error (NMSE) compared to standard interpolation and matrix completion methods under varying sampling densities and shadowing conditions."}
{"id": "2511.06806", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.06806", "abs": "https://arxiv.org/abs/2511.06806", "authors": ["Zhiyuan Zhai", "Wei Ni", "Xin Wang"], "title": "Learning Performance Optimization for Edge AI System with Time and Energy Constraints", "comment": null, "summary": "Edge AI, which brings artificial intelligence to the edge of the network for real-time processing and decision-making, has emerged as a transformative technology across various applications. However, the deployment of Edge AI systems faces significant challenges due to high energy consumption and extended operation time.\n  In this paper, we consider an Edge AI system which integrates the data acquisition, computation and communication processes, and focus on improving learning performance of this system. We model the time and energy consumption of different processes and perform a rigorous convergence analysis to quantify the impact of key system parameters, such as the amount of collected data and the number of training rounds, on the learning performance. Based on this analysis, we formulate a system-wide optimization problem that seeks to maximize learning performance under given time and energy constraints. We explore both homogeneous and heterogeneous device scenarios, developing low-complexity algorithms based on one-dimensional search and alternating optimization to jointly optimize data collection time and training rounds. Simulation results validate the accuracy of our convergence analysis and demonstrate the effectiveness of the proposed algorithms, providing valuable insights into designing energy-efficient Edge AI systems under real-world conditions."}
{"id": "2511.06866", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.06866", "abs": "https://arxiv.org/abs/2511.06866", "authors": ["Ahmet Kaplan", "Diana P. M. Osorio", "Erik G. Larsson"], "title": "Joint Access Point Selection and Beamforming Design for Bistatic Backscatter Communication", "comment": null, "summary": "Future Internet-of-Things networks are envisioned to use small and cheap sensor nodes with extremely low power consumption to avoid the extensive use of batteries. To provide connectivity to a massive number of these nodes, backscatter communication (BC) is emerging as an energy- and cost-efficient technology exploiting the reflection of radio frequency signals. However, challenges such as round-trip path loss and direct link interference (DLI) between the carrier emitter and the reader limit its performance. To tackle these limitations, this paper proposes a joint access point role selection and a novel beamforming technique for bistatic BC in a distributed multiple-input multiple- output setup. The proposed approach boosts the received backscattered energy while effectively mitigating DLI, thereby reducing the error probability. We also propose a channel estimation method tailored to operate under DLI conditions and propose a mismatch detector using estimated channel coefficients. Furthermore, we derive a closed-form expression for the probability of error for the detectors and model the quantization noise caused by DLI. Finally, comprehensive simulation results show that the proposed method with 1-bit analog-to-digital converters (ADCs) effectively mitigates DLI, reduces the quantization noise, and enhances backscattered signal energy, achieving performance comparable to the benchmark scenario with 8-bit ADCs."}
{"id": "2511.06874", "categories": ["eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.06874", "abs": "https://arxiv.org/abs/2511.06874", "authors": ["Giuseppe Baruffa", "Luca Rugini", "Francesco Binucci", "Fabrizio Frescura", "Paolo Banelli", "Renzo Perfetti"], "title": "Radio-Coverage-Aware Path Planning for Cooperative Autonomous Vehicles", "comment": "11 pages, 19 figures", "summary": "Fleets of autonomous vehicles (AV) often are at the core of intelligent transportation scenarios for smart cities, and may require a wireless Internet connection to offload computer vision tasks to data centers located either in the edge or the cloud section of the network. Cooperation among AVs is successful when the environment is unknown, or changes dynamically, so as to improve coverage and trip time, and minimize the traveled distance. The AVs, while mapping the environment with range-based sensors, move across the wireless coverage areas, with consequences on the achieved access bit rate, latency, and handover rate. In this paper, we propose to modify the cost of path planning algorithms such as Dijkstra and A*, so that not only the traveled distance is considered in the best path solution, but also the radio coverage experience. To this aim, several radio-related cost-weighting functions are introduced and tested, to assess the performance of the proposed techniques with extensive simulations. The proposed mapping algorithm can achieve a mapping error probability below 2%, while the proposed path-planning algorithms extend the experienced radio coverage of the AVs, with limited distance increase with respect to shortest-path existing methods, such as conventional Dijkstra and A* algorithms."}
{"id": "2511.06922", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.06922", "abs": "https://arxiv.org/abs/2511.06922", "authors": ["Konstantinos Alexoudis", "Jasper Müller", "Sai Kireet Patri", "Vincent A. J. M. Sleiffer", "Vishal Chandraprakash Rai", "André Sandmann", "Sander Jansen", "Thomas Bradley", "Chigo Okonkwo"], "title": "Real-Time Diverse Fiber Sensing Multi-Event Detection using Phase OTDR Measurements", "comment": "This work has been partially funded by the German Federal Ministry of Education and Research in the project HYPERCORE (#16KIS2098). We also acknowledge the Bilateral Project \"DistraSignalSense\" between the Eindhoven University of Technology, The Netherlands, and Adtran Networks SE", "summary": "We demonstrate an experimental phase optical time-domain reflectometry (OTDR) system capable of simultaneous detection and classification of various environmental events, such as wind-induced fiber movement, vehicle movement, and audio signatures, with real-time visualization."}
{"id": "2511.06971", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.06971", "abs": "https://arxiv.org/abs/2511.06971", "authors": ["Qiushi Liang", "Yeyue Cai", "Jianhua Mo", "Meixia Tao"], "title": "MARBLE-Net: Learning to Localize in Multipath Environment with Adaptive Rainbow Beams", "comment": null, "summary": "Integrated sensing and communication (ISAC) systems demand precise and efficient target localization, a task challenged by rich multipath propagation in complex wireless environments. This paper introduces MARBLE-Net (Multipath-Aware Rainbow Beam Learning Network), a deep learning framework that jointly optimizes the analog beamforming parameters of a frequency-dependent rainbow beam and a neural localization network for high-accuracy position estimation. By treating the phase-shifter (PS) and true-time-delay (TTD) parameters as learnable weights, the system adaptively refines its sensing beam to exploit environment-specific multipath characteristics. A structured multi-stage training strategy is proposed to ensure stable convergence and effective end-to-end optimization. Simulation results show that MARBLE-Net outperforms both a fixed-beam deep learning baseline (RaiNet) and a traditional k-nearest neighbors (k-NN) method, reducing localization error by more than 50\\% in a multipath-rich scene. Moreover, the results reveal a nuanced interaction with multipath propagation: while confined uni-directional multipath degrades accuracy, structured and directional multipath can be effectively exploited to achieve performance surpassing even line-of-sight (LoS) conditions."}
{"id": "2511.07026", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.07026", "abs": "https://arxiv.org/abs/2511.07026", "authors": ["Mikhail Krasnov", "Ljupcho Milosheski", "Mihael Mohorčič", "Carolina Fortuna"], "title": "Design Principles of Zero-Shot Self-Supervised Unknown Emitter Detectors", "comment": null, "summary": "The proliferation of wireless devices necessitates more robust and reliable emitter detection and identification for critical tasks such as spectrum management and network security. Existing studies exploring methods for unknown emitters identification, however, are typically hindered by their dependence on labeled or proprietary datasets, unrealistic assumptions (e.g. all samples with identical transmitted messages), or deficiency of systematic evaluations across different architectures and design dimensions. In this work, we present a comprehensive evaluation of unknown emitter detection systems across key aspects of the design space, focusing on data modality, learning approaches, and feature learn- ing modules. We demonstrate that prior self-supervised, zero-shot emitter detection approaches commonly use datasets with identical transmitted messages. To address this limitation, we propose a 2D- Constellation data modality for scenarios with varying messages, achieving up to a 40\\% performance improvement in ROC-AUC, NMI, and F1 metrics compared to conventional raw I/Q data. Furthermore, we introduce interpretable Kolmogorov--Arnold Net- works (KANs) to enhance model transparency, and a Singular Value Decomposition (SVD)-based initialization procedure for feature learning modules operating on sparse 2D-Constellation data, which improves the performance of Deep Clustering approaches by up to 40\\% across the same metrics comparing to the modules without SVD initialization. We evaluate all data modalities and learning modules across three learning approaches: Deep Clustering, Auto Encoder and Contrastive Learning."}
{"id": "2511.07178", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.07178", "abs": "https://arxiv.org/abs/2511.07178", "authors": ["Zhiyuan Zhai", "Yuan Gao", "Wei Ni", "Xiaojun Yuan", "Xin Wang"], "title": "Trajectory Design for UAV-Assisted Logistics Collection in Low-Altitude Economy", "comment": null, "summary": "Low-altitude economy (LAE) is rapidly emerging as a key driver of innovation, encompassing economic activities taking place in airspace below 500 meters. Unmanned aerial vehicles (UAVs) provide valuable tools for logistics collection within LAE systems, offering the ability to navigate through complex environments, avoid obstacles, and improve operational efficiency. However, logistics collection tasks involve UAVs flying through complex three-dimensional (3D) environments while avoiding obstacles, where traditional UAV trajectory design methods,typically developed under free-space conditions without explicitly accounting for obstacles, are not applicable. This paper presents, we propose a novel algorithm that combines the Lin-Kernighan-Helsgaun (LKH) and Deep Deterministic Policy Gradient (DDPG) methods to minimize the total collection time. Specifically, the LKH algorithm determines the optimal order of item collection, while the DDPG algorithm designs the flight trajectory between collection points. Simulations demonstrate that the proposed LKH-DDPG algorithm significantly reduces collection time by approximately 49 percent compared to baseline approaches, thereby highlighting its effectiveness in optimizing UAV trajectories and enhancing operational efficiency for logistics collection tasks in the LAE paradigm."}
{"id": "2511.07310", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.07310", "abs": "https://arxiv.org/abs/2511.07310", "authors": ["Mahmoud Zaher", "Emil Björnson"], "title": "Low-Complexity ADMM-Based Multicast Beamforming in Cell-Free Massive MIMO Systems", "comment": "13 pages, submitted to IEEE Transactions on Wireless Communications", "summary": "The growing demand for efficient delivery of common content to multiple user equipments (UEs) has motivated significant research in physical-layer multicasting. By exploiting the beamforming capabilities of massive MIMO, multicasting provides a spectrum-efficient solution that avoids unnecessary intra-group interference. A key challenge, however, is solving the max-min fair (MMF) and quality-of-service (QoS) multicast beamforming optimization problems, which are NP-hard due to the non-convex structure and the requirement for rank-1 solutions. Traditional approaches based on semidefinite relaxation (SDR) followed by randomization exhibit poor scalability with system size, while state-of-the-art successive convex approximation (SCA) methods only guarantee convergence to stationary points. In this paper, we propose an alternating direction method of multipliers (ADMM)-based framework for MMF and QoS multicast beamforming in cell-free massive MIMO networks. The algorithm leverages SDR but incorporates a novel iterative elimination strategy within the ADMM updates to efficiently obtain near-global optimal rank-1 beamforming solutions with reduced computational complexity compared to standard SDP solvers and randomization methods. Numerical evaluations demonstrate that the proposed ADMM-based procedure not only achieves superior spectral efficiency but also scales favorably with the number of antennas and UEs compared to state-of-the-art SCA-based algorithms, making it a practical tool for next-generation multicast systems."}
{"id": "2511.07376", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.07376", "abs": "https://arxiv.org/abs/2511.07376", "authors": ["Jiewei Feng", "Ken R. Duffy", "Muriel Médard"], "title": "Enhanced GCD through ORBGRAND-AI: Exploiting Partial and Total Correlation in Noise", "comment": null, "summary": "There have been significant advances in recent years in the development of forward error correction decoders that can decode codes of any structure, including practical realizations in synthesized circuits and taped out chips. While essentially all soft-decision decoders assume that bits have been impacted independently on the channel, for one of these new approaches it has been established that channel dependencies can be exploited to achieve superior decoding accuracy, resulting in Ordered Reliability Bits Guessing Random Additive Noise Decoding Approximate Independence (ORBGRAND-AI). Building on that capability, here we consider the integration of ORBGRAND-AI as a pattern generator for Guessing Codeword Decoding (GCD). We first establish that a direct approach delivers mildly degraded block error rate (BLER) but with reduced number of queried patterns when compared to ORBGRAND-AI. We then show that with a more nuanced approach it is possible to leverage total correlation to deliver an additional BLER improvement of around 0.75 dB while retaining reduced query numbers."}
{"id": "2511.06424", "categories": ["eess.IV", "cs.AI", "cs.CV", "eess.SP", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.06424", "abs": "https://arxiv.org/abs/2511.06424", "authors": ["Amit Vaisman", "Guy Ohayon", "Hila Manor", "Michael Elad", "Tomer Michaeli"], "title": "Turbo-DDCM: Fast and Flexible Zero-Shot Diffusion-Based Image Compression", "comment": "Code is available at https://amitvaisman.github.io/turbo_ddcm/", "summary": "While zero-shot diffusion-based compression methods have seen significant progress in recent years, they remain notoriously slow and computationally demanding. This paper presents an efficient zero-shot diffusion-based compression method that runs substantially faster than existing methods, while maintaining performance that is on par with the state-of-the-art techniques. Our method builds upon the recently proposed Denoising Diffusion Codebook Models (DDCMs) compression scheme. Specifically, DDCM compresses an image by sequentially choosing the diffusion noise vectors from reproducible random codebooks, guiding the denoiser's output to reconstruct the target image. We modify this framework with Turbo-DDCM, which efficiently combines a large number of noise vectors at each denoising step, thereby significantly reducing the number of required denoising operations. This modification is also coupled with an improved encoding protocol. Furthermore, we introduce two flexible variants of Turbo-DDCM, a priority-aware variant that prioritizes user-specified regions and a distortion-controlled variant that compresses an image based on a target PSNR rather than a target BPP. Comprehensive experiments position Turbo-DDCM as a compelling, practical, and flexible image compression scheme."}
