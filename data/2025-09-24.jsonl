{"id": "2509.18402", "categories": ["eess.IV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.18402", "abs": "https://arxiv.org/abs/2509.18402", "authors": ["Tingjun Liu", "Chicago Y. Park", "Yuyang Hu", "Hongyu An", "Ulugbek S. Kamilov"], "title": "Measurement Score-Based MRI Reconstruction with Automatic Coil Sensitivity Estimation", "comment": "7 pages, 2 figures. Equal contribution: Tingjun Liu and Chicago Y.\n  Park", "summary": "Diffusion-based inverse problem solvers (DIS) have recently shown outstanding\nperformance in compressed-sensing parallel MRI reconstruction by combining\ndiffusion priors with physical measurement models. However, they typically rely\non pre-calibrated coil sensitivity maps (CSMs) and ground truth images, making\nthem often impractical: CSMs are difficult to estimate accurately under heavy\nundersampling and ground-truth images are often unavailable. We propose\nCalibration-free Measurement Score-based diffusion Model (C-MSM), a new method\nthat eliminates these dependencies by jointly performing automatic CSM\nestimation and self-supervised learning of measurement scores directly from\nk-space data. C-MSM reconstructs images by approximating the full posterior\ndistribution through stochastic sampling over partial measurement posterior\nscores, while simultaneously estimating CSMs. Experiments on the multi-coil\nbrain fastMRI dataset show that C-MSM achieves reconstruction performance close\nto DIS with clean diffusion priors -- even without access to clean training\ndata and pre-calibrated CSMs."}
{"id": "2509.18553", "categories": ["eess.IV", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.18553", "abs": "https://arxiv.org/abs/2509.18553", "authors": ["Richa Rawat", "Faisal Ahmed"], "title": "Efficient Breast and Ovarian Cancer Classification via ViT-Based Preprocessing and Transfer Learning", "comment": "10 pages, 3 figures", "summary": "Cancer is one of the leading health challenges for women, specifically breast\nand ovarian cancer. Early detection can help improve the survival rate through\ntimely intervention and treatment. Traditional methods of detecting cancer\ninvolve manually examining mammograms, CT scans, ultrasounds, and other imaging\ntypes. However, this makes the process labor-intensive and requires the\nexpertise of trained pathologists. Hence, making it both time-consuming and\nresource-intensive. In this paper, we introduce a novel vision transformer\n(ViT)-based method for detecting and classifying breast and ovarian cancer. We\nuse a pre-trained ViT-Base-Patch16-224 model, which is fine-tuned for both\nbinary and multi-class classification tasks using publicly available\nhistopathological image datasets. Further, we use a preprocessing pipeline that\nconverts raw histophological images into standardized PyTorch tensors, which\nare compatible with the ViT architecture and also help improve the model\nperformance. We evaluated the performance of our model on two benchmark\ndatasets: the BreakHis dataset for binary classification and the UBC-OCEAN\ndataset for five-class classification without any data augmentation. Our model\nsurpasses existing CNN, ViT, and topological data analysis-based approaches in\nbinary classification. For multi-class classification, it is evaluated against\nrecent topological methods and demonstrates superior performance. Our study\nhighlights the effectiveness of Vision Transformer-based transfer learning\ncombined with efficient preprocessing in oncological diagnostics."}
{"id": "2509.18748", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2509.18748", "abs": "https://arxiv.org/abs/2509.18748", "authors": ["Pep Borrell-Tatché", "Till Aczel", "Théo Ladune", "Roger Wattenhofer"], "title": "HyperCool: Reducing Encoding Cost in Overfitted Codecs with Hypernetworks", "comment": null, "summary": "Overfitted image codecs like Cool-chic achieve strong compression by\ntailoring lightweight models to individual images, but their encoding is slow\nand computationally expensive. To accelerate encoding, Non-Overfitted (N-O)\nCool-chic replaces the per-image optimization with a learned inference model,\ntrading compression performance for encoding speed. We introduce HyperCool, a\nhypernetwork architecture that mitigates this trade-off. Building upon the N-O\nCool-chic framework, HyperCool generates content-adaptive parameters for a\nCool-chic decoder in a single forward pass, tailoring the decoder to the input\nimage without requiring per-image fine-tuning. Our method achieves a 4.9% rate\nreduction over N-O Cool-chic with minimal computational overhead. Furthermore,\nthe output of our hypernetwork provides a strong initialization for further\noptimization, reducing the number of steps needed to approach fully overfitted\nmodel performance. With fine-tuning, HEVC-level compression is achieved with\n60.4% of the encoding cost of the fully overfitted Cool-chic. This work\nproposes a practical method to accelerate encoding in overfitted image codecs,\nimproving their viability in scenarios with tight compute budgets."}
{"id": "2509.18310", "categories": ["eess.SP", "cs.LG", "stat.AP", "stat.ME"], "pdf": "https://arxiv.org/pdf/2509.18310", "abs": "https://arxiv.org/abs/2509.18310", "authors": ["Bahar Kor", "Bipin Gaikwad", "Abani Patra", "Eric L. Miller"], "title": "On Multi-entity, Multivariate Quickest Change Point Detection", "comment": null, "summary": "We propose a framework for online Change Point Detection (CPD) from\nmulti-entity, multivariate time series data, motivated by applications in crowd\nmonitoring where traditional sensing methods (e.g., video surveillance) may be\ninfeasible. Our approach addresses the challenge of detecting system-wide\nbehavioral shifts in complex, dynamic environments where the number and\nbehavior of individual entities may be uncertain or evolve. We introduce the\nconcept of Individual Deviation from Normality (IDfN), computed via a\nreconstruction-error-based autoencoder trained on normal behavior. We aggregate\nthese individual deviations using mean, variance, and Kernel Density Estimates\n(KDE) to yield a System-Wide Anomaly Score (SWAS). To detect persistent or\nabrupt changes, we apply statistical deviation metrics and the Cumulative Sum\n(CUSUM) technique to these scores. Our unsupervised approach eliminates the\nneed for labeled data or feature extraction, enabling real-time operation on\nstreaming input. Evaluations on both synthetic datasets and crowd simulations,\nexplicitly designed for anomaly detection in group behaviors, demonstrate that\nour method accurately detects significant system-level changes, offering a\nscalable and privacy-preserving solution for monitoring complex multi-agent\nsystems. In addition to this methodological contribution, we introduce new,\nchallenging multi-entity multivariate time series datasets generated from crowd\nsimulations in Unity and coupled nonlinear oscillators. To the best of our\nknowledge, there is currently no publicly available dataset of this type\ndesigned explicitly to evaluate CPD in complex collective and interactive\nsystems, highlighting an essential gap that our work addresses."}
{"id": "2509.18809", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2509.18809", "abs": "https://arxiv.org/abs/2509.18809", "authors": ["Dehui Yang", "Feng Xi", "Qihao Cao", "Huizhang Yang"], "title": "RFI Removal from SAR Imagery via Sparse Parametric Estimation of LFM Interferences", "comment": null, "summary": "One of the challenges in spaceborne synthetic aperture radar (SAR) is\nmodeling and mitigating radio frequency interference (RFI) artifacts in SAR\nimagery. Linear frequency modulated (LFM) signals have been commonly used for\ncharacterizing the radar interferences in SAR. In this letter, we propose a new\nsignal model that approximates RFI as a mixture of multiple LFM components in\nthe focused SAR image domain. The azimuth and range frequency modulation (FM)\nrates for each LFM component are estimated effectively using a sparse\nparametric representation of LFM interferences with a discretized LFM\ndictionary. This approach is then tested within the recently developed RFI\nsuppression framework using a 2-D SPECtral ANalysis (2-D SPECAN) algorithm\nthrough LFM focusing and notch filtering in the spectral domain [1].\nExperimental studies on Sentinel-1 single-look complex images demonstrate that\nthe proposed LFM model and sparse parametric estimation scheme outperforms\nexisting RFI removal methods."}
{"id": "2509.18381", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.18381", "abs": "https://arxiv.org/abs/2509.18381", "authors": ["Nicholas L. K. Goradia", "Harpreet S. Dhillon", "R. Michael Buehrer"], "title": "Multi-Target Detection for Cognitive MIMO Radar Networks", "comment": "12 pages, 16 figures", "summary": "In this work, we develop centralized and decentralized signal fusion\ntechniques for constant false alarm rate (CFAR) multi-target detection with a\ncognitive radar network in unknown noise and clutter distributions. Further, we\nfirst develop a detection statistic for co-located monostatic MIMO radar in\nunknown noise and clutter distributions which is asymptotically CFAR as the\nnumber of received pulses over all antennas grows large, and we provide\nconditions under which this detection statistic is valid. We leverage\nreinforcement learning (RL) for improved multi-target detection performance,\nwhere the radar learns likely target locations in a search area. These results\nare then generalized to the setting of cognitive radar networks, where radars\ncollaborate to learn where targets are likely to appear in a search area. We\nshow a fundamental tradeoff between the spatial and temporal domain for CFAR\ndetection in unknown noise and clutter distributions; in other words, we show a\ntradeoff between the number of radar antennas and the number of temporal\nsamples. We show the benefits and tradeoffs with centralized and decentralized\ndetection with a network of cognitive radars."}
{"id": "2509.18815", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2509.18815", "abs": "https://arxiv.org/abs/2509.18815", "authors": ["Shimon Murai", "Fangzheng Lin", "Jiro Katto"], "title": "FlashGMM: Fast Gaussian Mixture Entropy Model for Learned Image Compression", "comment": "Accepted by IEEE VCIP 2025", "summary": "High-performance learned image compression codecs require flexible\nprobability models to fit latent representations. Gaussian Mixture Models\n(GMMs) were proposed to satisfy this demand, but suffer from a significant\nruntime performance bottleneck due to the large Cumulative Distribution\nFunction (CDF) tables that must be built for rANS coding. This paper introduces\na fast coding algorithm that entirely eliminates this bottleneck. By leveraging\nthe CDF's monotonic property, our decoder performs a dynamic binary search to\nfind the correct symbol, eliminating the need for costly table construction and\nlookup. Aided by SIMD optimizations and numerical approximations, our approach\naccelerates the GMM entropy coding process by up to approximately 90x without\ncompromising rate-distortion performance, significantly improving the\npracticality of GMM-based codecs. The implementation will be made publicly\navailable at https://github.com/tokkiwa/FlashGMM."}
{"id": "2509.18426", "categories": ["eess.SP", "physics.ins-det"], "pdf": "https://arxiv.org/pdf/2509.18426", "abs": "https://arxiv.org/abs/2509.18426", "authors": ["Ziad Hatab", "Michael Ernst Gadringer", "Arash Arsanjani", "Wolfgang Boesch"], "title": "Automatic Model Extraction of the Match Standard in Symmetric--Reciprocal--Match Calibration", "comment": "https://github.com/ZiadHatab/srm-calibration", "summary": "This paper addresses the modeling of parasitics of the match standard in the\nsymmetric-reciprocal-match (SRM) calibration method of vector network analyzers\n(VNAs). In the general SRM procedure, the match standard is assumed to be fully\nknown. Here, we demonstrate that the match can be modeled with an arbitrary\nfrequency-dependent model using a non-linear global optimization procedure. To\nhighlight the validity of the suggested approach, numerical tests were\nconducted, demonstrating the ability to recover the match standard parasitic\nmodel down to software numerical precision. Additionally, we performed\nmicrostrip line measurements to compare the SRM calibration with match modeling\nto the multiline thru-reflect-line (TRL) calibration one, showing that\nautomatic model extraction can achieve accuracy similar to using a match\nstandard defined through multiline TRL calibration."}
{"id": "2509.19192", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2509.19192", "abs": "https://arxiv.org/abs/2509.19192", "authors": ["Yiyang Liu", "Rongxuan Zhang", "Istvan Gyongy", "Alistair Gorman", "Sarrah M. Patanwala", "Filip Taneski", "Robert K. Henderson"], "title": "An on-chip Pixel Processing Approach with 2.4μs latency for Asynchronous Read-out of SPAD-based dToF Flash LiDARs", "comment": null, "summary": "We propose a fully asynchronous peak detection approach for SPAD-based direct\ntime-of-flight (dToF) flash LiDAR, enabling pixel-wise event-driven depth\nacquisition without global synchronization. By allowing pixels to independently\nreport depth once a sufficient signal-to-noise ratio is achieved, the method\nreduces latency, mitigates motion blur, and increases effective frame rate\ncompared to frame-based systems. The framework is validated under two hardware\nimplementations: an offline 256$\\times$128 SPAD array with PC based processing\nand a real-time FPGA proof-of-concept prototype with 2.4$\\upmu$s latency for\non-chip integration. Experiments demonstrate robust depth estimation,\nreflectivity reconstruction, and dynamic event-based representation under both\nstatic and dynamic conditions. The results confirm that asynchronous operation\nreduces redundant background data and computational load, while remaining\ntunable via simple hyperparameters. These findings establish a foundation for\ncompact, low-latency, event-driven LiDAR architectures suited to robotics,\nautonomous driving, and consumer applications. In addition, we have derived a\nsemi-closed-form solution for the detection probability of the raw-peak finding\nbased LiDAR systems that could benefit both conventional frame-based and\nproposed asynchronous LiDAR systems."}
{"id": "2509.18555", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.18555", "abs": "https://arxiv.org/abs/2509.18555", "authors": ["Ping Wang", "Zulin Wang", "Yuanfang Ma", "Xiaosi Tian", "Yuanhan Ni"], "title": "A Secure Affine Frequency Division Multiplexing for Wireless Communication Systems", "comment": "6 pages, 5 figures, 2025 IEEE International Conference on\n  Communications", "summary": "This paper introduces a secure affine frequency division multiplexing\n(SE-AFDM) for wireless communication systems to enhance communication security.\nBesides configuring the parameter c1 to obtain communication reliability under\ndoubly selective channels, we also utilize the time-varying parameter c2 to\nimprove the security of the communications system. The derived input-output\nrelation shows that the legitimate receiver can eliminate the nonlinear impact\nintroduced by the time-varying c2 without losing the bit error rate (BER)\nperformance. Moreover, it is theoretically proved that the eavesdropper cannot\nseparate the time-varying c2 and random information symbols, such that the BER\nperformance of the eavesdropper is severely deteriorated. Meanwhile, the\nanalysis of the effective signal-to-interference-plus-noise ratio (SINR) of the\neavesdropper illustrates that the SINR decreases as the value range of c2\nexpands. Numerical results verify that the proposed SE-AFDM waveform has\nsignificant security while maintaining good BER performance in high-mobility\nscenarios."}
{"id": "2509.19277", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.19277", "abs": "https://arxiv.org/abs/2509.19277", "authors": ["Georgii Kolokolnikov", "Marie-Lena Schmalhofer", "Sophie Götz", "Lennart Well", "Said Farschtschi", "Victor-Felix Mautner", "Inka Ristow", "Rene Werner"], "title": "MOIS-SAM2: Exemplar-based Segment Anything Model 2 for multilesion interactive segmentation of neurobromas in whole-body MRI", "comment": null, "summary": "Background and Objectives: Neurofibromatosis type 1 is a genetic disorder\ncharacterized by the development of numerous neurofibromas (NFs) throughout the\nbody. Whole-body MRI (WB-MRI) is the clinical standard for detection and\nlongitudinal surveillance of NF tumor growth. Existing interactive segmentation\nmethods fail to combine high lesion-wise precision with scalability to hundreds\nof lesions. This study proposes a novel interactive segmentation model tailored\nto this challenge.\n  Methods: We introduce MOIS-SAM2, a multi-object interactive segmentation\nmodel that extends the state-of-the-art, transformer-based, promptable Segment\nAnything Model 2 (SAM2) with exemplar-based semantic propagation. MOIS-SAM2 was\ntrained and evaluated on 119 WB-MRI scans from 84 NF1 patients acquired using\nT2-weighted fat-suppressed sequences. The dataset was split at the patient\nlevel into a training set and four test sets (one in-domain and three\nreflecting different domain shift scenarios, e.g., MRI field strength\nvariation, low tumor burden, differences in clinical site and scanner vendor).\n  Results: On the in-domain test set, MOIS-SAM2 achieved a scan-wise DSC of\n0.60 against expert manual annotations, outperforming baseline 3D nnU-Net (DSC:\n0.54) and SAM2 (DSC: 0.35). Performance of the proposed model was maintained\nunder MRI field strength shift (DSC: 0.53) and scanner vendor variation (DSC:\n0.50), and improved in low tumor burden cases (DSC: 0.61). Lesion detection F1\nscores ranged from 0.62 to 0.78 across test sets. Preliminary inter-reader\nvariability analysis showed model-to-expert agreement (DSC: 0.62-0.68),\ncomparable to inter-expert agreement (DSC: 0.57-0.69).\n  Conclusions: The proposed MOIS-SAM2 enables efficient and scalable\ninteractive segmentation of NFs in WB-MRI with minimal user input and strong\ngeneralization, supporting integration into clinical workflows."}
{"id": "2509.18727", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.18727", "abs": "https://arxiv.org/abs/2509.18727", "authors": ["Yasaman Ettefagh", "Sharief Saleh", "Musa Furkan Keskin", "Hui Chen", "Gonzalo Seco-Granados", "Henk Wymeersch"], "title": "Integrated Cellular and LEO-based Positioning and Synchronization under User Mobility", "comment": null, "summary": "This paper investigates the localization, synchronization, and speed\nestimation of a mobile user equipment (UE) leveraging integrated terrestrial\nand non-terrestrial networks (NTNs), in particular low Earth orbit (LEO)\nsatellites. We focus on a minimal setup in which the UE received signal from\nonly one base station (BS) and one LEO satellite. We derive a generic signal\nmodel accounting for mobility, clock and frequency offsets, based on which a\nhierarchy of simplified models are proposed and organized by computational\ncomplexity. Estimation algorithms are developed for each model to facilitate\nefficient and accurate parameter recovery. Rigorous simulations validate the\neffectiveness of the proposed models, demonstrating their suitability across\ndiverse scenarios. The findings highlight how the trade-off between complexity\nand performance can be optimized for varying deployment environments and\napplication requirements, offering valuable insights for 6G positioning and\nsynchronization systems under user mobility."}
{"id": "2509.18753", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.18753", "abs": "https://arxiv.org/abs/2509.18753", "authors": ["Hao Wu", "Xinyuan Yao", "Rui Ni", "Chen Gong", "Kaibin Huang"], "title": "Detection Capability Comparison Between Intensity Detection and Splitting Detection for Rydberg-Atomic Sensors", "comment": null, "summary": "Rydberg atomic quantum receivers have been seen as novel radio frequency\nmeasurements and the high sensitivity to a large range of frequencies makes it\nattractive for communications reception. However, their unique physical\ncharacteristics enable two fundamental signal readout schemes: intensity-based\ndetection and splitting-based detection. The former measures the electric\nfields through laser intensity, while the latter utilizes Autler-Townes\nsplitting. In this work, we systematically categorize and model existing signal\nreadout methods, classifying them into these two paradigms. Then, we derive the\nmaximum likelihood estimation procedures and corresponding Cram\\'er-Rao lower\nbounds (CRLB) for each detection modality. Through the analysis of the CRLB, we\npropose strategy for both readout schemes to enhance sensitivity and minimize\nestimation variance: acquiring data in regions with maximal slope magnitudes.\nWhile this approach has been implemented in intensity-based detection (e.g.,\nsuperheterodyne schemes), its application to splitting-based detection remains\nunexplored. Implementation of non-uniform frequency scanning, with preferential\nsampling at regions exhibiting maximum peak slopes combined with our proposed\nmaximum likelihood splitting estimation method, achieves significantly reduced\nestimation variance compared to conventional polynomial fitting. The\ncomparative analysis reveals the optimal detection performance of the two\ndetection schemes. This work also contributes to enhancing the accuracy of\nmicrowave calibration. Numerical results reveal that both fundamental signal\nreadout methods achieve lower estimation variance based on our proposed maximum\nlikelihood estimation approach."}
{"id": "2509.18799", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.18799", "abs": "https://arxiv.org/abs/2509.18799", "authors": ["Sijia Cheng", "Liang Liu", "Ove Edfors", "Juan Vidal Alegria"], "title": "Highly Parallel Singular Value Decomposition for Low-Latency MIMO Processing", "comment": "5 pages, 6 figures, accepted to SiPS2025", "summary": "Singular value decomposition (SVD) is widely used in wireless systems,\nincluding multiple-input multiple-output (MIMO) processing and dimension\nreduction in distributed MIMO (D-MIMO). However, the iterative nature of\ndecomposition methods results in increased execution time as system size grows,\nposing challenges for real-time and low-latency applications. To address this,\nwe analyze the latency of state-of-art SVD methods, and highlight the\nefficiency of a 4-step highly parallel method based on Gram matrix\ntridiagonalization. Furthermore, we develop a time complexity (processing\nlatency) analysis framework with hardware profiling, allowing scalable and\nrealistic evaluation without full implementation. The numerical results\ndemonstrate the superior time efficiency of the selected parallel method,\nparticularly in massive MIMO scenarios."}
{"id": "2509.18853", "categories": ["eess.SP", "physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2509.18853", "abs": "https://arxiv.org/abs/2509.18853", "authors": ["Xiaolei Li", "Pengyu Wang", "Wenhua Song", "Yangjin Xu", "Wei Gao"], "title": "Normal mode parameters estimation by a VLA in single-shooting", "comment": null, "summary": "This paper proposes an orthogonality-constrained modal search (OCMS) method\nfor estimating modal wavenumbers and modal depth functions using a vertical\nlinear array (VLA). Under the assumption of a known sound speed profile, OCMS\nleverages the orthogonality of distinct modal depth functions to extract both\nthe modal depth functions and their corresponding wavenumbers, even when the\nVLA and a monochromatic sound source remain stationary.The performance of OCMS\nis evaluated through numerical simulations under varying signal-to-noise ratios\n(SNRs), different VLA apertures, varying numbers of VLA elements, VLA tilt and\nsound speed profile (SSP) uncertainty. The results demonstrate that OCMS is\nrobust against noise, VLA aperture variations, and changes in the number of VLA\nelements, meanwhile, the algorithm maintains reliable performance when SSP\nuncertainty < 1 m/s and VLA tilt angle <5{\\deg}. Furthermore, the effectiveness\nof OCMS is validated using SwellEx96 experimental data. The relative error\nbetween the modal wavenumbers derived from experimental data and those computed\nvia Kraken is on the order of $10^{-4}$."}
{"id": "2509.18918", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.18918", "abs": "https://arxiv.org/abs/2509.18918", "authors": ["Hamideh-Sadat Fazael-Ardekani", "Hadi Zayyani", "Hamid Soltanian-Zadeh"], "title": "Quaternion LMS for Graph Signal Recovery", "comment": null, "summary": "This letter generalizes the Graph Signal Recovery (GSR) problem in Graph\nSignal Processing (GSP) to the Quaternion domain. It extends the Quaternion\nLeast Mean Square (QLMS) in adaptive filtering literature, and Graph LMS (GLMS)\nalgorithm in GSP literature, to an algorithm called Quaternion GLMS (QGLMS).\nThe basic adaptation formula using Quaternion-based algebra is derived.\nMoreover, mean convergence analysis and mean-square convergence analysis are\nmathematically performed. Hence, a sufficient condition on the step-size\nparameter of QGLMS is suggested. Also, simulation results demonstrate the\neffectiveness of the proposed algorithm in graph signal reconstruction."}
{"id": "2509.19056", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.19056", "abs": "https://arxiv.org/abs/2509.19056", "authors": ["Razieh Torkamani", "Arash Amini", "Hadi Zayyani", "Mehdi Korki"], "title": "Bayesian Convolutional Neural Networks for Prior Learning in Graph Signal Recovery", "comment": null, "summary": "Graph signal recovery (GSR) is a fundamental problem in graph signal\nprocessing, where the goal is to reconstruct a complete signal defined over a\ngraph from a subset of noisy or missing observations. A central challenge in\nGSR is that the underlying statistical model of the graph signal is often\nunknown or too complex to specify analytically. To address this, we propose a\nflexible, data-driven framework that learns the signal prior directly from\ntraining samples. We develop a Bayesian convolutional neural network (BCNN)\narchitecture that models the prior distribution of graph signals using\ngraph-aware filters based on Chebyshev polynomials. By interpreting the hidden\nlayers of the CNN as Gibbs distributions and employing Gaussian mixture model\n(GMM) nonlinearities, we obtain a closed-form and expressive prior. This prior\nis integrated into a variational Bayesian (VB) inference framework to estimate\nthe posterior distribution of the signal and noise precision. Extensive\nexperiments on synthetic and real-world graph datasets demonstrate that the\nproposed BCNN-GSR algorithm achieves accurate and robust recovery across a\nvariety of signal distributions. The method generalizes well to complex,\nnon-Gaussian signal models and remains computationally efficient, making it\nsuitable for practical large-scale graph recovery tasks."}
{"id": "2509.19092", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.19092", "abs": "https://arxiv.org/abs/2509.19092", "authors": ["Abolfazl Zakeri", "Nhan Thanh Nguyen", "Ahmed Alkhateeb", "Markku Juntti"], "title": "Data-Free Knowledge Distillation for LiDAR-Aided Beam Tracking in MmWave Systems", "comment": "Submitted for possible publication", "summary": "Multimodal sensing reduces beam training overhead but is constrained by\nmachine learning complexity and dataset demands. To address this, we propose a\ndata-free (DF) knowledge distillation (KD) framework for efficient LiDAR-aided\nmmWave beam tracking, i.e., predicting the best current and future beams.\nSpecifically, we propose a knowledge inversion framework, where a generator\nsynthesizes LiDAR input data from random noise, guided by a loss function\ndefined on the features and outputs of a pre-trained teacher model. The student\nmodel is then trained using the synthetic data and knowledge distilled from the\nteacher. The generator loss combines three terms, called metadata loss,\nactivation loss, and entropy loss. For student training, in addition to the\nstandard Kullback-Leibler divergence loss, we also consider a mean-squared\nerror (MSE) loss between the teacher and student logits. Simulation results\nshow that the proposed DF-KD (slightly) outperforms the teacher in Top-1 and\nTop-5 accuracies. Moreover, we observe that the metadata loss contributes\nsignificantly to the generator performance, and that the MSE loss for the\nstudent can effectively replace the standard KD loss while requiring fewer\nfine-tuned hyperparameters."}
{"id": "2509.19119", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.19119", "abs": "https://arxiv.org/abs/2509.19119", "authors": ["Palatip Jopanya", "Diana P. M. Osorio"], "title": "Enabling Drone Detection with SWARM Repeater-Assisted MIMO ISAC", "comment": "5 pages, 2 figures", "summary": "As definitions about new architectural aspects, use cases, and standards for\nintegrated sensing and communication (ISAC) continue to appear, cellular\nsystems based on massive multiple-input multiple-output (MIMO) antenna\ntechnology are also experiencing a parallel evolution through the integration\nof novel network components. This evolution should support emerging ISAC use\ncases and services. In particular, this paper explores a recent vision for\ncost-efficient cellular network densification through the deployment of swarms\nof repeaters. Leveraging their ability to retransmit signals instantaneously,\nwe investigate how these repeaters can enhance radar sensing capabilities for\ndrone detection in a swarm repeater-assisted MIMO ISAC system. Our results\ndemonstrate that, by optimizing the gains of repeaters given a sufficient\nmaximum amplification gain, increasing the number of repeaters can lead to\ngains in sensing performance."}
{"id": "2509.19130", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.19130", "abs": "https://arxiv.org/abs/2509.19130", "authors": ["Abolfazl Zakeri", "Nhan Thanh Nguyen", "Ahmed Alkhateeb", "Markku Juntti"], "title": "Deep Reinforcement Learning for Dynamic Sensing and Communications", "comment": "Under review for possible publication", "summary": "Environmental sensing can significantly enhance mmWave communications by\nassisting beam training, yet its benefits must be balanced against the\nassociated sensing costs. To this end, we propose a unified machine learning\nframework that dynamically determines when to sense and leverages sensory data\nfor beam prediction. Specifically, we formulate a joint sensing and beamforming\nproblem that maximizes the av- erage signal-to-noise ratio under an average\nsensing budget. Lyapunov optimization is employed to enforce the sensing\nconstraint, while a deep Q-Network determines the sensing slots. A pretrained\ndeep neural network then maps the sens- ing data to optimal beams in the\ncodebook. Simulations based on the real-world DeepSense dataset demonstrate\nthat the pro- posed approach substantially reduces sensing overhead while\nmaintaining satisfactory communications performance."}
{"id": "2509.19235", "categories": ["eess.SP", "math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2509.19235", "abs": "https://arxiv.org/abs/2509.19235", "authors": ["Wamberto J. L. Queiroz", "Hugerles S. Silva", "Higo T. P. Silva", "Alexandros-Apostolos A. Boulogeorgos"], "title": "On the Performance of THz Wireless Systems over $α$-$\\mathcal{F}$ Channels with Beam Misalignment and Mobility", "comment": null, "summary": "This paper investigates the performance of terahertz~(THz) wireless systems\nover the $\\alpha$-$\\mathcal{F}$ fading channels with beam misalignment and\nmobility. New expressions are derived for the probability density, cumulative\ndistribution, and moment generating functions, as well as higher-order moments\nof the instantaneous signal-to-noise ratio. Building upon the aforementioned\nexpressions, we extract novel formulas for the outage probability, symbol error\nprobability, and average channel capacity. Asymptotic metrics are also deduced,\nwhich provide useful insights. Monte Carlo simulations results are presented to\nsupport the derived analytical framework."}
{"id": "2509.19272", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.19272", "abs": "https://arxiv.org/abs/2509.19272", "authors": ["Sathwik Chadaga"], "title": "Faster-Than-Nyquist Signalling - Theoretical Limits on Capacity and Techniques to Approach Capacity", "comment": null, "summary": "Faster-Than-Nyquist (FTN) Signalling is a non-orthogonal transmission scheme\nthat violates the Nyquist zero-ISI criterion providing higher throughput and\nbetter spectral efficiency than a Nyquist transmission scheme. In this thesis,\nthe inter symbol interference (ISI) introduced by FTN signalling is studied,\nand conditions on pulse shapes and $\\tau$ (time acceleration factor) are\nderived so that the ISI can be avoided completely. Further, these conditions\nare reinforced by investigating the theoretical limits on the capacities of FTN\nsystems. Finally, the use of power allocation and adaptive loading techniques\nare explored in reducing the effect of ISI and increasing the throughput of\northogonal frequency division multiplexing (OFDM) FTN systems. The\nimplementation of these techniques and simulation results are also\ndemonstrated."}
{"id": "2509.19275", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.19275", "abs": "https://arxiv.org/abs/2509.19275", "authors": ["Junzhe Song", "Ruisi He", "Mi Yang", "Zhengyu Zhang", "Xinwen Chen", "Xiaoying Zhang", "Bo Ai"], "title": "A Novel Site-Specific Inference Model for Urban Canyon Channels: From Measurements to Modeling", "comment": null, "summary": "With the rapid development of intelligent transportation and smart city\napplications, urban canyon has become a critical scenario for the design and\nevaluation of wireless communication systems. Due to its unique environmental\nlayout, the channel characteristics in urban canyon are strongly a street\ngeometry and building distribution, thereby exhibiting significant\nsite-specific channel condition. However, this feature has not been well\ncaptured in existing channel models. In this paper, we propose a site-specific\nchannel inference model based on environmental geometry, the model is\nparameterized using sub-6GHz channel measurements. Multipath components (MPCs)\nare extracted and clustered according to geometric propagation, which are\nexplicitly derived from the influence of canyon width, thereby establishing an\ninterpretable mapping between the physical environment and statistical\ncharacteristics of MPCs. A step-by-step implementation scheme is presented.\nSubsequently, the proposed site-specific channel inference model is validated\nby comparing second-order statistics of channels, derived from the model and\nmeasurements. The results show that the proposed model achieves high accuracy\nand robustness in different urban canyon scenarios."}
{"id": "2509.19281", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.19281", "abs": "https://arxiv.org/abs/2509.19281", "authors": ["Xiyang Lan", "Xin Li"], "title": "STFT-AECNN: An Attention-Enhanced CNN for Efficient Φ-OTDR Event Recognition in IoT-Enabled Distributed Acoustic Sensing", "comment": null, "summary": "Phase-sensitive optical time-domain reflectometry ({\\Phi}-OTDR) has emerged\nas a promising sensing technology in Internet of Things (IoT) infrastructures,\nenabling large-scale distributed acoustic sensing (DAS) for smart city\nsurveillance, industrial pipeline monitoring, and critical infrastructure\nprotection. However, accurately recognizing events from massive {\\Phi}-OTDR\ndata streams remains challenging, as existing deep learning methods either\ndisrupt the inherent spatiotemporal structure of signals or incur prohibitive\ncomputational costs, limiting their applicability in resource-constrained IoT\nscenarios. To overcome these challenges, we propose a novel STFT-based\nAttention-Enhanced Convolutional Neural Network (STFT-AECNN), which represents\nmulti-channel time-series data as stacked spectrograms to fully exploit their\nspatiotemporal characteristics while enabling efficient 2D CNN processing. A\nSpatial Efficient Attention Module (SEAM) is further introduced to adaptively\nemphasize the most informative channels, and a joint Cross-Entropy and Triplet\nloss is adopted to enhance the discriminability of the learned feature space.\nExtensive experiments on the public BJTU {\\Phi}-OTDR dataset demonstrate that\nSTFT-AECNN achieves a peak accuracy of 99.94% while maintaining high\ncomputational efficiency. These results highlight its potential for real-time,\nscalable, and robust event recognition in IoT-enabled DAS systems, paving the\nway for reliable and intelligent IoT sensing applications."}
