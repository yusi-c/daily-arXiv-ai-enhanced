{"id": "2508.18612", "categories": ["eess.IV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.18612", "abs": "https://arxiv.org/abs/2508.18612", "authors": ["Soumen Ghosh", "Christine Jestin Hannan", "Rajat Vashistha", "Parveen Kundu", "Sandra Brosda", "Lauren G. Aoude", "James Lonie", "Andrew Nathanson", "Jessica Ng", "Andrew P. Barbour", "Viktor Vegh"], "title": "Stress-testing cross-cancer generalizability of 3D nnU-Net for PET-CT tumor segmentation: multi-cohort evaluation with novel oesophageal and lung cancer datasets", "comment": null, "summary": "Robust generalization is essential for deploying deep learning based tumor\nsegmentation in clinical PET-CT workflows, where anatomical sites, scanners,\nand patient populations vary widely. This study presents the first cross cancer\nevaluation of nnU-Net on PET-CT, introducing two novel, expert-annotated\nwhole-body datasets. 279 patients with oesophageal cancer (Australian cohort)\nand 54 with lung cancer (Indian cohort). These cohorts complement the public\nAutoPET dataset and enable systematic stress-testing of cross domain\nperformance. We trained and tested 3D nnUNet models under three paradigms.\nTarget only (oesophageal), public only (AutoPET), and combined training. For\nthe tested sets, the oesophageal only model achieved the best in-domain\naccuracy (mean DSC, 57.8) but failed on external Indian lung cohort (mean DSC\nless than 3.4), indicating severe overfitting. The public only model\ngeneralized more broadly (mean DSC, 63.5 on AutoPET, 51.6 on Indian lung\ncohort) but underperformed in oesophageal Australian cohort (mean DSC, 26.7).\nThe combined approach provided the most balanced results (mean DSC, lung\n(52.9), oesophageal (40.7), AutoPET (60.9)), reducing boundary errors and\nimproving robustness across all cohorts. These findings demonstrate that\ndataset diversity, particularly multi demographic, multi center and multi\ncancer integration, outweighs architectural novelty as the key driver of robust\ngeneralization. This work presents the demography based cross cancer deep\nlearning segmentation evaluation and highlights dataset diversity, rather than\nmodel complexity, as the foundation for clinically robust segmentation."}
{"id": "2508.18613", "categories": ["eess.IV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.18613", "abs": "https://arxiv.org/abs/2508.18613", "authors": ["Eichi Takaya", "Ryusei Inamori"], "title": "ModAn-MulSupCon: Modality-and Anatomy-Aware Multi-Label Supervised Contrastive Pretraining for Medical Imaging", "comment": null, "summary": "Background and objective: Expert annotations limit large-scale supervised\npretraining in medical imaging, while ubiquitous metadata (modality, anatomical\nregion) remain underused. We introduce ModAn-MulSupCon, a modality- and\nanatomy-aware multi-label supervised contrastive pretraining method that\nleverages such metadata to learn transferable representations.\n  Method: Each image's modality and anatomy are encoded as a multi-hot vector.\nA ResNet-18 encoder is pretrained on a mini subset of RadImageNet (miniRIN,\n16,222 images) with a Jaccard-weighted multi-label supervised contrastive loss,\nand then evaluated by fine-tuning and linear probing on three binary\nclassification tasks--ACL tear (knee MRI), lesion malignancy (breast\nultrasound), and nodule malignancy (thyroid ultrasound).\n  Result: With fine-tuning, ModAn-MulSupCon achieved the best AUC on MRNet-ACL\n(0.964) and Thyroid (0.763), surpassing all baselines ($p<0.05$), and ranked\nsecond on Breast (0.926) behind SimCLR (0.940; not significant). With the\nencoder frozen, SimCLR/ImageNet were superior, indicating that ModAn-MulSupCon\nrepresentations benefit most from task adaptation rather than linear\nseparability.\n  Conclusion: Encoding readily available modality/anatomy metadata as\nmulti-label targets provides a practical, scalable pretraining signal that\nimproves downstream accuracy when fine-tuning is feasible. ModAn-MulSupCon is a\nstrong initialization for label-scarce clinical settings, whereas\nSimCLR/ImageNet remain preferable for frozen-encoder deployments."}
{"id": "2508.18912", "categories": ["eess.IV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.18912", "abs": "https://arxiv.org/abs/2508.18912", "authors": ["Mahmoud Dhimish"], "title": "HOTSPOT-YOLO: A Lightweight Deep Learning Attention-Driven Model for Detecting Thermal Anomalies in Drone-Based Solar Photovoltaic Inspections", "comment": null, "summary": "Thermal anomaly detection in solar photovoltaic (PV) systems is essential for\nensuring operational efficiency and reducing maintenance costs. In this study,\nwe developed and named HOTSPOT-YOLO, a lightweight artificial intelligence (AI)\nmodel that integrates an efficient convolutional neural network backbone and\nattention mechanisms to improve object detection. This model is specifically\ndesigned for drone-based thermal inspections of PV systems, addressing the\nunique challenges of detecting small and subtle thermal anomalies, such as\nhotspots and defective modules, while maintaining real-time performance.\nExperimental results demonstrate a mean average precision of 90.8%, reflecting\na significant improvement over baseline object detection models. With a reduced\ncomputational load and robustness under diverse environmental conditions,\nHOTSPOT-YOLO offers a scalable and reliable solution for large-scale PV\ninspections. This work highlights the integration of advanced AI techniques\nwith practical engineering applications, revolutionizing automated fault\ndetection in renewable energy systems."}
{"id": "2508.18712", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.18712", "abs": "https://arxiv.org/abs/2508.18712", "authors": ["Samin Yaser", "Mahad Ali", "Laura J. Brattain", "Yang Jiang", "VP Nguyen", "Jing Xiang"], "title": "A Synoptic Review of High-Frequency Oscillations as a Biomarker in Neurodegenerative Disease", "comment": null, "summary": "High Frequency Oscillations (HFOs), rapid bursts of brain activity above 80\nHz, have emerged as a highly specific biomarker for epileptogenic tissue.\nRecent evidence suggests that HFOs are also present in Alzheimer's Disease\n(AD), reflecting underlying network hyperexcitability and offering a promising,\nnoninvasive tool for early diagnosis and disease tracking. This synoptic review\nprovides a comprehensive analysis of publicly available electroencephalography\n(EEG) datasets relevant to HFO research in neurodegenerative disorders. We\nconducted a bibliometric analysis of 1,222 articles, revealing a significant\nand growing research interest in HFOs, particularly within the last ten years.\nWe then systematically profile and compare key public datasets, evaluating\ntheir participant cohorts, data acquisition parameters, and accessibility, with\na specific focus on their technical suitability for HFO analysis. Our\ncomparative synthesis highlights critical methodological heterogeneity across\ndatasets, particularly in sampling frequency and recording paradigms, which\nposes challenges for cross-study validation, but also offers opportunities for\nrobustness testing. By consolidating disparate information, clarifying\nnomenclature, and providing a detailed methodological framework, this review\nserves as a guide for researchers aiming to leverage public data to advance the\nrole of HFOs as a cross-disease biomarker for AD and related conditions."}
{"id": "2508.18968", "categories": ["eess.IV", "cs.MM", "eess.SP"], "pdf": "https://arxiv.org/pdf/2508.18968", "abs": "https://arxiv.org/abs/2508.18968", "authors": ["Hannah Och", "AndrÃ© Kaup"], "title": "Lossless 4:2:0 Screen Content Coding Using Luma-Guided Soft Context Formation", "comment": "5 pages, 4 figures, 3 tables, accepted to EUSIPCO 2025", "summary": "The soft context formation coder is a pixel-wise state-of-the-art lossless\nscreen content coder using pattern matching and color palette coding in\ncombination with arithmetic coding. It achieves excellent compression\nperformance on screen content images in RGB 4:4:4 format with few distinct\ncolors. In contrast to many other lossless compression methods, it codes entire\ncolor pixels at once, i.e., all color components of one pixel are coded\ntogether. Consequently, it does not natively support image formats with\ndownsampled chroma, such as YCbCr 4:2:0, which is an often used chroma format\nin video compression. In this paper, we extend the soft context formation\ncoding capabilities to 4:2:0 image compression, by successively coding Y and\nCbCr planes based on an analysis of normalized mutual information between image\nplanes. Additionally, we propose an enhancement to the chroma prediction based\non the luminance plane. Furthermore, we propose to transmit side-information\nabout occurring luma-chroma combinations to improve chroma probability\ndistribution modelling. Averaged over a large screen content image dataset, our\nproposed method outperforms HEVC-SCC, with HEVC-SCC needing 5.66% more bitrate\ncompared to our method."}
{"id": "2508.18735", "categories": ["eess.SP", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18735", "abs": "https://arxiv.org/abs/2508.18735", "authors": ["Afan Ali", "Irfanullah Khan"], "title": "SkyTrust: Blockchain-Enhanced UAV Security for NTNs with Dynamic Trust and Energy-Aware Consensus", "comment": "6 pages, 7 figures", "summary": "Non-Terrestrial Networks (NTNs) based on Unmanned Aerial Vehicles (UAVs) as\nbase stations are extremely susceptible to security attacks due to their\ndistributed and dynamic nature, which makes them vulnerable to rogue nodes. In\nthis paper, a new Dynamic Trust Score Adjustment Mechanism with Energy-Aware\nConsensus (DTSAM-EAC) is proposed to enhance security in UAV-based NTNs. The\nproposed framework integrates a permissioned Hyperledger Fabric blockchain with\nFederated Learning (FL) to support privacy-preserving trust evaluation. Trust\nratings are updated continuously through weighted aggregation of past trust,\npresent behavior, and energy contribution, thus making the system adaptive to\nchanging network conditions. An energy-aware consensus mechanism prioritizes\nUAVs with greater available energy for block validation, ensuring efficient use\nof resources under resource-constrained environments. FL aggregation with\ntrust-weighting further increases the resilience of the global trust model.\nSimulation results verify the designed framework achieves 94\\% trust score\nprediction accuracy and 96\\% rogue UAV detection rate while outperforming\ncentralized and static baselines of trust-based solutions on privacy, energy\nefficiency, and reliability. It complies with 6G requirements in terms of\ndistributed intelligence and sustainability and is an energy-efficient and\nscalable solution to secure NTNs."}
{"id": "2508.19112", "categories": ["eess.IV", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.19112", "abs": "https://arxiv.org/abs/2508.19112", "authors": ["Aneesh Rangnekar", "Harini Veeraraghavan"], "title": "Random forest-based out-of-distribution detection for robust lung cancer segmentation", "comment": null, "summary": "Accurate detection and segmentation of cancerous lesions from computed\ntomography (CT) scans is essential for automated treatment planning and cancer\ntreatment response assessment. Transformer-based models with self-supervised\npretraining can produce reliably accurate segmentation from in-distribution\n(ID) data but degrade when applied to out-of-distribution (OOD) datasets. We\naddress this challenge with RF-Deep, a random forest classifier that utilizes\ndeep features from a pretrained transformer encoder of the segmentation model\nto detect OOD scans and enhance segmentation reliability. The segmentation\nmodel comprises a Swin Transformer encoder, pretrained with masked image\nmodeling (SimMIM) on 10,432 unlabeled 3D CT scans covering cancerous and\nnon-cancerous conditions, with a convolution decoder, trained to segment lung\ncancers in 317 3D scans. Independent testing was performed on 603 3D CT public\ndatasets that included one ID dataset and four OOD datasets comprising chest\nCTs with pulmonary embolism (PE) and COVID-19, and abdominal CTs with kidney\ncancers and healthy volunteers. RF-Deep detected OOD cases with a FPR95 of\n18.26%, 27.66%, and less than 0.1% on PE, COVID-19, and abdominal CTs,\nconsistently outperforming established OOD approaches. The RF-Deep classifier\nprovides a simple and effective approach to enhance reliability of cancer\nsegmentation in ID and OOD scenarios."}
{"id": "2508.18810", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.18810", "abs": "https://arxiv.org/abs/2508.18810", "authors": ["Yonghwi Kim", "Sang-Hyun Park", "Siyun Yang", "Kai-Kit Wong", "Linglong Dai", "Chan-Byoung Chae"], "title": "Near-Field Challenges in Ultra-Wideband ISAC: Beamforming Strategies and System Insights", "comment": "7 pages, 6 figures", "summary": "The shift toward sixth-generation (6G) wireless networks places integrated\nsensing and communications (ISAC) at the core of future applications such as\nautonomous driving, extended reality, and smart manufacturing. However, the\ncombination of large antenna arrays and ultra-wide bandwidths brings near-field\npropagation effects and beam squint to the forefront, fundamentally challenging\ntraditional far-field designs. True time delay units (TTDs) offer a potential\nsolution, but their cost and hardware complexity limit scalability. In this\narticle, we present practical beamforming strategies for near-field\nultra-wideband ISAC systems. We explore codebook designs across analog and\ndigital domains that mitigate beam squint, ensure reliable user coverage, and\nenhance sensing accuracy. We further validate these approaches through\nlarge-scale system-level simulations, including 3D map-based evaluations that\nreflect real-world urban environments. Our results demonstrate how carefully\ndesigned beamforming can balance communication throughput with sensing\nperformance, achieving reliable coverage and efficient resource use even under\nsevere near-field conditions. We conclude by highlighting open challenges in\nhardware, algorithms, and system integration, pointing toward research\ndirections that will shape the deployment of 6G-ready ISAC networks."}
{"id": "2508.18854", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.18854", "abs": "https://arxiv.org/abs/2508.18854", "authors": ["Ruifeng Dong", "Ming Wang", "Ning Liu", "Tong Guo", "Jiayi Kang", "Xiaojing Shen", "Yao Mao"], "title": "DIFNet: Decentralized Information Filtering Fusion Neural Network with Unknown Correlation in Sensor Measurement Noises", "comment": null, "summary": "In recent years, decentralized sensor networks have garnered significant\nattention in the field of state estimation owing to enhanced robustness,\nscalability, and fault tolerance. Optimal fusion performance can be achieved\nunder fully connected communication and known noise correlation structures. To\nmitigate communication overhead, the global state estimation problem is\ndecomposed into local subproblems through structured observation model. This\nensures that even when the communication network is not fully connected, each\nsensor can achieve locally optimal estimates of its observable state\ncomponents. To address the degradation of fusion accuracy induced by unknown\ncorrelations in measurement noise, this paper proposes a data-driven method,\ntermed Decentralized Information Filter Neural Network (DIFNet), to learn\nunknown noise correlations in data for discrete-time nonlinear state space\nmodels with cross-correlated measurement noises. Numerical simulations\ndemonstrate that DIFNet achieves superior fusion performance compared to\nconventional filtering methods and exhibits robust characteristics in more\ncomplex scenarios, such as the presence of time-varying noise. The source code\nused in our numerical experiment can be found online at\nhttps://wisdom-estimation.github.io/DIFNet_Demonstrate/."}
{"id": "2508.19000", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.19000", "abs": "https://arxiv.org/abs/2508.19000", "authors": ["Atso Iivanainen", "Robin RajamÃ¤ki", "Visa Koivunen"], "title": "Beyond-Diagonal RIS: Adversarial Channels and Optimality of Low-Complexity Architectures", "comment": "\\copyright 2025 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "summary": "Beyond-diagonal reconfigurable intelligent surfaces (BD-RISs) have recently\ngained attention as an enhancement to conventional RISs. BD-RISs allow\noptimizing not only the phase, but also the amplitude responses of their\ndiscrete surface elements by introducing adjustable inter-element couplings.\nVarious BD-RIS architectures have been proposed to optimally trade off between\naverage performance and complexity of the architecture. However, little\nattention has been paid to worst-case performance. This paper characterizes\nnovel sets of adversarial channels for which certain low-complexity BD-RIS\narchitectures have suboptimal performance in terms of received signal power at\nan intended communications user. Specifically, we consider two recent BD-RIS\nmodels: the so-called group-connected and tree-connected architecture. The\nderived adversarial channel sets reveal new surprising connections between the\ntwo architectures. We validate our analytical results numerically,\ndemonstrating that adversarial channels can cause a significant performance\nloss. Our results pave the way towards efficient BD-RIS designs that are robust\nto adversarial propagation conditions and malicious attacks."}
{"id": "2508.19010", "categories": ["eess.SP", "cs.CR"], "pdf": "https://arxiv.org/pdf/2508.19010", "abs": "https://arxiv.org/abs/2508.19010", "authors": ["Poorya Mollahosseini", "Yasaman Ghasempour"], "title": "mmKey: Channel-Aware Beam Shaping for Reliable Key Generation in mmWave Wireless Networks", "comment": null, "summary": "Physical-layer key generation (PLKG) has emerged as a promising technique to\nsecure next-generation wireless networks by exploiting the inherent properties\nof the wireless channel. However, PLKG faces fundamental challenges in the\nmillimeter wave (mmWave) regime due to channel sparsity, higher phase noise,\nand higher path loss, which undermine both the randomness and reciprocity\nrequired for secure key generation. In this paper, we present mmKey, a novel\nPLKG framework that capitalizes on the availability of multiple antennas at\nmmWave wireless nodes to inject randomness into an otherwise quasi-static\nwireless channel. Different from prior works that sacrifice either the secrecy\nof the key generation or the robustness, mmKey balances these two requirements.\nIn particular, mmKey leverages a genetic algorithm to gradually evolve the\ninitial weight vector population toward configurations that suppress the LOS\ncomponent while taking into account the channel conditions, specifically, the\nsparsity and the signal-to-noise ratio (SNR). Extensive simulations show that\nmmKey improves the secrecy gap by an average of 39.4% over random beamforming\nand 34.0% over null beamforming, outperforming conventional schemes."}
{"id": "2508.19034", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.19034", "abs": "https://arxiv.org/abs/2508.19034", "authors": ["Poorya Mollahosseini", "Yasaman Ghasempour"], "title": "Fast Vortex Beam Alignment for OAM Mode Multiplexing in LOS MIMO Networks", "comment": "13 pages, 12 figures. This work has been submitted to the IEEE for\n  possible publication", "summary": "Orbital Angular Momentum (OAM)-based communication systems offer\nhigh-capacity multiplexing in line-of-sight (LOS) scenarios; yet, their\nperformance is sensitive to nodal misalignment, which disrupts modal\northogonality, hindering the data multiplexing gain. To tackle this challenge,\nwe present OrthoVortex, a novel framework that estimates the misalignment\nangles and applies the appropriate phase correction to restore orthogonality\nbetween modes. Unlike purely theoretical prior efforts that rely on impractical\nfully digital arrays or exhaustive beam scans, OrthoVortex introduces and\nleverages the cross-modal phase, as a unique signature for identifying the\nmisalignment angles. OrthoVortex is a few-shot alignment technique, making it\nfeasible for real-world implementations. Our key contributions include: (i) a\nrobust angle estimation and phase correction framework based on the physics of\nOAM propagation that estimates the misalignment and restores modal\northogonality, (ii) the first-ever experimental validation of OAM beam\nalignment with RF transceivers, and (iii) a comprehensive analysis of practical\nconstraints, including the impact of antenna count and bandwidth. Simulations\nand over-the-air measurements using low-cost, rapidly prototyped metasurfaces\noperating at 120 GHz demonstrate that OrthoVortex achieves fast and precise\nmisalignment estimation (mean absolute error of $0.69^{\\circ}$ for azimuth and\n$2.54^{\\circ}$ for elevation angle). Further, OrthoVortex can mitigate the\ninter-modal interference, yielding more than 12 dB increase in\nsignal-to-interference ratio and more than 4.5-fold improvement in link\ncapacity."}
{"id": "2508.19129", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.19129", "abs": "https://arxiv.org/abs/2508.19129", "authors": ["Tayfun Yilmaz", "Haci Ilhan", "Ibrahim Hokelek"], "title": "Space-Time Coded RIS-Assisted Wireless Systems with Practical Reflection Models: Error Rate Analysis and Negative Moment-Based Optimization with Saddle Point Approximation", "comment": "This work has been submitted for consideration in an IEEE journal", "summary": "RIS-assisted communication has recently attracted significant attention for\nenhancing wireless performance in challenging environments, making accurate\nerror analysis under practical hardware constraints crucial for future\nmulti-antenna systems. This paper presents a theoretical framework for SER\nanalysis of RIS-assisted multiple antenna systems employing OSTBC under\npractical reflection models with amplitude-dependent and quantized phase\nresponses. By exploiting the Gramian structure of the cascaded channel f, we\nderive exact MGF expressions of the nonzero eigenvalue of f'f for small RIS\nsizes. For large-scale RIS deployments, where closed-form analysis becomes\nintractable, we employ Saddle Point Approximation to approximate the eigenvalue\ndistribution. Using these results, we derive unified SER expressions using\nexact and SPA-based MGF formulations, applicable to arbitrary RIS sizes, phase\nconfiguration, and both identical and non-identical amplitude responses.\nExtensive Monte Carlo simulations confirm the accuracy of the proposed SER\nexpressions, demonstrating very close agreement for all configurations."}
{"id": "2508.19185", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.19185", "abs": "https://arxiv.org/abs/2508.19185", "authors": ["Nishant Mehrotra", "Sandesh Rao Mattu", "Robert Calderbank"], "title": "Instantaneous Polarimetry with Zak-OTFS", "comment": "8 pages, 4 figures, submitted to IEEE Transactions on Radar Systems\n  (Correspondence)", "summary": "Polarimetry, which is the ability to measure the scattering response of the\nenvironment across orthogonal polarizations, is fundamental to enhancing\nwireless communication and radar system performance. In this paper, we utilize\nthe Zak-OTFS modulation to enable instantaneous polarimetry within a single\ntransmission frame. We transmit a Zak-OTFS carrier waveform and a spread\ncarrier waveform mutually unbiased to it simultaneously over orthogonal\npolarizations. The mutual unbiasedness of the two waveforms enables the\nreceiver to estimate the full polarimetric response of the scattering\nenvironment from a single received frame. Unlike existing methods for\ninstantaneous polarimetry with computational complexity quadratic in the\ntime-bandwidth product, the proposed method enables instantaneous polarimetry\nat complexity that is only sublinear in the time-bandwidth product. Via\nnumerical simulations, we show ideal polarimetric target detection and\nparameter estimation results with the proposed method, with improvements in\nperformance and computational complexity over comparable baselines."}
{"id": "2508.18968", "categories": ["eess.IV", "cs.MM", "eess.SP"], "pdf": "https://arxiv.org/pdf/2508.18968", "abs": "https://arxiv.org/abs/2508.18968", "authors": ["Hannah Och", "AndrÃ© Kaup"], "title": "Lossless 4:2:0 Screen Content Coding Using Luma-Guided Soft Context Formation", "comment": "5 pages, 4 figures, 3 tables, accepted to EUSIPCO 2025", "summary": "The soft context formation coder is a pixel-wise state-of-the-art lossless\nscreen content coder using pattern matching and color palette coding in\ncombination with arithmetic coding. It achieves excellent compression\nperformance on screen content images in RGB 4:4:4 format with few distinct\ncolors. In contrast to many other lossless compression methods, it codes entire\ncolor pixels at once, i.e., all color components of one pixel are coded\ntogether. Consequently, it does not natively support image formats with\ndownsampled chroma, such as YCbCr 4:2:0, which is an often used chroma format\nin video compression. In this paper, we extend the soft context formation\ncoding capabilities to 4:2:0 image compression, by successively coding Y and\nCbCr planes based on an analysis of normalized mutual information between image\nplanes. Additionally, we propose an enhancement to the chroma prediction based\non the luminance plane. Furthermore, we propose to transmit side-information\nabout occurring luma-chroma combinations to improve chroma probability\ndistribution modelling. Averaged over a large screen content image dataset, our\nproposed method outperforms HEVC-SCC, with HEVC-SCC needing 5.66% more bitrate\ncompared to our method."}
