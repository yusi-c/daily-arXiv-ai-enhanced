{"id": "2601.22189", "categories": ["eess.IV", "cs.CV", "cs.LG", "cs.MM"], "pdf": "https://arxiv.org/pdf/2601.22189", "abs": "https://arxiv.org/abs/2601.22189", "authors": ["Han-Yu Lin", "Li-Wei Chen", "Hung-Shin Lee"], "title": "SCENE: Semantic-aware Codec Enhancement with Neural Embeddings", "comment": "Accepted to ICASSP 2026", "summary": "Compression artifacts from standard video codecs often degrade perceptual quality. We propose a lightweight, semantic-aware pre-processing framework that enhances perceptual fidelity by selectively addressing these distortions. Our method integrates semantic embeddings from a vision-language model into an efficient convolutional architecture, prioritizing the preservation of perceptually significant structures. The model is trained end-to-end with a differentiable codec proxy, enabling it to mitigate artifacts from various standard codecs without modifying the existing video pipeline. During inference, the codec proxy is discarded, and SCENE operates as a standalone pre-processor, enabling real-time performance. Experiments on high-resolution benchmarks show improved performance over baselines in both objective (MS-SSIM) and perceptual (VMAF) metrics, with notable gains in preserving detailed textures within salient regions. Our results show that semantic-guided, codec-aware pre-processing is an effective approach for enhancing compressed video streams."}
{"id": "2601.22202", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.22202", "abs": "https://arxiv.org/abs/2601.22202", "authors": ["Runze Cheng", "Yao Sun", "Ahmad Taha", "Xuesong Liu", "David Flynn", "Muhammad Ali Imran"], "title": "A Survey on Semantic Communication for Vision: Categories, Frameworks, Enabling Techniques, and Applications", "comment": null, "summary": "Semantic communication (SemCom) emerges as a transformative paradigm for traffic-intensive visual data transmission, shifting focus from raw data to meaningful content transmission and relieving the increasing pressure on communication resources. However, to achieve SemCom, challenges are faced in accurate semantic quantization for visual data, robust semantic extraction and reconstruction under diverse tasks and goals, transceiver coordination with effective knowledge utilization, and adaptation to unpredictable wireless communication environments. In this paper, we present a systematic review of SemCom for visual data transmission (SemCom-Vision), wherein an interdisciplinary analysis integrating computer vision (CV) and communication engineering is conducted to provide comprehensive guidelines for the machine learning (ML)-empowered SemCom-Vision design. Specifically, this survey first elucidates the basics and key concepts of SemCom. Then, we introduce a novel classification perspective to categorize existing SemCom-Vision approaches as semantic preservation communication (SPC), semantic expansion communication (SEC), and semantic refinement communication (SRC) based on communication goals interpreted through semantic quantization schemes. Moreover, this survey articulates the ML-based encoder-decoder models and training algorithms for each SemCom-Vision category, followed by knowledge structure and utilization strategies. Finally, we discuss potential SemCom-Vision applications."}
{"id": "2601.22537", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.22537", "abs": "https://arxiv.org/abs/2601.22537", "authors": ["Zhuoyu Wu", "Wenhui Ou", "Pei-Sze Tan", "Jiayan Yang", "Wenqi Fang", "Zheng Wang", "Raphaël C. -W. Phan"], "title": "EndoCaver: Handling Fog, Blur and Glare in Endoscopic Images via Joint Deblurring-Segmentation", "comment": "Accepted for publication at IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) 2026", "summary": "Endoscopic image analysis is vital for colorectal cancer screening, yet real-world conditions often suffer from lens fogging, motion blur, and specular highlights, which severely compromise automated polyp detection. We propose EndoCaver, a lightweight transformer with a unidirectional-guided dual-decoder architecture, enabling joint multi-task capability for image deblurring and segmentation while significantly reducing computational complexity and model parameters. Specifically, it integrates a Global Attention Module (GAM) for cross-scale aggregation, a Deblurring-Segmentation Aligner (DSA) to transfer restoration cues, and a cosine-based scheduler (LoCoS) for stable multi-task optimisation. Experiments on the Kvasir-SEG dataset show that EndoCaver achieves 0.922 Dice on clean data and 0.889 under severe image degradation, surpassing state-of-the-art methods while reducing model parameters by 90%. These results demonstrate its efficiency and robustness, making it well-suited for on-device clinical deployment. Code is available at https://github.com/ReaganWu/EndoCaver."}
{"id": "2601.22576", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.22576", "abs": "https://arxiv.org/abs/2601.22576", "authors": ["Hanjiang Zhu", "Pedro Martelleto Rezende", "Zhang Yang", "Tong Ye", "Bruce Z. Gao", "Feng Luo", "Siyu Huang", "Jiancheng Yang"], "title": "Bonnet: Ultra-fast whole-body bone segmentation from CT scans", "comment": "5 pages, 2 figures. Accepted for publication at the 2026 IEEE International Symposium on Biomedical Imaging (ISBI 2026)", "summary": "This work proposes Bonnet, an ultra-fast sparse-volume pipeline for whole-body bone segmentation from CT scans. Accurate bone segmentation is important for surgical planning and anatomical analysis, but existing 3D voxel-based models such as nnU-Net and STU-Net require heavy computation and often take several minutes per scan, which limits time-critical use. The proposed Bonnet addresses this by integrating a series of novel framework components including HU-based bone thresholding, patch-wise inference with a sparse spconv-based U-Net, and multi-window fusion into a full-volume prediction. Trained on TotalSegmentator and evaluated without additional tuning on RibSeg, CT-Pelvic1K, and CT-Spine1K, Bonnet achieves high Dice across ribs, pelvis, and spine while running in only 2.69 seconds per scan on an RTX A6000. Compared to strong voxel baselines, Bonnet attains a similar accuracy but reduces inference time by roughly 25x on the same hardware and tiling setup. The toolkit and pre-trained models will be released at https://github.com/HINTLab/Bonnet."}
{"id": "2601.22243", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.22243", "abs": "https://arxiv.org/abs/2601.22243", "authors": ["Zijun Wang", "Maria Nivetha A", "Ye Hu", "Rui Zhang"], "title": "Compressive Beam-Pattern-Aware Near-field Beam Training via Total Variation Denoising", "comment": null, "summary": "Extremely large antenna arrays envisioned for 6G incurs near-field effect, where steering vector depends on angles and range simultaneously. Polar-domain near-field codebooks can focus energy accurately but incur extra two-dimensional sweeping overhead; compressed-sensing (CS) approaches with Gaussian-masked DFT sensing offer a lower-overhead alternative. This letter revisits near-field beam training using conventional DFT codebooks. Unlike far-field responses that concentrate energy on a few isolated DFT beams, near-field responses produce contiguous, plateau-like energy segments with sharp transitions in the DFT beamspace. Pure LASSO denoising, therefore, tends to over-shrink magnitudes and fragment plateaus. We propose a beam-pattern-preserving beam training scheme for multiple-path scenarios that combines LASSO with a lightweight denoising pipeline: LASSO to suppress small-amplitude noise, followed by total variation (TV) to maintain plateau levels and edge sharpness. The two proximal steps require no near-field codebook design. Simulations with Gaussian pilots show consistent NMSE and cosine-similarity gains over least squares and LASSO at the same pilot budget."}
{"id": "2601.22637", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.22637", "abs": "https://arxiv.org/abs/2601.22637", "authors": ["Mohtady Barakat", "Omar Salah", "Ahmed Yasser", "Mostafa Ahmed", "Zahirul Arief", "Waleed Khan", "Dong Zhang", "Aondona Iorumbur", "Confidence Raymond", "Mohannad Barakat", "Noha Magdy"], "title": "Training Beyond Convergence: Grokking nnU-Net for Glioma Segmentation in Sub-Saharan MRI", "comment": null, "summary": "Gliomas are placing an increasingly clinical burden on Sub-Saharan Africa (SSA). In the region, the median survival for patients remains under two years, and access to diagnostic imaging is extremely limited. These constraints highlight an urgent need for automated tools that can extract the maximum possible information from each available scan, tools that are specifically trained on local data, rather than adapted from high-income settings where conditions are vastly different. We utilize the Brain Tumor Segmentation (BraTS) Africa 2025 Challenge dataset, an expert annotated collection of glioma MRIs. Our objectives are: (i) establish a strong baseline with nnUNet on this dataset, and (ii) explore whether the celebrated \"grokking\" phenomenon an abrupt, late training jump from memorization to superior generalization can be triggered to push performance without extra labels. We evaluate two training regimes. The first is a fast, budget-conscious approach that limits optimization to just a few epochs, reflecting the constrained GPU resources typically available in African institutions. Despite this limitation, nnUNet achieves strong Dice scores: 92.3% for whole tumor (WH), 86.6% for tumor core (TC), and 86.3% for enhancing tumor (ET). The second regime extends training well beyond the point of convergence, aiming to trigger a grokking-driven performance leap. With this approach, we were able to achieve grokking and enhanced our results to higher Dice scores: 92.2% for whole tumor (WH), 90.1% for tumor core (TC), and 90.2% for enhancing tumor (ET)."}
{"id": "2601.22270", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.22270", "abs": "https://arxiv.org/abs/2601.22270", "authors": ["Zulqarnain Bin Ashraf", "Triantafyllos Mavrovoltsos", "Constantinos Psomas", "Ioannis Krikidis", "Besma Smida"], "title": "Dual-Diode Unified SWIPT for High Data Rates with Adaptive Detection", "comment": "Accepted for presentation at IEEE International Conference on Communications (ICC) 2026", "summary": "Due to their low-complexity and energy-efficiency, unified simultaneous wireless information and power transfer (U-SWIPT) receivers are especially suitable for low-power Internet of Things (IoT) applications. Towards accurately modeling practical operating conditions, in this study, we provide a unified transient framework for a dual-diode U-SWIPT that jointly accounts for diode nonlinearity and capacitor-induced memory effects. The proposed model accurately describes the inherent time dependence of the rectifier, highlighting its fundamental impact on both energy harvesting (EH) and information decoding (ID) processes. Based on the provided memory-aware model, we design a low-complexity adaptive detector that learns the nonlinear state transition dynamics and performs decision-directed detection with linear complexity. The proposed detection scheme approaches maximum likelihood sequence detection (MLSD) performance in memory-dominated regimes, while avoiding the exponential search required by classical sequence detection. Overall, these results demonstrate that properly exploiting rectifier memory provides a better tradeoff between data rate and reliability for U-SWIPT receivers."}
{"id": "2601.22732", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.22732", "abs": "https://arxiv.org/abs/2601.22732", "authors": ["Hung-Chih Tu", "Bo-Syun Chen", "Yun-Chien Cheng"], "title": "Active Learning-Driven Lightweight YOLOv9: Enhancing Efficiency in Smart Agriculture", "comment": null, "summary": "This study addresses the demand for real-time detection of tomatoes and tomato flowers by agricultural robots deployed on edge devices in greenhouse environments. Under practical imaging conditions, object detection systems often face challenges such as large scale variations caused by varying camera distances, severe occlusion from plant structures, and highly imbalanced class distributions. These factors make conventional object detection approaches that rely on fully annotated datasets difficult to simultaneously achieve high detection accuracy and deployment efficiency. To overcome these limitations, this research proposes an active learning driven lightweight object detection framework, integrating data analysis, model design, and training strategy. First, the size distribution of objects in raw agricultural images is analyzed to redefine an operational target range, thereby improving learning stability under real-world conditions. Second, an efficient feature extraction module is incorporated to reduce computational cost, while a lightweight attention mechanism is introduced to enhance feature representation under multi-scale and occluded scenarios. Finally, an active learning strategy is employed to iteratively select high-information samples for annotation and training under a limited labeling budget, effectively improving the recognition performance of minority and small-object categories. Experimental results demonstrate that, while maintaining a low parameter count and inference cost suitable for edge-device deployment, the proposed method effectively improves the detection performance of tomatoes and tomato flowers in raw images. Under limited annotation conditions, the framework achieves an overall detection accuracy of 67.8% mAP, validating its practicality and feasibility for intelligent agricultural applications."}
{"id": "2601.22415", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.22415", "abs": "https://arxiv.org/abs/2601.22415", "authors": ["Sadaf Syed", "Wolfgang Utschick", "Michael Joham"], "title": "On the Optimality of Rate Balancing for Max-Min Fair Multicasting", "comment": null, "summary": "The max-min fair (MMF) multicasting problem is known to be NP-hard. In this work, we analytically derive the optimal solution to this NP-hard problem and establish the equivalence between rate balancing and the optimal MMF multicasting solution under certain conditions. Based on this theoretical insight, we propose a low-complexity algorithm for MMF multicasting that yields closed-form solutions. Simulation results validate our analysis and demonstrate that the proposed algorithm outperforms the state-of-the-art methods while being computationally more efficient."}
{"id": "2601.22755", "categories": ["eess.IV", "cs.GR", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.22755", "abs": "https://arxiv.org/abs/2601.22755", "authors": ["Xinxin Xu", "Yann Gousseau", "Christophe Kervazo", "Saïd Ladjal"], "title": "Synthetic Abundance Maps for Unsupervised Super-Resolution of Hyperspectral Remote Sensing Images", "comment": null, "summary": "Hyperspectral single image super-resolution (HS-SISR) aims to enhance the spatial resolution of hyperspectral images to fully exploit their spectral information. While considerable progress has been made in this field, most existing methods are supervised and require ground truth data for training-data that is often unavailable in practice. To overcome this limitation, we propose a novel unsupervised training framework for HS-SISR, based on synthetic abundance data. The approach begins by unmixing the hyperspectral image into endmembers and abundances. A neural network is then trained to perform abundance super-resolution using synthetic abundances only. These synthetic abundance maps are generated from a dead leaves model whose characteristics are inherited from the low-resolution image to be super-resolved. This trained network is subsequently used to enhance the spatial resolution of the original image's abundances, and the final super-resolution hyperspectral image is reconstructed by combining them with the endmembers. Experimental results demonstrate both the training value of the synthetic data and the effectiveness of the proposed method."}
{"id": "2601.22523", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.22523", "abs": "https://arxiv.org/abs/2601.22523", "authors": ["Yushi Lei", "Yusha Liu", "Guanghui Liu", "Lei Wan", "Kun Yang"], "title": "Superimposed-Pilot OTFS Under Fractional Doppler: Modular End-to-End Learning", "comment": "13 pages, 12 figures", "summary": "Orthogonal time frequency space (OTFS) modulation has emerged as a promising candidate to overcome the performance degradation of orthogonal frequency division multiplexing (OFDM), which are commonly encountered in high-mobility wireless communication scenarios. However, conventional OTFS transceivers rely on multiple separately designed signal-processing modules, whose isolated optimization often limits global optimal performance. To overcome limitations, this paper proposes a modular deep learning (DL) based end-to-end OTFS transceiver framework that consists of trainable and interchangeable neural network (NN) modules, including constellation mapping/demapping, superimposed pilot placement, inverse Zak (IZak)/Zak transforms, and a U-Net-enhanced NN tailored for joint channel estimation and detection (JCED), while explicitly accounting for the impact of the cyclic prefix. This physics-informed modular architecture provides flexibility for integration with conventional OTFS systems and adaptability to different communication configurations. Simulations demonstrate that the proposed design significantly outperforms baseline methods in terms of both normalized mean squared error (NMSE) and detection reliability, maintaining robustness under integer and fractional Doppler conditions. The results highlight the potential of DL-based end-to-end optimization to enable practical and high-performance OTFS transceivers for next-generation high-mobility networks."}
{"id": "2601.22878", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.22878", "abs": "https://arxiv.org/abs/2601.22878", "authors": ["Rajini Makam", "Sharanya Patil", "Dhatri Shankari T M", "Suresh Sundaram", "Narasimhan Sundararajan"], "title": "Development of Domain-Invariant Visual Enhancement and Restoration (DIVER) Approach for Underwater Images", "comment": "Submitted to IEEE Journal of Oceanic Engineering", "summary": "Underwater images suffer severe degradation due to wavelength-dependent attenuation, scattering, and illumination non-uniformity that vary across water types and depths. We propose an unsupervised Domain-Invariant Visual Enhancement and Restoration (DIVER) framework that integrates empirical correction with physics-guided modeling for robust underwater image enhancement. DIVER first applies either IlluminateNet for adaptive luminance enhancement or a Spectral Equalization Filter for spectral normalization. An Adaptive Optical Correction Module then refines hue and contrast using channel-adaptive filtering, while Hydro-OpticNet employs physics-constrained learning to compensate for backscatter and wavelength-dependent attenuation. The parameters of IlluminateNet and Hydro-OpticNet are optimized via unsupervised learning using a composite loss function. DIVER is evaluated on eight diverse datasets covering shallow, deep, and highly turbid environments, including both naturally low-light and artificially illuminated scenes, using reference and non-reference metrics. While state-of-the-art methods such as WaterNet, UDNet, and Phaseformer perform reasonably in shallow water, their performance degrades in deep, unevenly illuminated, or artificially lit conditions. In contrast, DIVER consistently achieves best or near-best performance across all datasets, demonstrating strong domain-invariant capability. DIVER yields at least a 9% improvement over SOTA methods in UCIQE. On the low-light SeaThru dataset, where color-palette references enable direct evaluation of color restoration, DIVER achieves at least a 4.9% reduction in GPMAE compared to existing methods. Beyond visual quality, DIVER also improves robotic perception by enhancing ORB-based keypoint repeatability and matching performance, confirming its robustness across diverse underwater environments."}
{"id": "2601.22724", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.22724", "abs": "https://arxiv.org/abs/2601.22724", "authors": ["Evangelos Koutsonas", "Alexandros-Apostolos A. Boulogeorgos", "Stylianos E. Trevlakis", "George C. Alexandropoulos", "Theodoros A. Tsiftsis", "Rui Zhang"], "title": "SORIS: A Self-Organized Reconfigurable Intelligent Surface Architecture for Wireless Communications", "comment": "12 figures, 1 table, journal", "summary": "In this paper, a new reconfigurable intelligent surface (RIS) hardware architecture, called self-organized RIS (SORIS), is proposed. The architecture incorporates a microcontroller connected to a single-antenna receiver operating at the same frequency as the RIS unit elements, operating either in transmission or reflection mode. The transmitting RIS elements enable the low latency estimation of both the incoming and outcoming channels at the microcontroller's side. In addition, a machine learning approach for estimating the incoming and outcoming channels involving the remaining RIS elements operating in reflection mode is devised. Specifically, by appropriately selecting a small number of elements in transmission mode, and based on the channel reciprocity principle, the respective channel coefficients are first estimated, which are then fed to a low-complexity neural network that, leveraging spatial channel correlation over RIS elements, returns predictions of the channel coefficients referring to the rest of elements. In this way, the SORIS microcontroller acquires channel state information, and accordingly reconfigures the panel's metamaterials to assist data communication between a transmitter and a receiver, without the need for separate connections with them. Moreover, the impact of channel estimation on the proposed solution, and a detailed complexity analysis for the used model, as well as a wiring density and control signaling analysis, is performed. The feasibility and efficacy of the proposed self-organized RIS design and operation are verified by Monte Carlo simulations, providing useful guidelines on the selection of the RIS elements for operating in transmission mode for initial channel estimation."}
{"id": "2601.23037", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.23037", "abs": "https://arxiv.org/abs/2601.23037", "authors": ["Brayan Monroy", "Jorge Bacca"], "title": "Scale Equivariance Regularization and Feature Lifting in High Dynamic Range Modulo Imaging", "comment": null, "summary": "Modulo imaging enables high dynamic range (HDR) acquisition by cyclically wrapping saturated intensities, but accurate reconstruction remains challenging due to ambiguities between natural image edges and artificial wrap discontinuities. This work proposes a learning-based HDR restoration framework that incorporates two key strategies: (i) a scale-equivariant regularization that enforces consistency under exposure variations, and (ii) a feature lifting input design combining the raw modulo image, wrapped finite differences, and a closed-form initialization. Together, these components enhance the network's ability to distinguish true structure from wrapping artifacts, yielding state-of-the-art performance across perceptual and linear HDR quality metrics."}
{"id": "2601.22765", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22765", "abs": "https://arxiv.org/abs/2601.22765", "authors": ["Rohit Varma Chiluvuri", "Santosh Nannuru"], "title": "Bayesian Matrix Completion Under Geometric Constraints", "comment": "4 pages, 3 figures, Accepted to ICASSP 2026", "summary": "The completion of a Euclidean distance matrix (EDM) from sparse and noisy observations is a fundamental challenge in signal processing, with applications in sensor network localization, acoustic room reconstruction, molecular conformation, and manifold learning. Traditional approaches, such as rank-constrained optimization and semidefinite programming, enforce geometric constraints but often struggle under sparse or noisy conditions. This paper introduces a hierarchical Bayesian framework that places structured priors directly on the latent point set generating the EDM, naturally embedding geometric constraints. By incorporating a hierarchical prior on latent point set, the model enables automatic regularization and robust noise handling. Posterior inference is performed using a Metropolis-Hastings within Gibbs sampler to handle coupled latent point posterior. Experiments on synthetic data demonstrate improved reconstruction accuracy compared to deterministic baselines in sparse regimes."}
{"id": "2601.23103", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.23103", "abs": "https://arxiv.org/abs/2601.23103", "authors": ["Ping Chen", "Zicheng Huang", "Xiangming Wang", "Yungeng Liu", "Bingyu Liang", "Haijin Zeng", "Yongyong Chen"], "title": "Vision-Language Controlled Deep Unfolding for Joint Medical Image Restoration and Segmentation", "comment": "18 pages, medical image", "summary": "We propose VL-DUN, a principled framework for joint All-in-One Medical Image Restoration and Segmentation (AiOMIRS) that bridges the gap between low-level signal recovery and high-level semantic understanding. While standard pipelines treat these tasks in isolation, our core insight is that they are fundamentally synergistic: restoration provides clean anatomical structures to improve segmentation, while semantic priors regularize the restoration process. VL-DUN resolves the sub-optimality of sequential processing through two primary innovations. (1) We formulate AiOMIRS as a unified optimization problem, deriving an interpretable joint unfolding mechanism where restoration and segmentation are mathematically coupled for mutual refinement. (2) We introduce a frequency-aware Mamba mechanism to capture long-range dependencies for global segmentation while preserving the high-frequency textures necessary for restoration. This allows for efficient global context modeling with linear complexity, effectively mitigating the spectral bias of standard architectures. As a pioneering work in the AiOMIRS task, VL-DUN establishes a new state-of-the-art across multi-modal benchmarks, improving PSNR by 0.92 dB and the Dice coefficient by 9.76\\%. Our results demonstrate that joint collaborative learning offers a superior, more robust solution for complex clinical workflows compared to isolated task processing. The codes are provided in https://github.com/cipi666/VLDUN."}
{"id": "2601.22915", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.22915", "abs": "https://arxiv.org/abs/2601.22915", "authors": ["Fatih Merdan", "Ozgur B. Akan"], "title": "Intrinsic MIMO Particle Communication Channel with Random Advection", "comment": "6 pages, 5 figures", "summary": "In this work, receiver diversity in advection-dominated diffusion-advection channels is investigated. Strong directed flow fundamentally alters the communication-theoretic properties of molecular communication systems (MC). Specifically, advection preserves the temporal ordering and shape of transmitted pulses, enabling pulse-based and higher-order modulation schemes that are typically infeasible in purely diffusive environments. Focusing on a single transmitter and a single type of information molecule, it is demonstrated that spatially distributed receivers can observe distinct realizations of the same transmitted signal, giving rise to diversity gain. Several receiver combining strategies are evaluated and shown to improve detection performance compared to single-receiver operation, particularly in low-to-moderate signal-to-noise ratio (SNR) regimes. The results provide a structured framework for understanding receiver-side diversity in molecular communication, highlighting the role of advection as a key enabler for reliable pulse-based signaling. This perspective establishes a foundation for future studies on advanced modulation, joint equalization and detection, and multi-molecule MIMO extensions that can further enhance the performance and physical applicability of MC systems."}
{"id": "2601.23148", "categories": ["eess.IV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.23148", "abs": "https://arxiv.org/abs/2601.23148", "authors": ["Han Wang", "Yhonatan Kvich", "Eduardo Pérez", "Florian Römer", "Yonina C. Eldar"], "title": "Compressed BC-LISTA via Low-Rank Convolutional Decomposition", "comment": "Inverse Problems, Model Compression, Compressed Sensing, Deep Unrolling, Computational Imaging", "summary": "We study Sparse Signal Recovery (SSR) methods for multichannel imaging with compressed {forward and backward} operators that preserve reconstruction accuracy. We propose a Compressed Block-Convolutional (C-BC) measurement model based on a low-rank Convolutional Neural Network (CNN) decomposition that is analytically initialized from a low-rank factorization of physics-derived forward/backward operators in time delay-based measurements. We use Orthogonal Matching Pursuit (OMP) to select a compact set of basis filters from the analytic model and compute linear mixing coefficients to approximate the full model. We consider the Learned Iterative Shrinkage-Thresholding Algorithm (LISTA) network as a representative example for which the C-BC-LISTA extension is presented. In simulated multichannel ultrasound imaging across multiple Signal-to-Noise Ratios (SNRs), C-BC-LISTA requires substantially fewer parameters and smaller model size than other state-of-the-art (SOTA) methods while improving reconstruction accuracy. In ablations over OMP, Singular Value Decomposition (SVD)-based, and random initializations, OMP-initialized structured compression performs best, yielding the most efficient training and the best performance."}
{"id": "2601.22989", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.22989", "abs": "https://arxiv.org/abs/2601.22989", "authors": ["Saeid Pakravan", "Mohsen Ahmadzadeh", "Ming Zeng", "Wessam Ajib", "Ji Wang", "Xingwang Li"], "title": "Fluid Antenna Systems under Channel Uncertainty and Hardware Impairments: Trends, Challenges, and Future Research Directions", "comment": "12 pages", "summary": "Fluid antenna systems (FAS) have recently emerged as a promising paradigm for achieving spatially reconfigurable, compact, and energy-efficient wireless communications in beyond fifth-generation (B5G) and sixth-generation (6G) networks. By dynamically repositioning a liquid-based radiating element within a confined physical structure, FAS can exploit spatial diversity without relying on multiple fixed antenna elements. This spatial mobility provides a new degree of freedom for mitigating channel fading and interference, while maintaining low hardware complexity and power consumption. However, the performance of FAS in realistic deployments is strongly affected by channel uncertainty, hardware nonidealities, and mechanical constraints, all of which can substantially deviate from idealized analytical assumptions. This paper presents a comprehensive survey of the operation and design of FAS under such practical considerations. Key aspects include the characterization of spatio-temporal channel uncertainty, analysis of hardware and mechanical impairments such as RF nonlinearity, port coupling, and fluid response delay, as well as the exploration of robust design and learning-based control strategies to enhance system reliability. Finally, open research directions are identified, aiming to guide future developments toward robust, adaptive, and cross-domain FAS design for next-generation wireless networks."}
{"id": "2601.23201", "categories": ["eess.IV", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.23201", "abs": "https://arxiv.org/abs/2601.23201", "authors": ["Darshan Thaker", "Mahmoud Mostapha", "Radu Miron", "Shihan Qiu", "Mariappan Nadar"], "title": "Scale-Cascaded Diffusion Models for Super-Resolution in Medical Imaging", "comment": "Accepted at IEEE International Symposium for Biomedical Imaging (ISBI) 2026", "summary": "Diffusion models have been increasingly used as strong generative priors for solving inverse problems such as super-resolution in medical imaging. However, these approaches typically utilize a diffusion prior trained at a single scale, ignoring the hierarchical scale structure of image data. In this work, we propose to decompose images into Laplacian pyramid scales and train separate diffusion priors for each frequency band. We then develop an algorithm to perform super-resolution that utilizes these priors to progressively refine reconstructions across different scales. Evaluated on brain, knee, and prostate MRI data, our approach both improves perceptual quality over baselines and reduces inference time through smaller coarse-scale networks. Our framework unifies multiscale reconstruction and diffusion priors for medical image super-resolution."}
{"id": "2601.23076", "categories": ["eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.23076", "abs": "https://arxiv.org/abs/2601.23076", "authors": ["Jayadev Joy", "Sundeep Rangan"], "title": "Learning-Based Signal Recovery in Nonlinear Systems with Spectrally Separated Interference", "comment": null, "summary": "Upper Mid-Band (FR3, 7-24 GHz) receivers for 6G must operate over wide bandwidths in dense spectral environments, making them particularly vulnerable to strong adjacent-band interference and front-end nonlinearities. While conventional linear receivers can suppress spectrally separated interferers under ideal hardware assumptions, receiver saturation and finite-resolution quantization cause nonlinear spectral leakage that severely degrades performance in practical wideband radios. We study the recovery of a desired signal from nonlinear receiver observations corrupted by a high-power out-of-band interferer. The receiver front-end is modeled as a smooth, memoryless nonlinearity followed by additive noise and optional quantization. To mitigate these nonlinear and quantization-induced distortions, we propose a learned multi-layer Vector Approximate Message Passing (LMLVAMP) algorithm that incorporates spectral priors with neural network based denoising. Simulation results demonstrate significant performance gains over conventional methods, particularly in high-interference regimes representative of FR3 coexistence scenarios."}
{"id": "2601.23231", "categories": ["eess.IV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.23231", "abs": "https://arxiv.org/abs/2601.23231", "authors": ["George Webber", "Alexander Denker", "Riccardo Barbano", "Andrew J Reader"], "title": "Solving Inverse Problems with Flow-based Models via Model Predictive Control", "comment": null, "summary": "Flow-based generative models provide strong unconditional priors for inverse problems, but guiding their dynamics for conditional generation remains challenging. Recent work casts training-free conditional generation in flow models as an optimal control problem; however, solving the resulting trajectory optimisation is computationally and memory intensive, requiring differentiation through the flow dynamics or adjoint solves. We propose MPC-Flow, a model predictive control framework that formulates inverse problem solving with flow-based generative models as a sequence of control sub-problems, enabling practical optimal control-based guidance at inference time. We provide theoretical guarantees linking MPC-Flow to the underlying optimal control objective and show how different algorithmic choices yield a spectrum of guidance algorithms, including regimes that avoid backpropagation through the generative model trajectory. We evaluate MPC-Flow on benchmark image restoration tasks, spanning linear and non-linear settings such as in-painting, deblurring, and super-resolution, and demonstrate strong performance and scalability to massive state-of-the-art architectures via training-free guidance of FLUX.2 (32B) in a quantised setting on consumer hardware."}
{"id": "2601.23119", "categories": ["eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.23119", "abs": "https://arxiv.org/abs/2601.23119", "authors": ["Ruibin Chen", "Jayadev Joy", "Yaqi Hu", "Mingsheng Yin", "Marco Mezzavilla", "Sundeep Rangan"], "title": "Interpolation Techniques for Fast Channel Estimation in Ray Tracing", "comment": "This is the authors accepted version of a paper published in the Proceedings of the 2024 58th Asilomar Conference on Signals, Systems, and Computers", "summary": "Ray tracing is increasingly utilized in wireless system simulations to estimate channel paths. In large-scale simulations with complex environments, ray tracing at high resolution can be computationally demanding. To reduce the computation, this paper presents a novel method for conducting ray tracing at a coarse set of reference points and interpolating the channels at other locations. The key insight is to interpolate the images of reflected points. In addition to the computational savings, the method directly captures the spherical nature of each wavefront enabling fast and accurate computation of channels using line-of-sight MIMO and other wide aperture techniques. Through empirical validation and comparison with exhaustive ray tracing, we demonstrate the efficacy and practicality of our approach in achieving high-fidelity channel predictions with reduced computational resources."}
{"id": "2601.22755", "categories": ["eess.IV", "cs.GR", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.22755", "abs": "https://arxiv.org/abs/2601.22755", "authors": ["Xinxin Xu", "Yann Gousseau", "Christophe Kervazo", "Saïd Ladjal"], "title": "Synthetic Abundance Maps for Unsupervised Super-Resolution of Hyperspectral Remote Sensing Images", "comment": null, "summary": "Hyperspectral single image super-resolution (HS-SISR) aims to enhance the spatial resolution of hyperspectral images to fully exploit their spectral information. While considerable progress has been made in this field, most existing methods are supervised and require ground truth data for training-data that is often unavailable in practice. To overcome this limitation, we propose a novel unsupervised training framework for HS-SISR, based on synthetic abundance data. The approach begins by unmixing the hyperspectral image into endmembers and abundances. A neural network is then trained to perform abundance super-resolution using synthetic abundances only. These synthetic abundance maps are generated from a dead leaves model whose characteristics are inherited from the low-resolution image to be super-resolved. This trained network is subsequently used to enhance the spatial resolution of the original image's abundances, and the final super-resolution hyperspectral image is reconstructed by combining them with the endmembers. Experimental results demonstrate both the training value of the synthetic data and the effectiveness of the proposed method."}
