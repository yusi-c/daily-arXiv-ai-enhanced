{"id": "2509.22685", "categories": ["eess.IV", "cs.CV", "cs.GR", "I.3.7; I.4.1; I.4.5; I.6.3"], "pdf": "https://arxiv.org/pdf/2509.22685", "abs": "https://arxiv.org/abs/2509.22685", "authors": ["Adam Haroon", "Anush Lakshman", "Badrinath Balasubramaniam", "Beiwen Li"], "title": "VIRTUS-FPP: Virtual Sensor Modeling for Fringe Projection Profilometry in NVIDIA Isaac Sim", "comment": "16 pages, 13 figures, in preparation for IEEE Transactions on\n  Instrumentation and Measurement", "summary": "Fringe projection profilometry (FPP) has been established as a high-accuracy\n3D reconstruction method capable of achieving sub-pixel accuracy. However, this\ntechnique faces significant constraints due to complex calibration\nrequirements, bulky system footprint, and sensitivity to environmental\nconditions. To address these limitations, we present VIRTUS-FPP, the first\ncomprehensive physics-based virtual sensor modeling framework for FPP built in\nNVIDIA Isaac Sim. By leveraging the physics-based rendering and programmable\nsensing capabilities of simulation, our framework enables end-to-end modeling\nfrom calibration to reconstruction with full mathematical fidelity to the\nunderlying principles of structured light. We conduct comprehensive virtual\ncalibration and validate our system's reconstruction accuracy through\nquantitative comparison against ground truth geometry. Additionally, we\ndemonstrate the ability to model the virtual system as a digital twin by\nreplicating a physical FPP system in simulation and validating correspondence\nbetween virtual and real-world measurements. Experimental results demonstrate\nthat VIRTUS-FPP accurately models optical phenomena critical to FPP and\nachieves results comparable to real-world systems while offering unprecedented\nflexibility for system configuration, sensor prototyping, and environmental\ncontrol. This framework significantly accelerates the development of real-world\nFPP systems by enabling rapid virtual prototyping before physical\nimplementation."}
{"id": "2509.22696", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.22696", "abs": "https://arxiv.org/abs/2509.22696", "authors": ["MohammadReza Abbaszadeh Bavil Soflaei", "Karim SamadZamini"], "title": "Explainable Deep Learning for Cataract Detection in Retinal Images: A Dual-Eye and Knowledge Distillation Approach", "comment": "13 Pages, 8 figures, Submitted as part of PhD research", "summary": "Cataract remains a leading cause of visual impairment worldwide, and early\ndetection from retinal imaging is critical for timely intervention. We present\na deep learning pipeline for cataract classification using the Ocular Disease\nRecognition dataset, containing left and right fundus photographs from 5000\npatients. We evaluated CNNs, transformers, lightweight architectures, and\nknowledge-distilled models. The top-performing model, Swin-Base Transformer,\nachieved 98.58% accuracy and an F1-score of 0.9836. A distilled MobileNetV3,\ntrained with Swin-Base knowledge, reached 98.42% accuracy and a 0.9787 F1-score\nwith greatly reduced computational cost. The proposed dual-eye Siamese variant\nof the distilled MobileNet, integrating information from both eyes, achieved an\naccuracy of 98.21%. Explainability analysis using Grad-CAM demonstrated that\nthe CNNs concentrated on medically significant features, such as lens opacity\nand central blur. These results show that accurate, interpretable cataract\ndetection is achievable even with lightweight models, supporting potential\nclinical integration in resource-limited settings"}
{"id": "2509.22712", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.22712", "abs": "https://arxiv.org/abs/2509.22712", "authors": ["Zihan Wei", "Tapabrata Chakraborti"], "title": "Achieving Fair Skin Lesion Detection through Skin Tone Normalization and Channel Pruning", "comment": "29pages, 12 figures", "summary": "Recent works have shown that deep learning based skin lesion image\nclassification models trained on unbalanced dataset can exhibit bias toward\nprotected demographic attributes such as race, age,and gender. Current bias\nmitigation methods usually either achieve high level of fairness with the\ndegradation of accuracy, or only improve the model fairness on a single\nattribute. Additionally usually most bias mitigation strategies are either pre\nhoc through data processing or post hoc through fairness evaluation, instead of\nbeing integrated into the model learning itself. To solve these existing\ndrawbacks, we propose a new Individual Typology Angle (ITA) Loss-based skin\ntone normalization and data augmentation method that directly feeds into an\nadaptable meta learning-based joint channel pruning framework. In skin tone\nnormalization, ITA is used to estimate skin tone type and adjust automatically\nto target tones for dataset balancing. In the joint channel pruning framework,\ntwo nested optimization loops are used to find critical channels.The inner\noptimization loop finds and prunes the local critical channels by weighted soft\nnearest neighbor loss, and the outer optimization loop updates the weight of\neach attribute using group wise variance loss on meta-set. Experiments\nconducted in the ISIC2019 dataset validate the effectiveness of our method in\nsimultaneously improving the fairness of the model on multiple sensitive\nattributes without significant degradation of accuracy. Finally, although the\npruning mechanism adds some computational cost during training phase, usually\ntraining is done off line. More importantly,"}
{"id": "2509.22736", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG", "physics.med-ph", "stat.ML"], "pdf": "https://arxiv.org/pdf/2509.22736", "abs": "https://arxiv.org/abs/2509.22736", "authors": ["Merve Gülle", "Junno Yun", "Yaşar Utku Alçalar", "Mehmet Akçakaya"], "title": "Consistency Models as Plug-and-Play Priors for Inverse Problems", "comment": null, "summary": "Diffusion models have found extensive use in solving numerous inverse\nproblems. Such diffusion inverse problem solvers aim to sample from the\nposterior distribution of data given the measurements, using a combination of\nthe unconditional score function and an approximation of the posterior related\nto the forward process. Recently, consistency models (CMs) have been proposed\nto directly predict the final output from any point on the diffusion ODE\ntrajectory, enabling high-quality sampling in just a few NFEs. CMs have also\nbeen utilized for inverse problems, but existing CM-based solvers either\nrequire additional task-specific training or utilize data fidelity operations\nwith slow convergence, not amenable to large-scale problems. In this work, we\nreinterpret CMs as proximal operators of a prior, enabling their integration\ninto plug-and-play (PnP) frameworks. We propose a solver based on PnP-ADMM,\nwhich enables us to leverage the fast convergence of conjugate gradient method.\nWe further accelerate this with noise injection and momentum, dubbed PnP-CM,\nand show it maintains the convergence properties of the baseline PnP-ADMM. We\nevaluate our approach on a variety of inverse problems, including inpainting,\nsuper-resolution, Gaussian deblurring, and magnetic resonance imaging (MRI)\nreconstruction. To the best of our knowledge, this is the first CM trained for\nMRI datasets. Our results show that PnP-CM achieves high-quality\nreconstructions in as few as 4 NFEs, and can produce meaningful results in 2\nsteps, highlighting its effectiveness in real-world inverse problems while\noutperforming comparable CM-based approaches."}
{"id": "2509.22795", "categories": ["eess.SP", "cs.AI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2509.22795", "abs": "https://arxiv.org/abs/2509.22795", "authors": ["Yi Hu", "Zheyuan Cheng"], "title": "Generative Modeling and Decision Fusion for Unknown Event Detection and Classification Using Synchrophasor Data", "comment": "10 pages", "summary": "Reliable detection and classification of power system events are critical for\nmaintaining grid stability and situational awareness. Existing approaches often\ndepend on limited labeled datasets, which restricts their ability to generalize\nto rare or unseen disturbances. This paper proposes a novel framework that\nintegrates generative modeling, sliding-window temporal processing, and\ndecision fusion to achieve robust event detection and classification using\nsynchrophasor data. A variational autoencoder-generative adversarial network is\nemployed to model normal operating conditions, where both reconstruction error\nand discriminator error are extracted as anomaly indicators. Two complementary\ndecision strategies are developed: a threshold-based rule for computational\nefficiency and a convex hull-based method for robustness under complex error\ndistributions. These features are organized into spatiotemporal detection and\nclassification matrices through a sliding-window mechanism, and an\nidentification and decision fusion stage integrates the outputs across PMUs.\nThis design enables the framework to identify known events while systematically\nclassifying previously unseen disturbances into a new category, addressing a\nkey limitation of supervised classifiers. Experimental results demonstrate\nstate-of-the-art accuracy, surpassing machine learning, deep learning, and\nenvelope-based baselines. The ability to recognize unknown events further\nhighlights the adaptability and practical value of the proposed approach for\nwide-area event analysis in modern power systems."}
{"id": "2509.23165", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2509.23165", "abs": "https://arxiv.org/abs/2509.23165", "authors": ["Guillaume Houry", "Tom Boeken", "Stéphanie Allassonnière", "Jean Feydy"], "title": "Untangling Vascular Trees for Surgery and Interventional Radiology", "comment": null, "summary": "The diffusion of minimally invasive, endovascular interventions motivates the\ndevelopment of visualization methods for complex vascular networks. We propose\na planar representation of blood vessel trees which preserves the properties\nthat are most relevant to catheter navigation: topology, length and curvature.\nTaking as input a three-dimensional digital angiography, our algorithm produces\na faithful two-dimensional map of the patient's vessels within a few seconds.\nTo this end, we propose optimized implementations of standard morphological\nfilters and a new recursive embedding algorithm that preserves the global\norientation of the vascular network. We showcase our method on peroperative\nimages of the brain, pelvic and knee artery networks. On the clinical side, our\nmethod simplifies the choice of devices prior to and during the intervention.\nThis lowers the risk of failure during navigation or device deployment and may\nhelp to reduce the gap between expert and common intervention centers. From a\nresearch perspective, our method simulates the cadaveric display of artery\ntrees from anatomical dissections. This opens the door to large population\nstudies on the branching patterns and tortuosity of fine human blood vessels.\nOur code is released under the permissive MIT license as part of the\nscikit-shapes Python library (https://scikit-shapes.github.io )."}
{"id": "2509.22810", "categories": ["eess.SP", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.22810", "abs": "https://arxiv.org/abs/2509.22810", "authors": ["Jianheng Zhou", "Chenyu Liu", "Jinan Zhou", "Yi Ding", "Yang Liu", "Haoran Luo", "Ziyu Jia", "Xinliang Zhou"], "title": "Introducing Multimodal Paradigm for Learning Sleep Staging PSG via General-Purpose Model", "comment": null, "summary": "Sleep staging is essential for diagnosing sleep disorders and assessing\nneurological health. Existing automatic methods typically extract features from\ncomplex polysomnography (PSG) signals and train domain-specific models, which\noften lack intuitiveness and require large, specialized datasets. To overcome\nthese limitations, we introduce a new paradigm for sleep staging that leverages\nlarge multimodal general-purpose models to emulate clinical diagnostic\npractices. Specifically, we convert raw one-dimensional PSG time-series into\nintuitive two-dimensional waveform images and then fine-tune a multimodal large\nmodel to learn from these representations. Experiments on three public datasets\n(ISRUC, MASS, SHHS) demonstrate that our approach enables general-purpose\nmodels, without prior exposure to sleep data, to acquire robust staging\ncapabilities. Moreover, explanation analysis reveals our model learned to mimic\nthe visual diagnostic workflow of human experts for sleep staging by PSG\nimages. The proposed method consistently outperforms state-of-the-art baselines\nin accuracy and robustness, highlighting its efficiency and practical value for\nmedical applications. The code for the signal-to-image pipeline and the PSG\nimage dataset will be released."}
{"id": "2509.23200", "categories": ["eess.IV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2509.23200", "abs": "https://arxiv.org/abs/2509.23200", "authors": ["Linwei Zhu", "Junhao Zhu", "Xu Zhang", "Huan Zhang", "Ye Li", "Runmin Cong", "Sam Kwong"], "title": "Enhanced Quality Aware-Scalable Underwater Image Compression", "comment": "19 pages, 14 figures; submitted to ACM Transactions on Multimedia\n  Computing, Communications, and Applications", "summary": "Underwater imaging plays a pivotal role in marine exploration and ecological\nmonitoring. However, it faces significant challenges of limited transmission\nbandwidth and severe distortion in the aquatic environment. In this work, to\nachieve the target of both underwater image compression and enhancement\nsimultaneously, an enhanced quality-aware scalable underwater image compression\nframework is presented, which comprises a Base Layer (BL) and an Enhancement\nLayer (EL). In the BL, the underwater image is represented by controllable\nnumber of non-zero sparse coefficients for coding bits saving. Furthermore, the\nunderwater image enhancement dictionary is derived with shared sparse\ncoefficients to make reconstruction close to the enhanced version. In the EL, a\ndual-branch filter comprising rough filtering and detail refinement branches is\ndesigned to produce a pseudo-enhanced version for residual redundancy removal\nand to improve the quality of final reconstruction. Extensive experimental\nresults demonstrate that the proposed scheme outperforms the state-of-the-art\nworks under five large-scale underwater image datasets in terms of Underwater\nImage Quality Measure (UIQM)."}
{"id": "2509.22869", "categories": ["eess.SP", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.22869", "abs": "https://arxiv.org/abs/2509.22869", "authors": ["Abdulkadir Bilge", "Erdem Ergen", "Burak Soner", "Sinem Coleri"], "title": "Scalable Wi-Fi RSS-Based Indoor Localization via Automatic Vision-Assisted Calibration", "comment": "Presented at the ICAT 2025 conference, Sarajevo, September 2025. See\n  https://icat.etf.unsa.ba/2025/", "summary": "Wi-Fi-based positioning promises a scalable and privacy-preserving solution\nfor location-based services in indoor environments such as malls, airports, and\ncampuses. RSS-based methods are widely deployable as RSS data is available on\nall Wi-Fi-capable devices, but RSS is highly sensitive to multipath, channel\nvariations, and receiver characteristics. While supervised learning methods\noffer improved robustness, they require large amounts of labeled data, which is\noften costly to obtain. We introduce a lightweight framework that solves this\nby automating high-resolution synchronized RSS-location data collection using a\nshort, camera-assisted calibration phase. An overhead camera is calibrated only\nonce with ArUco markers and then tracks a device collecting RSS data from\nbroadcast packets of nearby access points across Wi-Fi channels. The resulting\n(x, y, RSS) dataset is used to automatically train mobile-deployable\nlocalization algorithms, avoiding the privacy concerns of continuous video\nmonitoring. We quantify the accuracy limits of such vision-assisted RSS data\ncollection under key factors such as tracking precision and label\nsynchronization. Using the collected experimental data, we benchmark\ntraditional and supervised learning approaches under varying signal conditions\nand device types, demonstrating improved accuracy and generalization,\nvalidating the utility of the proposed framework for practical use. All code,\ntools, and datasets are released as open source."}
{"id": "2509.23341", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2509.23341", "abs": "https://arxiv.org/abs/2509.23341", "authors": ["Tiago de S. Fernandes", "Ricardo L. de Queiroz"], "title": "On the Impact of LiDAR Point Cloud Compression on Remote Semantic Segmentation", "comment": "5 pages, 8 figures", "summary": "Autonomous vehicles rely on LiDAR sensors to generate 3D point clouds for\naccurate segmentation and object detection. In a context of a smart city\nframework, we would like to understand the effect that transmission\n(compression) can have on remote (cloud) segmentation, instead of local\nprocessing. In this short paper, we try to understand the impact of point cloud\ncompression on semantic segmentation performance and to estimate the necessary\nbandwidth requirements. We developed a new (suitable) distortion metric to\nevaluate such an impact. Two of MPEG's compression algorithms (GPCC and L3C2)\nand two leading semantic segmentation algorithms (2DPASS and PVKD) were tested\nover the Semantic KITTI dataset. Results indicate that high segmentation\nquality requires communication throughput of approximately 0.6 MB/s for G-PCC\nand 2.8 MB/s for L3C2. These results are important in order to plan\ninfrastructure resources for autonomous navigation."}
{"id": "2509.22891", "categories": ["eess.SP", "astro-ph.IM"], "pdf": "https://arxiv.org/pdf/2509.22891", "abs": "https://arxiv.org/abs/2509.22891", "authors": ["Ashwini Kulkarni", "Santosh Nannuru"], "title": "Time-Frequency Analysis of Non-Uniformly Sampled Signals via Sample Density Adaptation", "comment": null, "summary": "The analysis of non-stationary signals in non-uniformly sampled data is a\nchallenging task. Time-integrated methods, such as the generalised Lomb-Scargle\n(GLS) periodogram, provide a robust statistical assessment of persistent\nperiodicities but are insensitive to transient events. Conversely, existing\ntime-frequency methods often rely on fixed-duration windows or interpolation,\nwhich can be suboptimal for non-uniform data. We introduce the non-uniform\nStockwell-transform (NUST), a time-frequency framework that applies a localized\ndensity adaptive spectral analysis directly to non-uniformly sampled data. NUST\nemploys a doubly adaptive window that adjusts its width based on both frequency\nand local data density, providing detailed time-frequency information for both\ntransient and persistent signals. We validate the NUST on numerous\nnon-uniformly sampled synthetic signals, demonstrating its superior\ntime-localization performance compared to GLS. Furthermore, we apply NUST to\nHARPS radial velocity data of the multi-planetary system HD 10180, successfully\ndistinguishing coherent planetary signals from stellar activity."}
{"id": "2509.23442", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2509.23442", "abs": "https://arxiv.org/abs/2509.23442", "authors": ["Md. Saiful Bari Siddiqui", "Mohammed Imamul Hassan Bhuiyan"], "title": "S$^3$F-Net: A Multi-Modal Approach to Medical Image Classification via Spatial-Spectral Summarizer Fusion Network", "comment": "Submitted to IEEE Journal of Biomedical and Health Informatics\n  (JBHI). This preprint includes few additional details not present in the\n  journal submission", "summary": "Convolutional Neural Networks have become a cornerstone of medical image\nanalysis due to their proficiency in learning hierarchical spatial features.\nHowever, this focus on a single domain is inefficient at capturing global,\nholistic patterns and fails to explicitly model an image's frequency-domain\ncharacteristics. To address these challenges, we propose the Spatial-Spectral\nSummarizer Fusion Network (S$^3$F-Net), a dual-branch framework that learns\nfrom both spatial and spectral representations simultaneously. The S$^3$F-Net\nperforms a fusion of a deep spatial CNN with our proposed shallow spectral\nencoder, SpectraNet. SpectraNet features the proposed SpectralFilter layer,\nwhich leverages the Convolution Theorem by applying a bank of learnable filters\ndirectly to an image's full Fourier spectrum via a computation-efficient\nelement-wise multiplication. This allows the SpectralFilter layer to attain a\nglobal receptive field instantaneously, with its output being distilled by a\nlightweight summarizer network. We evaluate S$^3$F-Net across four medical\nimaging datasets spanning different modalities to validate its efficacy and\ngeneralizability. Our framework consistently and significantly outperforms its\nstrong spatial-only baseline in all cases, with accuracy improvements of up to\n5.13%. With a powerful Bilinear Fusion, S$^3$F-Net achieves a SOTA competitive\naccuracy of 98.76% on the BRISC2025 dataset. Concatenation Fusion performs\nbetter on the texture-dominant Chest X-Ray Pneumonia dataset, achieving 93.11%\naccuracy, surpassing many top-performing, much deeper models. Our\nexplainability analysis also reveals that the S$^3$F-Net learns to dynamically\nadjust its reliance on each branch based on the input pathology. These results\nverify that our dual-domain approach is a powerful and generalizable paradigm\nfor medical image analysis."}
{"id": "2509.23065", "categories": ["eess.SP", "math.CV"], "pdf": "https://arxiv.org/pdf/2509.23065", "abs": "https://arxiv.org/abs/2509.23065", "authors": ["Mohammad Amin Saeidi", "Hina Tabassum"], "title": "Resource Allocation in Cooperative Mid-band/THz Networks in the Presence of Mobility", "comment": "This paper has been accepted for publication in IEEE journals", "summary": "This paper develops a comprehensive framework to investigate and optimize the\ndownlink performance of cooperative multi-band networks (MBNs) operating on\nupper mid-band (UMB) and terahertz (THz) frequencies, where base stations (BSs)\nin each band cooperatively serve users. The framework captures sophisticated\nfeatures such as near-field channel modeling, fully and partially connected\nantenna architectures, and users' mobility. First, we consider joint user\nassociation and hybrid beamforming optimization to maximize the system\nsum-rate, subject to power constraints, maximum cluster size of cooperating\nBSs, and users' quality-of-service (QoS) constraints. By leveraging fractional\nprogramming FP and majorization-minimization techniques, an iterative algorithm\nis proposed to solve the non-convex optimization problem. We then consider\nhandover (HO)-aware resource allocation for moving users in a cooperative\nUMB/THz MBN. Two HO-aware resource allocation methods are proposed. The first\nmethod focuses on maximizing the HO-aware system sum-rate subject to HO-aware\nQoS constraints. Using Jensen's inequality and properties of logarithmic\nfunctions, the non-convex optimization problem is tightly approximated with a\nconvex one and solved. The second method addresses a multi-objective\noptimization problem to maximize the system sum-rate, while minimizing the\ntotal number of HOs. Numerical results demonstrate the efficacy of the proposed\nalgorithms, cooperative UMB/THz MBN over stand-alone THz networks, as well as\nthe critical importance of accurate near-field modeling in extremely large\nantenna arrays. Moreover, the proposed HO-aware resource allocation methods\neffectively mitigate the impact of HOs, enhancing performance in the considered\nsystem."}
{"id": "2509.23590", "categories": ["eess.IV", "eess.SP"], "pdf": "https://arxiv.org/pdf/2509.23590", "abs": "https://arxiv.org/abs/2509.23590", "authors": ["Fangyu Liu", "Peiwen Jiang", "Wenjin Wang", "Chao-Kai Wen", "Shi Jin", "Jun Zhang"], "title": "Foundation Model-Based Adaptive Semantic Image Transmission for Dynamic Wireless Environments", "comment": null, "summary": "Foundation model-based semantic transmission has recently shown great\npotential in wireless image communication. However, existing methods exhibit\ntwo major limitations: (i) they overlook the varying importance of semantic\ncomponents for specific downstream tasks, and (ii) they insufficiently exploit\nwireless domain knowledge, resulting in limited robustness under dynamic\nchannel conditions. To overcome these challenges, this paper proposes a\nfoundation model-based adaptive semantic image transmission system for dynamic\nwireless environments, such as autonomous driving. The proposed system\ndecomposes each image into a semantic segmentation map and a compressed\nrepresentation, enabling task-aware prioritization of critical objects and\nfine-grained textures. A task-adaptive precoding mechanism then allocates radio\nresources according to the semantic importance of extracted features. To ensure\naccurate channel information for precoding, a channel estimation knowledge map\n(CEKM) is constructed using a conditional diffusion model that integrates user\nposition, velocity, and sparse channel samples to train scenario-specific\nlightweight estimators. At the receiver, a conditional diffusion model\nreconstructs high-quality images from the received semantic features, ensuring\nrobustness against channel impairments and partial data loss. Simulation\nresults on the BDD100K dataset with multi-scenario channels generated by\nQuaDRiGa demonstrate that the proposed method outperforms existing approaches\nin terms of perceptual quality (SSIM, LPIPS, FID), task-specific accuracy\n(IoU), and transmission efficiency. These results highlight the effectiveness\nof integrating task-aware semantic decomposition, scenario-adaptive channel\nestimation, and diffusion-based reconstruction for robust semantic transmission\nin dynamic wireless environments."}
{"id": "2509.23302", "categories": ["eess.SP", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2509.23302", "abs": "https://arxiv.org/abs/2509.23302", "authors": ["Wilson de Souza Junior", "Taufik Abrao", "Amine Mezghani", "Ekram Hossain"], "title": "Dual-Function Beam Pattern Design for Multi-Target ISAC Systems: A Decoupled Approach", "comment": "13 pages; 7 figures; tables; 3 tables; manuscript submitted to IEEE\n  journal", "summary": "We investigate the beampattern design problem for mono-static multi-user (MU)\nmulti-point-target integrated sensing and communication (ISAC) systems, where a\ndual-function multiple-input multiple-output (DF-MIMO) base station (BS)\nperforms downlink communication and radar sensing simultaneously. In ISAC\nsystems, sensing and communication inherently compete for resources. As\ncommunication demand increases, the beam pattern is reshaped, which might\ndegrade the direction of arrival (DoA) sensing accuracy, measured in terms of\nmean-squared error (MSE) and lower-bounded by the Cramer-Rao lower bound\n(CRLB). Since conventional joint formulations of the sensing-based problem\noften overlook this trade-off, our work addresses it by decomposing the\nsensing-based problem into two subproblems (SPs). This decomposition enables a\nmore effective exploitation of the beam pattern's physical properties, which we\nrefer to as the Sensing-Guided Communication Dual-Function (SGCDF) beam pattern\ndesign. We further develop a low-complexity extension using the Riemannian\nManifold Optimization (RMO) and convex closed-set projection. Simulation\nresults confirm that the proposed method improves multi-target estimation\naccuracy, compared to traditional joint optimization strategies, by preserving\nthe beam pattern, while the low-complexity version offers an excellent\nperformance-complexity tradeoff, maintaining high accuracy with significantly\nreduced computational cost."}
{"id": "2509.23930", "categories": ["eess.IV", "cs.CV", "92C55"], "pdf": "https://arxiv.org/pdf/2509.23930", "abs": "https://arxiv.org/abs/2509.23930", "authors": ["Eric Walser", "Peter McCaffrey", "Kal Clark", "Nicholas Czarnek"], "title": "A University of Texas Medical Branch Case Study on Aortic Calcification Detection", "comment": "9 pages, 2 figures", "summary": "This case study details The University of Texas Medical Branch (UTMB)'s\npartnership with Zauron Labs, Inc. to enhance detection and coding of aortic\ncalcifications (ACs) using chest radiographs. ACs are often underreported\ndespite their significant prognostic value for cardiovascular disease, and UTMB\npartnered with Zauron to apply its advanced AI tools, including a\nhigh-performing image model (AUC = 0.938) and a fine-tuned language model based\non Meta's Llama 3.2, to retrospectively analyze imaging and report data. The\neffort identified 495 patients out of 3,988 unique patients assessed (5,000\ntotal exams) whose reports contained indications of aortic calcifications that\nwere not properly coded for reimbursement (12.4% miscode rate) as well as an\nadditional 84 patients who had aortic calcifications that were missed during\ninitial review (2.1% misdiagnosis rate). Identification of these patients\nprovided UTMB with the potential to impact clinical care for these patients and\npursue $314k in missed annual revenue. These findings informed UTMB's decision\nto adopt Zauron's Guardian Pro software system-wide to ensure accurate,\nAI-enhanced peer review and coding, improving both patient care and financial\nsolvency. This study is covered under University of Texas Health San Antonio's\nInstitutional Review Board Study ID 00001887."}
{"id": "2509.23444", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.23444", "abs": "https://arxiv.org/abs/2509.23444", "authors": ["Lorenzo Italiano", "Alireza Pourafzal", "Hui Chen", "Mattia Brambilla", "Gonzalo Seco-Granados", "Monica Nicoli", "Henk Wymeersch"], "title": "HoloTrace: a Location Privacy Preservation Solution for mmWave MIMO-OFDM Systems", "comment": "submitted to IEEE Journal on Selected Areas in Communications", "summary": "The technological innovation towards 6G cellular networks introduces\nunprecedented capabilities for user equipment (UE) localization, but it also\nraises serious concerns about physical layer location privacy. This paper\nintroduces HoloTrace, a signal-level privacy preservation framework that relies\non user-side spoofing of localization-relevant features to prevent the\nextraction of precise location information from the signals received by a base\nstation (BS) in a mmWave MIMO-OFDM system. Spoofing is performed by the user on\nlocation parameters such as angle of arrival (AoA), angle of departure (AoD),\nand time difference of arrival (TDoA). Without requiring any protocol\nmodification nor network-side support, our method strategically perturbs pilot\ntransmissions to prevent a BS from performing non-consensual UE localization.\nThe methodology allows the UE to spoof its position, keeping the precoder\nunchanged. We formulate spoofing as a unified rank-constrained projection\nproblem, and provide closed-form solutions under varying levels of channel\nstate information (CSI) at the UE, including scenarios with and without CSI\nknowledge. Simulation results confirm that the proposed approach enables the UE\nto deceive the BS, inducing significant localization errors, while the impact\non link capacity varies depending on the spoofed position. Our findings\nestablish HoloTrace as a practical and robust privacy-preserving solution for\nfuture 6G networks."}
{"id": "2509.24227", "categories": ["eess.IV", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.24227", "abs": "https://arxiv.org/abs/2509.24227", "authors": ["Baltasar Ramos", "Cristian Garrido", "Paulette Narv'aez", "Santiago Gelerstein Claro", "Haotian Li", "Rafael Salvador", "Constanza V'asquez-Venegas", "Iv'an Gallegos", "Yi Zhang", "V'ictor Casta~neda", "Cristian Acevedo", "Dan Wu", "Gonzalo C'ardenas", "Camilo G. Sotomayor"], "title": "Non-Invasive Detection of PROState Cancer with Novel Time-Dependent Diffusion MRI and AI-Enhanced Quantitative Radiological Interpretation: PROS-TD-AI", "comment": "Study protocol preprint (not peer reviewed). Prepared with the MDPI\n  Journal of Imaging Word author template. Primary category: eess.IV. Code and\n  patient data are not publicly available due to privacy; requests will be\n  considered under a data-use agreement", "summary": "Prostate cancer (PCa) is the most frequently diagnosed malignancy in men and\nthe eighth leading cause of cancer death worldwide. Multiparametric MRI (mpMRI)\nhas become central to the diagnostic pathway for men at intermediate risk,\nimproving de-tection of clinically significant PCa (csPCa) while reducing\nunnecessary biopsies and over-diagnosis. However, mpMRI remains limited by\nfalse positives, false negatives, and moderate to substantial interobserver\nagreement. Time-dependent diffusion (TDD) MRI, a novel sequence that enables\ntissue microstructure characterization, has shown encouraging preclinical\nperformance in distinguishing clinically significant from insignificant PCa.\nCombining TDD-derived metrics with machine learning may provide robust,\nzone-specific risk prediction with less dependence on reader training and\nimproved accuracy compared to current standard-of-care. This study protocol\nout-lines the rationale and describes the prospective evaluation of a\nhome-developed AI-enhanced TDD-MRI software (PROSTDAI) in routine diagnostic\ncare, assessing its added value against PI-RADS v2.1 and validating results\nagainst MRI-guided prostate biopsy."}
{"id": "2509.23520", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.23520", "abs": "https://arxiv.org/abs/2509.23520", "authors": ["Kalpesh Jaykar", "Prasanth Velvaluri", "Nian X. Sun", "Richard D. James"], "title": "Theoretical framework of passive ME antenna arrays enabling in-vivo monitoring: A pathway to smart implants", "comment": null, "summary": "A new brain-computer interface (BCI) technology, deployed through minimally\ninvasive surgery, is changing the way we think about treating severe\nneurological conditions. The central idea is to place a device called Stentrode\nin the brain's vasculature, which enables neuromodulation and helps patients\nregain the ability to communicate. However, in such devices, the battery and\nelectronics are wired and could introduce damage or implant malfunction. In\nthese cases, a Stentrode integrated with magnetoelectric (ME) antennas could be\nof great interest. ME antennas offer significant advantages over traditional\nantennas, leveraging acoustic resonance rather than electromagnetic resonance\nto achieve a size reduction of up to five orders of magnitude. In addition to\ntheir compactness and immunity to ground-plane interference, ME antennas could\nbe adopted for use in vascular implants, such as coronary stents, potentially\nenabling minimally invasive monitoring and communication. Despite these\nadvantages, a single antenna embedded in the implant may be constrained by the\nlimited volume of magnetostrictive material, which could result in low output\ngain. To address this gain limitation, we propose using antenna arrays designed\nto produce constructive interference at a designated far-field point, ideally\nlocated outside the patient, to enhance signal transmission and receiving\ncapabilities. We develop a mathematical model to represent the antennas and\noptimize their spatial arrangement and phase synchronization. Simulations based\non this model demonstrate promising high-gain performance at the prescribed\nfar-field location through phase manipulation."}
{"id": "2509.24247", "categories": ["eess.IV", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.24247", "abs": "https://arxiv.org/abs/2509.24247", "authors": ["Kai Yuan", "Dongxu Li", "Jianhao Huang", "Han Zhang", "Chuan Huang"], "title": "Adaptive Source-Channel Coding for Multi-User Semantic and Data Communications", "comment": null, "summary": "This paper considers a multi-user semantic and data communication\n(MU-SemDaCom) system, where a base station (BS) simultaneously serves users\nwith different semantic and data tasks through a downlink multi-user\nmultiple-input single-output (MU-MISO) channel. The coexistence of\nheterogeneous communication tasks, diverse channel conditions, and the\nrequirements for digital compatibility poses significant challenges to the\nefficient design of MU-SemDaCom systems. To address these issues, we propose a\nmulti-user adaptive source-channel coding (MU-ASCC) framework that adaptively\noptimizes deep neural network (DNN)-based source coding, digital channel\ncoding, and superposition broadcasting. First, we employ a data-regression\nmethod to approximate the end-to-end (E2E) semantic and data distortions, for\nwhich no closed-form expressions exist. The obtained logistic formulas\ndecompose the E2E distortion as the addition of the source and channel\ndistortion terms, in which the logistic parameter variations are task-dependent\nand jointly determined by both the DNN and channel parameters. Then, based on\nthe derived formulas, we formulate a weighted-sum E2E distortion minimization\nproblem that jointly optimizes the source-channel coding rates, power\nallocation, and beamforming vectors for both the data and semantic users.\nFinally, an alternating optimization (AO) framework is developed, where the\nadaptive rate optimization is solved using the subgradient descent method,\nwhile the joint power and beamforming is addressed via the uplink-downlink\nduality (UDD) technique. Simulation results demonstrate that, compared with the\nconventional separate source-channel coding (SSCC) and deep joint\nsource-channel coding (DJSCC) schemes that are designed for a single task, the\nproposed MU-ASCC scheme achieves simultaneous improvements in both the data\nrecovery and semantic task performance."}
{"id": "2509.23644", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.23644", "abs": "https://arxiv.org/abs/2509.23644", "authors": ["Omkar Nitsure", "Sampath Kumar Dondapati", "Satish Mulleti"], "title": "Learnable Kernels for FRI -- Joint Kernel Encoder Optimization and Hardware Validation", "comment": "10 pages", "summary": "Finite Rate of Innovation (FRI) sampling techniques provide efficient\nframeworks for reconstructing signals with inherent sparsity at rates below\nNyquist. However, traditional FRI reconstruction methods rely heavily on\npre-defined kernels, often limiting hardware implementation and reconstruction\naccuracy under noisy conditions. In this paper, we propose a robust, flexible,\nand practically implementable framework for FRI reconstruction by introducing\nnovel learnable kernel strategies. First, we demonstrate effective\nreconstruction using known, fixed kernels such as truncated Gaussian and\nGaussian pair kernels, which mitigate the requirement that the samples should\nhave a sum-of-exponentials (SoE) form. Next, we extend this concept by jointly\noptimizing both the sampling kernel and reconstruction encoder through a\nunified learning approach, yielding adaptive kernels that significantly\noutperform traditional methods in resolution and noise robustness, with reduced\nsampling rates. Furthermore, we propose a practical hardware realization by\nrepresenting kernels as sums of two exponential decay signals with jointly\noptimized poles, facilitating compact, efficient analog implementations. Our\napproach is validated experimentally through hardware implementations using a\nunity-gain Sallen-Key analog filter, achieving accurate real-world signal\nrecovery. The developed convolutional neural network-based encoder\nsubstantially reduces computational complexity, demonstrating competitive\nperformance with fewer parameters, making our method particularly suitable for\nresource-constrained, edge-based deployments."}
{"id": "2509.24325", "categories": ["eess.IV", "cs.CV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2509.24325", "abs": "https://arxiv.org/abs/2509.24325", "authors": ["Jiaye Fu", "Qiankun Gao", "Chengxiang Wen", "Yanmin Wu", "Siwei Ma", "Jiaqi Zhang", "Jian Zhang"], "title": "ReCon-GS: Continuum-Preserved Guassian Streaming for Fast and Compact Reconstruction of Dynamic Scenes", "comment": null, "summary": "Online free-viewpoint video (FVV) reconstruction is challenged by slow\nper-frame optimization, inconsistent motion estimation, and unsustainable\nstorage demands. To address these challenges, we propose the Reconfigurable\nContinuum Gaussian Stream, dubbed ReCon-GS, a novel storage-aware framework\nthat enables high fidelity online dynamic scene reconstruction and real-time\nrendering. Specifically, we dynamically allocate multi-level Anchor Gaussians\nin a density-adaptive fashion to capture inter-frame geometric deformations,\nthereby decomposing scene motion into compact coarse-to-fine representations.\nThen, we design a dynamic hierarchy reconfiguration strategy that preserves\nlocalized motion expressiveness through on-demand anchor re-hierarchization,\nwhile ensuring temporal consistency through intra-hierarchical deformation\ninheritance that confines transformation priors to their respective hierarchy\nlevels. Furthermore, we introduce a storage-aware optimization mechanism that\nflexibly adjusts the density of Anchor Gaussians at different hierarchy levels,\nenabling a controllable trade-off between reconstruction fidelity and memory\nusage. Extensive experiments on three widely used datasets demonstrate that,\ncompared to state-of-the-art methods, ReCon-GS improves training efficiency by\napproximately 15% and achieves superior FVV synthesis quality with enhanced\nrobustness and stability. Moreover, at equivalent rendering quality, ReCon-GS\nslashes memory requirements by over 50% compared to leading state-of-the-art\nmethods."}
{"id": "2509.23687", "categories": ["eess.SP", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.23687", "abs": "https://arxiv.org/abs/2509.23687", "authors": ["Runze Dong", "Buhong Wang", "Cunqian Feng", "Jiang Weng", "Chen Han", "Jiwei Tian"], "title": "Joint Hybrid Beamforming and Artificial Noise Design for Secure Multi-UAV ISAC Networks", "comment": null, "summary": "Integrated sensing and communication (ISAC) emerges as a key enabler for\nnext-generation applications such as smart cities and autonomous systems. Its\nintegration with unmanned aerial vehicles (UAVs) unlocks new potentials for\nreliable communication and precise sensing in dynamic aerial environments.\nHowever, existing research predominantly treats UAVs as aerial base stations,\noverlooking their role as ISAC users, and fails to leverage large-scale antenna\narrays at terrestrial base stations to enhance security and spectral\nefficiency. This paper propose a secure and spectral efficient ISAC framework\nfor multi-UAV networks, and a two-stage optimization approach is developed to\njointly design hybrid beamforming (HBF), artificial noise (AN) injection, and\nUAV trajectories. Aiming at maximizing the sum secrecy rate, the first stage\nemploys Proximal Policy Optimization (PPO) to optimize digital beamformers and\ntrajectories, and the second stage decomposes the digital solution into analog\nand digital components via low-complexity matrix factorization. Simulation\nresults demonstrate the effectiveness of the proposed framework compared to\nbenchmark schemes."}
{"id": "2509.24334", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.24334", "abs": "https://arxiv.org/abs/2509.24334", "authors": ["Wankun Chen", "Feng Gao", "Yanhai Gan", "Jingchao Cao", "Junyu Dong", "Qian Du"], "title": "Wavelet-Assisted Mamba for Satellite-Derived Sea Surface Temperature Super-Resolution", "comment": "Accepted by IEEE TGRS 2025", "summary": "Sea surface temperature (SST) is an essential indicator of global climate\nchange and one of the most intuitive factors reflecting ocean conditions.\nObtaining high-resolution SST data remains challenging due to limitations in\nphysical imaging, and super-resolution via deep neural networks is a promising\nsolution. Recently, Mamba-based approaches leveraging State Space Models (SSM)\nhave demonstrated significant potential for long-range dependency modeling with\nlinear complexity. However, their application to SST data super-resolution\nremains largely unexplored. To this end, we propose the Wavelet-assisted Mamba\nSuper-Resolution (WMSR) framework for satellite-derived SST data. The WMSR\nincludes two key components: the Low-Frequency State Space Module (LFSSM) and\nHigh-Frequency Enhancement Module (HFEM). The LFSSM uses 2D-SSM to capture\nglobal information of the input data, and the robust global modeling\ncapabilities of SSM are exploited to preserve the critical temperature\ninformation in the low-frequency component. The HFEM employs the pixel\ndifference convolution to match and correct the high-frequency feature,\nachieving accurate and clear textures. Through comprehensive experiments on\nthree SST datasets, our WMSR demonstrated superior performance over\nstate-of-the-art methods. Our codes and datasets will be made publicly\navailable at https://github.com/oucailab/WMSR."}
{"id": "2509.23792", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.23792", "abs": "https://arxiv.org/abs/2509.23792", "authors": ["Kabuto Arai", "Takumi Yoshida", "Takumi Takahashi", "Koji Ishibashi"], "title": "Expectation Propagation-Based Signal Detection for Highly Correlated MIMO Systems", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Large-scale multiple-input-multiple-output (MIMO) systems typically operate\nin dense array deployments with limited scattering environments, leading to\nhighly correlated and ill-conditioned channel matrices that severely degrade\nthe performance of message-passing-based detectors. To tackle this issue, this\npaper proposes an expectation propagation (EP)-based detector, termed\noverlapping block partitioning EP (OvEP). In OvEP, the large-scale measurement\nvector is partitioned into partially overlapping blocks. For each block and its\noverlapping part, a low-complexity linear minimum mean square error\n(LMMSE)-based filter is designed according to the partitioned structure. The\nresulting LMMSE outputs are then combined to generate the input to the\ndenoiser. In this combining process, subtracting the overlapping-part outputs\nfrom the block outputs effectively mitigates the adverse effects of inter-block\ncorrelation induced by high spatial correlation. The proposed algorithm is\nconsistently derived within the EP framework, and its fixed point is\ntheoretically proven to coincide with the stationary point of a relaxed\nKullback- Leibler (KL) minimization problem. The mechanisms underlying the\ntheoretically predicted performance improvement are further clarified through\nnumerical simulations. The proposed algorithm achieves performance close to\nconventional LMMSE-EP with lower computational complexity."}
{"id": "2509.24497", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.24497", "abs": "https://arxiv.org/abs/2509.24497", "authors": ["Pranoti Nage", "Sanjay Shitole"], "title": "A Novel Preprocessing Unit for Effective Deep Learning based Classification and Grading of Diabetic Retinopathy", "comment": null, "summary": "Early detection of diabetic retinopathy (DR) is crucial as it allows for\ntimely intervention, preventing vision loss and enabling effective management\nof diabetic complications. This research performs detection of DR and DME at an\nearly stage through the proposed framework which includes three stages:\npreprocessing, segmentation, feature extraction, and classification. In the\npreprocessing stage, noise filtering is performed by fuzzy filtering, artefact\nremoval is performed by non-linear diffusion filtering, and the contrast\nimprovement is performed by a novel filter called Adaptive Variable Distance\nSpeckle (AVDS) filter. The AVDS filter employs four distance calculation\nmethods such as Euclidean, Bhattacharya, Manhattan, and Hamming. The filter\nadaptively chooses a distance method which produces the highest contrast value\namongst all 3 methods. From the analysis, hamming distance method was found to\nachieve better results for contrast and Euclidean distance showing less error\nvalue with high PSNR. The segmentation stage is performed using Improved\nMask-Regional Convolutional Neural Networks (Mask RCNN). In the final stage,\nfeature extraction and classification using novel Self-Spatial Attention\ninfused VGG-16 (SSA-VGG-16), which effectively captures both global contextual\nrelationships and critical spatial regions within retinal images, thereby\nimproving the accuracy and robustness of DR and DME detection and grading. The\neffectiveness of the proposed method is assessed using two distinct datasets:\nIDRiD and MESSIDOR."}
{"id": "2509.23807", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.23807", "abs": "https://arxiv.org/abs/2509.23807", "authors": ["Hongyu Wang", "Wenjia Xu", "Guangzuo Li", "Siyuan Wan", "Yaohua Sun", "Jiuniu Wang", "Mugen Peng"], "title": "Online Specific Emitter Identification via Collision-Alleviated Signal Hash", "comment": "This paper has been accepted by IEEE Transactions on Vehicular\n  Technology", "summary": "Specific Emitter Identification (SEI) has been widely studied, aiming to\ndistinguish signals from different emitters given training samples from those\nemitters. However, real-world scenarios often require identifying signals from\nnovel emitters previously unseen. Since these novel emitters only have a few or\nno prior samples, existing models struggle to identify signals from novel\nemitters online and tend to bias toward the distribution of seen emitters. To\naddress these challenges, we propose the Online Specific Emitter Identification\n(OSEI) task, comprising both online \\revise{few-shot and generalized zero-shot}\nlearning tasks. It requires constructing models using signal samples from seen\nemitters and then identifying new samples from seen and novel emitters online\nduring inference. We propose a novel hash-based model, Collision-Alleviated\nSignal Hash (CASH), providing a unified approach for addressing the OSEI task.\nThe CASH operates in two steps: in the seen emitters identifying step, a signal\nencoder and a seen emitters identifier determine whether the signal sample is\nfrom seen emitters, mitigating the model from biasing toward seen emitters\ndistribution. In the signal hash coding step, an online signal hasher assigns a\nhash code to each signal sample, identifying its specific emitter. Experimental\nresults on real-world signal datasets (i.e., ADSB and ORACLE) demonstrate that\nour method accurately identifies signals from both seen and novel emitters\nonline. This model outperforms existing methods by a minimum of 6.08\\% and\n8.55\\% in accuracy for the few-shot and \\revise{generalized zero-shot learning\n}tasks, respectively. The code will be open-sourced at\n\\href{https://github.com/IntelliSensing/OSEI-CASH}{https://github.com/IntelliSensing/OSEI-CASH}."}
{"id": "2509.03070", "categories": ["eess.SP", "cs.AI", "cs.CV", "cs.LG", "eess.IV"], "pdf": "https://arxiv.org/pdf/2509.03070", "abs": "https://arxiv.org/abs/2509.03070", "authors": ["Po-Heng Chou", "Wei-Lung Mao", "Ru-Ping Lin"], "title": "YOLO-based Bearing Fault Diagnosis With Continuous Wavelet Transform", "comment": "5 pages, 2 figures, 2 tables, submitted to IEEE Sensors Letters", "summary": "This letter proposes a YOLO-based framework for spatial bearing fault\ndiagnosis using time-frequency spectrograms derived from continuous wavelet\ntransform (CWT). One-dimensional vibration signals are first transformed into\ntime-frequency spectrograms using Morlet wavelets to capture transient fault\nsignatures. These spectrograms are then processed by YOLOv9, v10, and v11\nmodels to classify fault types. Evaluated on three benchmark datasets,\nincluding Case Western Reserve University (CWRU), Paderborn University (PU),\nand Intelligent Maintenance System (IMS), the proposed CWT-YOLO pipeline\nachieves significantly higher accuracy and generalizability than the baseline\nMCNN-LSTM model. Notably, YOLOv11 reaches mAP scores of 99.4% (CWRU), 97.8%\n(PU), and 99.5% (IMS). In addition, its region-aware detection mechanism\nenables direct visualization of fault locations in spectrograms, offering a\npractical solution for condition monitoring in rotating machinery."}
{"id": "2509.23920", "categories": ["eess.SP", "math.PR", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2509.23920", "abs": "https://arxiv.org/abs/2509.23920", "authors": ["Masahiro Kurisaki"], "title": "Asymptotic Expansion for Nonlinear Filtering in the Small System Noise Regime", "comment": "This paper is a self-contained exposition of the methodological part\n  of Section 4 in arXiv:2501.16333", "summary": "We propose a new asymptotic expansion method for nonlinear filtering, based\non a small parameter in the system noise. The conditional expectation is\nexpanded as a power series in the noise level, with each coefficient computed\nby solving a system of ordinary differential equations. This approach mitigates\nthe trade-off between computational efficiency and accuracy inherent in\nexisting methods such as Gaussian approximations and particle filters.\nMoreover, by incorporating an Edgeworth-type expansion, our method captures\ncomplex features of the conditional distribution, such as multimodality, with\nsignificantly lower computational cost than conventional filtering algorithms."}
{"id": "2509.24097", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.24097", "abs": "https://arxiv.org/abs/2509.24097", "authors": ["Henglin Pu", "Zhu Han", "Athina P. Petropulu", "Husheng Li"], "title": "Wideband Integrated Sensing and Communications: Spectral Efficiency and Signaling Design", "comment": null, "summary": "In integrated sensing and communications (ISAC), a distinguishing feature of\n6G wireless networks, the main challenge lies in integrating the two distinct\nfunctions of sensing and communication within the same waveform. In this paper,\nthe ISAC waveform synthesis is studied in the wideband regime, since a large\nbandwidth can simplify the analysis and is justified by the employment of\nmillimeter wave or higher frequency band. Standard orthogonal frequency\ndivision multiplexing (OFDM) signaling is assumed, and the wideband analysis of\nsensing is a counterpart of the existing studies on wideband communications. It\nis proposed that the phase over such OFDM subcarriers is for modulating\ncommunication messages while the power spectral density (PSD) is shaped for the\nsensing performance. Beyond OFDM, we further reveal a duality between the\nproposed PSD-shaping rule and the orthogonal time frequency space (OTFS)\nwaveform. Flattening the OTFS delay-axis PSD produces the same integrated\nsidelobe level (ISL) reduction effect in the delay-Doppler domain as PSD\ncontrol achieves for OFDM in the frequency domain. To balance communication and\nsensing performance over frequency-selective channels, we propose a\nlow-complexity, water-filling-like allocator with an explicit PSD-flatness\n(variance) constraint. The performance of the proposed wideband ISAC scheme is\ndemonstrated using both numerical simulations and hardware experiments."}
{"id": "2509.24178", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.24178", "abs": "https://arxiv.org/abs/2509.24178", "authors": ["Chengwei Zhou", "Steve Majerus", "Gourav Datta"], "title": "BladderFormer: A Streaming Transformer for Real-Time Urological State Monitoring", "comment": "Under review", "summary": "Bladder pressure monitoring systems are increasingly vital in diagnosing and\nmanaging urinary tract dysfunction. Existing solutions rely heavily on\nhand-crafted features and shallow classifiers, limiting their adaptability to\ncomplex signal dynamics. We propose a one-layer streaming transformer model for\nreal-time classification of bladder pressure states, operating on\nwavelet-transformed representations of raw time-series data. Our model\nincorporates temporal multi-head self-attention and state caching, enabling\nefficient online inference with high adaptability. Trained on a dataset of 91\npatients with 20,000-80,000 samples each, our method demonstrates improved\naccuracy, higher energy- and latency-efficiency. Implementation considerations\nfor edge deployment on low-power hardware, such as edge graphical processing\nunits (GPU) and micro-controllers, are also discussed."}
{"id": "2509.24222", "categories": ["eess.SP", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.24222", "abs": "https://arxiv.org/abs/2509.24222", "authors": ["Zhisheng Chen", "Yingwei Zhang", "Qizhen Lan", "Tianyu Liu", "Huacan Wang", "Yi Ding", "Ziyu Jia", "Ronghao Chen", "Kun Wang", "Xinliang Zhou"], "title": "Uni-NTFM: A Unified Foundation Model for EEG Signal Representation Learning", "comment": null, "summary": "Foundation models pretrained on various and unlabeled data have demonstrated\nsignificant success in natural language and vision, but their application to\nelectroencephalography (EEG) remains challenged due to the signal's unique\nproperties. Existing brain foundation models that inherit architectures\ndesigned for text or images lead to three limitations in pre-training: 1)\nconflating time-domain waveform patterns with frequency-domain rhythmic\nfeatures in a single processing stream, 2) ignoring the critical spatial\ntopology of electrodes with different standards, and 3) reliance on the\ninflexible, dense network to process functionally distinct EEG patterns. To\naddress these challenges, we introduce the Unified Neural Topological\nFoundation Model (Uni-NTFM), which is designed based on neuroscience principles\nto produce universal and interpretable representations. Uni-NTFM integrates\nthree core innovations: 1) a decoupled architecture parallelly encodes time,\nfrequency, and raw signal representations before performing cross-domain\nfeature integration; 2) a topological embedding mechanism to unify electrodes\nfrom different international standards and generate structured input sequences\nfor brain regions; and 3) a Mixture-of-Experts neural Transformer that\nefficiently scales model capacity by routing signal patterns to specialized\nsubnetworks. The largest model, Uni-NTFM$_{large}$, has a record-breaking 1.9B\nparameters and was pretrained on over 28,000 hours of diverse EEG data via a\ndual-domain masked reconstruction objective. Uni-NTFM significantly outperforms\nexisting task-specific methods and foundation models across nine distinct\ndownstream tasks under both linear probing and fine-tuning settings,\ndemonstrating a superior ability to learn universal representations of brain\nactivity."}
{"id": "2509.24355", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.24355", "abs": "https://arxiv.org/abs/2509.24355", "authors": ["Sefa Kayraklık", "Recep Baş", "Hasan Oğuzhan Çalışkan", "Samed Şahinoğlu", "Sercan Erdoğan", "İlhami Ünal", "İbrahim Hökelek", "Kıvanç Nurdan", "Ali Görçin"], "title": "N78 Frequency Band Modular RIS Design and Implementation", "comment": "Presented at EuMC2025, Copyright EuMA", "summary": "Reconfigurable intelligent surface (RIS), capable of dynamically controlling\nwireless propagation characteristics using reflecting antenna elements, is a\npromising technology for enhancing signal coverage and improving end-user\nconnectivity in next-generation wireless networks. This paper presents a\ncomplete design flow of a modular RIS prototype operating at the n78 frequency\nband, starting from the simulations to the prototype development and testing.\nAn RIS prototype includes one master and up to sixteen slave blocks, each of\nwhich has an identical hardware structure with $8\\times 8$ reflecting surface\nelements and a controller board. The phase shift response of each unit element\nis controlled with a PIN diode to form a $180^\\circ$ phase difference between\nthe ON and OFF states. The measurement experiment using two RIS blocks, horn\nantennas, and a vector network analyzer showed that the improvement of the\nreceived signal power is more than $15$ dB across the n78 frequency band for a\ngiven placement."}
{"id": "2509.24428", "categories": ["eess.SP", "cs.NA", "math.NA"], "pdf": "https://arxiv.org/pdf/2509.24428", "abs": "https://arxiv.org/abs/2509.24428", "authors": ["Santos Michelena", "Maxime Ferreira Da Costa", "José Picheral"], "title": "Strong Basin of Attraction for Unmixing Kernels With the Variable Projection Method", "comment": "5 pages, 4 figures. Submitted to the 2026 IEEE International\n  Conference on Acoustics, Speech and Signal Processing (ICASSP)", "summary": "The problem of recovering a mixture of spike signals convolved with distinct\npoint spread functions (PSFs) lying on a parametric manifold, under the\nassumption that the spike locations are known, is studied. The PSF unmixing\nproblem is formulated as a projected non-linear least squares estimator. A\nlower bound on the radius of the region of strong convexity is established in\nthe presence of noise as a function of the manifold coherence and Lipschitz\nproperties, guaranteeing convergence and stability of the optimization program.\nNumerical experiments highlight the speed of decay of the PSF class in the\nproblem's conditioning and confirm theoretical findings. Finally, the proposed\nestimator is deployed on real-world spectroscopic data from laser-induced\nbreakdown spectroscopy (LIBS), removing the need for manual calibration and\nvalidating the method's practical relevance."}
{"id": "2509.24537", "categories": ["eess.SP", "physics.app-ph"], "pdf": "https://arxiv.org/pdf/2509.24537", "abs": "https://arxiv.org/abs/2509.24537", "authors": ["Philipp del Hougne"], "title": "Low-Complexity Wireless Multi-Port Sensing by Multiplexed De-Embedding of an Over-the-Air Fixture", "comment": "9 pages including 5 figures", "summary": "Wireless multi-port sensing remotely retrieves the scattering matrix of a\nmulti-port device under test (DUT) connected to a set of\nnot-directly-accessible (NDA) antennas that couple over-the-air (OTA) to a set\nof accessible antennas. If (i) the OTA fixture characteristics are known, and\n(ii) the number of independent measurements at the accessible antennas is\nsufficient, the OTA fixture can be de-embedded to recover the DUT\ncharacteristics. In recent prior work, we solved (i) by connecting the NDA\nantennas to a specific known tunable load network (TLN). Here, we tackle (ii)\nby additionally using the TLN to provide measurement diversity. The connection\nbetween OTA fixture and TLN constitutes a programmable fixture (PF). When the\nDUT characteristics cannot be identified based on a single PF realization, we\nadd measurement diversity with multiple PF realizations. The underlying\n\"multiplexed de-embedding\" achieves the joint de-embedding of an ensemble of PF\nrealizations when a single PF realization cannot be de-embedded. We\nexperimentally demonstrate our concept by remotely estimating the scattering\nmatrix of a reciprocal, non-unitary 4-port DUT (10 complex-valued unknowns) via\na rich-scattering OTA fixture purely based on measurements of a single\ntransmission coefficient between two accessible antennas across 30 different PF\nrealizations. We systematically study the trade-off between the number of\nindependent measurements at the accessible antennas and the number of PF\nrealizations. Multiplexed de-embedding of the OTA fixture paves the path to\nimplementing wireless multi-port sensing with low hardware complexity in areas\nlike RFID and wireless bioelectronics."}
{"id": "2509.24588", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.24588", "abs": "https://arxiv.org/abs/2509.24588", "authors": ["Luis F. Abanto-Leon", "Muhammad Salman", "Lismer Andres Caceres-Najarro"], "title": "BARProp: Fast-Converging and Memory-Efficient RSS-Based Localization Algorithm for IoT", "comment": "9 pages, 8 figures, and 4 tables", "summary": "Leveraging received signal strength (RSS) measurements for indoor\nlocalization is highly attractive due to their inherent availability in\nubiquitous wireless protocols. However, prevailing RSS-based methods often\ndepend on complex computational algorithms or specialized hardware, rendering\nthem impractical for low-cost access points. To address these challenges, this\npaper introduces buffer-aided RMSProp (BARProp), a fast and memory-efficient\nlocalization algorithm specifically designed for RSS-based tasks. The key\ninnovation of BARProp lies in a novel mechanism that dynamically adapts the\ndecay factor by monitoring the energy variations of recent gradients stored in\na buffer, thereby achieving both accelerated convergence and enhanced\nstability. Furthermore, BARProp requires less than 15% of the memory used by\nstate-of-the-art methods. Extensive evaluations with real-world data\ndemonstrate that BARProp not only achieves higher localization accuracy but\nalso delivers at least a fourfold improvement in convergence speed compared to\nexisting benchmarks."}
{"id": "2509.24683", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.24683", "abs": "https://arxiv.org/abs/2509.24683", "authors": ["Johan Arbustini", "Eric Elzenheimer", "Elizaveta Spetzler", "Pablo Mendoza", "Daniel Fernández", "Jordi Madrenas", "Jeffrey McCord", "Michael Höft", "Robert Rieger", "Andreas Bahr"], "title": "Impedance Modeling of Magnetometers: A Path Toward Low-Noise Readout Circuits", "comment": "4 pages, 3 figures, BMT2025 conference paper", "summary": "Optimizing sensor readout schemes and integrated circuit designs for both\nopen-loop and closed-loop implementations requires precise modeling and\nsimulation strategies. This study introduces a novel two-port impedance model\nto estimate the behavior of a converse Magnetoelectric (cME) sensor. This model\nprovides a possible framework for calculating transfer functions and simulating\nmagnetometer behavior in both continuous- and discrete-time simulation\nenvironments, and it is also possibly transferable to other magnetometer types.\nCommon S-parameters were measured experimentally using an impedance analyzer\nand converted to Z-parameters to create a transfer function for system-level\nsimulations. The model was validated through an analysis of output-related\nnoise using MATLAB and LTSpice simulations to optimize the noise of the analog\ncircuit parts of the system. The simulation results were compared with\nexperimental measurements using a Zurich Instruments lock-in amplifier and the\ncustom-designed low-noise printed circuit board (PCB) under model\nconsiderations. The proposed methodology derives noise considerations and the\ntransfer function of a magnetometer. These are essential for readout schemes\nfor mixed-signal circuit design. This allows low-noise electronics to be\ndesigned and extended to other sensor interface electronics, broadening their\napplicability in high-performance magnetic sensing."}
{"id": "2509.24805", "categories": ["eess.SP", "cs.AI", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.24805", "abs": "https://arxiv.org/abs/2509.24805", "authors": ["Andriy Enttsel", "Alex Marchioni", "Andrea Zanellini", "Mauro Mangia", "Gianluca Setti", "Riccardo Rovatti"], "title": "RDD: Pareto Analysis of the Rate-Distortion-Distinguishability Trade-off", "comment": "12 pages, 11 figures", "summary": "Extensive monitoring systems generate data that is usually compressed for\nnetwork transmission. This compressed data might then be processed in the cloud\nfor tasks such as anomaly detection. However, compression can potentially\nimpair the detector's ability to distinguish between regular and irregular\npatterns due to information loss. Here we extend the information-theoretic\nframework introduced in [1] to simultaneously address the trade-off between the\nthree features on which the effectiveness of the system depends: the\neffectiveness of compression, the amount of distortion it introduces, and the\ndistinguishability between compressed normal signals and compressed anomalous\nsignals. We leverage a Gaussian assumption to draw curves showing how moving on\na Pareto surface helps administer such a trade-off better than simply relying\non optimal rate-distortion compression and hoping that compressed signals can\nbe distinguished from each other."}
{"id": "2509.24819", "categories": ["eess.SP", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.24819", "abs": "https://arxiv.org/abs/2509.24819", "authors": ["Kunyu Wu", "Qiushi Zhao", "Zihan Feng", "Yunxi Mu", "Hao Qin", "Xinyu Zhang", "Xingqi Zhang"], "title": "Intelligent Optimization of Wireless Access Point Deployment for Communication-Based Train Control Systems Using Deep Reinforcement Learning", "comment": null, "summary": "Urban railway systems increasingly rely on communication based train control\n(CBTC) systems, where optimal deployment of access points (APs) in tunnels is\ncritical for robust wireless coverage. Traditional methods, such as empirical\nmodel-based optimization algorithms, are hindered by excessive measurement\nrequirements and suboptimal solutions, while machine learning (ML) approaches\noften struggle with complex tunnel environments. This paper proposes a deep\nreinforcement learning (DRL) driven framework that integrates parabolic wave\nequation (PWE) channel modeling, conditional generative adversarial network\n(cGAN) based data augmentation, and a dueling deep Q network (Dueling DQN) for\nAP placement optimization. The PWE method generates high-fidelity path loss\ndistributions for a subset of AP positions, which are then expanded by the cGAN\nto create high resolution path loss maps for all candidate positions,\nsignificantly reducing simulation costs while maintaining physical accuracy. In\nthe DRL framework, the state space captures AP positions and coverage, the\naction space defines AP adjustments, and the reward function encourages signal\nimprovement while penalizing deployment costs. The dueling DQN enhances\nconvergence speed and exploration exploitation balance, increasing the\nlikelihood of reaching optimal configurations. Comparative experiments show\nthat the proposed method outperforms a conventional Hooke Jeeves optimizer and\ntraditional DQN, delivering AP configurations with higher average received\npower, better worst-case coverage, and improved computational efficiency. This\nwork integrates high-fidelity electromagnetic simulation, generative modeling,\nand AI-driven optimization, offering a scalable and data-efficient solution for\nnext-generation CBTC systems in complex tunnel environments."}
{"id": "2509.24941", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.24941", "abs": "https://arxiv.org/abs/2509.24941", "authors": ["Kuranage Roche Rayan Ranasinghe", "Giuseppe Thadeu Freitas de Abreu", "Emil Björnson"], "title": "Low-Complexity Receiver Design for Multicarrier CAPA-based Systems in Doubly-Dispersive Channels", "comment": "Submitted to an IEEE conference", "summary": "We propose a novel low-complexity receiver design for multicarrier continuous\naperture array (CAPA) systems operating over doubly-dispersive (DD) channels.\nThe receiver leverages a Gaussian Belief Propagation (GaBP)-based framework\nthat hinges only on element-wise scalar operations for the detection of the\ntransmitted symbols. Simulation results for the orthogonal frequency division\nmultiplexing (OFDM), orthogonal time frequency space (OTFS), and affine\nfrequency division multiplexing (AFDM) waveforms demonstrate significant\nperformance improvements in terms of uncoded bit error rate (BER) compared to\nconventional discrete antenna array systems, while maintaining very low\ncomputational complexity."}
{"id": "2509.25095", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.25095", "abs": "https://arxiv.org/abs/2509.25095", "authors": ["M A Al-Masud", "Juan Miguel Lopez Alcaraz", "Nils Strodthoff"], "title": "Benchmarking ECG Foundational Models: A Reality Check Across Clinical Tasks", "comment": "26 pages, 3 figures source code under\n  https://github.com/AI4HealthUOL/ecg-fm-benchmarking", "summary": "The 12-lead electrocardiogram (ECG) is a long-standing diagnostic tool. Yet\nmachine learning for ECG interpretation remains fragmented, often limited to\nnarrow tasks or datasets. Foundation models promise broader adaptability, but\ntheir generalization across diverse ECG tasks is not well understood. We\nbenchmarked eight ECG foundation models on 26 clinically relevant tasks using\n12 public datasets comprising 1,650 regression and classification targets.\nModels were evaluated under fine-tuning and frozen settings, with scaling\nanalyses across dataset sizes. Results show heterogeneous performance across\ndomains: in the most widely studied domain, adult ECG interpretation, three\nfoundation models consistently outperformed strong supervised baselines. In\ncontrast, ECG-CPC, a compact structured state-space model pretrained on HEEDB,\ndominated other categories where most foundation models failed to surpass\nsupervised learning. Foundation models also displayed distinct scaling\nbehaviors with dataset size, which are critical for small-scale clinical\napplications. Overall, while foundation models show promise for adult ECG\nanalysis, substantial gaps remain in cardiac structure, outcome prediction, and\npatient characterization. Notably, ECG-CPC's strong performance despite being\norders of magnitude smaller and consuming minimal computational resources\nhighlights untapped opportunities for advancing ECG foundation models."}
{"id": "2509.23442", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2509.23442", "abs": "https://arxiv.org/abs/2509.23442", "authors": ["Md. Saiful Bari Siddiqui", "Mohammed Imamul Hassan Bhuiyan"], "title": "S$^3$F-Net: A Multi-Modal Approach to Medical Image Classification via Spatial-Spectral Summarizer Fusion Network", "comment": "Submitted to IEEE Journal of Biomedical and Health Informatics\n  (JBHI). This preprint includes few additional details not present in the\n  journal submission", "summary": "Convolutional Neural Networks have become a cornerstone of medical image\nanalysis due to their proficiency in learning hierarchical spatial features.\nHowever, this focus on a single domain is inefficient at capturing global,\nholistic patterns and fails to explicitly model an image's frequency-domain\ncharacteristics. To address these challenges, we propose the Spatial-Spectral\nSummarizer Fusion Network (S$^3$F-Net), a dual-branch framework that learns\nfrom both spatial and spectral representations simultaneously. The S$^3$F-Net\nperforms a fusion of a deep spatial CNN with our proposed shallow spectral\nencoder, SpectraNet. SpectraNet features the proposed SpectralFilter layer,\nwhich leverages the Convolution Theorem by applying a bank of learnable filters\ndirectly to an image's full Fourier spectrum via a computation-efficient\nelement-wise multiplication. This allows the SpectralFilter layer to attain a\nglobal receptive field instantaneously, with its output being distilled by a\nlightweight summarizer network. We evaluate S$^3$F-Net across four medical\nimaging datasets spanning different modalities to validate its efficacy and\ngeneralizability. Our framework consistently and significantly outperforms its\nstrong spatial-only baseline in all cases, with accuracy improvements of up to\n5.13%. With a powerful Bilinear Fusion, S$^3$F-Net achieves a SOTA competitive\naccuracy of 98.76% on the BRISC2025 dataset. Concatenation Fusion performs\nbetter on the texture-dominant Chest X-Ray Pneumonia dataset, achieving 93.11%\naccuracy, surpassing many top-performing, much deeper models. Our\nexplainability analysis also reveals that the S$^3$F-Net learns to dynamically\nadjust its reliance on each branch based on the input pathology. These results\nverify that our dual-domain approach is a powerful and generalizable paradigm\nfor medical image analysis."}
{"id": "2509.23590", "categories": ["eess.IV", "eess.SP"], "pdf": "https://arxiv.org/pdf/2509.23590", "abs": "https://arxiv.org/abs/2509.23590", "authors": ["Fangyu Liu", "Peiwen Jiang", "Wenjin Wang", "Chao-Kai Wen", "Shi Jin", "Jun Zhang"], "title": "Foundation Model-Based Adaptive Semantic Image Transmission for Dynamic Wireless Environments", "comment": null, "summary": "Foundation model-based semantic transmission has recently shown great\npotential in wireless image communication. However, existing methods exhibit\ntwo major limitations: (i) they overlook the varying importance of semantic\ncomponents for specific downstream tasks, and (ii) they insufficiently exploit\nwireless domain knowledge, resulting in limited robustness under dynamic\nchannel conditions. To overcome these challenges, this paper proposes a\nfoundation model-based adaptive semantic image transmission system for dynamic\nwireless environments, such as autonomous driving. The proposed system\ndecomposes each image into a semantic segmentation map and a compressed\nrepresentation, enabling task-aware prioritization of critical objects and\nfine-grained textures. A task-adaptive precoding mechanism then allocates radio\nresources according to the semantic importance of extracted features. To ensure\naccurate channel information for precoding, a channel estimation knowledge map\n(CEKM) is constructed using a conditional diffusion model that integrates user\nposition, velocity, and sparse channel samples to train scenario-specific\nlightweight estimators. At the receiver, a conditional diffusion model\nreconstructs high-quality images from the received semantic features, ensuring\nrobustness against channel impairments and partial data loss. Simulation\nresults on the BDD100K dataset with multi-scenario channels generated by\nQuaDRiGa demonstrate that the proposed method outperforms existing approaches\nin terms of perceptual quality (SSIM, LPIPS, FID), task-specific accuracy\n(IoU), and transmission efficiency. These results highlight the effectiveness\nof integrating task-aware semantic decomposition, scenario-adaptive channel\nestimation, and diffusion-based reconstruction for robust semantic transmission\nin dynamic wireless environments."}
