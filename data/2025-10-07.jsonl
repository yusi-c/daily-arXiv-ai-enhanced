{"id": "2510.03516", "categories": ["eess.SP", "I.2.7"], "pdf": "https://arxiv.org/pdf/2510.03516", "abs": "https://arxiv.org/abs/2510.03516", "authors": ["Boyang Chen", "Mohd Tasleem Khan", "George Goussetis", "Mathini Sellathurai", "Yuan Ding", "Jo√£o F. C. Mota"], "title": "COMET: Co-Optimization of a CNN Model using Efficient-Hardware OBC Techniques", "comment": null, "summary": "Convolutional Neural Networks (CNNs) are highly effective for computer vision\nand pattern recognition tasks; however, their computational intensity and\nreliance on hardware such as FPGAs pose challenges for deployment on low-power\nedge devices. In this work, we present COMET, a framework of CNN designs that\nemploy efficient hardware offset-binary coding (OBC) techniques to enable\nco-optimization of performance and resource utilization. The approach\nformulates CNN inference with OBC representations of inputs (Scheme A) and\nweights (Scheme B) separately, enabling exploitation of bit-width asymmetry.\nThe shift-accumulate operation is modified by incorporating the offset term\nwith the pre-scaled bias. Leveraging inherent symmetries in Schemes A and B, we\nintroduce four novel look-up table (LUT) techniques -- parallel, shared, split,\nand hybrid -- and analyze them to identify the most efficient options. Building\non this foundation, we develop an OBC-based general matrix multiplication core\nusing the im2col transformation, enabling efficient acceleration of a\nfixed-point modified LeNet-5 model. FPGA evaluations demonstrate that the\nproposed co-optimization approach significantly reduces resource utilization\ncompared to state-of-the-art LeNet-5 based CNN designs, with minimal impact on\naccuracy."}
{"id": "2510.03594", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.03594", "abs": "https://arxiv.org/abs/2510.03594", "authors": ["Tuo Wu", "Kwai-Man Luk", "Jie Tang", "Kai-Kit Wong", "Jianchao Zheng", "Baiyang Liu", "David Morales-Jimenez", "Maged Elkashlan", "Kin-Fai Tong", "Chan-Byoung Chae", "Fumiyuki Adachi", "George K. Karagiannidis"], "title": "Variable Block-Correlation Modeling and Optimization for Secrecy Analysis in Fluid Antenna Systems", "comment": "13 pages", "summary": "Fluid antenna systems (FAS) are emerging as a transformative enabler for\nsixth-generation (6G) wireless communications, providing unprecedented spatial\ndiversity through dynamic reconfiguration of antenna ports. However, the\ninherent spatial correlation among ports poses significant challenges for\naccurate analysis. Conventional models such as Jakes are analytically\nintractable, while oversimplified constant-correlation models fail to capture\nthe true behavior. In this work, we address these challenges by applying the\nvariable block-correlation model (VBCM) -- originally proposed by\nRam\\'{i}rez-Espinosa \\textit{et al.} in 2024 -- to FAS security analysis, and\nby developing comprehensive optimization methods to enhance analytical\naccuracy. We derive new closed-form expressions for average secrecy capacity\n(ASC) and secrecy outage probability (SOP), demonstrating that the VBCM\nframework achieves simulation-aligned accuracy, with relative errors\nconsistently below $5\\%$ (compared to $10$--$15\\%$ for constant-correlation\nmodels). To maximize ASC, we further design two algorithms: a grid search (GS)\nmethod and a gradient descent (GD) method. Numerical results reveal that the\nVBCM-based approach not only provides reliable insights into FAS security\nperformance, but also yields substantial gains -- ASC improvements exceeding\n$120\\%$ in high-threat scenarios and $18$--$19\\%$ performance enhancements for\ncompact antenna configurations. These findings underscore the practical value\nof integrating VBCM into FAS security analysis and optimization, establishing\nit as a powerful tool for advancing 6G communication systems."}
{"id": "2510.03626", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.03626", "abs": "https://arxiv.org/abs/2510.03626", "authors": ["Jun Tong"], "title": "On-Grid Equivalence of Continuous-Time Doubly Selective Channels: A Revisit of Bello's Models", "comment": "This paper was presented at 2025 IEEE International Conference on\n  Communications Workshops (ICC Workshops)", "summary": "Significant studies on communications over doubly selective channels have\nutilized on-grid DD channel models, which are previously investigated in\nBello's seminar paper in 1963. The DD grid is typically specified by the\nbandwidth and time duration of the transmission frames. However, the physical\nchannels are determined by the propagation environments and they are typically\noff-grid. Hence, there is often a gap between an actual physical channel and\nthe on-grid model. This paper revisits the on-grid modeling of practical\nphysical channels. We study the associated on-grid DD-domain representations\nfor continuous-time, doubly selective channels with off-grid delay and Doppler\nshifts, accounting for practical time/frequency-domain windowing at the\ntransceivers. The universal models obtained are applicable under the mild\nassumption that the windows have finite supports, and they extend Bello's\nclassical results to account for more general windows. We also discuss the\nfeatures and implications of the equivalent on-grid models."}
{"id": "2510.03628", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.03628", "abs": "https://arxiv.org/abs/2510.03628", "authors": ["Haochen Li"], "title": "Pinching Antenna Systems (PASS) for Cell-Free Communications", "comment": "5 pages, 5 figures", "summary": "A pinching antenna system (PASS) assisted cell-free communication system is\nproposed. A sum rate maximization problem under the BS power budget constraint\nand PA deployment constraint is formulated. To tackle the proposed non-convex\noptimization problem, an alternating optimization (AO) algorithm is developed.\nIn particular, the digital beamforming sub-problem is solved using the weighted\nminimum mean square error (WMMSE) method, whereas the pinching beamforming\nsub-problem is handled via a penalty based approach combined with element-wise\noptimization. Simulation results demonstrate that: 1) the PASS assisted\ncell-free systems achieve superior performance over benchmark schemes; 2)\nincreasing the number of PAs per waveguides can improve the advantage of PASS\nassisted cell-free systems; and 3) the cell-free architecture mitigates the\naverage user rate degradation as the number of users increases."}
{"id": "2510.03372", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.03372", "abs": "https://arxiv.org/abs/2510.03372", "authors": ["Juampablo E. Heras Rivera", "Caitlin M. Neher", "Mehmet Kurt"], "title": "Real-time nonlinear inversion of magnetic resonance elastography with operator learning", "comment": null, "summary": "$\\textbf{Purpose:}$ To develop and evaluate an operator learning framework\nfor nonlinear inversion (NLI) of brain magnetic resonance elastography (MRE)\ndata, which enables real-time inversion of elastograms with comparable spatial\naccuracy to NLI.\n  $\\textbf{Materials and Methods:}$ In this retrospective study, 3D MRE data\nfrom 61 individuals (mean age, 37.4 years; 34 female) were used for development\nof the framework. A predictive deep operator learning framework (oNLI) was\ntrained using 10-fold cross-validation, with the complex curl of the measured\ndisplacement field as inputs and NLI-derived reference elastograms as outputs.\nA structural prior mechanism, analogous to Soft Prior Regularization in the MRE\nliterature, was incorporated to improve spatial accuracy. Subject-level\nevaluation metrics included Pearson's correlation coefficient, absolute\nrelative error, and structural similarity index measure between predicted and\nreference elastograms across brain regions of different sizes to understand\naccuracy. Statistical analyses included paired t-tests comparing the proposed\noNLI variants to the convolutional neural network baselines.\n  $\\textbf{Results:}$ Whole brain absolute percent error was 8.4 $\\pm$ 0.5\n($\\mu'$) and 10.0 $\\pm$ 0.7 ($\\mu''$) for oNLI and 15.8 $\\pm$ 0.8 ($\\mu'$) and\n26.1 $\\pm$ 1.1 ($\\mu''$) for CNNs. Additionally, oNLI outperformed\nconvolutional architectures as per Pearson's correlation coefficient, $r$, in\nthe whole brain and across all subregions for both the storage modulus and loss\nmodulus (p < 0.05).\n  $\\textbf{Conclusion:}$ The oNLI framework enables real-time MRE inversion\n(30,000x speedup), outperforming CNN-based approaches and maintaining the\nfine-grained spatial accuracy achievable with NLI in the brain."}
{"id": "2510.03749", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.03749", "abs": "https://arxiv.org/abs/2510.03749", "authors": ["Fanghao Xia", "Zesong Fei", "Xinyi Wang", "Nanchi Su", "Zhaolin Wang", "Yuanwei Liu", "Jie Xu"], "title": "Towards Secure ISAC Beamforming: How Many Dedicated Sensing Beams Are Required?", "comment": "13 pages, 12 figures", "summary": "In this paper, sensing-assisted secure communication in a multi-user\nmulti-eavesdropper integrated sensing and communication (ISAC) system is\ninvestigated. Confidential communication signals and dedicated sensing signals\nare jointly transmitted by a base station (BS) to simultaneously serve users\nand sense aerial eavesdroppers (AEs). A sum rate maximization problem is\nformulated under AEs' Signal-to-Interference-plus-Noise Ratio (SINR) and\nsensing Signal-to-Clutter-plus-Noise Ratio (SCNR) constraints. A\nfractional-programming-based alternating optimization algorithm is developed to\nsolve this problem for fully digital arrays, where successive convex\napproximation (SCA) and semidefinite relaxation (SDR) are leveraged to handle\nnon-convex constraints. Furthermore, the minimum number of dedicated sensing\nbeams is analyzed via a worst-case rank bound, upon which the proposed\nbeamforming design is further extended to the hybrid analog-digital (HAD) array\narchitecture, where the unit-modulus constraint is addressed by manifold\noptimization. Simulation results demonstrate that only a small number of\nsensing beams are sufficient for both sensing and jamming AEs, and the proposed\ndesigns consistently outperform strong baselines while also revealing the\ncommunication-sensing trade-off."}
{"id": "2510.03568", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.03568", "abs": "https://arxiv.org/abs/2510.03568", "authors": ["Claudia Takyi Ankomah", "Livingstone Eli Ayivor", "Ireneaus Nyame", "Leslie Wambo", "Patrick Yeboah Bonsu", "Aondona Moses Iorumbur", "Raymond Confidence", "Toufiq Musah"], "title": "How We Won BraTS-SSA 2025: Brain Tumor Segmentation in the Sub-Saharan African Population Using Segmentation-Aware Data Augmentation and Model Ensembling", "comment": "Brain Tumor Segmentation Challenge, Medical Image Computing and\n  Computer Assisted Intervention (MICCAI) Conference, 11 Pages, 2 Figures, 2\n  Tables", "summary": "Brain tumors, particularly gliomas, pose significant chall-enges due to their\ncomplex growth patterns, infiltrative nature, and the variability in brain\nstructure across individuals, which makes accurate diagnosis and monitoring\ndifficult. Deep learning models have been developed to accurately delineate\nthese tumors. However, most of these models were trained on relatively\nhomogenous high-resource datasets, limiting their robustness when deployed in\nunderserved regions. In this study, we performed segmentation-aware offline\ndata augmentation on the BraTS-Africa dataset to increase the data sample size\nand diversity to enhance generalization. We further constructed an ensemble of\nthree distinct architectures, MedNeXt, SegMamba, and Residual-Encoder U-Net, to\nleverage their complementary strengths. Our best-performing model, MedNeXt, was\ntrained on 1000 epochs and achieved the highest average lesion-wise dice and\nnormalized surface distance scores of 0.86 and 0.81 respectively. However, the\nensemble model trained for 500 epochs produced the most balanced segmentation\nperformance across the tumour subregions. This work demonstrates that a\ncombination of advanced augmentation and model ensembling can improve\nsegmentation accuracy and robustness on diverse and underrepresented datasets.\nCode available at:\nhttps://github.com/SPARK-Academy-2025/SPARK-2025/tree/main/SPARK2025_BraTs_MODELS/SPARK_NeuroAshanti"}
{"id": "2510.03780", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.03780", "abs": "https://arxiv.org/abs/2510.03780", "authors": ["Yiqiao Chen"], "title": "A Benchmark Study of Deep Learning Methods for Multi-Label Pediatric Electrocardiogram-Based Cardiovascular Disease Classification", "comment": "8 pages, 5 figures", "summary": "Cardiovascular disease (CVD) is a major pediatric health burden, and early\nscreening is of critical importance. Electrocardiography (ECG), as a\nnoninvasive and accessible tool, is well suited for this purpose. This paper\npresents the first benchmark study of deep learning for multi-label pediatric\nCVD classification on the recently released ZZU-pECG dataset, comprising 3716\nrecordings with 19 CVD categories. We systematically evaluate four\nrepresentative paradigms--ResNet-1D, BiLSTM, Transformer, and Mamba 2--under\nboth 9-lead and 12-lead configurations. All models achieved strong results,\nwith Hamming Loss as low as 0.0069 and F1-scores above 85% in most settings.\nResNet-1D reached a macro-F1 of 94.67% on the 12-lead subset, while BiLSTM and\nTransformer also showed competitive performance. Per-class analysis indicated\nchallenges for rare conditions such as hypertrophic cardiomyopathy in the\n9-lead subset, reflecting the effect of limited positive samples. This\nbenchmark establishes reusable baselines and highlights complementary strengths\nacross paradigms. It further points to the need for larger-scale, multi-center\nvalidation, age-stratified analysis, and broader disease coverage to support\nreal-world pediatric ECG applications."}
{"id": "2510.03812", "categories": ["eess.IV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03812", "abs": "https://arxiv.org/abs/2510.03812", "authors": ["Changhong Li", "Cl√©ment Bled", "Rosa Fernandez", "Shreejith Shanker"], "title": "ReTiDe: Real-Time Denoising for Energy-Efficient Motion Picture Processing with FPGAs", "comment": "This paper has been accepted by the 22nd ACM SIGGRAPH European\n  Conference on Visual Media Production (CVMP 2025)", "summary": "Denoising is a core operation in modern video pipelines. In codecs, in-loop\nfilters suppress sensor noise and quantisation artefacts to improve\nrate-distortion performance; in cinema post-production, denoisers are used for\nrestoration, grain management, and plate clean-up. However, state-of-the-art\ndeep denoisers are computationally intensive and, at scale, are typically\ndeployed on GPUs, incurring high power and cost for real-time, high-resolution\nstreams. This paper presents Real-Time Denoise (ReTiDe), a hardware-accelerated\ndenoising system that serves inference on data-centre Field Programmable Gate\nArrays (FPGAs). A compact convolutional model is quantised (post-training\nquantisation plus quantisation-aware fine-tuning) to INT8 and compiled for AMD\nDeep Learning Processor Unit (DPU)-based FPGAs. A client-server integration\noffloads computation from the host CPU/GPU to a networked FPGA service, while\nremaining callable from existing workflows, e.g., NUKE, without disrupting\nartist tooling. On representative benchmarks, ReTiDe delivers 37.71$\\times$\nGiga Operations Per Second (GOPS) throughput and 5.29$\\times$ higher energy\nefficiency than prior FPGA denoising accelerators, with negligible degradation\nin Peak Signal-to-Noise Ratio (PSNR)/Structural Similarity Index (SSIM). These\nresults indicate that specialised accelerators can provide practical, scalable\ndenoising for both encoding pipelines and post-production, reducing energy per\nframe without sacrificing quality or workflow compatibility. Code is available\nat https://github.com/RCSL-TCD/ReTiDe."}
{"id": "2510.03787", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.03787", "abs": "https://arxiv.org/abs/2510.03787", "authors": ["Jacopo Pegoraro", "Gianmaria Ventura", "Dario Tagliaferri", "Marco Mezzavilla", "Andrea Bedin", "Michele Rossi", "Joerg Widmer"], "title": "Toward Multiband Sensing in FR3: Frequency Anisotropy Characterization and Non-Contiguous Bands Aggregation Algorithms", "comment": "19 pages, 14 figures", "summary": "Frequency Range 3 (FR3) in the 7-24 GHz band will be the new spectrum for 6G\nwireless networks. The bandwidth availability and diversity of FR3 offer\nunprecedented opportunities for coherent multiband Integrated Sensing and\nCommunications (ISAC), which aggregates the carrier phase information from\nmultiple frequency bands to increase the sensing resolution to the cm-level.\nHowever, the frequency anisotropy of sensing targets over GHz-wide bands and\nthe non-contiguity of the 6G spectrum, pose critical challenges to the\napplication of existing multiband ISAC techniques. We present the first study\non coherent multiband sensing in FR3. We experimentally characterize the\nfrequency anisotropy of targets and propose new phase coherence metrics for\nmultiband processing. Then, we analyze the impact of non-contiguous FR3 bands\nconsidered by 3GPP, and design a new algorithm to mitigate the resulting\nsensing artifacts, outperforming existing techniques. Our results represent a\nfirst step toward fully developing multiband ISAC for FR3."}
{"id": "2510.03833", "categories": ["eess.IV", "cs.CV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2510.03833", "abs": "https://arxiv.org/abs/2510.03833", "authors": ["Shuoyan Wei", "Feng Li", "Shengeng Tang", "Runmin Cong", "Yao Zhao", "Meng Wang", "Huihui Bai"], "title": "Towards Robust and Generalizable Continuous Space-Time Video Super-Resolution with Events", "comment": "17 pages, 12 figures, 14 tables. Under review", "summary": "Continuous space-time video super-resolution (C-STVSR) has garnered\nincreasing interest for its capability to reconstruct high-resolution and\nhigh-frame-rate videos at arbitrary spatial and temporal scales. However,\nprevailing methods often generalize poorly, producing unsatisfactory results\nwhen applied to out-of-distribution (OOD) scales. To overcome this limitation,\nwe present EvEnhancer, a novel approach that marries the unique properties of\nhigh temporal resolution and high dynamic range encapsulated in event streams\nto achieve robust and generalizable C-STVSR. Our approach incorporates\nevent-adapted synthesis that capitalizes on the spatiotemporal correlations\nbetween frames and events to capture long-term motion trajectories, enabling\nadaptive interpolation and fusion across space and time. This is then coupled\nwith a local implicit video transformer that integrates local implicit video\nneural function with cross-scale spatiotemporal attention to learn continuous\nvideo representations and generate plausible videos at arbitrary resolutions\nand frame rates. We further develop EvEnhancerPlus, which builds a controllable\nswitching mechanism that dynamically determines the reconstruction difficulty\nfor each spatiotemporal pixel based on local event statistics. This allows the\nmodel to adaptively route reconstruction along the most suitable pathways at a\nfine-grained pixel level, substantially reducing computational overhead while\nmaintaining excellent performance. Furthermore, we devise a cross-derivative\ntraining strategy that stabilizes the convergence of such a multi-pathway\nframework through staged cross-optimization. Extensive experiments demonstrate\nthat our method achieves state-of-the-art performance on both synthetic and\nreal-world datasets, while maintaining superior generalizability at OOD scales.\nThe code is available at https://github.com/W-Shuoyan/EvEnhancerPlus."}
{"id": "2510.03818", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.03818", "abs": "https://arxiv.org/abs/2510.03818", "authors": ["Lulu Song", "Di Zhang", "Tingting Zhang"], "title": "Source PAC Coding for Low-latency Secret Key Generation in Short Blocklength Regime", "comment": null, "summary": "Source polar coding is a potential solution for short blocklength-based\nlow-latency key generation with limited sources, which is a critical aspect of\nsix generation (6G) Internet of things. However, existing source coding schemes\nstill suffer from significant degradation in key generation rate and\nreconciliation reliability in short blocklength regime. To address this issue,\nwe introduce a multilevel source polarization-adjusted convolutional (PAC)\ncoding framework. Furthermore, we propose a novel code construction algorithm\nthat jointly leverages polarization effects and the maximum likelihood (ML)\ndecoding error coefficient. Simulations demonstrate that the multilevel source\nPAC scheme with the proposed code construction achieves superior key generation\nrate under key disagreement constraints compared to conventional and multilevel\nsource polar coding methods even in short blocklength regimes."}
{"id": "2510.03856", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.03856", "abs": "https://arxiv.org/abs/2510.03856", "authors": ["Sanhita Basu", "Tomas Fr√∂ding", "Ali Teymur Kahraman", "Dimitris Toumpanakis", "Tobias Sj√∂blom"], "title": "AI-Assisted Pleural Effusion Volume Estimation from Contrast-Enhanced CT Images", "comment": null, "summary": "Background: Pleural Effusions (PE) is a common finding in many different\nclinical conditions, but accurately measuring their volume from CT scans is\nchallenging. Purpose: To improve PE segmentation and quantification for\nenhanced clinical management, we have developed and trained a semi-supervised\ndeep learning framework on contrast-enhanced CT volumes. Materials and Methods:\nThis retrospective study collected CT Pulmonary Angiogram (CTPA) data from\ninternal and external datasets. A subset of 100 cases was manually annotated\nfor model training, while the remaining cases were used for testing and\nvalidation. A novel semi-supervised deep learning framework, Teacher-Teaching\nAssistant-Student (TTAS), was developed and used to enable efficient training\nin non-segmented examinations. Segmentation performance was compared to that of\nstate-of-the-art models. Results: 100 patients (mean age, 72 years, 28\n[standard deviation]; 55 men) were included in the study. The TTAS model\ndemonstrated superior segmentation performance compared to state-of-the-art\nmodels, achieving a mean Dice score of 0.82 (95% CI, 0.79 - 0.84) versus 0.73\nfor nnU-Net (p < 0.0001, Student's T test). Additionally, TTAS exhibited a\nfour-fold lower mean Absolute Volume Difference (AbVD) of 6.49 mL (95% CI, 4.80\n- 8.20) compared to nnU-Net's AbVD of 23.16 mL (p < 0.0001). Conclusion: The\ndeveloped TTAS framework offered superior PE segmentation, aiding accurate\nvolume determination from CT scans."}
{"id": "2510.03848", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.03848", "abs": "https://arxiv.org/abs/2510.03848", "authors": ["Jianyu Wang", "Zhichao Li", "Wenchi Cheng", "Wei Zhang", "Hailin Zhang"], "title": "Multi-Frequency Resonating Based Magnetic Induction Underground Emergency Communications with Diverse Mediums", "comment": null, "summary": "Magnetic induction (MI) communication is an effective underground emergency\ncommunication technique after disasters such as landslides, mine collapses, and\nearthquakes, due to its advantages in mediums such as soil, concrete, and\nmetals. However, the propagation mediums in practical MI based underground\nemergency communications are usually diverse and composed randomly due to the\nimpact of disasters, which poses a challenge for MI communication in practical\napplications. In this paper, we formulate a statistical fading channel model,\nwhich reflects the random composition of diverse mediums and is shown to follow\na lognormal distribution. To mitigate the impact of diverse medium fading,\nMulti-frequency Resonating Compensation (MuReC) based coils are used to achieve\nmultiband transmission. Then, we analyze the performance of MuReC based\nmulti-band MI communication with diverse medium fading and derive the\nexpressions of signal-to-noise ratio (SNR) probability density functions,\nergodic capacities, average bit error rates (BERs), and outage probabilities\nfor both multiplexing and diversity cases. Numerical results show that MuReC\nbased multiband transmission schemes can effectively reduce the impact of\ndiverse medium fading and enhance the performance."}
{"id": "2510.03926", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.03926", "abs": "https://arxiv.org/abs/2510.03926", "authors": ["Alexander Kopte", "Andr√© Kaup"], "title": "Sliding Window Attention for Learned Video Compression", "comment": "Accepted for PCS 2025", "summary": "To manage the complexity of transformers in video compression, local\nattention mechanisms are a practical necessity. The common approach of\npartitioning frames into patches, however, creates architectural flaws like\nirregular receptive fields. When adapted for temporal autoregressive models,\nthis paradigm, exemplified by the Video Compression Transformer (VCT), also\nnecessitates computationally redundant overlapping windows. This work\nintroduces 3D Sliding Window Attention (SWA), a patchless form of local\nattention. By enabling a decoder-only architecture that unifies spatial and\ntemporal context processing, and by providing a uniform receptive field, our\nmethod significantly improves rate-distortion performance, achieving\nBj{\\o}rntegaard Delta-rate savings of up to 18.6 % against the VCT baseline.\nSimultaneously, by eliminating the need for overlapping windows, our method\nreduces overall decoder complexity by a factor of 2.8, while its entropy model\nis nearly 3.5 times more efficient. We further analyze our model's behavior and\nshow that while it benefits from long-range temporal context, excessive context\ncan degrade performance."}
{"id": "2510.03850", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.03850", "abs": "https://arxiv.org/abs/2510.03850", "authors": ["Fernando Dar√≠o Almeida Garc√≠a", "Francisco Raimundo Albuquerque Parente", "Michel Daoud Yacoub", "Jose C√¢ndido Silveira Santos Filho"], "title": "On the Exact Sum PDF and CDF of Œ±-Œº Variates", "comment": null, "summary": "The sum of random variables (RVs) appears extensively in wireless\ncommunications, at large, both conventional and advanced, and has been subject\nof longstanding research. The statistical characterization of the referred sum\nis crucial to determine the performance of such communications systems.\nAlthough efforts have been undertaken to unveil these sum statistics, e.g.,\nprobability density function (PDF) and cumulative distribution function (CDF),\nno general efficient nor manageable solutions capable of evaluating the exact\nsum PDF and CDF are available to date. The only formulations are given in terms\nof either the multi-fold Brennan's integral or the multivariate Fox H-function.\nUnfortunately, these methods are only feasible up to a certain number of RVs,\nmeaning that when the number of RVs in the sum increases, the computation of\nthe sum PDF and CDF is subject to stability problems, convergence issues, or\ninaccurate results. In this paper, we derive new, simple, exact formulations\nfor the PDF and CDF of the sum of L independent and identically distributed\n{\\alpha}-{\\mu} RVs. Unlike the available solutions, the computational\ncomplexity of our analytical expressions is independent of the number of\nsummands. Capitalizing on our unprecedented findings, we analyze, in exact and\nasymptotic manners, the performance of L-branch pre-detection equal-gain\ncombining and maximal-ratio combining receivers over {\\alpha}-{\\mu} fading\nenvironments. The coding and diversity gains of the system for both receivers\nare analyzed and quantified. Moreover, numerical simulations show that the\ncomputation time reduces drastically when using our expressions, which are\narguably the most efficient and manageable formulations derived so far."}
{"id": "2510.04369", "categories": ["eess.IV", "cs.CV", "cs.NA", "math.NA"], "pdf": "https://arxiv.org/pdf/2510.04369", "abs": "https://arxiv.org/abs/2510.04369", "authors": ["Bernadette Hahn", "Gael Rigaud", "Richard Schm√§hl"], "title": "The method of the approximate inverse for limited-angle CT", "comment": null, "summary": "Limited-angle computerized tomography stands for one of the most difficult\nchallenges in imaging. Although it opens the way to faster data acquisition in\nindustry and less dangerous scans in medicine, standard approaches, such as the\nfiltered backprojection (FBP) algorithm or the widely used total-variation\nfunctional, often produce various artefacts that hinder the diagnosis. With the\nrise of deep learning, many modern techniques have proven themselves successful\nin removing such artefacts but at the cost of large datasets. In this paper, we\npropose a new model-driven approach based on the method of the approximate\ninverse, which could serve as new starting point for learning strategies in the\nfuture. In contrast to FBP-type approaches, our reconstruction step consists in\nevaluating linear functionals on the measured data using reconstruction kernels\nthat are precomputed as solution of an auxiliary problem. With this problem\nbeing uniquely solvable, the derived limited-angle reconstruction kernel (LARK)\nis able to fully reconstruct the object without the well-known streak\nartefacts, even for large limited angles. However, it inherits severe\nill-conditioning which leads to a different kind of artefacts arising from the\nsingular functions of the limited-angle Radon transform. The problem becomes\nparticularly challenging when working on semi-discrete (real or analytical)\nmeasurements. We develop a general regularization strategy, named constrained\nlimited-angle reconstruction kernel (CLARK), by combining spectral filter, the\nmethod of the approximate inverse and custom edge-preserving denoising in order\nto stabilize the whole process. We further derive and interpret error estimates\nfor the application on real, i.e. semi-discrete, data and we validate our\napproach on synthetic and real data."}
{"id": "2510.03852", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.03852", "abs": "https://arxiv.org/abs/2510.03852", "authors": ["Jianyu Wang", "Tianrui Hou", "Wenchi Cheng", "Hailin Zhang"], "title": "Robust Beamforming for Magnetic Induction Based Underground Emergency Communications", "comment": null, "summary": "Magnetic induction (MI) communication is an effective underground emergency\ncommunication technique after disasters such as landslides, mine collapses, and\nearthquakes, due to its advantages in mediums such as soil, concrete, and\nmetals. Based on channel state information (CSI), magnetic beamforming can\nsignificantly improve the performance of MI communication. However, in\npost-disaster underground communication, channel estimation may suffer from\nerrors due to factors such as complex environmental interferences. Taking\nchannel estimation error into account, we formulate a beamforming optimization\nproblem for multi-user MI underground emergency communications, which aims to\nminimize the power consumption under the constraints of sum rate and signal to\ninterference plus noise ratio (SINR) of each user. Based on the worst-case\noptimization criterion and the S-procedure, the non-convex optimization problem\nis transformed into convex and solved. Numerical results show that the proposed\nrobust beamforming scheme can effectively enhance communication reliability and\neffective throughput in the presence of channel estimation errors."}
{"id": "2510.04382", "categories": ["eess.IV", "cs.CV", "cs.NA", "math.NA"], "pdf": "https://arxiv.org/pdf/2510.04382", "abs": "https://arxiv.org/abs/2510.04382", "authors": ["Wojciech G√≥rny", "Micha≈Ç ≈Åasica", "Alexandros Matsoukas"], "title": "Adaptive double-phase Rudin--Osher--Fatemi denoising model", "comment": "21 pages, 18 figures, supplementary material available at:\n  https://github.com/wojciechgorny/double-phase-ROF-model/", "summary": "We propose a new image denoising model based on a variable-growth total\nvariation regularization of double-phase type with adaptive weight. It is\ndesigned to reduce staircasing with respect to the classical\nRudin--Osher--Fatemi model, while preserving the edges of the image in a\nsimilar fashion. We implement the model and test its performance on synthetic\nand natural images in 1D and 2D over a range of noise levels."}
{"id": "2510.03901", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.03901", "abs": "https://arxiv.org/abs/2510.03901", "authors": ["Vincent Savaux", "Steve Sawadogo", "Hyeon Seok Rou", "Giuseppe Thadeu Freitas de Abreu"], "title": "On the Noise Robustness of Affine Frequency Division Multiplexing: Analysis and Applications", "comment": "9 pages, 5 figures, conference", "summary": "This paper investigates the robustness of affine frequency division\nmultiplexing (AFDM) and orthogonal time frequency space (OTFS) modulation\nschemes against non-white Gaussian noise, which can model various sources of\nadditive disturbances to the received signal. The proposed approach\ndemonstrates that the performance of these waveforms depends on the ability of\nthe demodulation matrix to whiten the noise-a property that is, in turn,\nrelated to the sparsity of the matrix. AFDM is shown to outperform OTFS and\northogonal frequency division multiplexing (OFDM), as its demodulation matrix\nis generally less sparse than those of the other waveforms. Based on this\nanalysis, several application examples and use cases are presented, such as the\nuse of AFDM and OTFS in narrowband signals or in coexistence with OFDM signals.\nFinally, simulation results confirm that AFDM achieves better performance than\nOTFS and OFDM in the presence of non-white noise, with gains exceeding 1 dB in\nmost application scenarios."}
{"id": "2510.04037", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.04037", "abs": "https://arxiv.org/abs/2510.04037", "authors": ["Mohammad Salman", "Hadi Zayyani", "Hasan Abu Hilal", "Mostafa Rashdan"], "title": "Closed-form Solutions for Velocity and Acceleration of a Moving Vehicle Using Range, Range Rate, and Derivative of Range Rate", "comment": null, "summary": "This letter presents a novel method for estimating the position, velocity,\nand acceleration of a moving target using range-based measurements. Although\nmost existing studies focus on position and velocity estimation, the framework\nof this letter is extended to include acceleration. To achieve this, we propose\nusing the derivative of the range rate, in addition to the range and range rate\nmeasurements. The proposed method estimates the position at first using\nTime-of-Arrival (TOA)-based techniques; then, develops a reformulated least\nsquares (LS) and weighted least squares (WLS) approaches for velocity\nestimation; and finally, employs the derivative of the range rate to estimate\nthe acceleration using previous position and velocity estimates. On the other\nhand, closed-form LS and WLS solutions are derived for both velocity and\nacceleration. The simulation results show that the proposed approach provides\nimproved performance in estimating moving target kinematics compared to\nexisting methods."}
{"id": "2510.04160", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.04160", "abs": "https://arxiv.org/abs/2510.04160", "authors": ["Mohammad Kazzazi", "Mohammad Morsali", "Rouhollah Amiri"], "title": "CLEAR: A Closed-Form Minimal-Sensor TDOA/FDOA Estimator for Moving-Source IoT Localization", "comment": "Mohammad Kazzazi and Mohammad Morsali contributed equally to this\n  work", "summary": "This paper presents CLEAR -- a closed-form localization estimator with a\nreduced sensor network. The proposed method is a computationally efficient,\ntwo-stage estimator that fuses time-difference-of-arrival (TDOA) and\nfrequency-difference-of-arrival (FDOA) measurements with a minimal number of\nsensors. CLEAR localizes a moving source in N-dimensional space using only N+1\nsensors, achieving the theoretical minimum sensor count. The first stage\nintroduces auxiliary range and range-rate parameters to construct a set of\npseudo-linear equations, solved via weighted least squares. An algebraic\nelimination using Sylvester's resultant then reduces the problem to a quartic\nequation, yielding closed-form estimates for the nuisance variables. A second,\nlightweight linear refinement stage is applied to mitigate residual bias. Under\nmild Gaussian noise assumptions, the estimator's position and velocity\nestimates are statistically efficient, closely approaching the Cramer-Rao lower\nbound (CRLB). Extensive Monte Carlo simulations in 2-D and 3-D scenarios\ndemonstrate CRLB-level accuracy and consistent performance gains over\nrepresentative two-stage and iterative baselines, confirming the method's high\nsuitability for power-constrained, distributed Internet of Things (IoT)\napplications such as UAV tracking and smart transportation."}
{"id": "2510.04240", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.04240", "abs": "https://arxiv.org/abs/2510.04240", "authors": ["Dario Tagliaferri", "Silvia Mura", "Musa Furkan Keskin", "Sauradeep Dey", "Henk Wymeersch"], "title": "Integrating Phase-Coherent Multistatic Imaging in Downlink D-MIMO Networks", "comment": "13 pages", "summary": "This paper addresses the challenge of integrating multistatic coherent\nimaging functionalities in the downlink (DL) of a phase-coherent distributed\nmultiple input multiple output (D-MIMO) communication network. During DL, the\nD-MIMO access points (APs) jointly precode the transmitted signals to maximize\nthe spectral efficiency (SE) at the users (UEs) locations. However, imaging\nrequires that \\textit{(i)} a fraction of the APs work as receivers for sensing\nand \\textit{(ii)} the transmitting APs emit AP-specific and orthogonal signals\nto illuminate the area to be imaged and allow multistatic operation. In these\nsettings, our contribution is twofold. We propose a novel distributed\nintegrated sensing and communication (D-ISAC) system that superposes a\npurposely designed AP-specific signal for imaging to the legacy UE-specific\ncommunication one, with a tunable trade-off factor. We detail both the imaging\nwaveform design according to the \\textit{extended orthogonality condition} and\nthe space-frequency precoder design. Then, we propose an optimized selection\nstrategy for the receiving APs, in order to maximize imaging performance under\nhalf-duplex constraints. Extensive numerical results prove the feasibility and\nbenefits of our proposal, materializing the potential of joint multistatic\nimaging and communications in practical D-MIMO deployments."}
{"id": "2510.04258", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.04258", "abs": "https://arxiv.org/abs/2510.04258", "authors": ["Ziang Zhao", "Weixi Liang", "Kai Hu", "Qun Zhang", "Xiongbin Yu", "Qiang Li"], "title": "Terahertz Channel Measurement and Modeling for Short-Range Indoor Environments", "comment": null, "summary": "Accurate channel modeling is essential for realizing the potential of\nterahertz (THz) communications in 6G indoor networks, where existing models\nstruggle with severe frequency selectivity and multipath effects. We propose a\nphysically grounded Rician fading channel model that jointly incorporates\ndeterministic line-of-sight (LOS) and stochastic non-line-of-sight (NLOS)\ncomponents, enhanced by frequency-dependent attenuation characterized by\noptimized exponents alpha and beta. Unlike conventional approaches, our model\nintegrates a two-ray reflection framework to capture standing wave phenomena\nand employs wideband spectral averaging to mitigate frequency selectivity over\nbandwidths up to 15 GHz. Empirical measurements at a 208 GHz carrier, spanning\n0.1-0.9 m, demonstrate that our model achieves root mean square errors (RMSE)\nas low as 2.54 dB, outperforming free-space path loss (FSPL) by up to 14.2% and\nreducing RMSE by 73.3% as bandwidth increases. These findings underscore the\nimportance of bandwidth in suppressing oscillatory artifacts and improving\nmodeling accuracy. Our approach provides a robust foundation for THz system\ndesign, supporting reliable indoor wireless personal area networks (WPANs),\ndevice-to-device (D2D) communications, and precise localization in future 6G\napplications."}
{"id": "2510.04359", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.04359", "abs": "https://arxiv.org/abs/2510.04359", "authors": ["Minsu Kim", "Walid Saad", "Dour Calin"], "title": "Efficient Domain Generalization in Wireless Networks with Scarce Multi-Modal Data", "comment": "Submitted to IEEE TWC", "summary": "In 6G wireless networks, multi-modal ML models can be leveraged to enable\nsituation-aware network decisions in dynamic environments. However, trained ML\nmodels often fail to generalize under domain shifts when training and test data\ndistributions are different because they often focus on modality-specific\nspurious features. In practical wireless systems, domain shifts occur\nfrequently due to dynamic channel statistics, moving obstacles, or hardware\nconfiguration. Thus, there is a need for learning frameworks that can achieve\nrobust generalization under scarce multi-modal data in wireless networks. In\nthis paper, a novel and data-efficient two-phase learning framework is proposed\nto improve generalization performance in unseen and unfamiliar wireless\nenvironments with minimal amount of multi-modal data. In the first stage, a\nphysics-based loss function is employed to enable each BS to learn the physics\nunderlying its wireless environment captured by multi-modal data. The\ndata-efficiency of the physics-based loss function is analytically\ninvestigated. In the second stage, collaborative domain adaptation is proposed\nto leverage the wireless environment knowledge of multiple BSs to guide\nunder-performing BSs under domain shift. Specifically, domain-similarity-aware\nmodel aggregation is proposed to utilize the knowledge of BSs that experienced\nsimilar domains. To validate the proposed framework, a new dataset generation\nframework is developed by integrating CARLA and MATLAB-based mmWave channel\nmodeling to predict mmWave RSS. Simulation results show that the proposed\nphysics-based training requires only 13% of data samples to achieve the same\nperformance as a state-of-the-art baseline that does not use physics-based\ntraining. Moreover, the proposed collaborative domain adaptation needs only 25%\nof data samples and 20% of FLOPs to achieve the convergence compared to\nbaselines."}
{"id": "2510.04402", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.04402", "abs": "https://arxiv.org/abs/2510.04402", "authors": ["Binyu Lu", "Matthias Frey", "Stark Draper", "Jingge Zhu"], "title": "Low-Rank-Based Approximate Computation with Memristors", "comment": "5 pages, 2 figures, submitted to an IEEE conference for possible\n  publication", "summary": "Memristor crossbars enable vector-matrix multiplication (VMM), and are\npromising for low-power applications. However, it can be difficult to write the\nmemristor conductance values exactly. To improve the accuracy of VMM, we\npropose a scheme based on low-rank matrix approximation. Specifically, singular\nvalue decomposition (SVD) is first applied to obtain a low-rank approximation\nof the target matrix, which is then factored into a pair of smaller matrices.\nSubsequently, a two-step serial VMM is executed, where the stochastic write\nerrors are mitigated through step-wise averaging. To evaluate the performance\nof the proposed scheme, we derive a general expression for the resulting\ncomputation error and provide an asymptotic analysis under a prescribed\nsingular-value profile, which reveals how the error scales with matrix size and\nrank. Both analytical and numerical results confirm the superiority of the\nproposed scheme compared with the benchmark scheme."}
{"id": "2510.04409", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.04409", "abs": "https://arxiv.org/abs/2510.04409", "authors": ["Samyadip Sarkar", "Arunashish Datta", "David Yang", "Mayukh Nath", "Shovan Maity", "Shreyas Sen"], "title": "Effect of nearby Metals on Electro-Quasistatic Human Body Communication", "comment": "18 pages, 25 Figures, 2 Tables, 5 Appendix", "summary": "In recent decades Human Body Communication has emerged as a promising\nalternative to traditional radio wave communication, utilizing the body's\nconductive properties for low-power connectivity among wearables. This method\nharnesses the human body as an energy-efficient channel for data transmission\nwithin the electro-quasistatic frequency range, enabling advancements in\nhuman-machine interaction. While prior work has noted the role of parasitic\nreturn paths in such capacitively coupled systems, the influence of surrounding\nmetallic objects on these paths, which are critical for EQS wireless signaling,\nhas not been fully explored. This paper fills that gap with a structured study\nof how various conducting objects, from non-grounded (floating) metals and\ngrounded metals to enclosed metallic environments such as elevators and cars,\naffect the body-communication channel. We present a theoretical framework\nsupported by finite element method simulations and experiments with wearable\ndevices. Results show that metallic objects within 20 cm of devices can reduce\ntransmission loss by about 10 dB. When a device ground connects to a grounded\nmetallic object, channel gain can increase by at least 20 dB. Contact area\nduring touch-based interactions with grounded metals produces contact-impedance\ndependent high-pass channel characteristics. Proximity to metallic objects\nintroduces variability within a critical distance, with grounded metals\nproducing a larger overall effect than floating metals. These findings improve\nunderstanding of body-centric communication links and inform design for\nhealthcare, consumer electronics, defense, and industrial applications."}
{"id": "2510.04413", "categories": ["eess.SP", "cs.NI"], "pdf": "https://arxiv.org/pdf/2510.04413", "abs": "https://arxiv.org/abs/2510.04413", "authors": ["Muhammad Umar Farooq Qaisar", "Weijie Yuan", "Onur G√ºnl√º", "Taneli Riihonen", "Yuanhao Cui", "Lin Zhang", "Nuria Gonzalez-Prelcic", "Marco Di Renzo", "Zhu Han"], "title": "The Role of ISAC in 6G Networks: Enabling Next-Generation Wireless Systems", "comment": "28 pages, 6 figures, and 5 tables", "summary": "The commencement of the sixth-generation (6G) wireless networks represents a\nfundamental shift in the integration of communication and sensing technologies\nto support next-generation applications. Integrated sensing and communication\n(ISAC) is a key concept in this evolution, enabling end-to-end support for both\ncommunication and sensing within a unified framework. It enhances spectrum\nefficiency, reduces latency, and supports diverse use cases, including smart\ncities, autonomous systems, and perceptive environments. This tutorial provides\na comprehensive overview of ISAC's role in 6G networks, beginning with its\nevolution since 5G and the technical drivers behind its adoption. Core\nprinciples and system variations of ISAC are introduced, followed by an\nin-depth discussion of the enabling technologies that facilitate its practical\ndeployment. The paper further analyzes current research directions to highlight\nkey challenges, open issues, and emerging trends. Design insights and\nrecommendations are also presented to support future development and\nimplementation. This work ultimately try to address three central questions:\nWhy is ISAC essential for 6G? What innovations does it bring? How will it shape\nthe future of wireless communication?"}
{"id": "2510.04492", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.04492", "abs": "https://arxiv.org/abs/2510.04492", "authors": ["Zhou Zhang", "Yizhu Wang", "Saman Atapattu", "Sumei Sun"], "title": "Joint Probing and Scheduling for Cache-Aided Hybrid Satellite-Terrestrial Networks", "comment": "6 pages, IEEE Global Communications Conference (GLOBECOM), December\n  2025, Taipei, Taiwan", "summary": "Caching is crucial in hybrid satellite-terrestrial networks to reduce\nlatency, optimize throughput, and improve data availability by storing\nfrequently accessed content closer to users, especially in bandwidth-limited\nsatellite systems, requiring strategic Medium Access Control (MAC) layer. This\npaper addresses throughput optimization in satellite-terrestrial integrated\nnetworks through opportunistic cooperative caching. We propose a joint probing\nand scheduling strategy to enhance content retrieval efficiency. The strategy\nleverages the LEO satellite to probe satellite-to-ground links and cache states\nof multiple cooperative terrestrial stations, enabling dynamic user scheduling\nfor content delivery. Using an optimal stopping theoretic approach with two\nlevels of incomplete information, we make real-time decisions on\nsatellite-terrestrial hybrid links and caching probing. Our threshold-based\nstrategy optimizes probing and scheduling, significantly improving average\nsystem throughput by exploiting cooperative caching, satellite-terrestrial link\ntransmission, and time diversity from dynamic user requests. Simulation results\nvalidate the effectiveness and practicality of the proposed strategies."}
{"id": "2510.04530", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.04530", "abs": "https://arxiv.org/abs/2510.04530", "authors": ["Gayathri Shekar", "Saman Atapattu", "Prathapasinghe Dharmawansa", "Kandeepan Sithamparanathan"], "title": "Performance Analysis for Multi-User Holographic MIMO Downlink with Matched Filter Precoding", "comment": "6 pages, IEEE Global Communications Conference (GLOBECOM), December\n  2025, Taipei, Taiwan", "summary": "Holographic MIMO (HMIMO) has emerged as a promising solution for future\nwireless systems by enabling ultra-dense, spatially continuous antenna\ndeployments. While prior studies have primarily focused on electromagnetic (EM)\nmodeling or simulation-based performance analysis, a rigorous\ncommunication-theoretic framework remains largely unexplored. This paper\npresents the first analytical performance study of a multi-user HMIMO downlink\nsystem with matched filter (MF) precoding - a low-complexity baseline scheme.\nBy incorporating multipath propagation, mutual coupling, and element\nexcitation, we derive a novel closed-form expression for the MF\nsignal-to-interference-plus-noise ratio (SINR) using an equivalent random\nvariable model. Leveraging bivariate gamma distributions, we then develop\ntractable throughput approximations under full, partial, and no channel state\ninformation (CSI) scenarios. Additionally, we formulate a max-min beamforming\nproblem to benchmark optimal user fairness performance. Numerical results\nvalidate the accuracy of the proposed framework and reveal that MF precoding\nachieves competitive performance with strong robustness to low SINR and CSI\nuncertainty."}
{"id": "2510.04600", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.04600", "abs": "https://arxiv.org/abs/2510.04600", "authors": ["Meidong Xia", "Zhenyao He", "Wei Xu", "Yongming Huang", "Derrick Wing Kwan Ng", "Naofal Al-Dhahir"], "title": "Coordinated Beamforming for Networked Integrated Communication and Multi-TMT Localization", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Networked integrated sensing and communication (ISAC) has gained significant\nattention as a promising technology for enabling next-generation wireless\nsystems. To further enhance networked ISAC, delegating the reception of sensing\nsignals to dedicated target monitoring terminals (TMTs) instead of base\nstations (BSs) offers significant advantages in terms of sensing capability and\ndeployment flexibility. Despite its potential, the coordinated beamforming\ndesign for networked integrated communication and time-of-arrival (ToA)-based\nmulti-TMT localization remains largely unexplored. In this paper, we present a\ncomprehensive study to fill this gap. Specifically, we first establish signal\nmodels for both communication and localization, and, for the first time, derive\na closed-form Cram\\'er-Rao lower bound (CRLB) to characterize the localization\nperformance. Subsequently, we exploit this CRLB to formulate two optimization\nproblems, focusing on sensing-centric and communication-centric criteria,\nrespectively. For the sensing-centric problem, we develop a globally optimal\nalgorithm based on semidefinite relaxation (SDR) when each BS is equipped with\nmore antennas than the total number of communication users. While for the\ncommunication-centric problem, we design a globally optimal algorithm for the\nsingle-BS case using bisection search. For the general case of both problems,\nwe propose a unified successive convex approximation (SCA)-based algorithm,\nwhich is suboptimal yet efficient, and further extend it from single-target\nscenarios to more practical multi-target scenarios. Finally, simulation results\ndemonstrate the effectiveness of our proposed algorithms, reveal the intrinsic\nperformance trade-offs between communication and localization, and further show\nthat deploying more TMTs is always preferable to deploying more BSs in\nnetworked ISAC systems."}
{"id": "2510.04734", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.04734", "abs": "https://arxiv.org/abs/2510.04734", "authors": ["Juan Vidal Alegr√≠a"], "title": "Dimensionally-Efficient Transmission and Storage of Unitary Matrices", "comment": "13 pages, 10 figures. This work has been submitted to the IEEE for\n  possible publication", "summary": "Unitary matrices are the basis of a large number of signal processing\napplications. In many of these applications, finding ways to efficiently store,\nand even transmit these matrices, can significantly reduce memory and\nthroughput requirements. In this work, we study the problem of efficient\ntransmission and storage of unitary matrices. Specifically, we explicitly\nderive a dimensionally-efficient parametrization (DEP) for unitary matrices\nthat allows identifying them with sequences of real numbers, where the\ndimension coincides with the dimension of the unitary group where they lie. We\nalso characterize its inverse map that allows retrieving the original unitary\nmatrices from their DEP. The proposed approach effectively allows halving the\ndimension with respect to naively considering all the entries of each unitary\nmatrix, thus reducing the resources required to store and transmit these\nmatrices. Furthermore, we show that the sequence of real numbers associated to\nthe proposed DEP is bounded, and we delimit the interval where these numbers\nare contained, facilitating the implementation of quantization approaches with\nlimited distortion. On the other hand, we outline ways to further reduce the\ndimension of the DEP when considering more restrictive constraints for matrices\nthat show up in certain applications. The numerical results showcase the\npotential of the proposed approach in general settings, as well as in three\nspecific applications of current interest for wireless communications research."}
{"id": "2510.04744", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.04744", "abs": "https://arxiv.org/abs/2510.04744", "authors": ["Wali Ullah Khan", "Chandan Kumar Sheemar", "Eva Lagunas", "Xingwang Li", "Symeon Chatzinotas", "Petar Popovski", "Zhu Han"], "title": "Multilayer Non-Terrestrial Networks with Spectrum Access aided by Beyond-Diagonal RIS", "comment": "13, 10", "summary": "In this work, we study a multi-user NTN in which a satellite serves as the\nprimary network and a high-altitude platform station (HAPS) operates as the\nsecondary network, acting as a cognitive radio. To reduce the cost, complexity,\nand power consumption of conventional antenna arrays, we equip the HAPS with a\ntransmissive BD-RIS antenna front end. We then formulate a joint optimization\nproblem for the BD-RIS phase response and the HAPS transmit power allocation\nunder strict per-user interference temperature constraints. To tackle the\nresulting highly nonconvex problem, we propose an alternating-optimization\nframework: the power-allocation subproblem admits a closed-form,\nwater-filling-type solution derived from the Karush-Kuhn-Tucker (KKT)\nconditions, while the BD-RIS configuration is refined via Riemannian manifold\noptimization. Simulation results show significant gains in data rate and\ninterference suppression over diagonal RIS-assisted benchmarks, establishing\nBD-RIS as a promising enabler for future multilayer NTNs."}
{"id": "2510.04745", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.04745", "abs": "https://arxiv.org/abs/2510.04745", "authors": ["Lucas Semp√©r√©", "Yue Bi", "Yue Wu", "Pengwenlong Gu", "Selma Boumerdassi"], "title": "Interference Alignment for Multi-cluster Over-the-Air Computation", "comment": null, "summary": "One of the main challenges facing Internet of Things (IoT) networks is\nmanaging interference caused by the large number of devices communicating\nsimultaneously, particularly in multi-cluster networks where multiple devices\nsimultaneously transmit to their respective receiver. Over-the-Air Computation\n(AirComp) has emerged as a promising solution for efficient real-time data\naggregation, yet its performance suffers in dense, interference-limited\nenvironments. To address this, we propose a novel Interference Alignment (IA)\nscheme tailored for up-link AirComp systems. Unlike previous approaches, the\nproposed method scales to an arbitrary number $\\sf K$ of clusters and enables\neach cluster to exploit half of the available channels, instead of only\n$\\tfrac{1}{\\sf K}$ as in time-sharing. In addition, we develop schemes tailored\nto scenarios where users are shared between adjacent clusters."}
{"id": "2510.04913", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.04913", "abs": "https://arxiv.org/abs/2510.04913", "authors": ["Andreas Bathelt", "Benjamin Deutschmann", "Hyeon Seok Rou", "Kuranage Roche Rayan Ranasinghe", "Giuseppe Thadeu Freitas de Abreu", "Peter Vouras"], "title": "The IEEE Signal Processing Society's Leading Role in Developing Standards for Computational Imaging and Sensing: Part II", "comment": "Submitted to the IEEE for possible publication", "summary": "In every imaging or sensing application, the physical hardware creates\nconstraints that must be overcome or they limit system performance. Techniques\nthat leverage additional degrees of freedom can effectively extend performance\nbeyond the inherent physical capabilities of the hardware. An example includes\nsynchronizing distributed sensors so as to synthesize a larger aperture for\nremote sensing applications. An additional example is integrating the\ncommunication and sensing functions in a wireless system through the clever\ndesign of waveforms and optimized resource management. As these technologies\nmature beyond the conceptual and prototype phase they will ultimately\ntransition to the commercial market. Here, standards play a critical role in\nensuring success. Standards ensure interoperability between systems\nmanufactured by different vendors and define industry best practices for\nvendors and customers alike. The Signal Processing Society of the Institute for\nElectrical and Electronics Engineers (IEEE) plays a leading role in developing\nhigh-quality standards for computational sensing technologies through the\nworking groups of the Synthetic Aperture Standards Committee (SASC). In this\ncolumn we highlight the standards activities of the P3383 Performance Metrics\nfor Integrated Sensing and Communication (ISAC) Systems Working Group and the\nP3343 Spatio-Temporal Synchronization of a Synthetic Aperture of Distributed\nSensors Working Group."}
{"id": "2510.04924", "categories": ["eess.SP", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.04924", "abs": "https://arxiv.org/abs/2510.04924", "authors": ["Ardavan Rahimian"], "title": "Steady-State Spread Bounds for Graph Diffusion via Laplacian Regularisation", "comment": null, "summary": "We study how far a diffusion process on a graph can drift from a designed\nstarting pattern when that pattern is produced using Laplacian regularisation.\nUnder standard stability conditions for undirected, entrywise nonnegative\ngraphs, we give a closed-form, instance-specific upper bound on the\nsteady-state spread, measured as the relative change between the final and\ninitial profiles. The bound separates two effects: (i) an irreducible term\ndetermined by the graph's maximum node degree, and (ii) a design-controlled\nterm that shrinks as the regularisation strength increases (following an\ninverse square-root law). This leads to a simple design rule: given any target\nlimit on spread, one can choose a sufficient regularisation strength in closed\nform. Although one motivating application is array beamforming, where the\ninitial pattern is the squared magnitude of the beamformer weights, the result\napplies to any scenario that first enforces Laplacian smoothness and then\nevolves by linear diffusion on a graph. Overall, the guarantee is\nnon-asymptotic, easy to compute, and certifies how much steady-state deviation\ncan occur."}
{"id": "2510.05000", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.05000", "abs": "https://arxiv.org/abs/2510.05000", "authors": ["Xiang-Gen Xia"], "title": "My First Five Years of Faculty Career at the University of Delaware", "comment": null, "summary": "In this short article, I would like to briefly summarize my research in the\nfirst 5 years in my university academia life in USA. I think that my research\nresults obtained in these 5 years are the best in my career, at least which I\nlike the most by myself. I wish that my experience in my junior academia career\ncould be of some help to young researchers."}
