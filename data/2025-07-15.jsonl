{"id": "2507.08821", "categories": ["eess.SP", "cs.IT", "cs.LG", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.08821", "abs": "https://arxiv.org/abs/2507.08821", "authors": ["Pedro D. Alvim", "Hugerles S. Silva", "Ugo S. Dias", "Osamah S. Badarneh", "Felipe A. P. Figueiredo", "Rausley A. A. de Souza"], "title": "LNN-powered Fluid Antenna Multiple Access", "comment": null, "summary": "Fluid antenna systems represent an innovative approach in wireless\ncommunication, recently applied in multiple access to optimize the\nsignal-to-interference-plus-noise ratio through port selection. This letter\nframes the port selection problem as a multi-label classification task for the\nfirst time, improving best-port selection with limited port observations. We\naddress this challenge by leveraging liquid neural networks (LNNs) to predict\nthe optimal port under emerging fluid antenna multiple access scenarios\nalongside a more general $\\alpha$-$\\mu$ fading model. We also apply\nhyperparameter optimization to refine LNN architectures for different\nobservation scenarios. Our approach yields lower outage probability values than\nexisting methods."}
{"id": "2507.08950", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.08950", "abs": "https://arxiv.org/abs/2507.08950", "authors": ["Xue Zhang", "Abla Kammoun", "Mohamed-Slim Alouini"], "title": "Fundamental limits via CRB of semi-blind channel estimation in Massive MIMO systems", "comment": null, "summary": "This paper investigates the asymptotic behavior of the deterministic and\nstochastic Cram\\'er-Rao Bounds (CRB) for semi-blind channel estimation in\nmassive multiple-input multiple-output (MIMO) systems. We derive and analyze\nmathematically tractable expressions for both metrics under various asymptotic\nregimes, which govern the growth rates of the number of antennas, the number of\nusers, the training sequence length, and the transmission block length. Unlike\nthe existing work, our results show that the CRB can be made arbitrarily small\nas the transmission block length increases, but only when the training sequence\nlength grows at the same rate and the number of users remains fixed. However,\nif the number of training sequences remains proportional to the number of\nusers, the channel estimation error is always lower-bounded by a non-vanishing\nconstant. Numerical results are presented to support our findings and\ndemonstrate the advantages of semi-blind channel estimation in reducing the\nrequired number of training sequences."}
{"id": "2507.08974", "categories": ["eess.SP", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.08974", "abs": "https://arxiv.org/abs/2507.08974", "authors": ["Thien Hieu Hoang", "Tri Nhu Do", "Georges Kaddoum"], "title": "Domain Adaptation-Enabled Realistic Map-Based Channel Estimation for MIMO-OFDM", "comment": null, "summary": "Accurate channel estimation is crucial for the improvement of signal\nprocessing performance in wireless communications. However, traditional\nmodel-based methods frequently experience difficulties in dynamic environments.\nSimilarly, alternative machine-learning approaches typically lack\ngeneralization across different datasets due to variations in channel\ncharacteristics. To address this issue, in this study, we propose a novel\ndomain adaptation approach to bridge the gap between the quasi-static channel\nmodel (QSCM) and the map-based channel model (MBCM). Specifically, we first\nproposed a channel estimation pipeline that takes into account realistic\nchannel simulation to train our foundation model. Then, we proposed domain\nadaptation methods to address the estimation problem. Using simulation-based\ntraining to reduce data requirements for effective application in practical\nwireless environments, we find that the proposed strategy enables robust model\nperformance, even with limited true channel information."}
{"id": "2507.08999", "categories": ["eess.SP", "I.5.3; I.2.6"], "pdf": "https://arxiv.org/pdf/2507.08999", "abs": "https://arxiv.org/abs/2507.08999", "authors": ["Duc Vu", "Selin Aviyente"], "title": "Hypergraph Overlapping Community Detection for Brain Networks", "comment": "6 Pages, Accepted for IEEE MLSP 2025", "summary": "Functional magnetic resonance imaging (fMRI) has been commonly used to\nconstruct functional connectivity networks (FCNs) of the human brain. TFCNs are\nprimarily limited to quantifying pairwise relationships between ROIs ignoring\nhigher order dependencies between multiple brain regions. Recently, hypergraph\nconstruction methods from fMRI time series data have been proposed to\ncharacterize the high-order relations among multiple ROIs. While there have\nbeen multiple methods for constructing hypergraphs from fMRI time series, the\nquestion of how to characterize the topology of these hypergraphs remains open.\nIn this paper, we make two key contributions to the field of community\ndetection in brain hypernetworks. First, we construct a hypergraph for each\nsubject capturing high order dependencies between regions. Second, we introduce\na spectral clustering based approach on hypergraphs to detect overlapping\ncommunity structure. Finally, the proposed method is implemented to detect the\nconsensus community structure across multiple subjects. The proposed method is\napplied to resting state fMRI data from Human Connectome Project to summarize\nthe overlapping community structure across a group of healthy young adults."}
{"id": "2507.08855", "categories": ["eess.IV", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.08855", "abs": "https://arxiv.org/abs/2507.08855", "authors": ["Yang Ming", "Jiang Shi Zhong", "Zhou Su Juan"], "title": "Multi-omic Prognosis of Alzheimer's Disease with Asymmetric Cross-Modal Cross-Attention Network", "comment": null, "summary": "Alzheimer's Disease (AD) is an irreversible neurodegenerative disease\ncharacterized by progressive cognitive decline as its main symptom. In the\nresearch field of deep learning-assisted diagnosis of AD, traditional\nconvolutional neural networks and simple feature concatenation methods fail to\neffectively utilize the complementary information between multimodal data, and\nthe simple feature concatenation approach is prone to cause the loss of key\ninformation during the process of modal fusion. In recent years, the\ndevelopment of deep learning technology has brought new possibilities for\nsolving the problem of how to effectively fuse multimodal features. This paper\nproposes a novel deep learning algorithm framework to assist medical\nprofessionals in AD diagnosis. By fusing medical multi-view information such as\nbrain fluorodeoxyglucose positron emission tomography (PET), magnetic resonance\nimaging (MRI), genetic data, and clinical data, it can accurately detect the\npresence of AD, Mild Cognitive Impairment (MCI), and Cognitively Normal (CN).\nThe innovation of the algorithm lies in the use of an asymmetric cross-modal\ncross-attention mechanism, which can effectively capture the key information\nfeatures of the interactions between different data modal features. This paper\ncompares the asymmetric cross-modal cross-attention mechanism with the\ntraditional algorithm frameworks of unimodal and multimodal deep learning\nmodels for AD diagnosis, and evaluates the importance of the asymmetric\ncross-modal cross-attention mechanism. The algorithm model achieves an accuracy\nof 94.88% on the test set."}
{"id": "2507.09215", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.09215", "abs": "https://arxiv.org/abs/2507.09215", "authors": ["Yi Wang", "Keke Zu", "Luping Xiang", "Martin Haardt", "Kun Yang"], "title": "Time-Varying Offset Estimation for Clock-Asynchronous Bistatic ISAC Systems", "comment": null, "summary": "The bistatic Integrated Sensing and Communication (ISAC) is poised to become\na key application for next generation communication networks (e.g., B5G/6G),\nproviding simultaneous sensing and communication services with minimal changes\nto existing network infrastructure and hardware. However, a significant\nchallenge in bistatic cooperative sensing is clock asynchronism, arising from\nthe use of different clocks at far separated transmitters and receivers. This\nasynchrony leads to Timing Offsets (TOs) and Carrier Frequency Offsets (CFOs),\npotentially causing sensing ambiguity. Traditional synchronization methods\ntypically rely on static reference links or GNSS-based timing sources, both of\nwhich are often unreliable or unavailable in UAVbased bistatic ISAC scenarios.\nTo overcome these limitations, we propose a Time-Varying Offset Estimation\n(TVOE) framework tailored for clock-asynchronous bistatic ISAC systems, which\nleverages the geometrically predictable characteristics of the Line-of-Sight\n(LoS) path to enable robust, infrastructure-free\n  synchronization. The framework treats the LoS delay and the Doppler shift as\ndynamic observations and models their evolution as a hidden stochastic process.\nA state-space formulation is developed to jointly estimate TO and CFO via an\nExtended Kalman Filter (EKF), enabling real-time tracking of clock offsets\nacross successive frames. Furthermore, the estimated offsets are subsequently\napplied to correct the timing misalignment of all Non-Line-of-Sight (NLoS)\ncomponents, thereby enhancing the high-resolution target sensing performance.\nExtensive simulation results demonstrate that the proposed TVOE method improves\nthe estimation accuracy by 60%."}
{"id": "2507.08952", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.08952", "abs": "https://arxiv.org/abs/2507.08952", "authors": ["Silas Nyboe Ørting", "Kristina Miger", "Anne Sophie Overgaard Olesen", "Mikael Ploug Boesen", "Michael Brun Andersen", "Jens Petersen", "Olav W. Nielsen", "Marleen de Bruijne"], "title": "Interpretable Artificial Intelligence for Detecting Acute Heart Failure on Acute Chest CT Scans", "comment": "34 pages, 11 figures, Submitted to \"Radiology AI\"", "summary": "Introduction: Chest CT scans are increasingly used in dyspneic patients where\nacute heart failure (AHF) is a key differential diagnosis. Interpretation\nremains challenging and radiology reports are frequently delayed due to a\nradiologist shortage, although flagging such information for emergency\nphysicians would have therapeutic implication. Artificial intelligence (AI) can\nbe a complementary tool to enhance the diagnostic precision. We aim to develop\nan explainable AI model to detect radiological signs of AHF in chest CT with an\naccuracy comparable to thoracic radiologists.\n  Methods: A single-center, retrospective study during 2016-2021 at Copenhagen\nUniversity Hospital - Bispebjerg and Frederiksberg, Denmark. A Boosted Trees\nmodel was trained to predict AHF based on measurements of segmented cardiac and\npulmonary structures from acute thoracic CT scans. Diagnostic labels for\ntraining and testing were extracted from radiology reports. Structures were\nsegmented with TotalSegmentator. Shapley Additive explanations values were used\nto explain the impact of each measurement on the final prediction.\n  Results: Of the 4,672 subjects, 49% were female. The final model incorporated\ntwelve key features of AHF and achieved an area under the ROC of 0.87 on the\nindependent test set. Expert radiologist review of model misclassifications\nfound that 24 out of 64 (38%) false positives and 24 out of 61 (39%) false\nnegatives were actually correct model predictions, with the errors originating\nfrom inaccuracies in the initial radiology reports.\n  Conclusion: We developed an explainable AI model with strong discriminatory\nperformance, comparable to thoracic radiologists. The AI model's stepwise,\ntransparent predictions may support decision-making."}
{"id": "2507.09218", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.09218", "abs": "https://arxiv.org/abs/2507.09218", "authors": ["Yi Wang", "Keke Zu", "Luping Xiang", "Martin Haardt", "Chaochao Wang", "Xianchao Zhang", "Kun Yang"], "title": "Image Super-Resolution-Based Signal Enhancement in Bistatic ISAC", "comment": null, "summary": "Bistatic Integrated Sensing and Communication (ISAC) is poised to become a\ncornerstone technology in next-generation communication networks, such as\nBeyond 5G (B5G) and 6G, by enabling the concurrent execution of sensing and\ncommunication functions without requiring significant modifications to existing\ninfrastructure. Despite its promising potential, a major challenge in bistatic\ncooperative sensing lies in the degradation of sensing accuracy, primarily\ncaused by the inherently weak received signals resulting from high reflection\nlosses in complex environments. Traditional methods have predominantly relied\non adaptive filtering techniques to enhance the Signal-to-Noise Ratio (SNR) by\ndynamically adjusting the filter coefficients. However, these methods often\nstruggle to adapt effectively to the increasingly complex and diverse network\ntopologies. To address these challenges, we propose a novel Image\nSuper-Resolution-based Signal Enhancement (ISR-SE) framework that significantly\nimproves the recognition and recovery capabilities of ISAC signals.\nSpecifically, we first perform a time-frequency analysis by applying the\nShort-Time Fourier Transform (STFT) to the received signals, generating\nspectrograms that capture the frequency, magnitude, and phase components. These\ncomponents are then mapped into RGB images, where each channel represents one\nof the extracted features, enabling a more intuitive and informative\nvisualization of the signal structure. To enhance these RGB images, we design\nan improved denoising network that combines the strengths of the UNet\narchitecture and diffusion models. This hybrid architecture leverages UNet's\nmulti-scale feature extraction and the generative capacity of diffusion models\nto perform effective image denoising, thereby improving the quality and clarity\nof signal representations under low-SNR conditions."}
{"id": "2507.08982", "categories": ["eess.IV", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.08982", "abs": "https://arxiv.org/abs/2507.08982", "authors": ["Hanene F. Z. Brachemi Meftah", "Wassim Hamidouche", "Sid Ahmed Fezza", "Olivier Déforges"], "title": "VIP: Visual Information Protection through Adversarial Attacks on Vision-Language Models", "comment": null, "summary": "Recent years have witnessed remarkable progress in developing Vision-Language\nModels (VLMs) capable of processing both textual and visual inputs. These\nmodels have demonstrated impressive performance, leading to their widespread\nadoption in various applications. However, this widespread raises serious\nconcerns regarding user privacy, particularly when models inadvertently process\nor expose private visual information. In this work, we frame the preservation\nof privacy in VLMs as an adversarial attack problem. We propose a novel attack\nstrategy that selectively conceals information within designated Region Of\nInterests (ROIs) in an image, effectively preventing VLMs from accessing\nsensitive content while preserving the semantic integrity of the remaining\nimage. Unlike conventional adversarial attacks that often disrupt the entire\nimage, our method maintains high coherence in unmasked areas. Experimental\nresults across three state-of-the-art VLMs namely LLaVA, Instruct-BLIP, and\nBLIP2-T5 demonstrate up to 98% reduction in detecting targeted ROIs, while\nmaintaining global image semantics intact, as confirmed by high similarity\nscores between clean and adversarial outputs. We believe that this work\ncontributes to a more privacy conscious use of multimodal models and offers a\npractical tool for further research, with the source code publicly available\nat: https://github.com/hbrachemi/Vlm_defense-attack."}
{"id": "2507.09244", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.09244", "abs": "https://arxiv.org/abs/2507.09244", "authors": ["Nishant Gupta", "Muris Sarajlic", "Erik G. Larsson"], "title": "Deep Learning for sub-THz Radio Unit Selection using sub-10 GHz Channel Information and Inferred Device Beamforming", "comment": "Accepted for Publication in IEEE VTC-Spring 2025, held at Oslo,\n  Norway", "summary": "The dense and distributed deployment of sub-THz radio units (RUs) alongside\nsub-10 GHz access point (AP) is a promising approach to provide high data rate\nand reliable coverage for future 6G applications. However, beam search or RU\nselection for the sub-THz RUs incurs significant overhead and high power\nconsumption. To address this, we introduce a method that leverages deep\nlearning to infer a suitable sub-THz RU candidate from a set of sub-THz RUs\nusing the sub-10 GHz channel characteristics. A novel aspect of this work is\nthe consideration of inter-band beam configuration (IBBC), defined as the\nbroadside angle between the low-band and high-band antenna patterns of the user\nequipment (UE). Since IBBC indicates the beamforming information or UE's\norientation, it is typically not shared with the network as a part of\nsignalling. Therefore, we propose a solution strategy to infer a suitable\nsub-THz RU even when UEs do not share their IBBC information. Simulation\nresults illustrate the performance of the inferred sub-THz RU and highlights\nthe detrimental impact of neglecting UE orientation on the systems performance."}
{"id": "2507.09158", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.09158", "abs": "https://arxiv.org/abs/2507.09158", "authors": ["Sunil Munthumoduku Krishna Murthy", "Kumar Rajamani", "Srividya Tirunellai Rajamani", "Yupei Li", "Qiyang Sun", "Bjoern W. Schuller"], "title": "Automatic Contouring of Spinal Vertebrae on X-Ray using a Novel Sandwich U-Net Architecture", "comment": null, "summary": "In spinal vertebral mobility disease, accurately extracting and contouring\nvertebrae is essential for assessing mobility impairments and monitoring\nvariations during flexion-extension movements. Precise vertebral contouring\nplays a crucial role in surgical planning; however, this process is\ntraditionally performed manually by radiologists or surgeons, making it\nlabour-intensive, time-consuming, and prone to human error. In particular,\nmobility disease analysis requires the individual contouring of each vertebra,\nwhich is both tedious and susceptible to inconsistencies. Automated methods\nprovide a more efficient alternative, enabling vertebra identification,\nsegmentation, and contouring with greater accuracy and reduced time\nconsumption. In this study, we propose a novel U-Net variation designed to\naccurately segment thoracic vertebrae from anteroposterior view on X-Ray\nimages. Our proposed approach, incorporating a ``sandwich\" U-Net structure with\ndual activation functions, achieves a 4.1\\% improvement in Dice score compared\nto the baseline U-Net model, enhancing segmentation accuracy while ensuring\nreliable vertebral contour extraction."}
{"id": "2507.09268", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.09268", "abs": "https://arxiv.org/abs/2507.09268", "authors": ["Xiangjun Li", "Zilong Liu", "Zhengchun Zhou", "Pingzhi Fan"], "title": "Matched Filtering-Based Channel Estimation for AFDM Systems in Doubly Selective Channels", "comment": null, "summary": "Affine frequency division multiplexing (AFDM) has recently emerged as an\nexcellent backward-compatible 6G waveform. In this paper, an enhanced AFDM is\nproposed whereby the delay-Doppler (DD) coupling phase is considered.\nSpecifically, we study matched filtering (MF) assisted channel estimation (CE)\nfor AFDM systems in complex doubly selective channels. By deriving the complete\ninput-output relationship, the inter-chirp-carrier interference,\nsignal-to-interference-plus-noise ratio (SINR), and the effective SINR loss of\nAFDM, are investigated in discrete affine Fourier transform (DAFT) domain.\nFurther, we look into the path ambiguity problem and show that it may lead to\nsevere performance deterioration in fractional-delay fractional-Doppler\nchannels. To address such a problem, we introduce an MF assisted CE scheme\nbuilding upon a novel pilot arrangement across two consecutive AFDM\ntransmissions. This allows us to sequentially estimate the parameters of each\npath by exploiting the separability and approximate orthogonality of different\npaths in the DAFT domain, thus leading to significantly reduced complexity.\nFurthermore, based on generalized Fibonacci search (GFS), an MF-GFS scheme is\nproposed to avoid significantly redundant computation, which can be extended to\ntypical wide-band systems. Extensive simulation results indicate that the\nproposed schemes offer superior advantages in terms of their improved\ncommunication performance and lower complexity."}
{"id": "2507.09227", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.09227", "abs": "https://arxiv.org/abs/2507.09227", "authors": ["Sanyam Jain", "Bruna Neves de Freitas", "Andreas Basse-OConnor", "Alexandros Iosifidis", "Ruben Pauwels"], "title": "PanoDiff-SR: Synthesizing Dental Panoramic Radiographs using Diffusion and Super-resolution", "comment": null, "summary": "There has been increasing interest in the generation of high-quality,\nrealistic synthetic medical images in recent years. Such synthetic datasets can\nmitigate the scarcity of public datasets for artificial intelligence research,\nand can also be used for educational purposes. In this paper, we propose a\ncombination of diffusion-based generation (PanoDiff) and Super-Resolution (SR)\nfor generating synthetic dental panoramic radiographs (PRs). The former\ngenerates a low-resolution (LR) seed of a PR (256 X 128) which is then\nprocessed by the SR model to yield a high-resolution (HR) PR of size 1024 X\n512. For SR, we propose a state-of-the-art transformer that learns local-global\nrelationships, resulting in sharper edges and textures. Experimental results\ndemonstrate a Frechet inception distance score of 40.69 between 7243 real and\nsynthetic images (in HR). Inception scores were 2.55, 2.30, 2.90 and 2.98 for\nreal HR, synthetic HR, real LR and synthetic LR images, respectively. Among a\ndiverse group of six clinical experts, all evaluating a mixture of 100\nsynthetic and 100 real PRs in a time-limited observation, the average accuracy\nin distinguishing real from synthetic images was 68.5% (with 50% corresponding\nto random guessing)."}
{"id": "2507.09386", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.09386", "abs": "https://arxiv.org/abs/2507.09386", "authors": ["Ruangrawee Kitichotkul", "Shashwath Bharadwaj", "Joshua Rapp", "Yanting Ma", "Alexander Mehta", "Vivek K Goyal"], "title": "Free-running vs. Synchronous: Single-Photon Lidar for High-flux 3D Imaging", "comment": "20 pages, 15 figures, to be presented at the International Conference\n  on Computer Vision (ICCV) 2025", "summary": "Conventional wisdom suggests that single-photon lidar (SPL) should operate in\nlow-light conditions to minimize dead-time effects. Many methods have been\ndeveloped to mitigate these effects in synchronous SPL systems. However,\nsolutions for free-running SPL remain limited despite the advantage of reduced\nhistogram distortion from dead times. To improve the accuracy of free-running\nSPL, we propose a computationally efficient joint maximum likelihood estimator\nof the signal flux, the background flux, and the depth using only histograms,\nalong with a complementary regularization framework that incorporates a learned\npoint cloud score model as a prior. Simulations and experiments demonstrate\nthat free-running SPL yields lower estimation errors than its synchronous\ncounterpart under identical conditions, with our regularization further\nimproving accuracy."}
{"id": "2507.09236", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2507.09236", "abs": "https://arxiv.org/abs/2507.09236", "authors": ["Eric Bezzam", "Martin Vetterli"], "title": "Encryption and Authentication with a Lensless Camera Based on a Programmable Mask", "comment": "6 pages main, 3 pages supplementary, accepted to ICME 2025", "summary": "Lensless cameras replace traditional optics with thin masks, leading to\nhighly multiplexed measurements akin to encryption. However, static masks in\nconventional designs leave systems vulnerable to simple attacks. This work\nexplores the use of programmable masks to enhance security by dynamically\nvarying the mask patterns. We perform our experiments with a low-cost system\n(around 100 USD) based on a liquid crystal display. Experimental results\ndemonstrate that variable masks successfully block a variety of attacks while\nenabling high-quality recovery for legitimate users. The system's encryption\nstrength exceeds AES-256, achieving effective key lengths over 2'500 bits.\nAdditionally, we demonstrate how a programmable mask enables robust\nauthentication and verification, as each mask pattern leaves a unique\nfingerprint on the image. When combined with a lensed system, lensless\nmeasurements can serve as analog certificates, providing a novel solution for\nverifying image authenticity and combating deepfakes."}
{"id": "2507.09408", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.09408", "abs": "https://arxiv.org/abs/2507.09408", "authors": ["Sajedeh Norouzi", "Mostafa Rahmani", "Yi Chu", "Torsten Braun", "Kaushik Chowdhury", "Alister Burr"], "title": "Lightweight Graph Neural Networks for Enhanced 5G NR Channel Estimation", "comment": "Accepted in IEEE PIMRC 2025", "summary": "Effective channel estimation CE is critical for optimizing the performance of\n5G New Radio NR systems particularly in dynamic environments where traditional\nmethods struggle with complexity and adaptability This paper introduces\nGraphNet a novel lightweight Graph Neural Network GNNbased estimator designed\nto enhance CE in 5G NR Our proposed method utilizes a GNN architecture that\nminimizes computational overhead while capturing essential features necessary\nfor accurate CE We evaluate GraphNet across various channel conditions from\nslowvarying to highly dynamic environments and compare its performance to\nChannelNet a wellknown deep learningbased CE method GraphNet not only matches\nChannelNets performance in stable conditions but significantly outperforms it\nin highvariation scenarios particularly in terms of Block Error Rate It also\nincludes builtin noise estimation that enhances robustness in challenging\nchannel conditions Furthermore its significantly lighter computational\nfootprint makes GraphNet highly suitable for realtime deployment especially on\nedge devices with limited computational resources By underscoring the potential\nof GNNs to transform CE processes GraphNet offers a scalable and robust\nsolution that aligns with the evolving demands of 5G technologies highlighting\nits efficiency and performance as a nextgeneration solution for wireless\ncommunication systems"}
{"id": "2507.09393", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2507.09393", "abs": "https://arxiv.org/abs/2507.09393", "authors": ["Necmettin Bayar", "Isin Erer", "Deniz Kumlu"], "title": "Deep Image Prior Assisted ISAR Imaging for Missing Data Case", "comment": null, "summary": "In Inverse Synthetic Aperture Radar (ISAR), random missing entries of the\nreceived radar echo matrix deteriorate the imaging quality, compromising target\ndistinction from the background. Compressive sensing techniques or matrix\ncompletion prior to conventional imaging have been used in recent years to\nsolve this issue. However, while the former techniques fail to preserve target\ncontinuity due to the sparsity constraint, the latter fails for high missing\nratios. This paper proposes to use deep image prior (DIP) to complete the\ncomplex radar data and then obtain the radar image by conventional Fourier\nimaging. Real and imaginary parts are separately completed by independent deep\nstructures and then put together for the imaging part. The proposed DIP based\nimaging method has been compared with IALM, 2D-SL0 and NNM methods visually and\nquantitatively for both simulated and real data. The results demonstrate an\nincrease of 100% for some extreme cases in terms of RMSE, 50% increase on\nCorrelation and 30% increase on IC metrics quantitatively."}
{"id": "2507.09458", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.09458", "abs": "https://arxiv.org/abs/2507.09458", "authors": ["Wang Ning", "Zhang Chenyu", "Sun Yanshi", "Min Minghui", "Liu Yuanwei", "Li Shiyin"], "title": "An Enregy Efficient Design of Hybrid NOMA Based on Hybrid SIC with Power Adaptation", "comment": "13pages, 8figures, 4tables. Submitted to IEEE TWC, manuscript ID is\n  Paper-TW-Jul-25-1790", "summary": "Recently, hybrid non-orthogonal multiple access (H-NOMA) technology, which\neffectively utilizes both NOMA and orthogonal multiple access (OMA)\ntechnologies through flexible resource allocation in a single transmission, has\ndemonstrated immense potential for enhancing the performance of wireless\ncommunication systems. To further release the potential of HNOMA, this paper\nproposes a novel design of H-NOMA which jointly incorporates hybrid successive\ninterference cancellation (HSIC) and power adaptation (PA) in the NOMA\ntransmission phase. To reveal the potential of the proposed HSIC-PA aided\nH-NOMA scheme, closed-form expression for the probability of the event that\nH-NOMA can achieve a higher data rate than pure OMA by consuming less energy is\nrigorously derived. Furthermore, the asymptotic analysis demonstrates that the\nprobability of the proposed H-NOMA scheme approaches 1 in the high\nsignal-to-noise ratio (SNR) regime without any constraints on either users'\ntarget rates or transmit power ratios. This represents a significant\nimprovement over conventional H-NOMA schemes, which require specific\nrestrictive conditions to achieve probability 1 at high SNRs as shown in\nexisting work. The above observation indicates that with less energy\nconsumption, the proposed HSIC-PA aided H-NOMA can achieve a higher data rate\nthan pure OMA with probability 1 at high SNRs, and hence a higher energy\nefficiency. Finally, numerical results are provided to verify the accuracy of\nthe analysis and also demonstrate the superior performance of the proposed\nH-NOMA scheme."}
{"id": "2507.09608", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.09608", "abs": "https://arxiv.org/abs/2507.09608", "authors": ["Mehmet Onurcan Kaya", "Figen S. Oktem"], "title": "prNet: Data-Driven Phase Retrieval via Stochastic Refinement", "comment": null, "summary": "We propose a novel framework for phase retrieval that leverages Langevin\ndynamics to enable efficient posterior sampling, yielding reconstructions that\nexplicitly balance distortion and perceptual quality. Unlike conventional\napproaches that prioritize pixel-wise accuracy, our method navigates the\nperception-distortion tradeoff through a principled combination of stochastic\nsampling, learned denoising, and model-based updates. The framework comprises\nthree variants of increasing complexity, integrating theoretically grounded\nLangevin inference, adaptive noise schedule learning, parallel reconstruction\nsampling, and warm-start initialization from classical solvers. Extensive\nexperiments demonstrate that our method achieves state-of-the-art performance\nacross multiple benchmarks, both in terms of fidelity and perceptual quality."}
{"id": "2507.09535", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.09535", "abs": "https://arxiv.org/abs/2507.09535", "authors": ["Chaoran Li", "Xingguo Xu", "Siyuan Mu"], "title": "Reframing SAR Target Recognition as Visual Reasoning: A Chain-of-Thought Dataset with Multimodal LLMs", "comment": null, "summary": "In the context of Synthetic Aperture Radar (SAR) image recognition,\ntraditional methods often struggle with the intrinsic limitations of SAR data,\nsuch as weak texture, high noise, and ambiguous object boundaries. This work\nexplores a novel perspective by reformulating SAR target recognition as a\nmultimodal reasoning task. We leverage multimodal large language models\n(MLLMs), specifically GPT-4o, to perform target classification based on SAR\nimagery, guided by candidate categories and enhanced with Chain-of-Thought\n(CoT) reasoning. A new dataset is constructed based on the FAIR-CSAR benchmark,\ncomprising raw SAR images, structured target annotations, candidate label sets,\nand GPT-generated CoT reasoning chains. Experimental results show that the\nMLLMs are capable of generating logically coherent and interpretable inferences\nin most scenarios. Our analysis highlights both the strengths and current\nlimitations of MLLMs in interpreting SAR imagery, and we provide detailed\ninsights into model behavior through failure case analysis. This work\ndemonstrates the feasibility of incorporating MLLMs into SAR analysis pipelines\nand establishes a foundation for future research in SAR-oriented visual\nreasoning."}
{"id": "2507.09609", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.09609", "abs": "https://arxiv.org/abs/2507.09609", "authors": ["Mehmet Onurcan Kaya", "Figen S. Oktem"], "title": "I2I-PR: Deep Iterative Refinement for Phase Retrieval using Image-to-Image Diffusion Models", "comment": null, "summary": "Phase retrieval involves recovering a signal from intensity-only\nmeasurements, crucial in many fields such as imaging, holography, optical\ncomputing, crystallography, and microscopy. Although there are several\nwell-known phase retrieval algorithms, including classical iterative solvers,\nthe reconstruction performance often remains sensitive to initialization and\nmeasurement noise. Recently, image-to-image diffusion models have gained\ntraction in various image reconstruction tasks, yielding significant\ntheoretical insights and practical breakthroughs. In this work, we introduce a\nnovel phase retrieval approach based on an image-to-image diffusion framework\ncalled Inversion by Direct Iteration. Our method begins with an enhanced\ninitialization stage that leverages a hybrid iterative technique, combining the\nHybrid Input-Output and Error Reduction methods and incorporating a novel\nacceleration mechanism to obtain a robust crude estimate. Then, it iteratively\nrefines this initial crude estimate using the learned image-to-image pipeline.\nOur method achieves substantial improvements in both training efficiency and\nreconstruction quality. Furthermore, our approach utilizes aggregation\ntechniques to refine quality metrics and demonstrates superior results compared\nto both classical and contemporary techniques. This highlights its potential\nfor effective and efficient phase retrieval across various applications."}
{"id": "2507.09561", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.09561", "abs": "https://arxiv.org/abs/2507.09561", "authors": ["Can Wang", "Wei Liu", "Hanzhi Ma", "Xiaonan Jiang", "Erping Li", "Steven Gao"], "title": "Novel Physics-Aware Attention-Based Machine Learning Approach for Mutual Coupling Modeling", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "This article presents a physics-aware convolutional long short-term memory\n(PC-LSTM) network for efficient and accurate extraction of mutual impedance\nmatrices in dipole antenna arrays. By reinterpreting the Green's function\nthrough a physics-aware neural network and embedding it into an adaptive loss\nfunction, the proposed machine learning-based approach achieves enhanced\nphysical interpretability in mutual coupling modeling. Also, an attention\nmechanism is carefully designed to calibrate complex-valued features by fusing\nthe real and imaginary parts of the Green's function matrix. These fused\nrepresentations are then processed by a convolutional long short-term memory\nnetwork, and the impedance matrix of the linear antenna array can be finally\nderived. Validation against five benchmarks underscores the efficacy of the\nproposed approach, demonstrating accurate impedance extraction with up to a 7x\nspeedup compared to CST Microwave Studio, making it a fast alternative to\nfull-wave simulations for mutual coupling characterization."}
{"id": "2507.09731", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.09731", "abs": "https://arxiv.org/abs/2507.09731", "authors": ["Robby Hoover", "Nelly Elsayed", "Zag ElSayed", "Chengcheng Li"], "title": "Pre-trained Under Noise: A Framework for Robust Bone Fracture Detection in Medical Imaging", "comment": "7 pages, under review", "summary": "Medical Imagings are considered one of the crucial diagnostic tools for\ndifferent bones-related diseases, especially bones fractures. This paper\ninvestigates the robustness of pre-trained deep learning models for classifying\nbone fractures in X-ray images and seeks to address global healthcare disparity\nthrough the lens of technology. Three deep learning models have been tested\nunder varying simulated equipment quality conditions. ResNet50, VGG16 and\nEfficientNetv2 are the three pre-trained architectures which are compared.\nThese models were used to perform bone fracture classification as images were\nprogressively degraded using noise. This paper specifically empirically studies\nhow the noise can affect the bone fractures detection and how the pre-trained\nmodels performance can be changes due to the noise that affect the quality of\nthe X-ray images. This paper aims to help replicate real world challenges\nexperienced by medical imaging technicians across the world. Thus, this paper\nestablishes a methodological framework for assessing AI model degradation using\ntransfer learning and controlled noise augmentation. The findings provide\npractical insight into how robust and generalizable different pre-trained deep\nlearning powered computer vision models can be when used in different contexts."}
{"id": "2507.09713", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.09713", "abs": "https://arxiv.org/abs/2507.09713", "authors": ["Burak Ahmet Ozden", "Erdogan Aydin", "Ahmet Elbir", "Filiz Gurkan"], "title": "A New Wireless Image Transmission System Using Code Index Modulation and Image Enhancement for High-Rate Next Generation Networks", "comment": "17 pages, 14 figures", "summary": "With the development of wireless network technologies, the wireless image\ntransmission area has become prominent. The need for high resolution, data\ntraffic density, widespread use of multimedia applications, and the importance\nof high rate and reliable image transmission in medical and military fields\nnecessitate the design of novel and high-performance wireless image\ntransmission systems. This paper proposes a code index modulation (CIM)-based\nimage transmission (CIM-IT) system that utilizes spreading code index and\nquadrature amplitude modulation (QAM) symbol for image transmission over a\nwireless channel. The proposed CIM-IT system maps bits to each pixel value of\nthe image to be transmitted and transmits these bits over a wireless channel\nusing a single-input and multiple-output system comprising code index\nmodulation and QAM techniques. At the receiver, the active spreading code index\nand the selected QAM symbol are estimated using a despreading-based maximum\nlikelihood detector, and the corresponding bits are obtained. The image\nconveyed from the transmitter is then reconstructed at the receiver side using\nthe pixel values corresponding to the bits. The obtained noisy image is\nenhanced using important enhancement filters. In addition, an advanced filter\nis proposed to improve the transmitted degraded image with optimum results.\nFurthermore, error performance, spectral efficiency, energy efficiency, and\nthroughputof the CIM-IT system are performed and the results are compared with\ntraditional wireless communication techniques."}
{"id": "2507.09759", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.09759", "abs": "https://arxiv.org/abs/2507.09759", "authors": ["Abdul Manaf", "Nimra Mughal"], "title": "AI-Enhanced Pediatric Pneumonia Detection: A CNN-Based Approach Using Data Augmentation and Generative Adversarial Networks (GANs)", "comment": null, "summary": "Pneumonia is a leading cause of mortality in children under five, requiring\naccurate chest X-ray diagnosis. This study presents a machine learning-based\nPediatric Chest Pneumonia Classification System to assist healthcare\nprofessionals in diagnosing pneumonia from chest X-ray images. The CNN-based\nmodel was trained on 5,863 labeled chest X-ray images from children aged 0-5\nyears from the Guangzhou Women and Children's Medical Center. To address\nlimited data, we applied augmentation techniques (rotation, zooming, shear,\nhorizontal flipping) and employed GANs to generate synthetic images, addressing\nclass imbalance. The system achieved optimal performance using combined\noriginal, augmented, and GAN-generated data, evaluated through accuracy and F1\nscore metrics. The final model was deployed via a Flask web application,\nenabling real-time classification with probability estimates. Results\ndemonstrate the potential of deep learning and GANs in improving diagnostic\naccuracy and efficiency for pediatric pneumonia classification, particularly\nvaluable in resource-limited clinical settings\nhttps://github.com/AbdulManaf12/Pediatric-Chest-Pneumonia-Classification"}
{"id": "2507.09776", "categories": ["eess.SP", "cs.AR"], "pdf": "https://arxiv.org/pdf/2507.09776", "abs": "https://arxiv.org/abs/2507.09776", "authors": ["Mihir Kavishwar", "Naresh Shanbhag"], "title": "Compute SNR-Optimal Analog-to-Digital Converters for Analog In-Memory Computing", "comment": "Code available at: https://github.com/mihirvk2/CSNR-optimal-ADC", "summary": "Analog in-memory computing (AIMC) is an energy-efficient alternative to\ndigital architectures for accelerating machine learning and signal processing\nworkloads. However, its energy efficiency is limited by the high energy cost of\nthe column analog-to-digital converters (ADCs). Reducing the ADC precision is\nan effective approach to lowering its energy cost. However, doing so also\nreduces the AIMC's computational accuracy thereby making it critical to\nidentify the minimum precision required to meet a target accuracy. Prior works\noverestimate the ADC precision requirements by modeling quantization error as\ninput-independent noise, maximizing the signal-to-quantization-noise ratio\n(SQNR), and ignoring the discrete nature of ideal pre-ADC signal. We address\nthese limitations by developing analytical expressions for estimating the\ncompute signal-to-noise ratio (CSNR), a true metric of accuracy for AIMCs, and\npropose CACTUS, an algorithm to obtain CSNR-optimal ADC parameters. Using a\ncircuit-aware behavioral model of an SRAM-based AIMC in a 28nm CMOS process, we\nshow that for a 256-dimensional binary dot product, CACTUS reduces the ADC\nprecision requirements by 3b while achieving 6dB higher CSNR over prior\nmethods. We also delineate operating conditions under which our proposed\nCSNR-optimal ADCs outperform conventional SQNR-optimal ADCs."}
{"id": "2507.09872", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.09872", "abs": "https://arxiv.org/abs/2507.09872", "authors": ["Shengjie Liu", "Lu Zhang", "Siqin Wang"], "title": "Resolution Revolution: A Physics-Guided Deep Learning Framework for Spatiotemporal Temperature Reconstruction", "comment": "ICCV 2025 Workshop SEA -- International Conference on Computer Vision\n  2025 Workshop on Sustainability with Earth Observation and AI", "summary": "Central to Earth observation is the trade-off between spatial and temporal\nresolution. For temperature, this is especially critical because real-world\napplications require high spatiotemporal resolution data. Current technology\nallows for hourly temperature observations at 2 km, but only every 16 days at\n100 m, a gap further exacerbated by cloud cover. Earth system models offer\ncontinuous hourly temperature data, but at a much coarser spatial resolution\n(9-31 km). Here, we present a physics-guided deep learning framework for\ntemperature data reconstruction that integrates these two data sources. The\nproposed framework uses a convolutional neural network that incorporates the\nannual temperature cycle and includes a linear term to amplify the coarse Earth\nsystem model output into fine-scale temperature values observed from\nsatellites. We evaluated this framework using data from two satellites, GOES-16\n(2 km, hourly) and Landsat (100 m, every 16 days), and demonstrated effective\ntemperature reconstruction with hold-out and in situ data across four datasets.\nThis physics-guided deep learning framework opens new possibilities for\ngenerating high-resolution temperature data across spatial and temporal scales,\nunder all weather conditions and globally."}
{"id": "2507.09894", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.09894", "abs": "https://arxiv.org/abs/2507.09894", "authors": ["Saif Khan Mohammed", "Amit Kumar Pathak", "Muhammad Ubadah", "Ronny Hadani", "Ananthanarayanan Chockalingam", "Robert Calderbank"], "title": "Precoded Zak-OTFS for Per-Carrier Equalization", "comment": null, "summary": "In Zak-OTFS (orthogonal time frequency space) modulation the carrier waveform\nis a pulse in the delay-Doppler (DD) domain, formally a quasi-periodic\nlocalized function with specific periods along delay and Doppler. When the\nchannel delay spread is less than the delay period, and the channel Doppler\nspread is less than the Doppler period, the response to a single Zak-OTFS\ncarrier provides an image of the scattering environment and can be used to\npredict the effective channel at all other carriers. The image of the\nscattering environment changes slowly, making it possible to employ precoding\nat the transmitter. Precoding techniques were developed more than thirty years\nago for wireline modem channels (V.34 standard) defined by linear convolution\nwhere a pulse in the time domain (TD) is used to probe the one-dimensional\npartial response channel. The action of a doubly spread channel on Zak-OTFS\nmodulation determines a two-dimensional partial response channel defined by\ntwisted convolution, and we develop a novel precoding technique for this\nchannel. The proposed precoder leads to separate equalization of each DD\ncarrier which has significantly lower complexity than joint equalization of all\ncarriers. Further, the effective precoded channel results in non-interfering DD\ncarriers which significantly reduces the overhead of guard carriers separating\ndata and pilot carriers, which improves the spectral efficiency significantly."}
{"id": "2507.09898", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.09898", "abs": "https://arxiv.org/abs/2507.09898", "authors": ["Alireza Golkarieha", "Kiana Kiashemshakib", "Sajjad Rezvani Boroujenic", "Nasibeh Asadi Isakand"], "title": "Advanced U-Net Architectures with CNN Backbones for Automated Lung Cancer Detection and Segmentation in Chest CT Images", "comment": "This manuscript has 20 pages and 10 figures. It is submitted to the\n  Journal 'Scientific Reports'", "summary": "This study investigates the effectiveness of U-Net architectures integrated\nwith various convolutional neural network (CNN) backbones for automated lung\ncancer detection and segmentation in chest CT images, addressing the critical\nneed for accurate diagnostic tools in clinical settings. A balanced dataset of\n832 chest CT images (416 cancerous and 416 non-cancerous) was preprocessed\nusing Contrast Limited Adaptive Histogram Equalization (CLAHE) and resized to\n128x128 pixels. U-Net models were developed with three CNN backbones: ResNet50,\nVGG16, and Xception, to segment lung regions. After segmentation, CNN-based\nclassifiers and hybrid models combining CNN feature extraction with traditional\nmachine learning classifiers (Support Vector Machine, Random Forest, and\nGradient Boosting) were evaluated using 5-fold cross-validation. Metrics\nincluded accuracy, precision, recall, F1-score, Dice coefficient, and ROC-AUC.\nU-Net with ResNet50 achieved the best performance for cancerous lungs (Dice:\n0.9495, Accuracy: 0.9735), while U-Net with VGG16 performed best for\nnon-cancerous segmentation (Dice: 0.9532, Accuracy: 0.9513). For\nclassification, the CNN model using U-Net with Xception achieved 99.1 percent\naccuracy, 99.74 percent recall, and 99.42 percent F1-score. The hybrid\nCNN-SVM-Xception model achieved 96.7 percent accuracy and 97.88 percent\nF1-score. Compared to prior methods, our framework consistently outperformed\nexisting models. In conclusion, combining U-Net with advanced CNN backbones\nprovides a powerful method for both segmentation and classification of lung\ncancer in CT scans, supporting early diagnosis and clinical decision-making."}
{"id": "2507.09895", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.09895", "abs": "https://arxiv.org/abs/2507.09895", "authors": ["Hyung-Joo Moon", "Chan-Byoung Chae", "Kai-Kit Wong", "Robert W. Heath Jr"], "title": "AI-Enhanced Wide-Area Data Imaging via Massive Non-Orthogonal Direct Device-to-HAPS Transmission", "comment": "7 pages, 6 figures, IEEE Communications Magazine (under revision)", "summary": "Massive Aerial Processing for X MAP-X is an innovative framework for\nreconstructing spatially correlated ground data, such as environmental or\nindustrial measurements distributed across a wide area, into data maps using a\nsingle high altitude pseudo-satellite (HAPS) and a large number of distributed\nsensors. With subframe-level data reconstruction, MAP-X provides a\ntransformative solution for latency-sensitive IoT applications. This article\nexplores two distinct approaches for AI integration in the post-processing\nstage of MAP-X. The DNN-based pointwise estimation approach enables real-time,\nadaptive reconstruction through online training, while the CNN-based image\nreconstruction approach improves reconstruction accuracy through offline\ntraining with non-real-time data. Simulation results show that both approaches\nsignificantly outperform the conventional inverse discrete Fourier transform\n(IDFT)-based linear post-processing method. Furthermore, to enable AI-enhanced\nMAP-X, we propose a ground-HAPS cooperation framework, where terrestrial\nstations collect, process, and relay training data to the HAPS. With its\nenhanced capability in reconstructing field data, AI-enhanced MAP-X is\napplicable to various real-world use cases, including disaster response and\nnetwork management."}
{"id": "2507.09923", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.09923", "abs": "https://arxiv.org/abs/2507.09923", "authors": ["Sejin Park", "Sangmin Lee", "Kyong Hwan Jin", "Seung-Won Jung"], "title": "IM-LUT: Interpolation Mixing Look-Up Tables for Image Super-Resolution", "comment": "ICCV 2025", "summary": "Super-resolution (SR) has been a pivotal task in image processing, aimed at\nenhancing image resolution across various applications. Recently, look-up table\n(LUT)-based approaches have attracted interest due to their efficiency and\nperformance. However, these methods are typically designed for fixed scale\nfactors, making them unsuitable for arbitrary-scale image SR (ASISR). Existing\nASISR techniques often employ implicit neural representations, which come with\nconsiderable computational cost and memory demands. To address these\nlimitations, we propose Interpolation Mixing LUT (IM-LUT), a novel framework\nthat operates ASISR by learning to blend multiple interpolation functions to\nmaximize their representational capacity. Specifically, we introduce IM-Net, a\nnetwork trained to predict mixing weights for interpolation functions based on\nlocal image patterns and the target scale factor. To enhance efficiency of\ninterpolation-based methods, IM-Net is transformed into IM-LUT, where LUTs are\nemployed to replace computationally expensive operations, enabling lightweight\nand fast inference on CPUs while preserving reconstruction quality.\nExperimental results on several benchmark datasets demonstrate that IM-LUT\nconsistently achieves a superior balance between image quality and efficiency\ncompared to existing methods, highlighting its potential as a promising\nsolution for resource-constrained applications."}
{"id": "2507.09987", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.09987", "abs": "https://arxiv.org/abs/2507.09987", "authors": ["Zihang Zeng", "Shu Sun", "Meixia Tao", "Yin Xu", "Xianghao Yu"], "title": "VoxelRF: Voxelized Radiance Field for Fast Wireless Channel Modeling", "comment": null, "summary": "Wireless channel modeling in complex environments is crucial for wireless\ncommunication system design and deployment. Traditional channel modeling\napproaches face challenges in balancing accuracy, efficiency, and scalability,\nwhile recent neural approaches such as neural radiance field (NeRF) suffer from\nlong training and slow inference. To tackle these challenges, we propose\nvoxelized radiance field (VoxelRF), a novel neural representation for wireless\nchannel modeling that enables fast and accurate synthesis of spatial spectra.\nVoxelRF replaces the costly multilayer perception (MLP) used in NeRF-based\nmethods with trilinear interpolation of voxel grid-based representation, and\ntwo shallow MLPs to model both propagation and transmitter-dependent effects.\nTo further accelerate training and improve generalization, we introduce\nprogressive learning, empty space skipping, and an additional background\nentropy loss function. Experimental results demonstrate that VoxelRF achieves\ncompetitive accuracy with significantly reduced computation and limited\ntraining data, making it more practical for real-time and resource-constrained\nwireless applications."}
{"id": "2507.09966", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.09966", "abs": "https://arxiv.org/abs/2507.09966", "authors": ["Mingda Zhang"], "title": "A Brain Tumor Segmentation Method Based on CLIP and 3D U-Net with Cross-Modal Semantic Guidance and Multi-Level Feature Fusion", "comment": "13 pages,6 figures", "summary": "Precise segmentation of brain tumors from magnetic resonance imaging (MRI) is\nessential for neuro-oncology diagnosis and treatment planning. Despite advances\nin deep learning methods, automatic segmentation remains challenging due to\ntumor morphological heterogeneity and complex three-dimensional spatial\nrelationships. Current techniques primarily rely on visual features extracted\nfrom MRI sequences while underutilizing semantic knowledge embedded in medical\nreports. This research presents a multi-level fusion architecture that\nintegrates pixel-level, feature-level, and semantic-level information,\nfacilitating comprehensive processing from low-level data to high-level\nconcepts. The semantic-level fusion pathway combines the semantic understanding\ncapabilities of Contrastive Language-Image Pre-training (CLIP) models with the\nspatial feature extraction advantages of 3D U-Net through three mechanisms:\n3D-2D semantic bridging, cross-modal semantic guidance, and semantic-based\nattention mechanisms. Experimental validation on the BraTS 2020 dataset\ndemonstrates that the proposed model achieves an overall Dice coefficient of\n0.8567, representing a 4.8% improvement compared to traditional 3D U-Net, with\na 7.3% Dice coefficient increase in the clinically important enhancing tumor\n(ET) region."}
{"id": "2507.09999", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.09999", "abs": "https://arxiv.org/abs/2507.09999", "authors": ["Lital Dabush", "Nir Shlezinger", "Tirza Routtenberg"], "title": "Sparsity-Aware Extended Kalman Filter for Tracking Dynamic Graphs", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "A broad range of applications involve signals with irregular structures that\ncan be represented as a graph. As the underlying structures can change over\ntime, the tracking dynamic graph topologies from observed signals is a\nfundamental challenge in graph signal processing (GSP), with applications in\nvarious domains, such as power systems, the brain-machine interface, and\ncommunication systems. In this paper, we propose a method for tracking dynamic\nchanges in graph topologies. Our approach builds on a representation of the\ndynamics as a graph-based nonlinear state-space model (SSM), where the\nobservations are graph signals generated through graph filtering, and the\nunderlying evolving topology serves as the latent states. In our formulation,\nthe graph Laplacian matrix is parameterized using the incidence matrix and edge\nweights, enabling a structured representation of the state. In order to track\nthe evolving topology in the resulting SSM, we develop a sparsity-aware\nextended Kalman filter (EKF) that integrates $\\ell_1$-regularized updates\nwithin the filtering process. Furthermore, a dynamic programming scheme to\nefficiently compute the Jacobian of the graph filter is introduced. Our\nnumerical study demonstrates the ability of the proposed method to accurately\ntrack sparse and time-varying graphs under realistic conditions, with highly\nnonlinear measurements, various noise levels, and different change rates, while\nmaintaining low computational complexity."}
{"id": "2507.09995", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.09995", "abs": "https://arxiv.org/abs/2507.09995", "authors": ["Guohao Huo", "Ruiting Dai", "Hao Tang"], "title": "Graph-based Multi-Modal Interaction Lightweight Network for Brain Tumor Segmentation (GMLN-BTS) in Edge Iterative MRI Lesion Localization System (EdgeIMLocSys)", "comment": null, "summary": "Brain tumor segmentation plays a critical role in clinical diagnosis and\ntreatment planning, yet the variability in imaging quality across different MRI\nscanners presents significant challenges to model generalization. To address\nthis, we propose the Edge Iterative MRI Lesion Localization System\n(EdgeIMLocSys), which integrates Continuous Learning from Human Feedback to\nadaptively fine-tune segmentation models based on clinician feedback, thereby\nenhancing robustness to scanner-specific imaging characteristics. Central to\nthis system is the Graph-based Multi-Modal Interaction Lightweight Network for\nBrain Tumor Segmentation (GMLN-BTS), which employs a Modality-Aware Adaptive\nEncoder (M2AE) to extract multi-scale semantic features efficiently, and a\nGraph-based Multi-Modal Collaborative Interaction Module (G2MCIM) to model\ncomplementary cross-modal relationships via graph structures. Additionally, we\nintroduce a novel Voxel Refinement UpSampling Module (VRUM) that\nsynergistically combines linear interpolation and multi-scale transposed\nconvolutions to suppress artifacts while preserving high-frequency details,\nimproving segmentation boundary accuracy. Our proposed GMLN-BTS model achieves\na Dice score of 85.1% on the BraTS2017 dataset with only 4.58 million\nparameters, representing a 98% reduction compared to mainstream 3D Transformer\nmodels, and significantly outperforms existing lightweight approaches. This\nwork demonstrates a synergistic breakthrough in achieving high-accuracy,\nresource-efficient brain tumor segmentation suitable for deployment in\nresource-constrained clinical environments."}
{"id": "2507.10063", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.10063", "abs": "https://arxiv.org/abs/2507.10063", "authors": ["Hongpu Zhang", "Shu Sun", "Hangsong Yan", "Jianhua Mo"], "title": "Deep Learning-Based Beamforming Design Using Target Beam Patterns", "comment": "6 pages, 5 figures", "summary": "This paper proposes a deep learning-based beamforming design framework that\ndirectly maps a target beam pattern to optimal beamforming vectors across\nmultiple antenna array architectures, including digital, analog, and hybrid\nbeamforming. The proposed method employs a lightweight encoder-decoder network\nwhere the encoder compresses the complex beam pattern into a low-dimensional\nfeature vector and the decoder reconstructs the beamforming vector while\nsatisfying hardware constraints. To address training challenges under diverse\nand limited channel station information (CSI) conditions, a two-stage training\nprocess is introduced, which consists of an offline pre-training for robust\nfeature extraction using an auxiliary module, followed by online training of\nthe decoder with a composite loss function that ensures alignment between the\nsynthesized and target beam patterns in terms of the main lobe shape and side\nlobe suppression. Simulation results based on NYUSIM-generated channels show\nthat the proposed method can achieve spectral efficiency close to that of fully\ndigital beamforming under limited CSI and outperforms representative existing\nmethods."}
{"id": "2507.10250", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.10250", "abs": "https://arxiv.org/abs/2507.10250", "authors": ["Ashkan Shakarami", "Lorenzo Nicole", "Rocco Cappellesso", "Angelo Paolo Dei Tos", "Stefano Ghidoni"], "title": "DepViT-CAD: Deployable Vision Transformer-Based Cancer Diagnosis in Histopathology", "comment": "25 pages, 15 figures", "summary": "Accurate and timely cancer diagnosis from histopathological slides is vital\nfor effective clinical decision-making. This paper introduces DepViT-CAD, a\ndeployable AI system for multi-class cancer diagnosis in histopathology. At its\ncore is MAViT, a novel Multi-Attention Vision Transformer designed to capture\nfine-grained morphological patterns across diverse tumor types. MAViT was\ntrained on expert-annotated patches from 1008 whole-slide images, covering 11\ndiagnostic categories, including 10 major cancers and non-tumor tissue.\nDepViT-CAD was validated on two independent cohorts: 275 WSIs from The Cancer\nGenome Atlas and 50 routine clinical cases from pathology labs, achieving\ndiagnostic sensitivities of 94.11% and 92%, respectively. By combining\nstate-of-the-art transformer architecture with large-scale real-world\nvalidation, DepViT-CAD offers a robust and scalable approach for AI-assisted\ncancer diagnostics. To support transparency and reproducibility, software and\ncode will be made publicly available at GitHub."}
{"id": "2507.10145", "categories": ["eess.SP", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2507.10145", "abs": "https://arxiv.org/abs/2507.10145", "authors": ["Ryohei Fukuma", "Yoshinobu Kawahara", "Okito Yamashita", "Kei Majima", "Haruhiko Kishima", "Takufumi Yanagisawa"], "title": "Intrinsic frequency distribution characterises neural dynamics", "comment": null, "summary": "Decomposing multivariate time series with certain basic dynamics is crucial\nfor understanding, predicting and controlling nonlinear spatiotemporally\ndynamic systems such as the brain. Dynamic mode decomposition (DMD) is a method\nfor decomposing nonlinear spatiotemporal dynamics into several basic dynamics\n(dynamic modes; DMs) with intrinsic frequencies and decay rates. In particular,\nunlike Fourier transform-based methods, which are used to decompose a\nsingle-channel signal into the amplitudes of sinusoidal waves with discrete\nfrequencies at a regular interval, DMD can derive the intrinsic frequencies of\na multichannel signal on the basis of the available data; furthermore, it can\ncapture nonstationary components such as alternations between states with\ndifferent intrinsic frequencies. Here, we propose the use of the distribution\nof intrinsic frequencies derived from DMDs (DM frequencies) to characterise\nneural activities. The distributions of DM frequencies in the\nelectroencephalograms of healthy subjects and patients with dementia or\nParkinson's disease in a resting state were evaluated. By using the\ndistributions, these patients were distinguished from healthy subjects with\nsignificantly greater accuracy than when using amplitude spectra derived by\ndiscrete Fourier transform. This finding suggests that the distribution of DM\nfrequencies exhibits distinct behaviour from amplitude spectra, and therefore,\nthe distribution may serve as a new biomarker by characterising the nonlinear\nspatiotemporal dynamics of electrophysiological signals."}
{"id": "2507.10167", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.10167", "abs": "https://arxiv.org/abs/2507.10167", "authors": ["Kaidi Wang", "Zhiguo Ding", "Naofal Al-Dhahir"], "title": "Pinching-Antenna Systems for Physical Layer Security", "comment": null, "summary": "This letter investigates the potential of pinching-antenna systems for\nenhancing physical layer security. By pre-installing multiple pinching antennas\nat discrete positions along a waveguide, the capability of the considered\nsystem to perform amplitude and phase adjustment is validated through the\nformulation of a secrecy rate maximization problem. Specifically, amplitude\ncontrol is applied to enhance the signal quality at the legitimate user, while\nphase alignment is designed to degrade the received signal quality at the\neavesdropper. This cooperation among pinching antennas is modeled as a\ncoalitional game, and a corresponding antenna activation algorithm is proposed.\nThe individual impact of each antenna is quantified based on the Shapley value\nand marginal contribution, providing a fair and efficient method for\nperformance evaluation. Simulation results show that the considered\npinching-antenna system achieves significant improvements in secrecy rate, and\nthat the Shapley value based algorithm outperforms conventional coalition value\nbased solutions."}
{"id": "2507.10173", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.10173", "abs": "https://arxiv.org/abs/2507.10173", "authors": ["Kaidi Wang", "Chongjun Ouyang", "Yuanwei Liu", "Zhiguo Ding"], "title": "Pinching-Antenna Systems with LoS Blockages", "comment": null, "summary": "The aim of this letter is to explore the capability of pinching-antenna\nsystems to construct line-of-sight (LoS) links in the presence of LoS\nblockages. Specifically, pinching antennas are pre-installed at preconfigured\npositions along waveguides and can be selectively activated to create LoS links\nfor enhancing desired signals and non-line-of-sight (NLoS) links for\neliminating inter-user interference. On this basis, a sum-rate maximization\nproblem is formulated by jointly optimizing waveguide assignment and antenna\nactivation. To solve this problem, a matching based algorithm is proposed using\ntwo distinct preference designs. Simulation results demonstrate that the\nconsidered pinching-antenna system and proposed solutions can dynamically\nestablish LoS links and effectively exploit LoS blockages to mitigate\ninterference, thereby significantly improving system throughput."}
{"id": "2507.10308", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.10308", "abs": "https://arxiv.org/abs/2507.10308", "authors": ["Hung Nguyen-Kha", "Vu Nguyen Ha", "Eva Lagunas", "Symeon Chatzinotas", "Joel Grotz"], "title": "Enhanced Throughput and Seamless Handover Solutions for Urban 5G-Vehicle C-Band Integrated Satellite-Terrestrial Networks", "comment": "ACCEPTED FOR PUBLICATION IN IEEE TRANSACTIONS ON COMMUNICATIONS", "summary": "This paper investigates downlink transmission in 5G Integrated\nSatellite-Terrestrial Networks (ISTNs) supporting automotive users (UEs) in\nurban environments, where base stations (BSs) and Low Earth Orbit (LEO)\nsatellites (LSats) cooperate to serve moving UEs over shared C-band frequency\ncarriers. Urban settings, characterized by dense obstructions, together with UE\nmobility, and the dynamic movement and coverage of LSats pose significant\nchallenges to user association and resource allocation. To address these\nchallenges, we formulate a multi-objective optimization problem designed to\nimprove both throughput and seamless handover (HO). Particularly, the\nformulated problem balances sum-rate (SR) maximization and connection change\n(CC) minimization through a weighted trade-off by jointly optimizing power\nallocation and BS-UE/LSat-UE associations over a given time window. This is a\nmixed-integer and non-convex problem which is inherently difficult to solve. To\nsolve this problem efficiently, we propose an iterative algorithm based on the\nSuccessive Convex Approximation (SCA) technique. Furthermore, we introduce a\npractical prediction-based algorithm capable of providing efficient solutions\nin real-world implementations. Especially, the simulations use a realistic 3D\nmap of London and UE routes obtained from the Google Navigator application to\nensure practical examination. Thanks to these realistic data, the simulation\nresults can show valuable insights into the link budget assessment in urban\nareas due to the impact of buildings on transmission links under the blockage,\nreflection, and diffraction effects. Furthermore, the numerical results\ndemonstrate the effectiveness of our proposed algorithms in terms of SR and the\nCC-number compared to the greedy and benchmark algorithms."}
