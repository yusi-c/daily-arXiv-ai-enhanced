{"id": "2511.16827", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.16827", "abs": "https://arxiv.org/abs/2511.16827", "authors": ["Bassel Abou Ali Modad", "Xin Yu", "Yao-Yi Chiang", "Andreas F. Molisch"], "title": "Line-of-Sight Probability in Macrocells: Framework, Statistical Models, and Parametrization from Massive Real World Datasets in the USA", "comment": null, "summary": "Accurate modeling of line-of-sight (LOS) probability is crucial for wireless channel description and coverage planning. The presence of a LOS impacts other channel characteristics such as pathloss, fading depth, delay- and angular spread, etc.. Existing models, although useful, are based on very limited datasets. In this paper, we establish a framework to produce high accuracy LOS models from geospatial data in different environments, and apply it to create a LOS model for macrocells, using datasets of the United States (US) on a nationalscale, using more than 13, 000 locations of real-world macrocells. Based on this we create a new, fully parameterized model that better describes macrocell deployments in the US than the 3GPP model. We furthermore demonstrate that for improved accuracy the LOS probability should be modeled on a per cell basis, and the model parameters treated as random variables; we provide a full description and parameterization of this novel approach and by simulations show that it better predicts the inter-cell interference at the cell-edge than an average-based model."}
{"id": "2511.16888", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.16888", "abs": "https://arxiv.org/abs/2511.16888", "authors": ["Haiquan Zhao", "Xiong Yin", "Jinhui Hu"], "title": "State-of-charge estimation of lithium-ion batteries using a tree seed and genetic algorithm-optimized generalized mixture minimum error entropy-based square root cubature Kalman filter", "comment": null, "summary": "The cubature Kalman filter based on minimum error entropy (MEE-CKF) offers accurate and robust performance in state of charge (SOC) estimation. However, due to the inflexibility of the minimum error entropy (MEE), this algorithm demonstrates limited robustness when confronted with more complex noise environments. To address these limitations, this paper proposes a generalized mixture minimum error entropy-based (GMMEE) square-root cubature Kalman filter (GMMEE-SRCKF). The square-root algorithm ensures improved numerical stability and avoids covariance degeneration, while the GMMEE criterion with two flexible kernels adapts effectively to non-Gaussian noise. Moreover, a hybrid tree seed and genetic algorithm (TSGA) is introduced to optimize the kernel parameters automatically. Experimental results confirm that the TSGA-optimized GMMEE-SRCKF outperforms existing robust filters, achieving the root mean square error (RMSE) of less than 0.5%."}
{"id": "2511.17007", "categories": ["eess.SP", "cs.LG", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.17007", "abs": "https://arxiv.org/abs/2511.17007", "authors": ["Wangqian Chen", "Junting Chen", "Shuguang Cui"], "title": "Generative MIMO Beam Map Construction for Location Recovery and Beam Tracking", "comment": null, "summary": "Machine learning (ML) has greatly advanced data-driven channel modeling and resource optimization in wireless communication systems. However, most existing ML-based methods rely on large, accurately labeled datasets with location information, which are often difficult and costly to obtain. This paper proposes a generative framework to recover location labels directly from sequences of sparse channel state information (CSI) measurements, without explicit location labels for radio map construction. Instead of directly storing raw CSI, we learn a compact low-dimensional radio map embedding and leverage a generative model to reconstruct the high-dimensional CSI. Specifically, to address the uncertainty of sparse CSI, a dual-scale feature extraction scheme is designed to enhance feature representation by jointly exploiting correlations from angular space and across neighboring samples. We develop a hybrid recurrent-convolutional encoder to learn mobility patterns, which combines a truncation strategy and multi-scale convolutions in the recurrent neural network (RNN) to ensure feature robustness against short-term fluctuations. Unlike conventional Gaussian priors in latent space, we embed a learnable radio map to capture the location information by encoding high-level positional features from CSI measurements. Finally, a diffusion-based generative decoder reconstructs the full CSI with high fidelity by conditioning on the positional features in the radio map. Numerical experiments demonstrate that the proposed model can improve localization accuracy by over 30% and achieve a 20% capacity gain in non-line-of-sight (NLOS) scenarios compared with model-based Kalman filter approaches."}
{"id": "2511.17058", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.17058", "abs": "https://arxiv.org/abs/2511.17058", "authors": ["Ziyuan Zheng", "Qingqing Wu", "Wen Chen", "Weiren Zhu", "Ying Gao"], "title": "Movable Intelligent Surface-Enabled Wireless Communications: Static Phase Shifts with Mechanical Reconfigurability", "comment": "16 pages, 18 figures, submitted for possible publication in IEEE journals", "summary": "Intelligent surfaces that reshape electromagnetic waves are regarded as disruptive technologies for wireless networks. However, existing designs sit at two costly extremes: dynamic reconfigurable intelligent surfaces (RISs) offer fine beam control but require dense cabling, continuous power consumption, and substantial signaling overhead, whereas low-cost static surfaces require no control lines or electronics but are limited to a single beam pattern. This disparity leaves a practical gap for quasi-static environments, such as industrial Internet-of-things and smart agriculture scenarios, where channels are stable with user demands changing only occasionally or periodically, and neither extreme is sufficiently economical or flexible. To bridge this gap, we propose a novel movable intelligent surface (MIS) architecture, whose beam patterns are switched not by electronic phase tuning but by mechanically sliding a small, pre-phased secondary metasurface layer across a larger, likewise static primary layer. We develop an MIS signal model that characterizes the interaction between static phase elements with dynamic geometry via binary selection matrices. Based on this model, we formulate a new type of optimization problems that jointly design static phase shifts and the overlapping position selection of MS2 (equal to beam pattern scheduling). Efficient algorithms based on the penalty method, block coordinate descent, and Riemannian manifold optimization are proposed to tackle these mixed-integer non-convex problems. Simulation results demonstrate that the proposed MIS architecture substantially narrows the performance gap between single-layer static surfaces and dynamic RISs, providing a practical and flexible solution for quasi-static wireless applications."}
{"id": "2511.16854", "categories": ["eess.IV", "cs.AI", "cs.CV", "eess.SP"], "pdf": "https://arxiv.org/pdf/2511.16854", "abs": "https://arxiv.org/abs/2511.16854", "authors": ["Mohammad Khateri", "Serge Vasylechko", "Morteza Ghahremani", "Liam Timms", "Deniz Kocanaogullari", "Simon K. Warfield", "Camilo Jaimes", "Davood Karimi", "Alejandra Sierra", "Jussi Tohka", "Sila Kurugol", "Onur Afacan"], "title": "MRI Super-Resolution with Deep Learning: A Comprehensive Survey", "comment": "41 pages", "summary": "High-resolution (HR) magnetic resonance imaging (MRI) is crucial for many clinical and research applications. However, achieving it remains costly and constrained by technical trade-offs and experimental limitations. Super-resolution (SR) presents a promising computational approach to overcome these challenges by generating HR images from more affordable low-resolution (LR) scans, potentially improving diagnostic accuracy and efficiency without requiring additional hardware. This survey reviews recent advances in MRI SR techniques, with a focus on deep learning (DL) approaches. It examines DL-based MRI SR methods from the perspectives of computer vision, computational imaging, inverse problems, and MR physics, covering theoretical foundations, architectural designs, learning strategies, benchmark datasets, and performance metrics. We propose a systematic taxonomy to categorize these methods and present an in-depth study of both established and emerging SR techniques applicable to MRI, considering unique challenges in clinical and research contexts. We also highlight open challenges and directions that the community needs to address. Additionally, we provide a collection of essential open-access resources, tools, and tutorials, available on our GitHub: https://github.com/mkhateri/Awesome-MRI-Super-Resolution.\n  IEEE keywords: MRI, Super-Resolution, Deep Learning, Computational Imaging, Inverse Problem, Survey."}
{"id": "2511.17062", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.17062", "abs": "https://arxiv.org/abs/2511.17062", "authors": ["Keying Zhu", "Xingyu Zhou", "Jie Yang", "Le Liang", "Shi Jin"], "title": "Super-Resolution ISAC Receivers: An MCMC-Based Gridless Sparse Bayesian Learning Approach", "comment": null, "summary": "Integrated sensing and communication (ISAC) is crucial for low-altitude wireless networks (LAWNs), where the safety-critical demand for high-accuracy sensing creates a trade-off between precision and complexity for conventional methods. To address this, we propose a novel gridless sparse Bayesian learning (SBL) framework for joint super-resolution multi-target detection and high-accuracy parameter estimation with manageable computational cost. Our model treats target parameters as continuous variables to bypass the grid limitations of conventional approaches. This SBL formulation, however, transforms the estimation task into a challenging high-dimensional inference problem, which we address by developing an enhanced gradient-based Markov chain Monte Carlo algorithm. Our method integrates mini-batch sampling and the Adam optimizer to ensure computational efficiency and rapid convergence. Finally, we validate the framework's robustness in strong clutter and provide a theoretical benchmark by deriving the corresponding Bayesian Cramer-Rao bound. Simulation results demonstrate remarkable super-resolution capabilities, successfully resolving multiple targets separated by merely 50% of the Rayleigh limit in range, 17% in velocity, and 52% in angle. At a signal-to-noise ratio of 20 dB, the algorithm achieves a multi-target detection probability exceeding 90% while concurrently delivering ultra-high accuracy, with root mean square error of 0.07 m, 0.024 m/s, and 0.015 degree for range, velocity, and angle, respectively. This robust performance, demonstrated against strong clutter, showcases its suitability for practical ISAC-LAWNs applications."}
{"id": "2511.16876", "categories": ["eess.IV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2511.16876", "abs": "https://arxiv.org/abs/2511.16876", "authors": ["Xin Xiong", "Samuel Fernández-Menduiña", "Eduardo Pavez", "Antonio Ortega", "Neil Birkbeck", "Balu Adsumilli"], "title": "Avoiding Quality Saturation in UGC Compression Using Denoised References", "comment": null, "summary": "Video-sharing platforms must re-encode large volumes of noisy user-generated content (UGC) to meet streaming demands. However, conventional codecs, which aim to minimize the mean squared error (MSE) between the compressed and input videos, can cause quality saturation (QS) when applied to UGC, i.e., increasing the bitrate preserves input artifacts without improving visual quality. A direct approach to solve this problem is to detect QS by repeatedly evaluating a non-reference metric (NRM) on videos compressed with multiple codec parameters, which is inefficient. In this paper, we re-frame UGC compression and QS detection from the lens of noisy source coding theory: rather than using a NRM, we compute the MSE with respect to the denoised UGC, which serves as an alternative reference (D-MSE). Unlike MSE measured between the UGC input and the compressed UGC, D-MSE saturates at non-zero values as bitrates increase, a phenomenon we term distortion saturation (DS). Since D-MSE can be computed at the block level in the transform domain, we can efficiently detect D-MSE without coding and decoding with various parameters. We propose two methods for DS detection: distortion saturation detection (DSD), which relies on an input-dependent threshold derived from the D-MSE of the input UGC, and rate-distortion saturation detection (RDSD), which estimates the Lagrangian at the saturation point using a low-complexity compression method. Both methods work as a pre-processing step that can help standard-compliant codecs avoid QS in UGC compression. Experiments with AVC show that preventing encoding in the saturation region, i.e., avoiding encoding at QPs that result in QS according to our methods, achieves BD-rate savings of 8%-20% across multiple different NRMs, compared to a naïve baseline that encodes at the given input QP while ignoring QS."}
{"id": "2511.17066", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.17066", "abs": "https://arxiv.org/abs/2511.17066", "authors": ["Duc Viet Nguyen", "Haiquan Zhao", "Jinhui Hu"], "title": "Distributed Cubature Kalman Filter based on MEEF with Adaptive Cauchy Kernel for State Estimation", "comment": "13 pages, 11 figures", "summary": "Nowadays, with the development of multi-sensor networks, the distributed cubature Kalman filter is one of the well-known existing schemes for state estimation, for which the influence of the non-Gaussian noise, abnormal data, and communication burden are urgent challenges. In this paper, a distributed cubature Kalman filter based on adaptive minimum error entropy with fiducial points (AMEEF) criterion (AMEEF-DCKF) is proposed to overcome the above limitations. Specifically, firstly, in order to solve the influence of various types of non-Gaussian noise and abnormal data, the AMEEF optimization criterion is designed, in which the kernels used are Cauchy kernels with adaptive bandwidth. At the same time, the designed optimization criterion has enhanced the numerical stability and optimized the kernel bandwidth value. Next, in order to address the communication burden problem in multi-sensor networks, where a leader and a follower are distinguished, a distributed algorithm is constructed to achieve an average consensus among these sensors, called leader-follower average consensus (LFAC). Additionally, the convergence proof of the average consensus algorithm and the computational complexity analysis of the AMEEF-DCKF algorithm are also presented. Finally, through a 10-node sensor network, the effectiveness of the proposed algorithm is demonstrated in estimating the state of the power system and navigating land vehicles in complex environments."}
{"id": "2511.17043", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.17043", "abs": "https://arxiv.org/abs/2511.17043", "authors": ["Rama Krishna Boya", "Mohan Kireeti Magalanadu", "Azaruddin Palavalli", "Rupa Ganesh Tekuri", "Amrit Pattanayak", "Prasanthi Enuga", "Vignesh Esakki Muthu", "Vivek Aditya Boya"], "title": "MedImageInsight for Thoracic Cavity Health Classification from Chest X-rays", "comment": "9 pages, 5 figures and 3 tables", "summary": "Chest radiography remains one of the most widely used imaging modalities for thoracic diagnosis, yet increasing imaging volumes and radiologist workload continue to challenge timely interpretation. In this work, we investigate the use of MedImageInsight, a medical imaging foundational model, for automated binary classification of chest X-rays into Normal and Abnormal categories. Two approaches were evaluated: (1) fine-tuning MedImageInsight for end-to-end classification, and (2) employing the model as a feature extractor for a transfer learning pipeline using traditional machine learning classifiers. Experiments were conducted using a combination of the ChestX-ray14 dataset and real-world clinical data sourced from partner hospitals. The fine-tuned classifier achieved the highest performance, with an ROC-AUC of 0.888 and superior calibration compared to the transfer learning models, demonstrating performance comparable to established architectures such as CheXNet. These results highlight the effectiveness of foundational medical imaging models in reducing task-specific training requirements while maintaining diagnostic reliability. The system is designed for integration into web-based and hospital PACS workflows to support triage and reduce radiologist burden. Future work will extend the model to multi-label pathology classification to provide preliminary diagnostic interpretation in clinical environments."}
{"id": "2511.17122", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.17122", "abs": "https://arxiv.org/abs/2511.17122", "authors": ["Aron Schott", "Berk Acikgöz", "Omar Massoud", "Marina Petrova", "Ljiljana Simić"], "title": "Unleashing Sensor-Aided Environment Awareness for Beam Management in Beyond-5G Networks: An OpenAirInterface Experimental Platform", "comment": null, "summary": "Large antenna arrays and beamforming techniques are key components for exploiting the spectrum-rich FR2 bands in next-generation mobile communication networks. Given the site-specific spatio-temporal variations of the mm-wave channel, non-RF sensor inputs and environment awareness can be leveraged to greatly enhance beam management decisions, e.g. via machine learning (ML) techniques. However, the current literature lacks open platforms to gather datasets for the training of such ML techniques and to evaluate novel beam management approaches in real-time, real-world scenarios and full-stack endto-end networks. In this work, we present our SDR-based experimental platform based on OpenAirInterface and are the first to integrate popular low-cost antenna array transceivers, beam sweeping capabilities, and a highly-modular sensor framework and associated interfaces into such a full-stack experimental platform. This enables beam management experimentation in real-world, real-time scenarios and facilitates gathering datasets necessary for developing ML-based beam management protocols that incorporate environment awareness via sensor modalities."}
{"id": "2511.17126", "categories": ["eess.IV", "cs.CV", "cs.LG", "physics.optics"], "pdf": "https://arxiv.org/pdf/2511.17126", "abs": "https://arxiv.org/abs/2511.17126", "authors": ["Qi Jiang", "Xiaolong Qian", "Yao Gao", "Lei Sun", "Kailun Yang", "Zhonghua Yi", "Wenyong Li", "Ming-Hsuan Yang", "Luc Van Gool", "Kaiwei Wang"], "title": "OmniLens++: Blind Lens Aberration Correction via Large LensLib Pre-Training and Latent PSF Representation", "comment": "The source code and datasets will be made publicly available at https://github.com/zju-jiangqi/OmniLens2", "summary": "Emerging deep-learning-based lens library pre-training (LensLib-PT) pipeline offers a new avenue for blind lens aberration correction by training a universal neural network, demonstrating strong capability in handling diverse unknown optical degradations. This work proposes the OmniLens++ framework, which resolves two challenges that hinder the generalization ability of existing pipelines: the difficulty of scaling data and the absence of prior guidance characterizing optical degradation. To improve data scalability, we expand the design specifications to increase the degradation diversity of the lens source, and we sample a more uniform distribution by quantifying the spatial-variation patterns and severity of optical degradation. In terms of model design, to leverage the Point Spread Functions (PSFs), which intuitively describe optical degradation, as guidance in a blind paradigm, we propose the Latent PSF Representation (LPR). The VQVAE framework is introduced to learn latent features of LensLib's PSFs, which is assisted by modeling the optical degradation process to constrain the learning of degradation priors. Experiments on diverse aberrations of real-world lenses and synthetic LensLib show that OmniLens++ exhibits state-of-the-art generalization capacity in blind aberration correction. Beyond performance, the AODLibpro is verified as a scalable foundation for more effective training across diverse aberrations, and LPR can further tap the potential of large-scale LensLib. The source code and datasets will be made publicly available at https://github.com/zju-jiangqi/OmniLens2."}
{"id": "2511.17164", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.17164", "abs": "https://arxiv.org/abs/2511.17164", "authors": ["Ioanna Chourdaki", "Kleanthis Avramidis", "Christos Garoufis", "Athanasia Zlatintsi", "Petros Maragos"], "title": "Teager-Kaiser Energy Methods For EEG Feature Extraction In Biomedical Applications", "comment": "Submitted to ICASSP 2026", "summary": "Electroencephalography (EEG) signals are inherently non-linear, non-stationary, and vulnerable to noise sources, making the extraction of discriminative features a long-standing challenge. In this work, we investigate the non-linear Teager-Kaiser Energy Operator (TKEO) for modeling the underlying energy dynamics of EEG in three representative tasks: motor imagery, emotion recognition, and epilepsy detection. To accommodate the narrowband nature of the operator, we employ Gabor filterbanks to isolate canonical frequency bands, followed by the Energy Separation Algorithm to decompose the TKEO output into amplitude envelope and instantaneous frequency components. We then derive a set of energy descriptors based on this demodulation and compare their classification performance against established signal energy and power spectrum features. TKEO features outperform the respective baselines in motor imagery and epilepsy detection, whereas they perform on par in emotion recognition. Our findings suggest that the proposed TKEO-based pipeline provides an intuitive framework for extracting EEG signal dynamics."}
{"id": "2511.17353", "categories": ["eess.IV", "cs.CV", "physics.optics"], "pdf": "https://arxiv.org/pdf/2511.17353", "abs": "https://arxiv.org/abs/2511.17353", "authors": ["Xiaolong Qian", "Qi Jiang", "Lei Sun", "Zongxi Yu", "Kailun Yang", "Peixuan Wu", "Jiacheng Zhou", "Yao Gao", "Yaoguang Ma", "Ming-Hsuan Yang", "Kaiwei Wang"], "title": "Learning Latent Transmission and Glare Maps for Lens Veiling Glare Removal", "comment": "All code and datasets will be publicly released at https://github.com/XiaolongQian/DeVeiler", "summary": "Beyond the commonly recognized optical aberrations, the imaging performance of compact optical systems-including single-lens and metalens designs-is often further degraded by veiling glare caused by stray-light scattering from non-ideal optical surfaces and coatings, particularly in complex real-world environments. This compound degradation undermines traditional lens aberration correction yet remains underexplored. A major challenge is that conventional scattering models (e.g., for dehazing) fail to fit veiling glare due to its spatial-varying and depth-independent nature. Consequently, paired high-quality data are difficult to prepare via simulation, hindering application of data-driven veiling glare removal models. To this end, we propose VeilGen, a generative model that learns to simulate veiling glare by estimating its underlying optical transmission and glare maps in an unsupervised manner from target images, regularized by Stable Diffusion (SD)-based priors. VeilGen enables paired dataset generation with realistic compound degradation of optical aberrations and veiling glare, while also providing the estimated latent optical transmission and glare maps to guide the veiling glare removal process. We further introduce DeVeiler, a restoration network trained with a reversibility constraint, which utilizes the predicted latent maps to guide an inverse process of the learned scattering model. Extensive experiments on challenging compact optical systems demonstrate that our approach delivers superior restoration quality and physical fidelity compared with existing methods. These suggest that VeilGen reliably synthesizes realistic veiling glare, and its learned latent maps effectively guide the restoration process in DeVeiler. All code and datasets will be publicly released at https://github.com/XiaolongQian/DeVeiler."}
{"id": "2511.17440", "categories": ["eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.17440", "abs": "https://arxiv.org/abs/2511.17440", "authors": ["Omar A. Alotaibi", "Brian L. Mark", "Mohammad Reza Fasihi"], "title": "Incorporating Bayesian Transfer Learning into Particle Filter for Dual-Tracking System with Asymmetric Noise Intensities", "comment": "20 pages, 8 figures", "summary": "Using Bayesian transfer learning, we develop a particle filter approach for tracking a nonlinear dynamical model in a dual-tracking system where intensities of measurement noise for both sensors are asymmetric. The densities for Bayesian transfer learning are approximated with the sum of weighted particles to improve the tracking performance of the primary sensor, which experiences a higher noise intensity compared to the source sensor. We present simulation results that validate the effectiveness of the proposed approach compared to an isolated particle filter and transfer learning applied to the unscented Kalman filter and the cubature Kalman filter. Furthermore, increasing the number of particles shows an improvement in the performance of transfer learning applied to the particle filter with a higher rate compared to the isolated particle filter. However, increasing the number of particles raises computational time per step. Moreover, the performance gain from incorporating Bayesian transfer learning is approximately linearly proportional to the absolute difference value between the noise intensities of the sensors in the dual-tracking system."}
{"id": "2511.16854", "categories": ["eess.IV", "cs.AI", "cs.CV", "eess.SP"], "pdf": "https://arxiv.org/pdf/2511.16854", "abs": "https://arxiv.org/abs/2511.16854", "authors": ["Mohammad Khateri", "Serge Vasylechko", "Morteza Ghahremani", "Liam Timms", "Deniz Kocanaogullari", "Simon K. Warfield", "Camilo Jaimes", "Davood Karimi", "Alejandra Sierra", "Jussi Tohka", "Sila Kurugol", "Onur Afacan"], "title": "MRI Super-Resolution with Deep Learning: A Comprehensive Survey", "comment": "41 pages", "summary": "High-resolution (HR) magnetic resonance imaging (MRI) is crucial for many clinical and research applications. However, achieving it remains costly and constrained by technical trade-offs and experimental limitations. Super-resolution (SR) presents a promising computational approach to overcome these challenges by generating HR images from more affordable low-resolution (LR) scans, potentially improving diagnostic accuracy and efficiency without requiring additional hardware. This survey reviews recent advances in MRI SR techniques, with a focus on deep learning (DL) approaches. It examines DL-based MRI SR methods from the perspectives of computer vision, computational imaging, inverse problems, and MR physics, covering theoretical foundations, architectural designs, learning strategies, benchmark datasets, and performance metrics. We propose a systematic taxonomy to categorize these methods and present an in-depth study of both established and emerging SR techniques applicable to MRI, considering unique challenges in clinical and research contexts. We also highlight open challenges and directions that the community needs to address. Additionally, we provide a collection of essential open-access resources, tools, and tutorials, available on our GitHub: https://github.com/mkhateri/Awesome-MRI-Super-Resolution.\n  IEEE keywords: MRI, Super-Resolution, Deep Learning, Computational Imaging, Inverse Problem, Survey."}
