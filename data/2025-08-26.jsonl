{"id": "2508.16650", "categories": ["eess.IV", "cs.CV", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2508.16650", "abs": "https://arxiv.org/abs/2508.16650", "authors": ["James K Ruffle", "Samia Mohinta", "Guilherme Pombo", "Asthik Biswas", "Alan Campbell", "Indran Davagnanam", "David Doig", "Ahmed Hamman", "Harpreet Hyare", "Farrah Jabeen", "Emma Lim", "Dermot Mallon", "Stephanie Owen", "Sophie Wilkinson", "Sebastian Brandner", "Parashkev Nachev"], "title": "Predicting brain tumour enhancement from non-contrast MR imaging with artificial intelligence", "comment": "38 pages", "summary": "Brain tumour imaging assessment typically requires both pre- and\npost-contrast MRI, but gadolinium administration is not always desirable, such\nas in frequent follow-up, renal impairment, allergy, or paediatric patients. We\naimed to develop and validate a deep learning model capable of predicting brain\ntumour contrast enhancement from non-contrast MRI sequences alone. We assembled\n11089 brain MRI studies from 10 international datasets spanning adult and\npaediatric populations with various neuro-oncological states, including glioma,\nmeningioma, metastases, and post-resection appearances. Deep learning models\n(nnU-Net, SegResNet, SwinUNETR) were trained to predict and segment enhancing\ntumour using only non-contrast T1-, T2-, and T2/FLAIR-weighted images.\nPerformance was evaluated on 1109 held-out test patients using patient-level\ndetection metrics and voxel-level segmentation accuracy. Model predictions were\ncompared against 11 expert radiologists who each reviewed 100 randomly selected\npatients. The best-performing nnU-Net achieved 83% balanced accuracy, 91.5%\nsensitivity, and 74.4% specificity in detecting enhancing tumour. Enhancement\nvolume predictions strongly correlated with ground truth (R2 0.859). The model\noutperformed expert radiologists, who achieved 69.8% accuracy, 75.9%\nsensitivity, and 64.7% specificity. 76.8% of test patients had Dice over 0.3\n(acceptable detection), 67.5% had Dice over 0.5 (good detection), and 50.2% had\nDice over 0.7 (excellent detection). Deep learning can identify\ncontrast-enhancing brain tumours from non-contrast MRI with clinically relevant\nperformance. These models show promise as screening tools and may reduce\ngadolinium dependence in neuro-oncology imaging. Future work should evaluate\nclinical utility alongside radiology experts."}
{"id": "2508.16730", "categories": ["eess.IV", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.16730", "abs": "https://arxiv.org/abs/2508.16730", "authors": ["Prabhant Singh", "Yiping Li", "Yasmina Al Khalil"], "title": "Analysis of Transferability Estimation Metrics for Surgical Phase Recognition", "comment": "Accepted at DEMI workshop MICCAI 2025", "summary": "Fine-tuning pre-trained models has become a cornerstone of modern machine\nlearning, allowing practitioners to achieve high performance with limited\nlabeled data. In surgical video analysis, where expert annotations are\nespecially time-consuming and costly, identifying the most suitable pre-trained\nmodel for a downstream task is both critical and challenging.\nSource-independent transferability estimation (SITE) offers a solution by\npredicting how well a model will fine-tune on target data using only its\nembeddings or outputs, without requiring full retraining. In this work, we\nformalize SITE for surgical phase recognition and provide the first\ncomprehensive benchmark of three representative metrics, LogME, H-Score, and\nTransRate, on two diverse datasets (RAMIE and AutoLaparo). Our results show\nthat LogME, particularly when aggregated by the minimum per-subset score,\naligns most closely with fine-tuning accuracy; H-Score yields only weak\npredictive power; and TransRate often inverses true model rankings. Ablation\nstudies show that when candidate models have similar performances,\ntransferability estimates lose discriminative power, emphasizing the importance\nof maintaining model diversity or using additional validation. We conclude with\npractical guidelines for model selection and outline future directions toward\ndomain-specific metrics, theoretical foundations, and interactive benchmarking\ntools."}
{"id": "2508.16882", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.16882", "abs": "https://arxiv.org/abs/2508.16882", "authors": ["Junhao Wu", "Yun Li", "Junhao Li", "Jingliang Bian", "Xiaomao Fan", "Wenbin Lei", "Ruxin Wang"], "title": "Multimodal Medical Endoscopic Image Analysis via Progressive Disentangle-aware Contrastive Learning", "comment": "12 pages,6 figures, 6 tables", "summary": "Accurate segmentation of laryngo-pharyngeal tumors is crucial for precise\ndiagnosis and effective treatment planning. However, traditional\nsingle-modality imaging methods often fall short of capturing the complex\nanatomical and pathological features of these tumors. In this study, we present\nan innovative multi-modality representation learning framework based on the\n`Align-Disentangle-Fusion' mechanism that seamlessly integrates 2D White Light\nImaging (WLI) and Narrow Band Imaging (NBI) pairs to enhance segmentation\nperformance. A cornerstone of our approach is multi-scale distribution\nalignment, which mitigates modality discrepancies by aligning features across\nmultiple transformer layers. Furthermore, a progressive feature disentanglement\nstrategy is developed with the designed preliminary disentanglement and\ndisentangle-aware contrastive learning to effectively separate\nmodality-specific and shared features, enabling robust multimodal contrastive\nlearning and efficient semantic fusion. Comprehensive experiments on multiple\ndatasets demonstrate that our method consistently outperforms state-of-the-art\napproaches, achieving superior accuracy across diverse real clinical scenarios."}
{"id": "2508.16897", "categories": ["eess.IV", "cs.CV", "physics.med-ph"], "pdf": "https://arxiv.org/pdf/2508.16897", "abs": "https://arxiv.org/abs/2508.16897", "authors": ["Pouya Shiri", "Xin Yi", "Neel P. Mistry", "Samaneh Javadinia", "Mohammad Chegini", "Seok-Bum Ko", "Amirali Baniasadi", "Scott J. Adams"], "title": "Generating Synthetic Contrast-Enhanced Chest CT Images from Non-Contrast Scans Using Slice-Consistent Brownian Bridge Diffusion Network", "comment": null, "summary": "Contrast-enhanced computed tomography (CT) imaging is essential for\ndiagnosing and monitoring thoracic diseases, including aortic pathologies.\nHowever, contrast agents pose risks such as nephrotoxicity and allergic-like\nreactions. The ability to generate high-fidelity synthetic contrast-enhanced CT\nangiography (CTA) images without contrast administration would be\ntransformative, enhancing patient safety and accessibility while reducing\nhealthcare costs. In this study, we propose the first bridge diffusion-based\nsolution for synthesizing contrast-enhanced CTA images from non-contrast CT\nscans. Our approach builds on the Slice-Consistent Brownian Bridge Diffusion\nModel (SC-BBDM), leveraging its ability to model complex mappings while\nmaintaining consistency across slices. Unlike conventional slice-wise synthesis\nmethods, our framework preserves full 3D anatomical integrity while operating\nin a high-resolution 2D fashion, allowing seamless volumetric interpretation\nunder a low memory budget. To ensure robust spatial alignment, we implement a\ncomprehensive preprocessing pipeline that includes resampling, registration\nusing the Symmetric Normalization method, and a sophisticated dilated\nsegmentation mask to extract the aorta and surrounding structures. We create\ntwo datasets from the Coltea-Lung dataset: one containing only the aorta and\nanother including both the aorta and heart, enabling a detailed analysis of\nanatomical context. We compare our approach against baseline methods on both\ndatasets, demonstrating its effectiveness in preserving vascular structures\nwhile enhancing contrast fidelity."}
{"id": "2508.16601", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.16601", "abs": "https://arxiv.org/abs/2508.16601", "authors": ["Marco Donald Migliore"], "title": "Notes on Deterministic and Stochastic Approaches in Electromagnetic Information Theory", "comment": null, "summary": "This paper investigates the relationship between the Number of Degrees of\nFreedom ($N_{\\rm DoF}$) of the field in deterministic and stochastic source\nmodels within Electromagnetic Information Theory (EIT). Our findings\ndemonstrate a fundamental connection between these two approaches.\nSpecifically, we show that a deterministic model and a stochastic model with a\nspatially incoherent and homogeneous source yield not only the same $N_{\\rm\nDoF}$ but also identical eigenvalues and basis functions for field\nrepresentation. This key equivalence not only explains the effectiveness of\ndeterministic approaches in EIT but also corroborates the use of classical\nelectromagnetic methods within this new discipline."}
{"id": "2508.17223", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.17223", "abs": "https://arxiv.org/abs/2508.17223", "authors": ["Asadullah Bin Rahman", "Masud Ibn Afjal", "Md. Abdulla Al Mamun"], "title": "Deep Learning Architectures for Medical Image Denoising: A Comparative Study of CNN-DAE, CADTra, and DCMIEDNet", "comment": null, "summary": "Medical imaging modalities are inherently susceptible to noise contamination\nthat degrades diagnostic utility and clinical assessment accuracy. This paper\npresents a comprehensive comparative evaluation of three state-of-the-art deep\nlearning architectures for MRI brain image denoising: CNN-DAE, CADTra, and\nDCMIEDNet. We systematically evaluate these models across multiple Gaussian\nnoise intensities ($\\sigma = 10, 15, 25$) using the Figshare MRI Brain Dataset.\nOur experimental results demonstrate that DCMIEDNet achieves superior\nperformance at lower noise levels, with PSNR values of $32.921 \\pm 2.350$ dB\nand $30.943 \\pm 2.339$ dB for $\\sigma = 10$ and $15$ respectively. However,\nCADTra exhibits greater robustness under severe noise conditions ($\\sigma =\n25$), achieving the highest PSNR of $27.671 \\pm 2.091$ dB. All deep learning\napproaches significantly outperform traditional wavelet-based methods, with\nimprovements ranging from 5-8 dB across tested conditions. This study\nestablishes quantitative benchmarks for medical image denoising and provides\ninsights into architecture-specific strengths for varying noise intensities."}
{"id": "2508.16735", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.16735", "abs": "https://arxiv.org/abs/2508.16735", "authors": ["Seyed Mohammad Amin Shirinbayan", "Gholamreza Moradi"], "title": "A Practical Approach to the Design of an S-Band Image-Rejecting Dual-Conversion Super-Heterodyne RF Chain of a Receiver Considering Spur Signals", "comment": "18 pages, 31 figures, 13 tables, This preprint is being submitted\n  with the intention of publication in the Journal of Electrical Engineering &\n  Technology (Springer)", "summary": "This paper presents a typical design of the RF section of a radar receiver,\nthe chain within a superheterodyne dual-conversion architecture. A significant\nchallenge in this framework is the occurrence of spur signals, which negatively\nimpact the dynamic range of the RF chain. When addressing this issue, the paper\nintroduces an innovative approach to mitigate (or even wipe out) these\nundesired effects, utilizing two mutually verifying MATLAB codes. These codes\nhave been tested with two distinct commercial mixers and could be applied to\nany superheterodyne configuration with various mixers. The presented method\nmakes the Spurious-Free Dynamic Range (SFDR) of the chain the least different\nfrom the dynamic range of the chain. Also, the selection of other components\ngets optimized to align with spurious signals consideration, with explanations\nprovided for these choices. Moreover, two filters of the RF chain, the second\nand the third, have been designed to reduce implementation costs. Various\nMicrowave software and full-wave analyses were employed for detailed design and\nanalysis, with the results compared to evaluate their performance."}
{"id": "2508.17326", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.17326", "abs": "https://arxiv.org/abs/2508.17326", "authors": ["Tristan S. W. Stevens", "Oisín Nolan", "Ruud J. G. van Sloun"], "title": "Semantic Diffusion Posterior Sampling for Cardiac Ultrasound Dehazing", "comment": "10 pages, 4 figures, MICCAI challenge", "summary": "Echocardiography plays a central role in cardiac imaging, offering dynamic\nviews of the heart that are essential for diagnosis and monitoring. However,\nimage quality can be significantly degraded by haze arising from multipath\nreverberations, particularly in difficult-to-image patients. In this work, we\npropose a semantic-guided, diffusion-based dehazing algorithm developed for the\nMICCAI Dehazing Echocardiography Challenge (DehazingEcho2025). Our method\nintegrates a pixel-wise noise model, derived from semantic segmentation of hazy\ninputs into a diffusion posterior sampling framework guided by a generative\nprior trained on clean ultrasound data. Quantitative evaluation on the\nchallenge dataset demonstrates strong performance across contrast and fidelity\nmetrics. Code for the submitted algorithm is available at\nhttps://github.com/tristan-deep/semantic-diffusion-echo-dehazing."}
{"id": "2508.16888", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.16888", "abs": "https://arxiv.org/abs/2508.16888", "authors": ["Jiazhe Li", "Nicolò Decarli", "Francesco Guidi", "Anna Guerra", "Alessandro Bazzi", "Zhuoming Li"], "title": "Dual Orthogonal Projections-Based Multiuser Interference Cancellation for mmWave Beamforming in XL-MIMO Systems", "comment": null, "summary": "This paper investigates multiuser interference (MUI) cancellation for\nmillimeter-wave (mmWave) beamforming in extremely large-scale multiple-input\nmultiple-output (XL-MIMO) communication systems. We propose a linear algorithm,\ntermed iterative dual orthogonal projections (DOP), which alternates between\ntwo orthogonal projections: one to eliminate MUI and the other to refine\ncombiners, ensuring a monotonic increase in spectral efficiency. Theoretical\nanalysis and simulation results show that, with each iteration, the signal\npower for each user increases monotonically, the equivalent noise power after\nreceive combining decreases monotonically, and the spectral efficiency improves\naccordingly and converges rapidly, closely approaching the theoretical optimum\ndetermined by dirty paper coding (DPC), outperforming existing linear\nalgorithms in spectral efficiency."}
{"id": "2508.17351", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2508.17351", "abs": "https://arxiv.org/abs/2508.17351", "authors": ["Mohtashim Baqar", "Sian Lun Lau", "Mansoor Ebrahim"], "title": "A Hybrid Approach for Unified Image Quality Assessment: Permutation Entropy-Based Features Fused with Random Forest for Natural-Scene and Screen-Content Images for Cross-Content Applications", "comment": null, "summary": "Image Quality Assessment (IQA) plays a vital role in applications such as\nimage compression, restoration, and multimedia streaming. However, existing\nmetrics often struggle to generalize across diverse image types - particularly\nbetween natural-scene images (NSIs) and screen-content images (SCIs) - due to\ntheir differing structural and perceptual characteristics. To address this\nlimitation, we propose a novel full-reference IQA framework: Permutation\nEntropy-based Features Fused with Random Forest (PEFRF). PEFRF captures\nstructural complexity by extracting permutation entropy from the gradient maps\nof reference, distorted, and fused images, forming a robust feature vector.\nThese features are then input into a Random Forest regressor trained on\nsubjective quality scores to predict final image quality. The framework is\nevaluated on 13 benchmark datasets comprising over 21,000 images and 40+\nstate-of-the-art IQA metrics. Experimental results demonstrate that PEFRF\nconsistently outperforms existing methods across various distortion types and\ncontent domains, establishing its effectiveness as a unified and statistically\nsignificant solution for cross-content image quality assessment."}
{"id": "2508.16946", "categories": ["eess.SP", "cs.NA", "math.NA", "60D05, 60G55, 68M10", "C.2.1; C.2.3; G.3"], "pdf": "https://arxiv.org/pdf/2508.16946", "abs": "https://arxiv.org/abs/2508.16946", "authors": ["Rashmi Kumari", "Gourab Ghatak", "Abhishek K. Gupta"], "title": "Spatially Correlated Blockage Aware Placement of RIS in IIoT Networks", "comment": "13 pages, 21 figures. A preliminary version of this work was accepted\n  in IEEE PIMRC 2025 under the title \"Blockage Aware Placement of RIS in IIoT\n  Networks\"", "summary": "We study the impact of deploying reconfigurable intelligent surfaces (RISs)\nin mitigating coverage gaps and enhancing transmission reliability in an\nindustrial internet of things (IIoT) network. First, we consider a single\nblockage scenario and characterize the correlation between blocking events of\nthe base station (BS)-user and the RIS-user links and study its impact on the\nprobability of establishing a viable reflected link. Then, by considering\nmultiple blockages, we derive the distribution of the signal to noise ratio\n(SNR) as a function of data size, blockage density, the number of RISs, and the\ndeployment area. We analyze the impact of normalized blockage radius and\nidentify the threshold beyond which the assumption of independent blockages\ndeviates from the ground truth of correlated blocking. Finally, we compare the\noutage performance of this RIS-assisted system with that operated with network-\ncontrolled relays, and demonstrate that while the relays provide a higher\nreliability beyond a certain blockage threshold, increasing the number of RISs\nmay help mitigate this effect. These insights offer valuable design guidelines\nfor deploying RIS-aided IIoT networks in dense blockage environments."}
{"id": "2508.17428", "categories": ["eess.IV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2508.17428", "abs": "https://arxiv.org/abs/2508.17428", "authors": ["Henrique Domingues Garcia", "Marcelo Menezes de Carvalho"], "title": "py360tool: Um framework para manipulação de vídeo 360$^\\circ$ com ladrilhos", "comment": "in Portuguese language, Submetido ao WFA, Workshop de Ferramentas e\n  Aplica\\c{c}\\~oes de 2025, evento sat\\'elite do 31{\\deg} Simp\\'osio Brasileiro\n  de Sistemas Multim\\'idia e Web", "summary": "Streaming 360$^\\circ$ videos for virtual reality demands a lot of bandwidth.\nTo optimize this transmission, videos are divided into \"tiles\" and selectively\ndistributed to the user based on what they are looking at. This interactive\napproach makes it difficult to assess quality and user experience. To solve\nthis, the paper presents py360tools, a Python library that automates\nclient-side tasks like video reconstruction, tile selection, and viewport\nextraction. This facilitates the reproduction, simulation, and analysis of\n360$^\\circ$ video streaming sessions."}
{"id": "2508.17051", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.17051", "abs": "https://arxiv.org/abs/2508.17051", "authors": ["Christopher Saetia", "Daniel M. Dobkin", "Gregory Durgin"], "title": "Radio Frequency Identification: Decades at a Time", "comment": null, "summary": "In this article, we briefly review the history of the use of radio signals to\nidentify objects, and of the key Radio Frequency Identification (RFID)\nstandards for ultra-high-frequency (UHF) and near-field communications that\nenabled broad use of these technologies in daily life. We will compare the\nvision for the future presented by the Auto-ID Lab in the early 21st century\nwith the reality we see today, two decades and a little after. We will review\nsome of the applications in which UHF RFID technology has become hugely\nsuccessful, others where High Frequency Near-field Communications (HF NFC) is\npreferred, and applications where optical identification or active wireless\ncommunications are dominant.\n  We will then examine some possible future paths for RFID technology. We\nanticipate that UHF read capability will become widely available for\ncellphones, making it as universal as NFC and Bluetooth are today. We will look\nat more sophisticated radio interfaces, such as multiple-antenna phased arrays\nfor readers, and tunnel diode reflection for tags. We will discuss the\nintegration of information from Artificial Intelligence (AI)-based image\nprocessing, barcodes, NFC and UHF tags, into a digital twin of the real\nenvironment experienced by the human user. We will examine the role of RFID\nwith sensing in improving the management of perishable goods. The role that\nRFID might play in a truly circular economy, with intelligent recycling and\nreuse, will be discussed. Finally, we survey the many hazards and obstacles\nthat obstruct the path to an RF-informed future."}
{"id": "2508.17768", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.17768", "abs": "https://arxiv.org/abs/2508.17768", "authors": ["Toufiq Musah", "Chinasa Kalaiwo", "Maimoona Akram", "Ubaida Napari Abdulai", "Maruf Adewole", "Farouk Dako", "Adaobi Chiazor Emegoakor", "Udunna C. Anazodo", "Prince Ebenezer Adjei", "Confidence Raymond"], "title": "Towards Trustworthy Breast Tumor Segmentation in Ultrasound using Monte Carlo Dropout and Deep Ensembles for Epistemic Uncertainty Estimation", "comment": "Medical Image Computing in Resource Constrained Settings Workshop &\n  Knowledge Interchange", "summary": "Automated segmentation of BUS images is important for precise lesion\ndelineation and tumor characterization, but is challenged by inherent artifacts\nand dataset inconsistencies. In this work, we evaluate the use of a modified\nResidual Encoder U-Net for breast ultrasound segmentation, with a focus on\nuncertainty quantification. We identify and correct for data duplication in the\nBUSI dataset, and use a deduplicated subset for more reliable estimates of\ngeneralization performance. Epistemic uncertainty is quantified using Monte\nCarlo dropout, deep ensembles, and their combination. Models are benchmarked on\nboth in-distribution and out-of-distribution datasets to demonstrate how they\ngeneralize to unseen cross-domain data. Our approach achieves state-of-the-art\nsegmentation accuracy on the Breast-Lesion-USG dataset with in-distribution\nvalidation, and provides calibrated uncertainty estimates that effectively\nsignal regions of low model confidence. Performance declines and increased\nuncertainty observed in out-of-distribution evaluation highlight the persistent\nchallenge of domain shift in medical imaging, and the importance of integrated\nuncertainty modeling for trustworthy clinical deployment. \\footnote{Code\navailable at: https://github.com/toufiqmusah/nn-uncertainty.git}"}
{"id": "2508.17246", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.17246", "abs": "https://arxiv.org/abs/2508.17246", "authors": ["Takuma Sumi", "Georgi S. Medvedev"], "title": "Graphon Signal Processing for Spiking and Biological Neural Networks", "comment": "20 pages, 10 figures", "summary": "Graph Signal Processing (GSP) extends classical signal processing to signals\ndefined on graphs, enabling filtering, spectral analysis, and sampling of data\ngenerated by networks of various kinds. Graphon Signal Processing (GnSP)\ndevelops this framework further by employing the theory of graphons. Graphons\nare measurable functions on the unit square that represent graphs and limits of\nconvergent graph sequences. The use of graphons provides stability of GSP\nmethods to stochastic variability in network data and improves computational\nefficiency for very large networks. We use GnSP to address the stimulus\nidentification problem (SIP) in computational and biological neural networks.\nThe SIP is an inverse problem that aims to infer the unknown stimulus s from\nthe observed network output f. We first validate the approach in spiking neural\nnetwork simulations and then analyze calcium imaging recordings. Graphon-based\nspectral projections yield trial-invariant, lowdimensional embeddings that\nimprove stimulus classification over Principal Component Analysis and discrete\nGSP baselines. The embeddings remain stable under variations in network\nstochasticity, providing robustness to different network sizes and noise\nlevels. To the best of our knowledge, this is the first application of GnSP to\nbiological neural networks, opening new avenues for graphon-based analysis in\nneuroscience."}
{"id": "2508.17920", "categories": ["eess.IV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2508.17920", "abs": "https://arxiv.org/abs/2508.17920", "authors": ["Haoshuo Zhang", "Yufei Bo", "Hongwei Zhang", "Meixia Tao"], "title": "Prompt-based Multimodal Semantic Communication for Multi-spectral Image Segmentation", "comment": null, "summary": "Multimodal semantic communication has gained widespread attention due to its\nability to enhance downstream task performance. A key challenge in such systems\nis the effective fusion of features from different modalities, which requires\nthe extraction of rich and diverse semantic representations from each modality.\nTo this end, we propose ProMSC-MIS, a Prompt-based Multimodal Semantic\nCommunication system for Multi-spectral Image Segmentation. Specifically, we\npropose a pre-training algorithm where features from one modality serve as\nprompts for another, guiding unimodal semantic encoders to learn diverse and\ncomplementary semantic representations. We further introduce a semantic fusion\nmodule that combines cross-attention mechanisms and squeeze-and-excitation (SE)\nnetworks to effectively fuse cross-modal features. Simulation results show that\nProMSC-MIS significantly outperforms benchmark methods across various\nchannel-source compression levels, while maintaining low computational\ncomplexity and storage overhead. Our scheme has great potential for\napplications such as autonomous driving and nighttime surveillance."}
{"id": "2508.17354", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.17354", "abs": "https://arxiv.org/abs/2508.17354", "authors": ["Jun Wu", "Weijie Yuan", "Xiaoqi Zhang", "Yaohuan Yu", "Yuanhao Cui", "Fan Liu", "Geng Sun", "Jiacheng Wang", "Dusit Niyato", "Dong In Kim"], "title": "Toward Multi-Functional LAWNs with ISAC: Opportunities, Challenges, and the Road Ahead", "comment": null, "summary": "Integrated sensing and communication (ISAC) has been envisioned as a\nfoundational technology for future low-altitude wireless networks (LAWNs),\nenabling real-time environmental perception and data exchange across\naerial-ground systems. In this article, we first explore the roles of ISAC in\nLAWNs from both node-level and network-level perspectives. We highlight the\nperformance gains achieved through hierarchical integration and cooperation,\nwherein key design trade-offs are demonstrated. Apart from physical-layer\nenhancements, emerging LAWN applications demand broader functionalities. To\nthis end, we propose a multi-functional LAWN framework that extends ISAC with\ncapabilities in control, computation, wireless power transfer, and large\nlanguage model (LLM)-based intelligence. We further provide a representative\ncase study to present the benefits of ISAC-enabled LAWNs and the promising\nresearch directions are finally outlined."}
{"id": "2508.17965", "categories": ["eess.IV", "cs.CV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2508.17965", "abs": "https://arxiv.org/abs/2508.17965", "authors": ["Xiangfei Sheng", "Zhichao Duan", "Xiaofeng Pan", "Yipo Huang", "Zhichao Yang", "Pengfei Chen", "Leida Li"], "title": "TuningIQA: Fine-Grained Blind Image Quality Assessment for Livestreaming Camera Tuning", "comment": "9 pages,8 figures", "summary": "Livestreaming has become increasingly prevalent in modern visual\ncommunication, where automatic camera quality tuning is essential for\ndelivering superior user Quality of Experience (QoE). Such tuning requires\naccurate blind image quality assessment (BIQA) to guide parameter optimization\ndecisions. Unfortunately, the existing BIQA models typically only predict an\noverall coarse-grained quality score, which cannot provide fine-grained\nperceptual guidance for precise camera parameter tuning. To bridge this gap, we\nfirst establish FGLive-10K, a comprehensive fine-grained BIQA database\ncontaining 10,185 high-resolution images captured under varying camera\nparameter configurations across diverse livestreaming scenarios. The dataset\nfeatures 50,925 multi-attribute quality annotations and 19,234 fine-grained\npairwise preference annotations. Based on FGLive-10K, we further develop\nTuningIQA, a fine-grained BIQA metric for livestreaming camera tuning, which\nintegrates human-aware feature extraction and graph-based camera parameter\nfusion. Extensive experiments and comparisons demonstrate that TuningIQA\nsignificantly outperforms state-of-the-art BIQA methods in both score\nregression and fine-grained quality ranking, achieving superior performance\nwhen deployed for livestreaming camera tuning."}
{"id": "2508.17526", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.17526", "abs": "https://arxiv.org/abs/2508.17526", "authors": ["Kangda Zhi", "Tianyu Yang", "Shuangyang Li", "Yi Song", "Amir Rezaei", "Giuseppe Caire"], "title": "Near-Field Integrated Imaging and Communication in Distributed MIMO Networks", "comment": "18 pages, 15 figures", "summary": "In this work, we propose a general framework for wireless imaging in\ndistributed MIMO wideband communication systems, considering multi-view\nnon-isotropic targets and near-field propagation effects. For indoor scenarios\nwhere the objective is to image small-scale objects with high resolution, we\npropose a range migration algorithm (RMA)-based scheme using three kinds of\narray architectures: the full array, boundary array, and distributed boundary\narray. With non-isotropic near-field channels, we establish the Fourier\ntransformation (FT)-based relationship between the imaging reflectivity and the\ndistributed spatial-domain signals and discuss the corresponding theoretical\nproperties. Next, for outdoor scenarios where the objective is to reconstruct\nthe large-scale three-dimensional (3D) environment with coarse resolution, we\npropose a sparse Bayesian learning (SBL)-based algorithm to solve the multiple\nmeasurement vector (MMV) problem, which further addresses the non-isotropic\nreflectivity across different subcarriers. Numerical results demonstrate the\neffectiveness of the proposed algorithms in acquiring high-resolution small\nobjects and accurately reconstructing large-scale environments."}
{"id": "2508.17873", "categories": ["eess.SP", "eess.IV"], "pdf": "https://arxiv.org/pdf/2508.17873", "abs": "https://arxiv.org/abs/2508.17873", "authors": ["Mehdi Abdollahpour", "Carsten Bockelmann", "Tajim Md Hasibur Rahman", "Armin Dekorsy", "Andreas Fischer"], "title": "Compressed Learning for Nanosurface Deficiency Recognition Using Angle-resolved Scatterometry Data", "comment": null, "summary": "Nanoscale manufacturing requires high-precision surface inspection to\nguarantee the quality of the produced nanostructures. For production\nenvironments, angle-resolved scatterometry offers a non- invasive and in-line\ncompatible alternative to traditional surface inspection methods, such as\nscanning electron microscopy. However, angle-resolved scatterometry currently\nsuffers from long data acquisition time. Our study addresses the issue of slow\ndata acquisition by proposing a compressed learning framework for the accurate\nrecognition of nanosurface deficiencies using angle-resolved scatterometry\ndata. The framework uses the particle swarm optimization algorithm with a\nsampling scheme customized for scattering patterns. This combination allows the\nidentification of optimal sampling points in scatterometry data that maximize\nthe detection accuracy of five different levels of deficiency in ZnO\nnanosurfaces. The proposed method significantly reduces the amount of sampled\ndata while maintaining a high accuracy in deficiency detection, even in noisy\nenvironments. Notably, by sampling only 1% of the data, the method achieves an\naccuracy of over 86%, which further improves to 94% when the sampling rate is\nincreased to 6%. These results demonstrate a favorable balance between data\nreduction and classification performance. The obtained results also show that\nthe compressed learning framework effectively identifies critical sampling\nareas."}
{"id": "2508.17607", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.17607", "abs": "https://arxiv.org/abs/2508.17607", "authors": ["Yankai Zhang", "Jiafeng Ding", "Jingjing Ning", "Qiaoxi Zhu"], "title": "Steerable Invariant Beamformer Using a Differential Line Array of Omnidirectional and Directional Microphones with Null Constraints", "comment": "12 pages, 15 figures", "summary": "Line differential microphone arrays have attracted attention for their\nability to achieve frequency-invariant beampatterns and high directivity.\nRecently, the Jacobi-Anger expansion-based approach has enabled the design of\nfully steerable-invariant differential beamformers for line arrays combining\nomnidirectional and directional microphones. However, this approach relies on\nthe analytical expression of the ideal beam pattern and the proper selection of\ntruncation order, which is not always practical. This paper introduces a\nnull-constraint-based method for designing frequency- and steerable-invariant\ndifferential beamformers using a line array of omnidirectional and directional\nmicrophones. The approach employs a multi-constraint optimisation framework,\nwhere the reference filter and ideal beam pattern are first determined based on\nspecified nulls and desired direction. Subsequently, the white noise gain\nconstraint is derived from the reference filter, and the beampattern constraint\nis from the ideal beam pattern. The optimal filter is then obtained by\nconsidering constraints related to the beampattern, nulls, and white noise\ngain. This method achieves a balance between white noise gain and mean square\nerror, allowing robust, frequency- and steerableinvariant differential\nbeamforming performance. It addresses limitations in beam pattern flexibility\nand truncation errors, offering greater design freedom and improved practical\napplicability. Simulations and experiments demonstrate that this method\noutperforms the Jacobi-Anger expansion-based approach in three key aspects: an\nextended effective range, improved main lobe and null alignment, and greater\nflexibility in microphone array configuration and beam pattern design,\nrequiring only steering direction and nulls instead of an analytic beam pattern\nexpression."}
{"id": "2508.17640", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.17640", "abs": "https://arxiv.org/abs/2508.17640", "authors": ["Can Zheng", "Jiguang He", "Chung G. Kang", "Guofa Cai", "Henk Wymeersch"], "title": "Multimodal Radio and Vision Fusion for Robust Localization in Urban V2I Communications", "comment": "6 pages, 6 figures, submitted to conference", "summary": "Accurate localization is critical for vehicle-to-infrastructure (V2I)\ncommunication systems, especially in urban areas where GPS signals are often\nobstructed by tall buildings, leading to significant positioning errors,\nnecessitating alternative or complementary techniques for reliable and precise\npositioning in applications like autonomous driving and smart city\ninfrastructure. This paper proposes a multimodal contrastive learning\nregression based localization framework for V2I scenarios that combines channel\nstate information (CSI) with visual information to achieve improved accuracy\nand reliability. The approach leverages the complementary strengths of wireless\nand visual data to overcome the limitations of traditional localization\nmethods, offering a robust solution for V2I applications. Simulation results\ndemonstrate that the proposed CSI and vision fusion model significantly\noutperforms traditional methods and single modal models, achieving superior\nlocalization accuracy and precision in complex urban environments."}
{"id": "2508.17704", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.17704", "abs": "https://arxiv.org/abs/2508.17704", "authors": ["Neil Irwin Bernardo"], "title": "Symbol Detection Using an Integrate-and-Fire Time Encoding Receiver", "comment": "5 pages, 2 figures. This work has been accepted for publication at\n  the 38th IEEE Workshop on Signal Processing Systems (SiPS 2025)", "summary": "Event-driven sampling is a promising alternative to uniform sampling methods,\nparticularly for systems constrained by power and hardware cost. A notable\nexample of this sampling approach is the integrate-and-fire time encoding\nmachine (IF-TEM), which encodes an analog signal into a sequence of time stamps\nby generating an event each time the integral of the input signal reaches a\nfixed threshold. In this paper, we propose a receiver architecture that\nestimates the sequence of transmitted symbols directly from the encoded time\nstamps, called time encodings, produced by the IF-TEM sampler on the received\nsignal. We show that waveform reconstruction from time encodings is not\nnecessary for symbol detection. We develop an analytical approximation for the\nsymbol error probability (SEP) of the proposed IF-TEM-based receiver and show\nthat it closely matches the SEP results obtained through Monte Carlo\nsimulations. Additionally, we demonstrate that narrowing the 3 dB bandwidth of\nthe transmit pulse shaping filter degrades the proposed IF-TEM receiver's\nperformance, highlighting a trade-off between spectral efficiency and error\nresilience."}
{"id": "2508.17710", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.17710", "abs": "https://arxiv.org/abs/2508.17710", "authors": ["Dianhao Jia", "Wenqian Shen", "Jianping An", "Byonghyo Shim"], "title": "Blind Channel Estimation for RIS-Assisted Millimeter Wave Communication Systems", "comment": null, "summary": "In the research of RIS-assisted communication systems, channel estimation is\na problem of vital importance for further performance optimization. In order to\nreduce the pilot overhead to the greatest extent, blind channel estimation\nmethods are required, which can estimate the channel and the transmit signals\nat the same time without transmitting pilot sequence. Different from existing\nresearches in traditional MIMO systems, the RIS-assisted two-hop channel brings\nnew challenges to the blind channel estimation design. Hence, a novel blind\nchannel estimation method based on compressed sensing for RIS-assisted\nmultiuser millimeter wave communication systems is proposed for the first time\nin this paper. Specifically, for accurately estimating the RIS-assisted two-hop\nchannel without transmitting pilots, we propose a block-wise transmission\nscheme. Among different blocks of data transmission, RIS elements are\nreconfigured for better estimating the cascade channel. Inside each block, data\nfor each user are mapped to a codeword for realizing the transmit signal\nrecovery and equivalent channel estimation simultaneously. Simulation results\ndemonstrate that our method can achieve a considerable accuracy of channel\nestimation and transmit signal recovery."}
{"id": "2508.17742", "categories": ["eess.SP", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2508.17742", "abs": "https://arxiv.org/abs/2508.17742", "authors": ["Wei Xiong", "Jiangtong Li", "Jie Li", "Kun Zhu"], "title": "EEG-FM-Bench: A Comprehensive Benchmark for the Systematic Evaluation of EEG Foundation Models", "comment": "17 pages, 7 pages", "summary": "Electroencephalography (EEG) foundation models are poised to significantly\nadvance brain signal analysis by learning robust representations from\nlarge-scale, unlabeled datasets. However, their rapid proliferation has\noutpaced the development of standardized evaluation benchmarks, which\ncomplicates direct model comparisons and hinders systematic scientific\nprogress. This fragmentation fosters scientific inefficiency and obscures\ngenuine architectural advancements. To address this critical gap, we introduce\nEEG-FM-Bench, the first comprehensive benchmark for the systematic and\nstandardized evaluation of EEG foundation models (EEG-FMs). Our contributions\nare threefold: (1) we curate a diverse suite of downstream tasks and datasets\nfrom canonical EEG paradigms, implementing standardized processing and\nevaluation protocols within a unified open-source framework; (2) we benchmark\nprominent state-of-the-art foundation models to establish comprehensive\nbaseline results for a clear comparison of the current landscape; (3) we\nperform qualitative analyses of the learned representations to provide insights\ninto model behavior and inform future architectural design. Through extensive\nexperiments, we find that fine-grained spatio-temporal feature interaction,\nmultitask unified training and neuropsychological priors would contribute to\nenhancing model performance and generalization capabilities. By offering a\nunified platform for fair comparison and reproducible research, EEG-FM-Bench\nseeks to catalyze progress and guide the community toward the development of\nmore robust and generalizable EEG-FMs. Code is released at\nhttps://github.com/xw1216/EEG-FM-Bench."}
{"id": "2508.17852", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.17852", "abs": "https://arxiv.org/abs/2508.17852", "authors": ["Hossein Mohammadi Firouzjaei", "Rafaela Scaciota", "Sumudu Samarakoon", "Beatriz Lorenzo"], "title": "Cross-Domain Lifelong Reinforcement Learning for Wireless Sensor Networks", "comment": null, "summary": "Wireless sensor networks (WSNs) with energy harvesting (EH) are expected to\nplay a vital role in intelligent 6G systems, especially in industrial sensing\nand control, where continuous operation and sustainable energy use are\ncritical. Given limited energy resources, WSNs must operate efficiently to\nensure long-term performance. Their deployment, however, is challenged by\ndynamic environments where EH conditions, network scale, and traffic rates\nchange over time. In this work, we address system dynamics that yield different\nlearning tasks, where decision variables remain fixed but strategies vary, as\nwell as learning domains, where both decision space and strategies evolve. To\nhandle such scenarios, we propose a cross-domain lifelong reinforcement\nlearning (CD-L2RL) framework for energy-efficient WSN design. Our CD-L2RL\nalgorithm leverages prior experience to accelerate adaptation across tasks and\ndomains. Unlike conventional approaches based on Markov decision processes or\nLyapunov optimization, which assume relatively stable environments, our\nsolution achieves rapid policy adaptation by reusing knowledge from past tasks\nand domains to ensure continuous operations. We validate the approach through\nextensive simulations under diverse conditions. Results show that our method\nimproves adaptation speed by up to 35% over standard reinforcement learning and\nup to 70% over Lyapunov-based optimization, while also increasing total\nharvested energy. These findings highlight the strong potential of CD-L2RL for\ndeployment in dynamic 6G WSNs."}
{"id": "2508.17873", "categories": ["eess.SP", "eess.IV"], "pdf": "https://arxiv.org/pdf/2508.17873", "abs": "https://arxiv.org/abs/2508.17873", "authors": ["Mehdi Abdollahpour", "Carsten Bockelmann", "Tajim Md Hasibur Rahman", "Armin Dekorsy", "Andreas Fischer"], "title": "Compressed Learning for Nanosurface Deficiency Recognition Using Angle-resolved Scatterometry Data", "comment": null, "summary": "Nanoscale manufacturing requires high-precision surface inspection to\nguarantee the quality of the produced nanostructures. For production\nenvironments, angle-resolved scatterometry offers a non- invasive and in-line\ncompatible alternative to traditional surface inspection methods, such as\nscanning electron microscopy. However, angle-resolved scatterometry currently\nsuffers from long data acquisition time. Our study addresses the issue of slow\ndata acquisition by proposing a compressed learning framework for the accurate\nrecognition of nanosurface deficiencies using angle-resolved scatterometry\ndata. The framework uses the particle swarm optimization algorithm with a\nsampling scheme customized for scattering patterns. This combination allows the\nidentification of optimal sampling points in scatterometry data that maximize\nthe detection accuracy of five different levels of deficiency in ZnO\nnanosurfaces. The proposed method significantly reduces the amount of sampled\ndata while maintaining a high accuracy in deficiency detection, even in noisy\nenvironments. Notably, by sampling only 1% of the data, the method achieves an\naccuracy of over 86%, which further improves to 94% when the sampling rate is\nincreased to 6%. These results demonstrate a favorable balance between data\nreduction and classification performance. The obtained results also show that\nthe compressed learning framework effectively identifies critical sampling\nareas."}
{"id": "2508.17942", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.17942", "abs": "https://arxiv.org/abs/2508.17942", "authors": ["Qingtang Jiang", "Shuixin Li", "Jiecheng Chen", "Lin Li"], "title": "Synchrosqueezed X-Ray Wavelet-Chirplet Transform for Accurate Chirp Rate Estimation and Retrieval of Modes from Multicomponent Signals with Crossover Instantaneous Frequencies", "comment": null, "summary": "Recent advances in the chirplet transform and wavelet-chirplet transform\n(WCT) have enabled the estimation of instantaneous frequencies (IFs) and\nchirprates, as well as mode retrieval from multicomponent signals with\ncrossover IF curves. However, chirprate estimation via these approaches remains\nless accurate than IF estimation, primarily due to the slow decay of the\nchirplet transform or WCT along the chirprate direction. To address this, the\nsynchrosqueezed chirplet transform (SCT) and multiple SCT methods were\nproposed, achieving moderate improvements in IF and chirprate estimation\naccuracy. Nevertheless, a novel approach is still needed to enhance the\ntransform's decay along the chirprate direction.\n  This paper introduces an X-ray transform-based wavelet-chirprate transform,\ntermed the X-ray wavelet-chirplet transform (XWCT), which exhibits superior\ndecay along the chirprate direction compared to the WCT. Furthermore,\nthird-order synchrosqueezed variants of the WCT and XWCT are developed to yield\nsharp time-frequency-chirprate representations of signals. Experimental results\ndemonstrate that the XWCT achieves significantly faster decay along the\nchirprate axis, while the third-order synchrosqueezed XWCT enables accurate IF\nand chirprate estimation, as well as mode retrieval, without requiring multiple\nsynchrosqueezing operations."}
{"id": "2508.17960", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.17960", "abs": "https://arxiv.org/abs/2508.17960", "authors": ["Yuto Kawai", "Rajeev Koodli"], "title": "A Unified Transformer Architecture for Low-Latency and Scalable Wireless Signal Processing", "comment": "10 pages, 8 figures", "summary": "We propose a unified Transformer-based architecture for wireless signal\nprocessing tasks, offering a low-latency, task-adaptive alternative to\nconventional receiver pipelines. Unlike traditional modular designs, our model\nintegrates channel estimation, interpolation, and demapping into a single,\ncompact attention-driven architecture designed for real-time deployment. The\nmodel's structure allows dynamic adaptation to diverse output formats by simply\nmodifying the final projection layer, enabling consistent reuse across receiver\nsubsystems. Experimental results demonstrate strong generalization to varying\nuser counts, modulation schemes, and pilot configurations, while satisfying\nlatency constraints imposed by practical systems. The architecture is evaluated\nacross three core use cases: (1) an End-to-End Receiver, which replaces the\nentire baseband processing pipeline from pilot symbols to bit-level decisions;\n(2) Channel Frequency Interpolation, implemented and tested within a\n3GPP-compliant OAI+Aerial system; and (3) Channel Estimation, where the model\ninfers full-band channel responses from sparse pilot observations. In all\ncases, our approach outperforms classical baselines in terms of accuracy,\nrobustness, and computational efficiency. This work presents a deployable,\ndata-driven alternative to hand-engineered PHY-layer blocks, and lays the\nfoundation for intelligent, software-defined signal processing in\nnext-generation wireless communication systems."}
{"id": "2508.18009", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2508.18009", "abs": "https://arxiv.org/abs/2508.18009", "authors": ["Leonardo Tercas", "Markku Juntti"], "title": "Positioning via Probabilistic Graphical Models in RIS-Aided Systems with Channel Estimation Errors", "comment": "6 pages, 4 figures, 2 tables. Presented at 2025 IEEE International\n  Conference on Communications (ICC), June 2025, Montreal, Canada", "summary": "We propose a 6D Bayesian-based localization framework to estimate the\nposition and rotation angles of a mobile station (MS) within an indoor\nreconfigurable intelligent surface (RIS)-aided system. This framework relies on\na probabilistic graphical model to represent the joint probability distribution\nof random variables through their conditional dependencies and employs the\nNo-U-Turn Sampler (NUTS) to approximate the posterior distribution based on the\nestimated channel parameters. Our framework estimates both the position and\nrotation of the mobile station (MS), in the presence of channel parameter\nestimation errors. We derive the Cramer-Rao lower bound (CRLB) for the proposed\nscenario and use it to evaluate the system's position error bound (PEB) and\nrotation error bound (REB). We compare the system performances with and without\nRIS. The results demonstrate that the RIS can enhance positioning accuracy\nsignificantly."}
