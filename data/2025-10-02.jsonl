{"id": "2510.00029", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.00029", "abs": "https://arxiv.org/abs/2510.00029", "authors": ["Madhushan Ramalingam", "Yaish Riaz", "Priyanthi Rajamanoharan", "Piyumi Dasanayaka"], "title": "Enhancing Safety in Diabetic Retinopathy Detection: Uncertainty-Aware Deep Learning Models with Rejection Capabilities", "comment": "VBLL, Rejection threshold, Expected Calibration Error , Coverage,\n  Rejection rate", "summary": "Diabetic retinopathy (DR) is a major cause of visual impairment, and\neffective treatment options depend heavily on timely and accurate diagnosis.\nDeep learning models have demonstrated great success identifying DR from\nretinal images. However, relying only on predictions made by models, without\nany indication of model confidence, creates uncertainty and poses significant\nrisk in clinical settings. This paper investigates an alternative in\nuncertainty-aware deep learning models, including a rejection mechanism to\nreject low-confidence predictions, contextualized by deferred decision-making\nin clinical practice. The results show there is a trade-off between prediction\ncoverage and coverage reliability. The Variational Bayesian model adopted a\nmore conservative strategy when predicting DR, subsequently rejecting the\nuncertain predictions. The model is evaluated by means of important performance\nmetrics such as Accuracy on accepted predictions, the proportion of accepted\ncases (coverage), the rejection-ratio, and Expected Calibration Error (ECE).\nThe findings also demonstrate a clear trade-off between accuracy and caution,\nestablishing that the use of uncertainty estimation and selective rejection\nimproves the model's reliability in safety-critical diagnostic use cases."}
{"id": "2510.00035", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.00035", "abs": "https://arxiv.org/abs/2510.00035", "authors": ["P K Dutta", "Anushri Chowdhury", "Anouska Bhattacharyya", "Shakya Chakraborty", "Sujatra Dey"], "title": "Deep Learning-Based Pneumonia Detection from Chest X-ray Images: A CNN Approach with Performance Analysis and Clinical Implications", "comment": "8 pages, 2 figures", "summary": "Deep learning integration into medical imaging systems has transformed\ndisease detection and diagnosis processes with a focus on pneumonia\nidentification. The study introduces an intricate deep learning system using\nConvolutional Neural Networks for automated pneumonia detection from chest Xray\nimages which boosts diagnostic precision and speed. The proposed CNN\narchitecture integrates sophisticated methods including separable convolutions\nalong with batch normalization and dropout regularization to enhance feature\nextraction while reducing overfitting. Through the application of data\naugmentation techniques and adaptive learning rate strategies the model\nunderwent training on an extensive collection of chest Xray images to enhance\nits generalization capabilities. A convoluted array of evaluation metrics such\nas accuracy, precision, recall, and F1 score collectively verify the model\nexceptional performance by recording an accuracy rate of 91. This study tackles\ncritical clinical implementation obstacles such as data privacy protection,\nmodel interpretability, and integration with current healthcare systems beyond\njust model performance. This approach introduces a critical advancement by\nintegrating medical ontologies with semantic technology to improve diagnostic\naccuracy. The study enhances AI diagnostic reliability by integrating machine\nlearning outputs with structured medical knowledge frameworks to boost\ninterpretability. The findings demonstrate AI powered healthcare tools as a\nscalable efficient pneumonia detection solution. This study advances AI\nintegration into clinical settings by developing more precise automated\ndiagnostic methods that deliver consistent medical imaging results."}
{"id": "2510.00048", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG", "stat.AP", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.00048", "abs": "https://arxiv.org/abs/2510.00048", "authors": ["Fahad Mostafa", "Kannon Hossain", "Hafiz Khan"], "title": "Deep Learning Approaches with Explainable AI for Differentiating Alzheimer Disease and Mild Cognitive Impairment", "comment": "18 pages, 4 figures", "summary": "Early and accurate diagnosis of Alzheimer Disease is critical for effective\nclinical intervention, particularly in distinguishing it from Mild Cognitive\nImpairment, a prodromal stage marked by subtle structural changes. In this\nstudy, we propose a hybrid deep learning ensemble framework for Alzheimer\nDisease classification using structural magnetic resonance imaging. Gray and\nwhite matter slices are used as inputs to three pretrained convolutional neural\nnetworks such as ResNet50, NASNet, and MobileNet, each fine tuned through an\nend to end process. To further enhance performance, we incorporate a stacked\nensemble learning strategy with a meta learner and weighted averaging to\noptimally combine the base models. Evaluated on the Alzheimer Disease\nNeuroimaging Initiative dataset, the proposed method achieves state of the art\naccuracy of 99.21% for Alzheimer Disease vs. Mild Cognitive Impairment and\n91.0% for Mild Cognitive Impairment vs. Normal Controls, outperforming\nconventional transfer learning and baseline ensemble methods. To improve\ninterpretability in image based diagnostics, we integrate Explainable AI\ntechniques by Gradient weighted Class Activation, which generates heatmaps and\nattribution maps that highlight critical regions in gray and white matter\nslices, revealing structural biomarkers that influence model decisions. These\nresults highlight the frameworks potential for robust and scalable clinical\ndecision support in neurodegenerative disease diagnostics."}
{"id": "2510.00049", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.00049", "abs": "https://arxiv.org/abs/2510.00049", "authors": ["Suhyeon Lim", "Ye-eun Kim", "Andrew J. Choi"], "title": "AI-Based Stroke Rehabilitation Domiciliary Assessment System with ST_GCN Attention", "comment": "9 pages(except references), 7 figures 6 Tables", "summary": "Effective stroke recovery requires continuous rehabilitation integrated with\ndaily living. To support this need, we propose a home-based rehabilitation\nexercise and feedback system. The system consists of (1) hardware setup with\nRGB-D camera and wearable sensors to capture Stroke movements, (2) a mobile\napplication for exercise guidance, and (3) an AI server for assessment and\nfeedback. When Stroke user exercises following the application guidance, the\nsystem records skeleton sequences, which are then Assessed by the deep learning\nmodel, RAST-G@. The model employs a spatio-temporal graph convolutional network\n(ST-GCN) to extract skeletal features and integrates transformer-based temporal\nattention to figure out action quality. For system implementation, we\nconstructed the NRC dataset, include 10 upper-limb activities of daily living\n(ADL) and 5 range-of-motion (ROM) collected from stroke and non-disabled\nparticipants, with Score annotations provided by licensed physiotherapists.\nResults on the KIMORE and NRC datasets show that RAST-G@ improves over baseline\nin terms of MAD, RMSE, and MAPE. Furthermore, the system provides user feedback\nthat combines patient-centered assessment and monitoring. The results\ndemonstrate that the proposed system offers a scalable approach for\nquantitative and consistent domiciliary rehabilitation assessment."}
{"id": "2510.00032", "categories": ["eess.SP", "cs.AI", "cs.CL", "cs.LG", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2510.00032", "abs": "https://arxiv.org/abs/2510.00032", "authors": ["Ziyi Zeng", "Zhenyang Cai", "Yixi Cai", "Xidong Wang", "Junying Chen", "Rongsheng Wang", "Yipeng Liu", "Siqi Cai", "Benyou Wang", "Zhiguo Zhang", "Haizhou Li"], "title": "WaveMind: Towards a Conversational EEG Foundation Model Aligned to Textual and Visual Modalities", "comment": null, "summary": "Electroencephalography (EEG) interpretation using multimodal large language\nmodels (MLLMs) offers a novel approach for analyzing brain signals. However,\nthe complex nature of brain activity introduces critical challenges: EEG\nsignals simultaneously encode both cognitive processes and intrinsic neural\nstates, creating a mismatch in EEG paired-data modality that hinders effective\ncross-modal representation learning. Through a pivot investigation, we uncover\ncomplementary relationships between these modalities. Leveraging this insight,\nwe propose mapping EEG signals and their corresponding modalities into a\nunified semantic space to achieve generalized interpretation. To fully enable\nconversational capabilities, we further introduce WaveMind-Instruct-338k, the\nfirst cross-task EEG dataset for instruction tuning. The resulting model\ndemonstrates robust classification accuracy while supporting flexible,\nopen-ended conversations across four downstream tasks, thereby offering\nvaluable insights for both neuroscience research and the development of\ngeneral-purpose EEG models."}
{"id": "2510.00051", "categories": ["eess.IV", "cs.CV", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2510.00051", "abs": "https://arxiv.org/abs/2510.00051", "authors": ["Trinh Ngoc Huynh", "Nguyen Duc Kien", "Nguyen Hai Anh", "Dinh Tran Hiep", "Manuela Vaneckova", "Tomas Uher", "Jeroen Van Schependom", "Stijn Denissen", "Tran Quoc Long", "Nguyen Linh Trung", "Guy Nagels"], "title": "Latent Representation Learning from 3D Brain MRI for Interpretable Prediction in Multiple Sclerosis", "comment": "The abstract has been condensed to under 1920 characters", "summary": "We present InfoVAE-Med3D, a latent-representation learning approach for 3D\nbrain MRI that targets interpretable biomarkers of cognitive decline. Standard\nstatistical models and shallow machine learning often lack power, while most\ndeep learning methods behave as black boxes. Our method extends InfoVAE to\nexplicitly maximize mutual information between images and latent variables,\nproducing compact, structured embeddings that retain clinically meaningful\ncontent. We evaluate on two cohorts: a large healthy-control dataset (n=6527)\nwith chronological age, and a clinical multiple sclerosis dataset from Charles\nUniversity in Prague (n=904) with age and Symbol Digit Modalities Test (SDMT)\nscores. The learned latents support accurate brain-age and SDMT regression,\npreserve key medical attributes, and form intuitive clusters that aid\ninterpretation. Across reconstruction and downstream prediction tasks,\nInfoVAE-Med3D consistently outperforms other VAE variants, indicating stronger\ninformation capture in the embedding space. By uniting predictive performance\nwith interpretability, InfoVAE-Med3D offers a practical path toward MRI-based\nbiomarkers and more transparent analysis of cognitive deterioration in\nneurological disease."}
{"id": "2510.00141", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.00141", "abs": "https://arxiv.org/abs/2510.00141", "authors": ["Dipankar Shakya", "Naveed A. Abbasi", "Mingjun Ying", "Isha Jariwala", "Jason J. Qin", "Ishaan S. Gupte", "Bridget Meier", "Guanyue Qian", "Daniel Abraham", "Theodore S. Rappaport", "Andreas F. Molisch"], "title": "Standardized Machine-Readable Point-Data Format for Consolidating Wireless Propagation Across Environments, Frequencies, and Institutions", "comment": "6 pages, 4 figures, 4 tables, IEEE MILCOM 2025 conference", "summary": "The necessity of new spectrum for 6G has intensified global interest in radio\npropagation measurements across emerging frequency bands, use cases, and\nantenna types. These measurements are vital for understanding radio channel\nproperties in diverse environments, and involve time-consuming and expensive\ncampaigns. A major challenge for the effective utilization of propagation\nmeasurement data has been the lack of a standardized format for reporting and\narchiving results. Although organizations such as NIST, NGA, and 3GPP have made\ncommendable efforts for data pooling, a unified machine-readable data format\nfor consolidating measurements across different institutions and frequencies\nremains a missing piece in advancing global standardization efforts. This paper\nintroduces a standardized point-data format for radio propagation measurements\nand demonstrates how institutions may merge disparate campaigns into a common\nformat. This data format, alongside an environmental map and a measurement\nsummary metadata table, enables integration of data from disparate sources by\nusing a structured representation of key parameters. Here, we show the efficacy\nof the point-data format standard using data gathered from two independent\nsub-THz urban microcell (UMi) campaigns: 142 GHz measurements at New York\nUniversity (NYU) and 145 GHz measurements at the University of Southern\nCalifornia (USC). A joint path loss analysis using the close-in path loss model\n(1 m ref. distance) yields a refined estimate of the path loss exponent (PLE)\nemploying the proposed standard to pool measurements. Other statistics such as\nRMS delay spread and angular spread are also determined using a joint\npoint-data table. Adopting this simple, unified format will accelerate channel\nmodel development, build multi-institutional datasets, and feed AI/ML\napplications with reliable training data in a common format from many sources."}
{"id": "2510.00053", "categories": ["eess.IV", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.00053", "abs": "https://arxiv.org/abs/2510.00053", "authors": ["Yucheng Xing", "Ling Huang", "Jingying Ma", "Ruping Hong", "Jiangdong Qiu", "Pei Liu", "Kai He", "Huazhu Fu", "Mengling Feng"], "title": "DPsurv: Dual-Prototype Evidential Fusion for Uncertainty-Aware and Interpretable Whole-Slide Image Survival Prediction", "comment": null, "summary": "Pathology whole-slide images (WSIs) are widely used for cancer survival\nanalysis because of their comprehensive histopathological information at both\ncellular and tissue levels, enabling quantitative, large-scale, and\nprognostically rich tumor feature analysis. However, most existing methods in\nWSI survival analysis struggle with limited interpretability and often overlook\npredictive uncertainty in heterogeneous slide images. In this paper, we propose\nDPsurv, a dual-prototype whole-slide image evidential fusion network that\noutputs uncertainty-aware survival intervals, while enabling interpretation of\npredictions through patch prototype assignment maps, component prototypes, and\ncomponent-wise relative risk aggregation. Experiments on five publicly\navailable datasets achieve the highest mean concordance index and the lowest\nmean integrated Brier score, validating the effectiveness and reliability of\nDPsurv. The interpretation of prediction results provides transparency at the\nfeature, reasoning, and decision levels, thereby enhancing the trustworthiness\nand interpretability of DPsurv."}
{"id": "2510.00342", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.00342", "abs": "https://arxiv.org/abs/2510.00342", "authors": ["Samuel Li", "Ian P. Roberts"], "title": "Site-Specific Beam Learning for Full-Duplex Massive MIMO Wireless Systems", "comment": null, "summary": "Existing beamforming-based full-duplex solutions for multi-antenna wireless\nsystems often rely on explicit estimation of the self-interference channel. The\npilot overhead of such estimation, however, can be prohibitively high in\nmillimeter-wave and massive MIMO systems, thus limiting the practicality of\nexisting solutions, especially in fast-fading conditions. In this work, we\npresent a novel beam learning framework that bypasses explicit\nself-interference channel estimation by designing beam codebooks to efficiently\nobtain implicit channel knowledge that can then be processed by a deep learning\nnetwork to synthesize transmit and receive beams for full-duplex operation.\nSimulation results using ray-tracing illustrate that our proposed technique can\nallow a full-duplex base station to craft serving beams that couple low\nself-interference while delivering high SNR, with 75-97% fewer measurements\nthan would be required for explicit estimation of the self-interference\nchannel."}
{"id": "2510.00055", "categories": ["eess.IV", "cs.CV", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.00055", "abs": "https://arxiv.org/abs/2510.00055", "authors": ["Kiran Nijjer", "Ryan Bui", "Derek Jiu", "Adnan Ahmed", "Peter Wang", "Benjamin Liu", "Kevin Zhu", "Lilly Zhu"], "title": "Adapting Large Language Models to Mitigate Skin Tone Biases in Clinical Dermatology Tasks: A Mixed-Methods Study", "comment": "Accepted to EADV (European Academy of Dermatology) and SID (Society\n  for Investigative Dermatology)", "summary": "SkinGPT-4, a large vision-language model, leverages annotated skin disease\nimages to augment clinical workflows in underserved communities. However, its\ntraining dataset predominantly represents lighter skin tones, limiting\ndiagnostic accuracy for darker tones. Here, we evaluated performance biases in\nSkinGPT-4 across skin tones on common skin diseases, including eczema,\nallergic-contact dermatitis, and psoriasis using the open-sourced SCIN dataset.\nWe leveraged the SkinGPT-4 backbone to develop finetuned models for custom skin\ndisease classification tasks and explored bias mitigation strategies. Clinical\nevaluation by board-certified dermatologists on six relevant skin diseases from\n300 SCIN cases assessed images for diagnostic accuracy, informativity,\nphysician utility, and patient utility. Model fairness metrics, including\ndemographic parity and equalized odds, were calculated across skin tones.\nSkinGPT-4 achieved an average demographic parity of 0.10 across Fitzpatrick\ntypes, with notable differences of 0.10-0.15 between lightest and darkest tones\nacross evaluation metrics. Model hallucinations in artifacts and anatomy\noccurred at a rate of 17.8. Our customized models achieved average F1,\nprecision, and AUROC of 0.75, 0.78, and 0.78 across visually similar disease\npairs. Fairness analysis showed an average demographic parity of 0.75, with a\nmaximum disparity of 0.21 across skin tones. The best model achieved parity\nscores of 0.83, 0.83, 0.76, 0.89, 0.90, and 0.90 for Fitzpatrick I-VI,\nindicating robust fairness. Large language models such as SkinGPT-4 showed\nweaker performance on darker tones. Model biases exist across evaluation\ncriteria, and hallucinations may affect diagnostic efficacy. These findings\ndemonstrate the efficacy of training accurate, fair models using existing\nbackbones for custom skin disease classification."}
{"id": "2510.00422", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.00422", "abs": "https://arxiv.org/abs/2510.00422", "authors": ["Kleanthis Avramidis", "Myzelle Hughes", "Idan A Blank", "Dani Byrd", "Assal Habibi", "Takfarinas Medani", "Richard M Leahy", "Shrikanth Narayanan"], "title": "A Point Process Model of Skin Conductance Responses in a Stroop Task for Predicting Depression and Suicidal Ideation", "comment": "\\c{opyright} 2025 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "summary": "Accurate identification of mental health biomarkers can enable earlier\ndetection and objective assessment of compromised mental well-being. In this\nstudy, we analyze electrodermal activity recorded during an Emotional Stroop\ntask to capture sympathetic arousal dynamics associated with depression and\nsuicidal ideation. We model the timing of skin conductance responses as a point\nprocess whose conditional intensity is modulated by task-based covariates,\nincluding stimulus valence, reaction time, and response accuracy. The resulting\nsubject-specific parameter vector serves as input to a machine learning\nclassifier for distinguishing individuals with and without depression. Our\nresults show that the model parameters encode meaningful physiological\ndifferences associated with depressive symptomatology and yield superior\nclassification performance compared to conventional feature extraction methods."}
{"id": "2510.00058", "categories": ["eess.IV", "cs.CV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2510.00058", "abs": "https://arxiv.org/abs/2510.00058", "authors": ["Priyanka Mudgal", "Feng Liu"], "title": "Variable Rate Image Compression via N-Gram Context based Swin-transformer", "comment": "Accepted at ISVC 2025", "summary": "This paper presents an N-gram context-based Swin Transformer for learned\nimage compression. Our method achieves variable-rate compression with a single\nmodel. By incorporating N-gram context into the Swin Transformer, we overcome\nits limitation of neglecting larger regions during high-resolution image\nreconstruction due to its restricted receptive field. This enhancement expands\nthe regions considered for pixel restoration, thereby improving the quality of\nhigh-resolution reconstructions. Our method increases context awareness across\nneighboring windows, leading to a -5.86\\% improvement in BD-Rate over existing\nvariable-rate learned image compression techniques. Additionally, our model\nimproves the quality of regions of interest (ROI) in images, making it\nparticularly beneficial for object-focused applications in fields such as\nmanufacturing and industrial vision systems."}
{"id": "2510.00550", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.00550", "abs": "https://arxiv.org/abs/2510.00550", "authors": ["Tai Le", "Hau Luu", "Loan Pham-Nguyen", "Hung Viet-Dao", "Duc Nguyen Minh", "Afshan B. Hameed", "Hoang Nguyen", "Liem Thanh Nguyen", "Huy-Dung Han", "Hung Cao"], "title": "Investigation of Using Non-Contact Electrodes for Fetal ECG Monitoring", "comment": null, "summary": "Regular physiological monitoring of maternal and fetal parameters is\nindispensable for ensuring safe outcomes during pregnancy and parturition.\nFetal electrocardiogram (fECG) assessment is crucial to detect fetal distress\nand developmental anomalies. Given challenges of prenatal care due to the lack\nof medical professionals and the limit of accessibility, especially in remote\nand resource-poor areas, we develop a fECG monitoring system using novel\nnon-contact electrodes (NCE) to record the fetal/maternal ECG (f/mECG) signals\nthrough clothes, thereby improving the comfort during measurement. The system\nis designed to be incorporated inside a maternity belt with data acquisition,\ndata transmission module as well as novel NCEs. Thorough characterizations were\ncarried out to evaluate the novel NCE against traditional wet electrodes (i.e.,\nAg/AgCl electrodes), showing comparable performance. A successful {preliminary\npilot feasibility study} conducted with pregnant women (n = 10) between 25 and\n32 weeks of gestation demonstrates the system's performance, usability and\nsafety."}
{"id": "2510.00061", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.00061", "abs": "https://arxiv.org/abs/2510.00061", "authors": ["Abdul Rahman", "Bumshik Lee"], "title": "Survey of AI-Powered Approaches for Osteoporosis Diagnosis in Medical Imaging", "comment": "56 pages, 18 figures", "summary": "Osteoporosis silently erodes skeletal integrity worldwide; however, early\ndetection through imaging can prevent most fragility fractures. Artificial\nintelligence (AI) methods now mine routine Dual-energy X-ray Absorptiometry\n(DXA), X-ray, Computed Tomography (CT), and Magnetic Resonance Imaging (MRI)\nscans for subtle, clinically actionable markers, but the literature is\nfragmented. This survey unifies the field through a tri-axial framework that\ncouples imaging modalities with clinical tasks and AI methodologies (classical\nmachine learning, convolutional neural networks (CNNs), transformers,\nself-supervised learning, and explainable AI). Following a concise clinical and\ntechnical primer, we detail our Preferred Reporting Items for Systematic\nReviews and Meta-Analyses (PRISMA)-guided search strategy, introduce the\ntaxonomy via a roadmap figure, and synthesize cross-study insights on data\nscarcity, external validation, and interpretability. By identifying emerging\ntrends, open challenges, and actionable research directions, this review\nprovides AI scientists, medical imaging researchers, and musculoskeletal\nclinicians with a clear compass to accelerate rigorous, patient-centered\ninnovation in osteoporosis care. The project page of this survey can also be\nfound on Github."}
{"id": "2510.00562", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.00562", "abs": "https://arxiv.org/abs/2510.00562", "authors": ["Shingo Takemoto", "Shunsuke Ono"], "title": "Geometric Spatio-Spectral Total Variation for Hyperspectral Image Denoising and Destriping", "comment": "Submitted to IEEE Open Journal of Signal Processing. The source code\n  is available at\n  https://github.com/MDI-TokyoTech/Geometric-Spatio-Spectral-Total-Variation", "summary": "This article proposes a novel regularization method, named Geometric\nSpatio-Spectral Total Variation (GeoSSTV), for hyperspectral (HS) image\ndenoising and destriping. HS images are inevitably affected by various types of\nnoise due to the measurement equipment and environment. Total Variation\n(TV)-based regularization methods that model the spatio-spectral piecewise\nsmoothness inherent in HS images are promising approaches for HS image\ndenoising and destriping. However, existing TV-based methods are based on\nclassical anisotropic and isotropic TVs, which cause staircase artifacts and\nlack rotation invariance, respectively, making it difficult to accurately\nrecover round structures and oblique edges. To address this issue, GeoSSTV\nintroduces a geometrically consistent formulation of TV that measures\nvariations across all directions in a Euclidean manner. Through this\nformulation, GeoSSTV removes noise while preserving round structures and\noblique edges. Furthermore, we formulate the HS image denoising problem as a\nconstrained convex optimization problem involving GeoSSTV and develop an\nefficient algorithm based on a preconditioned primal-dual splitting method.\nExperimental results on HS images contaminated with mixed noise demonstrate the\nsuperiority of the proposed method over existing approaches."}
{"id": "2510.00298", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2510.00298", "abs": "https://arxiv.org/abs/2510.00298", "authors": ["Changjie Lu", "Sourya Sengupta", "Hua Li", "Mark A. Anastasio"], "title": "Observer-Usable Information as a Task-specific Image Quality Metric", "comment": null, "summary": "Objective, task-based, measures of image quality (IQ) have been widely\nadvocated for assessing and optimizing medical imaging technologies. Besides\nsignal detection theory-based measures, information-theoretic quantities have\nbeen proposed to quantify task-based IQ. For example, task-specific information\n(TSI), defined as the mutual information between an image and task variable,\nrepresents an optimal measure of how informative an image is for performing a\nspecified task. However, like the ideal observer from signal detection theory,\nTSI does not quantify the amount of task-relevant information in an image that\ncan be exploited by a sub-ideal observer. A recently proposed relaxation of\nTSI, termed predictive V-information (V-info), removes this limitation and can\nquantify the utility of an image with consideration of a specified family of\nsub-ideal observers. In this study, for the first time, V-info is proposed and\ninvestigated as an objective, task-specific, IQ metric. To corroborate its\nusefulness, a stylized magnetic resonance image restoration problem is\nconsidered in which V-info is employed to quantify signal detection or\ndiscrimination performance. The presented results show that V-info correlates\nwith area under the receiver operating characteristic (ROC) curve for binary\ntasks, while being readily applicable to multi-class (>2) tasks where ROC\nanalysis is challenging. Notably, V-info exhibits greater sensitivity in\nscenarios where conventional metrics saturate. These findings demonstrate that\nV-info represents a new objective IQ measure that can complement conventional\nsignal detection theory-based ones."}
{"id": "2510.00581", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.00581", "abs": "https://arxiv.org/abs/2510.00581", "authors": ["Zhuoran Li", "Zhen Gao", "Boyu Ning", "Zhaocheng Wang"], "title": "Radiation Pattern Reconfigurable FAS-Empowered Interference-Resilient UAV Communication", "comment": "Simulation codes are provided to reproduce the results in this paper:\n  \\href{https://github.com/LiZhuoRan0/2025-JSAC-RadiationPatternReconfigurableAntenna}{https://github.com/LiZhuoRan0}", "summary": "The widespread use of uncrewed aerial vehicles (UAVs) has propelled the\ndevelopment of advanced techniques on countering unauthorized UAV flights.\nHowever, the resistance of legal UAVs to illegal interference remains\nunder-addressed. This paper proposes radiation pattern reconfigurable fluid\nantenna systems (RPR-FAS)-empowered interference-resilient UAV communication\nscheme. This scheme integrates the reconfigurable pixel antenna technology,\nwhich provides each antenna with an adjustable radiation pattern. Therefore,\nRPR-FAS can enhance the angular resolution of a UAV with a limited number of\nantennas, thereby improving spectral efficiency (SE) and interference\nresilience. Specifically, we first design dedicated radiation pattern adapted\nfrom 3GPP-TR-38.901, where the beam direction and half power beamwidth are\ntailored for UAV communications. Furthermore, we propose a low-storage-overhead\northogonal matching pursuit multiple measurement vectors algorithm, which\naccurately estimates the angle-of-arrival (AoA) of the communication link, even\nin the single antenna case. Particularly, by utilizing the Fourier transform to\nthe radiation pattern gain matrix, we design a dimension-reduction technique to\nachieve 1--2 order-of-magnitude reduction in storage requirements. Meanwhile,\nwe propose a maximum likelihood interference AoA estimation method based on the\nlaw of large numbers, so that the SE can be further improved. Finally,\nalternating optimization is employed to obtain the optimal uplink radiation\npattern and combiner, while an exhaustive search is applied to determine the\noptimal downlink pattern, complemented by the water-filling algorithm for\nbeamforming. Comprehensive simulations demonstrate that the proposed schemes\noutperform traditional methods in terms of angular sensing precision and\nspectral efficiency."}
{"id": "2510.00418", "categories": ["eess.IV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.00418", "abs": "https://arxiv.org/abs/2510.00418", "authors": ["Pierre Fayolle", "Alexandre Bône", "Noëlie Debs", "Pihlippe Robert", "Pascal Bourdon", "Remy Guillevin", "David Helbert"], "title": "Improving Virtual Contrast Enhancement using Longitudinal Data", "comment": "11 pages, 4 figures, Workshop MICCAI 2025 - Learning with\n  Longitudinal Medical Images and Data", "summary": "Gadolinium-based contrast agents (GBCAs) are widely used in magnetic\nresonance imaging (MRI) to enhance lesion detection and characterisation,\nparticularly in the field of neuro-oncology. Nevertheless, concerns regarding\ngadolinium retention and accumulation in brain and body tissues, most notably\nfor diseases that require close monitoring and frequent GBCA injection, have\nled to the need for strategies to reduce dosage. In this study, a deep learning\nframework is proposed for the virtual contrast enhancement of full-dose\npost-contrast T1-weighted MRI images from corresponding low-dose acquisitions.\nThe contribution of the presented model is its utilisation of longitudinal\ninformation, which is achieved by incorporating a prior full-dose MRI\nexamination from the same patient. A comparative evaluation against a\nnon-longitudinal single session model demonstrated that the longitudinal\napproach significantly improves image quality across multiple reconstruction\nmetrics. Furthermore, experiments with varying simulated contrast doses\nconfirmed the robustness of the proposed method. These results emphasize the\npotential of integrating prior imaging history into deep learning-based virtual\ncontrast enhancement pipelines to reduce GBCA usage without compromising\ndiagnostic utility, thus paving the way for safer, more sustainable\nlongitudinal monitoring in clinical MRI practice."}
{"id": "2510.00696", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.00696", "abs": "https://arxiv.org/abs/2510.00696", "authors": ["Ferdaous Tarhouni", "Muneer AlZubi", "Mohamed-Slim Alouini"], "title": "Machine Learning-based Path Loss Prediction in Suburban Environment in the Sub-6 GHz Band", "comment": null, "summary": "Accurate path loss (PL) prediction is crucial for successful network\nplanning, antenna design, and performance optimization in wireless\ncommunication systems. Several conventional approaches for PL prediction have\nbeen adopted, but they have been demonstrated to lack flexibility and accuracy.\nIn this work, we investigate the effectiveness of Machine Learning (ML) models\nin predicting PL, particularly for the sub-6 GHz band in a suburban campus of\nKing Abdullah University of Science and Technology (KAUST). For training\npurposes, we generate synthetic datasets using the ray-tracing simulation\ntechnique. The feasibility and accuracy of the ML-based PL models are verified\nand validated using both synthetic and measurement datasets. The random forest\nregression (RFR) and the K-nearest neighbors (KNN) algorithms provide the best\nPL prediction accuracy compared to other ML models. In addition, we compare the\nperformance of the developed ML-based PL models with the traditional\npropagation models, including COST-231 Hata, Longley-Rice, and Close-in models.\nThe results show the superiority of the ML-based PL models compared to\nconventional models. Therefore, the ML approach using the ray-tracing technique\ncan provide a promising and cost-effective solution for predicting and modeling\nradio wave propagation in various scenarios in a flexible manner."}
{"id": "2510.00505", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.00505", "abs": "https://arxiv.org/abs/2510.00505", "authors": ["Hidenori Takeshima", "Shuki Maruyama"], "title": "A Fast and Precise Method for Searching Rectangular Tumor Regions in Brain MR Images", "comment": null, "summary": "Purpose: To develop a fast and precise method for searching rectangular\nregions in brain tumor images. Methods: The authors propose a new method for\nsearching rectangular tumor regions in brain MR images. The proposed method\nconsisted of a segmentation network and a fast search method with a\nuser-controllable search metric. As the segmentation network, the U-Net whose\nencoder was replaced by the EfficientNet was used. In the fast search method,\nsummed-area tables were used for accelerating sums of voxels in rectangular\nregions. Use of the summed-area tables enabled exhaustive search of the 3D\noffset (3D full search). The search metric was designed for giving priority to\ncubes over oblongs, and assigning better values for higher tumor fractions even\nif they exceeded target tumor fractions. The proposed computation and metric\nwere compared with those used in a conventional method using the Brain Tumor\nImage Segmentation dataset. Results: When the 3D full search was used, the\nproposed computation (8 seconds) was 100-500 times faster than the conventional\ncomputation (11-40 minutes). When the user-controllable parts of the search\nmetrics were changed variously, the tumor fractions of the proposed metric were\nhigher than those of the conventional metric. In addition, the conventional\nmetric preferred oblongs whereas the proposed metric preferred cubes.\nConclusion: The proposed method is promising for implementing fast and precise\nsearch of rectangular tumor regions, which is useful for brain tumor diagnosis\nusing MRI systems. The proposed computation reduced processing times of the 3D\nfull search, and the proposed metric improved the quality of the assigned\nrectangular tumor regions."}
{"id": "2510.00816", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.00816", "abs": "https://arxiv.org/abs/2510.00816", "authors": ["Fernando Moya Caceres", "Akram Al-Hourani", "Saman Atapattu", "Kandeepan Sithamparanathan"], "title": "Null-Shaping for Interference Mitigation in LEO Satellites Under Location Uncertainty", "comment": "6 pages, 8 figures, GLOBECOM 2025", "summary": "Radio frequency interference (RFI) poses a growing challenge to satellite\ncommunications, particularly in uplink channels of Low Earth Orbit (LEO)\nsystems, due to increasing spectrum congestion and uncertainty in the location\nof terrestrial interferers. This paper addresses the impact of RFI source\nposition uncertainty on beamforming-based interference mitigation. First, we\nanalytically characterize how geographic uncertainty in RFI location translates\ninto angular deviation as observed from the satellite. Building on this, we\npropose a robust null-shaping framework to increase resilience in the\ncommunication links by incorporating the probability density function (PDF) of\nthe RFI location uncertainty into the beamforming design via stochastic\noptimization. This allows adaptive shaping of the antenna array's nulling\npattern to enhance interference suppression under uncertainty. Extensive Monte\nCarlo simulations, incorporating realistic satellite orbital dynamics and\nvarious RFI scenarios, demonstrate that the proposed approach achieves\nsignificantly improved mitigation performance compared to conventional\ndeterministic designs."}
{"id": "2510.00585", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.00585", "abs": "https://arxiv.org/abs/2510.00585", "authors": ["Zulkaif Sajjad", "Furqan Shaukat", "Junaid Mir"], "title": "U-DFA: A Unified DINOv2-Unet with Dual Fusion Attention for Multi-Dataset Medical Segmentation", "comment": null, "summary": "Accurate medical image segmentation plays a crucial role in overall diagnosis\nand is one of the most essential tasks in the diagnostic pipeline. CNN-based\nmodels, despite their extensive use, suffer from a local receptive field and\nfail to capture the global context. A common approach that combines CNNs with\ntransformers attempts to bridge this gap but fails to effectively fuse the\nlocal and global features. With the recent emergence of VLMs and foundation\nmodels, they have been adapted for downstream medical imaging tasks; however,\nthey suffer from an inherent domain gap and high computational cost. To this\nend, we propose U-DFA, a unified DINOv2-Unet encoder-decoder architecture that\nintegrates a novel Local-Global Fusion Adapter (LGFA) to enhance segmentation\nperformance. LGFA modules inject spatial features from a CNN-based Spatial\nPattern Adapter (SPA) module into frozen DINOv2 blocks at multiple stages,\nenabling effective fusion of high-level semantic and spatial features. Our\nmethod achieves state-of-the-art performance on the Synapse and ACDC datasets\nwith only 33\\% of the trainable model parameters. These results demonstrate\nthat U-DFA is a robust and scalable framework for medical image segmentation\nacross multiple modalities."}
{"id": "2510.00838", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.00838", "abs": "https://arxiv.org/abs/2510.00838", "authors": ["Hasnul Hashim"], "title": "Effectiveness of Reconfigurable Intelligent Surface in Multipath Fading Channel", "comment": "8 pages, 16 figures", "summary": "A method of simulating a single-input single-output reconfigurable\nintelligent surface (RIS) assisted channel is presented using three channel\nblack boxes to represent the direct signal path, the transmit path to the RIS\nand the reflected path from the RIS. The complex coefficients for each channel\nbox is obtained by ray tracing in a scenario with geographic terrain\ninformation that also contains approximate building shapes. The electrical\ncharacteristics of the ground and building walls were also accounted for in the\nray tracing function. Simulations were conducted with reflected rays only and\nreflected rays together with diffracted rays. The received power exhibits\nvariations typical of multipath fading environments. In the best locations, the\nRIS-assisted channel simulation result agrees well with theoretical models, the\nperformance increasing by the RIS size squared as the number of RIS elements is\nincreased. In the simplified theoretical model where the transmitter and\nreceiver are inline and the RIS orthogonal but much closer than the distance\nbetween the former elements, the simulation results also corroborate best\ndeployment close the transmitter or the receiver with a U-shaped drop between\nthem."}
{"id": "2510.00851", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.00851", "abs": "https://arxiv.org/abs/2510.00851", "authors": ["Abdelaziz Salama", "Mohammed M. H. Qazzaz", "Zeinab Nezami", "Maryam Hafeez", "Syed Ali Raza Zaidi"], "title": "Agentic AI meets Neural Architecture Search: Proactive Traffic Prediction for AI-RAN", "comment": null, "summary": "Next-generation wireless networks require intelligent traffic prediction to\nenable autonomous resource management and handle diverse, dynamic service\ndemands. The Open Radio Access Network (O-RAN) framework provides a promising\nfoundation for embedding machine learning intelligence through its\ndisaggregated architecture and programmable interfaces. This work applies a\nNeural Architecture Search (NAS)-based framework that dynamically selects and\norchestrates efficient Long Short-Term Memory (LSTM) architectures for traffic\nprediction in O-RAN environments. Our approach leverages the O-RAN paradigm by\nseparating architecture optimisation (via non-RT RIC rApps) from real-time\ninference (via near-RT RIC xApps), enabling adaptive model deployment based on\ntraffic conditions and resource constraints. Experimental evaluation across six\nLSTM architectures demonstrates that lightweight models achieve $R^2 \\approx\n0.91$--$0.93$ with high efficiency for regular traffic, while complex models\nreach near-perfect accuracy ($R^2 = 0.989$--$0.996$) during critical scenarios.\nOur NAS-based orchestration achieves a 70-75\\% reduction in computational\ncomplexity compared to static high-performance models, while maintaining high\nprediction accuracy when required, thereby enabling scalable deployment in\nreal-world edge environments."}
{"id": "2510.00896", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.00896", "abs": "https://arxiv.org/abs/2510.00896", "authors": ["Romina Garcia Camargo", "Zhiyang Wang", "Alejandro Ribeiro"], "title": "Graph Neural Networks in Large Scale Wireless Communication Networks: Scalability Across Random Geometric Graphs", "comment": null, "summary": "The growing complexity of wireless systems has accelerated the move from\ntraditional methods to learning-based solutions. Graph Neural Networks (GNNs)\nare especially well-suited here, since wireless networks can be naturally\nrepresented as graphs. A key property of GNNs is transferability: models\ntrained on one graph often generalize to much larger graphs with little\nperformance loss. While empirical studies have shown that GNN-based wireless\npolicies transfer effectively, existing theoretical guarantees do not capture\nthis phenomenon. Most works focus on dense graphs where node degrees scale with\nnetwork size, an assumption that fails in wireless systems. In this work, we\nprovide a formal theoretical foundation for transferability on Random Geometric\nGraphs (RGGs), a sparse and widely used model of wireless networks. We further\nvalidate our results through numerical experiments on power allocation, a\nfundamental resource management task."}
{"id": "2510.00934", "categories": ["eess.SP", "eess.AS"], "pdf": "https://arxiv.org/pdf/2510.00934", "abs": "https://arxiv.org/abs/2510.00934", "authors": ["Junwei Ji", "Dongyuan Shi", "Zhengding Luo", "Boxiang Wang", "Ziyi Yang", "Haowen Li", "Woon-Seng Gan"], "title": "A Robust Proactive Communication Strategy for Distributed Active Noise Control Systems", "comment": null, "summary": "Distributed multichannel active noise control (DMCANC) systems assign the\nhigh computational load of conventional centralized algorithms across multiple\nprocessing nodes, leveraging inter-node communication to collaboratively\nsuppress unwanted noise. However, communication overhead can undermine\nalgorithmic stability and degrade overall performance. To address this\nchallenge, we propose a robust communication framework that integrates\nadaptive-fixed-filter switching and the mixed-gradient combination strategy. In\nthis approach, each node independently executes a single-channel filtered\nreference least mean square (FxLMS) algorithm while monitoring real-time noise\nreduction levels. When the current noise reduction performance degrades\ncompared to the previous state, the node halts its adaptive algorithm, switches\nto a fixed filter, and simultaneously initiates a communication request. The\nexchanged information comprises the difference between the current control\nfilter and the filter at the time of the last communication, equivalent to the\naccumulated gradient sum during non-communication intervals. Upon receiving\nneighboring cumulative gradients, the node employs a mixed-gradient combination\nmethod to update its control filter, subsequently reverting to the adaptive\nmode. This proactive communication strategy and adaptive-fixed switching\nmechanism ensure system robustness by mitigating instability risks caused by\ncommunication issues. Simulations demonstrate that the proposed method achieves\nnoise reduction performance comparable to centralized algorithms while\nmaintaining stability under communication constraints, highlighting its\npractical applicability in real-world distributed ANC scenarios."}
