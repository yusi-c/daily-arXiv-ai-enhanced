{"id": "2507.22906", "categories": ["eess.SP", "cs.AI", "cs.IT", "cs.LG", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.22906", "abs": "https://arxiv.org/abs/2507.22906", "authors": ["Bin Deng", "Jiatong Bai", "Feilong Zhao", "Zuming Xie", "Maolin Li", "Yan Wang", "Feng Shu"], "title": "DNN-based Methods of Jointly Sensing Number and Directions of Targets via a Green Massive H2AD MIMO Receiver", "comment": null, "summary": "As a green MIMO structure, the heterogeneous hybrid analog-digital H2AD MIMO\narchitecture has been shown to own a great potential to replace the massive or\nextremely large-scale fully-digital MIMO in the future wireless networks to\naddress the three challenging problems faced by the latter: high energy\nconsumption, high circuit cost, and high complexity. However, how to\nintelligently sense the number and direction of multi-emitters via such a\nstructure is still an open hard problem. To address this, we propose a\ntwo-stage sensing framework that jointly estimates the number and direction\nvalues of multiple targets. Specifically, three target number sensing methods\nare designed: an improved eigen-domain clustering (EDC) framework, an enhanced\ndeep neural network (DNN) based on five key statistical features, and an\nimproved one-dimensional convolutional neural network (1D-CNN) utilizing full\neigenvalues. Subsequently, a low-complexity and high-accuracy DOA estimation is\nachieved via the introduced online micro-clustering (OMC-DOA) method.\nFurthermore, we derive the Cram\\'er-Rao lower bound (CRLB) for the H2AD under\nmultiple-source conditions as a theoretical performance benchmark. Simulation\nresults show that the developed three methods achieve 100\\% number of targets\nsensing at moderate-to-high SNRs, while the improved 1D-CNN exhibits superior\nunder extremely-low SNR conditions. The introduced OMC-DOA outperforms existing\nclustering and fusion-based DOA methods in multi-source environments."}
{"id": "2507.22909", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.22909", "abs": "https://arxiv.org/abs/2507.22909", "authors": ["Yin Zhang", "Jiayi Zhang", "Bokai Xu", "Yuanbin Chen", "Zhilong Liu", "Jiakang Zheng", "Enyu Shi", "Ziheng Liu", "Tierui Gong", "Wei E. I. Sha", "Chau Yuen", "Shi Jin", "Bo Ai"], "title": "Rydberg Atomic Receivers for Wireless Communications: Fundamentals, Potential, Applications, and Challenges", "comment": null, "summary": "Rydberg atomic receivers (RARs) leverage the quantum coherence of highly\nexcited atoms to overcome the intrinsic physical limitations of conventional\nradio frequency receivers (RFRs), particularly in sensitivity, and bandwidth.\nThis innovative technology represents a paradigm shift in wireless\ncommunication systems. This paper systematically explains the fundamental\nsensing mechanisms of RARs, contrasts their differences from RFRs in working\nprinciples and architectures. We explore their advantages in emerging wireless\ncommunication scenarios, such as integrated sensing and communications, quantum\nRydberg radar, and quantum space communications. Practical challenges, such as\nlimited instantaneous bandwidth and nonlinear distortion, are identified. To\naddress these issues, mitigation strategies and future research directions are\nalso outlined, supporting the advancement of RAR-aided wireless systems."}
{"id": "2507.23057", "categories": ["eess.SP", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2507.23057", "abs": "https://arxiv.org/abs/2507.23057", "authors": ["Triet M. Tran", "Sina Khanmohammadi"], "title": "Neural Energy Landscapes Predict Working Memory Decline After Brain Tumor Resection", "comment": null, "summary": "Surgical resection is the primary treatment option for brain tumor patients,\nbut it carries the risk of postoperative cognitive dysfunction. This study\ninvestigates how tumor-induced alterations in presurgical neural dynamics\nrelate to postoperative working memory decline. We analyzed functional magnetic\nresonance imaging (fMRI) of brain tumor patients before surgery and extracted\nenergy landscapes of high-order brain interactions. We then examined the\nrelation between these energy features and postoperative working memory\nperformance using statistical and machine learning (random forest) models.\nPatients with lower postoperative working memory scores exhibited fewer but\nmore extreme transitions between local energy minima and maxima, whereas\npatients with higher scores showed more frequent but less extreme shifts.\nFurthermore, the presurgical high-order energy features were able to accurately\npredict postoperative working memory decline with a mean accuracy of 90\\%, F1\nscore of 87.5\\%, and an AUC of 0.95. Our study suggests that the brain\ntumor-induced disruptions in high-order neural dynamics before surgery are\npredictive of postoperative working memory decline. Our findings pave the path\nfor personalized surgical planning and targeted interventions to mitigate\ncognitive risks associated with brain tumor resection."}
{"id": "2507.23235", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.23235", "abs": "https://arxiv.org/abs/2507.23235", "authors": ["Mohammad Roueinfar", "Masoud Ardini"], "title": "In-Orbit Cosmo-SkyMed antenna pattern estimation by a narrowband sweeper receiver", "comment": null, "summary": "This paper introduces a novel method for antenna pattern estimation in\nsatellites equipped with Synthetic Aperture Radar (SAR), utilizing a Narrowband\nSweeper Receiver (NSR). By accurately measuring power across individual\nfrequencies within SAR's inherently broadband spectrum, the NSR significantly\nenhances antenna pattern extraction accuracy. Analytical models and practical\nexperiments conducted using the Cosmo-SkyMed satellite validate the receiver's\nperformance, demonstrating superior signal-to-noise ratio (SNR) compared to\nconventional receivers. This research represents a key advancement in SAR\ntechnology, offering a robust framework for future satellite calibration and\nverification methodologies."}
{"id": "2507.22953", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2507.22953", "abs": "https://arxiv.org/abs/2507.22953", "authors": ["Murong Xu", "Tamaz Amiranashvili", "Fernando Navarro", "Maksym Fritsak", "Ibrahim Ethem Hamamci", "Suprosanna Shit", "Bastian Wittmann", "Sezgin Er", "Sebastian M. Christ", "Ezequiel de la Rosa", "Julian Deseoe", "Robert Graf", "Hendrik Möller", "Anjany Sekuboyina", "Jan C. Peeken", "Sven Becker", "Giulia Baldini", "Johannes Haubold", "Felix Nensa", "René Hosch", "Nikhil Mirajkar", "Saad Khalid", "Stefan Zachow", "Marc-André Weber", "Georg Langs", "Jakob Wasserthal", "Mehmet Kemal Ozdemir", "Andrey Fedorov", "Ron Kikinis", "Stephanie Tanadini-Lang", "Jan S. Kirschke", "Stephanie E. Combs", "Bjoern Menze"], "title": "CADS: A Comprehensive Anatomical Dataset and Segmentation for Whole-Body Anatomy in Computed Tomography", "comment": null, "summary": "Accurate delineation of anatomical structures in volumetric CT scans is\ncrucial for diagnosis and treatment planning. While AI has advanced automated\nsegmentation, current approaches typically target individual structures,\ncreating a fragmented landscape of incompatible models with varying performance\nand disparate evaluation protocols. Foundational segmentation models address\nthese limitations by providing a holistic anatomical view through a single\nmodel. Yet, robust clinical deployment demands comprehensive training data,\nwhich is lacking in existing whole-body approaches, both in terms of data\nheterogeneity and, more importantly, anatomical coverage. In this work, rather\nthan pursuing incremental optimizations in model architecture, we present CADS,\nan open-source framework that prioritizes the systematic integration,\nstandardization, and labeling of heterogeneous data sources for whole-body CT\nsegmentation. At its core is a large-scale dataset of 22,022 CT volumes with\ncomplete annotations for 167 anatomical structures, representing a significant\nadvancement in both scale and coverage, with 18 times more scans than existing\ncollections and 60% more distinct anatomical targets. Building on this diverse\ndataset, we develop the CADS-model using established architectures for\naccessible and automated full-body CT segmentation. Through comprehensive\nevaluation across 18 public datasets and an independent real-world hospital\ncohort, we demonstrate advantages over SoTA approaches. Notably, thorough\ntesting of the model's performance in segmentation tasks from radiation\noncology validates its direct utility for clinical interventions. By making our\nlarge-scale dataset, our segmentation models, and our clinical software tool\npublicly available, we aim to advance robust AI solutions in radiology and make\ncomprehensive anatomical analysis accessible to clinicians and researchers\nalike."}
{"id": "2507.23236", "categories": ["eess.SP", "eess.IV"], "pdf": "https://arxiv.org/pdf/2507.23236", "abs": "https://arxiv.org/abs/2507.23236", "authors": ["Zhuoyin Dai", "Di Wu", "Yong Zeng", "Xiaoli Xu", "Xinyi Wang", "Zesong Fei"], "title": "BS-1-to-N: Diffusion-Based Environment-Aware Cross-BS Channel Knowledge Map Generation for Cell-Free Networks", "comment": null, "summary": "Channel knowledge map (CKM) inference across base stations (BSs) is the key\nto achieving efficient environmentaware communications. This paper proposes an\nenvironmentaware cross-BS CKM inference method called BS-1-to-N based on the\ngenerative diffusion model. To this end, we first design the BS location\nembedding (BSLE) method tailored for cross-BS CKM inference to embed BS\nlocation information in the feature vector of CKM. Further, we utilize the\ncross- and self-attention mechanism for the proposed BS-1-to-N model to\nrespectively learn the relationships between source and target BSs, as well as\nthat among target BSs. Therefore, given the locations of the source and target\nBSs, together with the source CKMs as control conditions, cross-BS CKM\ninference can be performed for an arbitrary number of source and target BSs.\nSpecifically, in architectures with massive distributed nodes like cell-free\nnetworks, traditional methods of sequentially traversing each BS for CKM\nconstruction are prohibitively costly. By contrast, the proposed BS-1-to-N\nmodel is able to achieve efficient CKM inference for a target BS at any\npotential location based on the CKMs of source BSs. This is achieved by\nexploiting the fact that within a given area, different BSs share the same\nwireless environment that leads to their respective CKMs. Therefore, similar to\nmulti-view synthesis, CKMs of different BSs are representations of the same\nwireless environment from different BS locations. By mining the implicit\ncorrelation between CKM and BS location based on the wireless environment, the\nproposed BS-1-to-N method achieves efficient CKM inference across BSs. We\nprovide extensive comparisons of CKM inference between the proposed BS-1-to-N\ngenerative model versus benchmarking schemes, and provide one use case study to\ndemonstrate its practical application for the optimization of BS deployment."}
{"id": "2507.23001", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.23001", "abs": "https://arxiv.org/abs/2507.23001", "authors": ["Jamil Fayyad", "Nourhan Bayasi", "Ziyang Yu", "Homayoun Najjaran"], "title": "LesionGen: A Concept-Guided Diffusion Model for Dermatology Image Synthesis", "comment": "Accepted at the MICCAI 2025 ISIC Workshop", "summary": "Deep learning models for skin disease classification require large, diverse,\nand well-annotated datasets. However, such resources are often limited due to\nprivacy concerns, high annotation costs, and insufficient demographic\nrepresentation. While text-to-image diffusion probabilistic models (T2I-DPMs)\noffer promise for medical data synthesis, their use in dermatology remains\nunderexplored, largely due to the scarcity of rich textual descriptions in\nexisting skin image datasets. In this work, we introduce LesionGen, a\nclinically informed T2I-DPM framework for dermatology image synthesis. Unlike\nprior methods that rely on simplistic disease labels, LesionGen is trained on\nstructured, concept-rich dermatological captions derived from expert\nannotations and pseudo-generated, concept-guided reports. By fine-tuning a\npretrained diffusion model on these high-quality image-caption pairs, we enable\nthe generation of realistic and diverse skin lesion images conditioned on\nmeaningful dermatological descriptions. Our results demonstrate that models\ntrained solely on our synthetic dataset achieve classification accuracy\ncomparable to those trained on real images, with notable gains in worst-case\nsubgroup performance. Code and data are available here."}
{"id": "2507.23381", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.23381", "abs": "https://arxiv.org/abs/2507.23381", "authors": ["Ziang Liu", "Bruno Clerckx"], "title": "A Secure Full-Duplex Wireless Circulator enabled by Non-Reciprocal Beyond-Diagonal RIS", "comment": "Submitted for IEEE journal", "summary": "Beyond-diagonal reconfigurable intelligent surface (BD-RIS) has arisen as a\npromising technology for enhancing wireless communication systems by enabling\nflexible and intelligent wave manipulation. This is achieved through the\ninterconnections among the ports of the impedance network, enabling wave\nreconfiguration when they flow through the surface. Thus, the output wave at\none port depends on waves impinging on neighboring ports, allowing non-local\ncontrol of both phase and magnitude. Non-reciprocal (NR)-BD-RIS further\nenhances this capability by breaking circuit reciprocity and, consequently,\nchannel reciprocity. This feature potentially benefits communication among\nnon-aligned transceivers. This paper introduces a novel application of\nNR-BD-RIS in full-duplex (FD) wireless circulators, where multiple FD devices\ncommunicate via an NR-BD-RIS. This system is particularly beneficial for secure\ntransmission, as it enforces one-way communication among FD devices, suppresses\nsignal from all other users, and thus prevents eavesdropping. In addition, a\nphysics-compliant system model is considered by incorporating structural\nscattering, also known as specular reflection. By accounting for this effect,\nthe advantages of NR-BD-RIS are further validated. Specifically, we formulate\nan all-user sum-rate maximization problem and propose an iterative optimization\nalgorithm that employs block coordinate descent (BCD) and penalty dual\ndecomposition (PDD) methods. Numerical evaluations illustrate that NR-BD-RIS\nconsistently outperforms reciprocal (R)-BD-RIS and conventional diagonal\n(D)-RIS in terms of sum-rate performance, particularly when more than two\nimpinging and reflection directions need to be supported. By analyzing the\npower of signals from all other users and the beampatterns, we show that secure\ntransmission can be achieved."}
{"id": "2507.23065", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2507.23065", "abs": "https://arxiv.org/abs/2507.23065", "authors": ["Jonathan Monsalve", "Kumar Vijay Mishra"], "title": "Diffusion model for gradient preconditioning in hyperspectral imaging inverse problems", "comment": null, "summary": "Recovering high-dimensional statistical structure from limited measurements\nis a fundamental challenge in hyperspectral imaging, where capturing\nfull-resolution data is often infeasible due to sensor, bandwidth, or\nacquisition constraints. A common workaround is to partition measurements and\nestimate local statistics-such as the covariance matrix-using only partial\nobservations. However, this strategy introduces noise in the optimization\ngradients, especially when each partition contains few samples. In this work,\nwe reinterpret this accumulation of gradient noise as a diffusion process,\nwhere successive partitions inject increasing uncertainty into the learning\nsignal. Building on this insight, we propose a novel framework that leverages\ndenoising diffusion models to learn a reverse process in gradient space. The\nmodel is trained to map noisy gradient estimates toward clean, well-conditioned\nupdates, effectively preconditioning the optimization. Our approach bridges\ngenerative modeling and inverse problem solving, improving convergence and\nreconstruction quality under aggressive sampling regimes. We validate our\nmethod on hyperspectral recovery tasks, demonstrating significant gains in\naccuracy and stability over traditional optimization pipelines."}
{"id": "2507.23518", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.23518", "abs": "https://arxiv.org/abs/2507.23518", "authors": ["Joel Poncha Lemayian", "Hachem Bensalem", "Ghyslain Gagnon", "Kaiwen Zhang", "Pascal Giard"], "title": "EVMx: An FPGA-Based Smart Contract Processing Unit", "comment": "6 pages", "summary": "Ethereum blockchain uses smart contracts (SCs) to implement decentralized\napplications (dApps). SCs are executed by the Ethereum virtual machine (EVM)\nrunning within an Ethereum client. Moreover, the EVM has been widely adopted by\nother blockchain platforms, including Solana, Cardano, Avalanche, Polkadot, and\nmore. However, the EVM performance is limited by the constraints of the\ngeneral-purpose computer it operates on. This work proposes offloading SC\nexecution onto a dedicated hardware-based EVM. Specifically, EVMx is an\nFPGA-based SC execution engine that benefits from the inherent parallelism and\nhigh-speed processing capabilities of a hardware architecture. Synthesis\nresults demonstrate a reduction in execution time of 61% to 99% for commonly\nused operation codes compared to CPU-based SC execution environments. Moreover,\nthe execution time of Ethereum blocks on EVMx is up to 6x faster compared to\nanalogous works in the literature. These results highlight the potential of the\nproposed architecture to accelerate SC execution and enhance the performance of\nEVM-compatible blockchains."}
{"id": "2507.23129", "categories": ["eess.IV", "cs.CV", "physics.med-ph"], "pdf": "https://arxiv.org/pdf/2507.23129", "abs": "https://arxiv.org/abs/2507.23129", "authors": ["Felix Frederik Zimmermann", "Patrick Schuenke", "Christoph S. Aigner", "Bill A. Bernhardt", "Mara Guastini", "Johannes Hammacher", "Noah Jaitner", "Andreas Kofler", "Leonid Lunin", "Stefan Martin", "Catarina Redshaw Kranich", "Jakob Schattenfroh", "David Schote", "Yanglei Wu", "Christoph Kolbitsch"], "title": "MRpro - open PyTorch-based MR reconstruction and processing package", "comment": "Submitted to Magnetic Resonance in Medicine", "summary": "We introduce MRpro, an open-source image reconstruction package built upon\nPyTorch and open data formats. The framework comprises three main areas. First,\nit provides unified data structures for the consistent manipulation of MR\ndatasets and their associated metadata (e.g., k-space trajectories). Second, it\noffers a library of composable operators, proximable functionals, and\noptimization algorithms, including a unified Fourier operator for all common\ntrajectories and an extended phase graph simulation for quantitative MR. These\ncomponents are used to create ready-to-use implementations of key\nreconstruction algorithms. Third, for deep learning, MRpro includes essential\nbuilding blocks such as data consistency layers, differentiable optimization\nlayers, and state-of-the-art backbone networks and integrates public datasets\nto facilitate reproducibility. MRpro is developed as a collaborative project\nsupported by automated quality control. We demonstrate the versatility of MRpro\nacross multiple applications, including Cartesian, radial, and spiral\nacquisitions; motion-corrected reconstruction; cardiac MR fingerprinting;\nlearned spatially adaptive regularization weights; model-based learned image\nreconstruction and quantitative parameter estimation. MRpro offers an\nextensible framework for MR image reconstruction. With reproducibility and\nmaintainability at its core, it facilitates collaborative development and\nprovides a foundation for future MR imaging research."}
{"id": "2507.23526", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.23526", "abs": "https://arxiv.org/abs/2507.23526", "authors": ["Wen-Xuan Long", "Shengyu Ye", "Marco Moretti", "Michele Morelli", "Luca Sanguinetti", "Rui Chen", "Cheng-Xiang Wang"], "title": "Channel Estimation for 6G Near-Field Wireless Communications: A Comprehensive Survey", "comment": null, "summary": "The sixth-generation (6G) wireless systems are expected to adopt extremely\nlarge aperture arrays (ELAAs), novel antenna architectures, and operate in\nextremely high-frequency bands to meet growing data demands. ELAAs\nsignificantly increase the number of antennas, enabling finer spatial\nresolution and improved beamforming. At high frequencies, ELAAs shift\ncommunication from the conventional far-field to near-field regime, where\nspherical wavefronts dominate and the channel response depends on both angle\nand distance, increasing channel dimensionality. Conventional far-field channel\nestimation methods, which rely on angular information, struggle in near-field\nscenarios due to increased pilot overhead and computational complexity. This\npaper presents a comprehensive survey of recent advances in near-field channel\nestimation. It first defines the near- and far-field boundary from an\nelectromagnetic perspective and discusses key propagation differences,\nalongside a brief review of ELAA developments. Then, it introduces mainstream\nnear-field channel models and compares them with far-field models. Major\nestimation techniques are reviewed under different configurations\n(single/multi-user, single/multi-carrier), including both direct estimation and\nRIS-assisted cascaded estimation. These techniques reveal trade-offs among\nestimation accuracy, complexity, and overhead. This survey aims to provide\ninsights and foundations for efficient and scalable near-field channel\nestimation in 6G systems, while identifying key challenges and future research\ndirections."}
{"id": "2507.23219", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.23219", "abs": "https://arxiv.org/abs/2507.23219", "authors": ["Yang Ren", "Hai Jiang", "Wei Li", "Menglong Yang", "Heng Zhang", "Zehua Sheng", "Qingsheng Ye", "Shuaicheng Liu"], "title": "Learning Arbitrary-Scale RAW Image Downscaling with Wavelet-based Recurrent Reconstruction", "comment": "Accepted by ACM MM 2025", "summary": "Image downscaling is critical for efficient storage and transmission of\nhigh-resolution (HR) images. Existing learning-based methods focus on\nperforming downscaling within the sRGB domain, which typically suffers from\nblurred details and unexpected artifacts. RAW images, with their unprocessed\nphotonic information, offer greater flexibility but lack specialized\ndownscaling frameworks. In this paper, we propose a wavelet-based recurrent\nreconstruction framework that leverages the information lossless attribute of\nwavelet transformation to fulfill the arbitrary-scale RAW image downscaling in\na coarse-to-fine manner, in which the Low-Frequency Arbitrary-Scale Downscaling\nModule (LASDM) and the High-Frequency Prediction Module (HFPM) are proposed to\npreserve structural and textural integrity of the reconstructed low-resolution\n(LR) RAW images, alongside an energy-maximization loss to align high-frequency\nenergy between HR and LR domain. Furthermore, we introduce the Realistic\nNon-Integer RAW Downscaling (Real-NIRD) dataset, featuring a non-integer\ndownscaling factor of 1.3$\\times$, and incorporate it with publicly available\ndatasets with integer factors (2$\\times$, 3$\\times$, 4$\\times$) for\ncomprehensive benchmarking arbitrary-scale image downscaling purposes.\nExtensive experiments demonstrate that our method outperforms existing\nstate-of-the-art competitors both quantitatively and visually. The code and\ndataset will be released at https://github.com/RenYangSCU/ASRD."}
{"id": "2507.23570", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.23570", "abs": "https://arxiv.org/abs/2507.23570", "authors": ["Manjun Cui", "Zhichao Zhang", "Wei Yao"], "title": "Multiple-Parameter Graph Fractional Fourier Transform: Theory and Applications", "comment": null, "summary": "The graph fractional Fourier transform (GFRFT) applies a single global\nfractional order to all graph frequencies, which restricts its adaptability to\ndiverse signal characteristics across the spectral domain. To address this\nlimitation, in this paper, we propose two types of multiple-parameter GFRFTs\n(MPGFRFTs) and establish their corresponding theoretical frameworks. We design\na spectral compression strategy tailored for ultra-low compression ratios,\neffectively preserving essential information even under extreme dimensionality\nreduction. To enhance flexibility, we introduce a learnable order vector scheme\nthat enables adaptive compression and denoising, demonstrating strong\nperformance on both graph signals and images. We explore the application of\nMPGFRFTs to image encryption and decryption. Experimental results validate the\nversatility and superior performance of the proposed MPGFRFT framework across\nvarious graph signal processing tasks."}
{"id": "2507.23224", "categories": ["eess.IV", "eess.SP"], "pdf": "https://arxiv.org/pdf/2507.23224", "abs": "https://arxiv.org/abs/2507.23224", "authors": ["Syed M. Arshad", "Lee C. Potter", "Yingmin Liu", "Christopher Crabtree", "Matthew S. Tong", "Rizwan Ahmad"], "title": "EMORe: Motion-Robust 5D MRI Reconstruction via Expectation-Maximization-Guided Binning Correction and Outlier Rejection", "comment": null, "summary": "We propose EMORe, an adaptive reconstruction method designed to enhance\nmotion robustness in free-running, free-breathing self-gated 5D cardiac\nmagnetic resonance imaging (MRI). Traditional self-gating-based motion binning\nfor 5D MRI often results in residual motion artifacts due to inaccuracies in\ncardiac and respiratory signal extraction and sporadic bulk motion,\ncompromising clinical utility. EMORe addresses these issues by integrating\nadaptive inter-bin correction and explicit outlier rejection within an\nexpectation-maximization (EM) framework, whereby the E-step and M-step are\nexecuted alternately until convergence. In the E-step, probabilistic (soft) bin\nassignments are refined by correcting misassignment of valid data and rejecting\nmotion-corrupted data to a dedicated outlier bin. In the M-step, the image\nestimate is improved using the refined soft bin assignments. Validation in a\nsimulated 5D MRXCAT phantom demonstrated EMORe's superior performance compared\nto standard compressed sensing reconstruction, showing significant improvements\nin peak signal-to-noise ratio, structural similarity index, edge sharpness, and\nbin assignment accuracy across varying levels of simulated bulk motion. In vivo\nvalidation in 13 volunteers further confirmed EMORe's robustness, significantly\nenhancing blood-myocardium edge sharpness and reducing motion artifacts\ncompared to compressed sensing, particularly in scenarios with controlled\ncoughing-induced motion. Although EMORe incurs a modest increase in\ncomputational complexity, its adaptability and robust handling of bulk motion\nartifacts significantly enhance the clinical applicability and diagnostic\nconfidence of 5D cardiac MRI."}
{"id": "2507.23695", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.23695", "abs": "https://arxiv.org/abs/2507.23695", "authors": ["Mouli Chakraborty", "Subhash Chandra", "Avishek Nag", "Anshu Mukherjee"], "title": "On the Achievable Rate of Satellite Quantum Communication Channel using Deep Autoencoder Gaussian Mixture Model", "comment": null, "summary": "We present a comparative study of the Gaussian mixture model (GMM) and the\nDeep Autoencoder Gaussian Mixture Model (DAGMM) for estimating satellite\nquantum channel capacity, considering hybrid quantum noise (HQN) and\ntransmission constraints. While GMM is simple and interpretable, DAGMM better\ncaptures non-linear variations and noise distributions. Simulations show that\nDAGMM provides tighter capacity bounds and improved clustering. This introduces\nthe Deep Cluster Gaussian Mixture Model (DCGMM) for high-dimensional quantum\ndata analysis in quantum satellite communication."}
{"id": "2507.23256", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.23256", "abs": "https://arxiv.org/abs/2507.23256", "authors": ["Ahmed Jaheen", "Abdelrahman Elsayed", "Damir Kim", "Daniil Tikhonov", "Matheus Scatolin", "Mohor Banerjee", "Qiankun Ji", "Mostafa Salem", "Hu Wang", "Sarim Hashmi", "Mohammad Yaqub"], "title": "EMedNeXt: An Enhanced Brain Tumor Segmentation Framework for Sub-Saharan Africa using MedNeXt V2 with Deep Supervision", "comment": "Submitted to the BraTS-Lighthouse 2025 Challenge (MICCAI 2025)", "summary": "Brain cancer affects millions worldwide, and in nearly every clinical\nsetting, doctors rely on magnetic resonance imaging (MRI) to diagnose and\nmonitor gliomas. However, the current standard for tumor quantification through\nmanual segmentation of multi-parametric MRI is time-consuming, requires expert\nradiologists, and is often infeasible in under-resourced healthcare systems.\nThis problem is especially pronounced in low-income regions, where MRI scanners\nare of lower quality and radiology expertise is scarce, leading to incorrect\nsegmentation and quantification. In addition, the number of acquired MRI scans\nin Africa is typically small. To address these challenges, the BraTS-Lighthouse\n2025 Challenge focuses on robust tumor segmentation in sub-Saharan Africa\n(SSA), where resource constraints and image quality degradation introduce\nsignificant shifts. In this study, we present EMedNeXt -- an enhanced brain\ntumor segmentation framework based on MedNeXt V2 with deep supervision and\noptimized post-processing pipelines tailored for SSA. EMedNeXt introduces three\nkey contributions: a larger region of interest, an improved nnU-Net v2-based\narchitectural skeleton, and a robust model ensembling system. Evaluated on the\nhidden validation set, our solution achieved an average LesionWise DSC of 0.897\nwith an average LesionWise NSD of 0.541 and 0.84 at a tolerance of 0.5 mm and\n1.0 mm, respectively."}
{"id": "2507.23707", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.23707", "abs": "https://arxiv.org/abs/2507.23707", "authors": ["Renato Luis Garrido Cavalcante", "Tomasz Piotrowski", "Slawomir Stanczak"], "title": "Cellular, Cell-less, and Everything in Between: A Unified Framework for Utility Region Analysis in Wireless Networks", "comment": null, "summary": "We introduce a unified framework for analyzing utility regions of wireless\nnetworks, with a focus on the signal-to-interference-noise-ratio (SINR) and\nachievable rate regions. The framework provides valuable insights into\ninterference patterns of modern network architectures, such as cell-less and\nextremely large MIMO networks, and it generalizes existing characterizations of\nthe weak Pareto boundary. A central contribution is the derivation of\nsufficient conditions that guarantee convexity of the utility regions.\nConvexity is an important property because it ensures that time sharing (or\nuser grouping) cannot simultaneously increase the utility of all users when the\nnetwork operates on the weak Pareto boundary. These sufficient conditions also\nhave two key implications. First, they identify a family of (weighted) sum-rate\nmaximization problems that are inherently convex without any variable\ntransformations, thus paving the way for the development of efficient, provably\noptimal solvers for this family. Second, they provide a rigorous justification\nfor formulating sum-rate maximization problems directly in terms of achievable\nrates, rather than SINR levels. Our theoretical insights also motivate an\nalternative to the concept of favorable propagation in the massive MIMO\nliterature -- one that explicitly accounts for self-interference and the\nbeamforming strategy."}
{"id": "2507.23359", "categories": ["eess.IV", "cs.CV", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2507.23359", "abs": "https://arxiv.org/abs/2507.23359", "authors": ["Huayu Fu", "Jiamin Li", "Haozhi Qu", "Xiaolin Hu", "Zengcai Guo"], "title": "Pixel Embedding Method for Tubular Neurite Segmentation", "comment": null, "summary": "Automatic segmentation of neuronal topology is critical for handling large\nscale neuroimaging data, as it can greatly accelerate neuron annotation and\nanalysis. However, the intricate morphology of neuronal branches and the\nocclusions among fibers pose significant challenges for deep learning based\nsegmentation. To address these issues, we propose an improved framework: First,\nwe introduce a deep network that outputs pixel level embedding vectors and\ndesign a corresponding loss function, enabling the learned features to\neffectively distinguish different neuronal connections within occluded regions.\nSecond, building on this model, we develop an end to end pipeline that directly\nmaps raw neuronal images to SWC formatted neuron structure trees. Finally,\nrecognizing that existing evaluation metrics fail to fully capture segmentation\naccuracy, we propose a novel topological assessment metric to more\nappropriately quantify the quality of neuron segmentation and reconstruction.\nExperiments on our fMOST imaging dataset demonstrate that, compared to several\nclassical methods, our approach significantly reduces the error rate in\nneuronal topology reconstruction."}
{"id": "2507.23746", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.23746", "abs": "https://arxiv.org/abs/2507.23746", "authors": ["Hossein Kazemi", "Isaac N. O. Osahon", "Tiankuo Jiao", "David Butler", "Nikolay Ledentsov Jr.", "Ilya Titkov", "Nikolay Ledentsov", "Harald Haas"], "title": "Real-Time Transmission of Uncompressed High-Definition Video Via A VCSEL-Based Optical Wireless Link With Ultra-Low Latency", "comment": "8 pages, 6 figures, 2 tables", "summary": "Real-time transmission of high-resolution video signals in an uncompressed\nand unencrypted format requires an ultra-reliable and low-latency\ncommunications (URLLC) medium with high bandwidth to maintain the quality of\nexperience (QoE) for users. We put forward the design and experimental\ndemonstration of a high-performance laser-based optical wireless communication\n(OWC) system that enables high-definition (HD) video transmission with\nsubmillisecond latencies. The serial digital interface (SDI) output of a camera\nis used to transmit the live video stream over an optical wireless link by\ndirectly modulating the SDI signal on the intensity of a 940 nm vertical cavity\nsurface emitting laser (VCSEL). The proposed SDI over light fidelity (LiFi)\nsystem corroborates error-free transmission of full HD (FHD) and 4K\nultra-high-definition (UHD) resolutions at data rates of 2.97 Gb/s and 5.94\nGb/s, respectively, with a measured end-to-end latency of under 35 ns. Since\nSDI standards support various video formats and VCSELs are high-bandwidth and\nlow-power devices, this presents a scalable and inexpensive solution for\nwireless connectivity between professional broadcast equipment using\noff-the-shelf SDI components."}
{"id": "2507.23398", "categories": ["eess.IV", "cs.AR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.23398", "abs": "https://arxiv.org/abs/2507.23398", "authors": ["Oliver Bause", "Julia Werner", "Paul Palomero Bernardo", "Oliver Bringmann"], "title": "Smart Video Capsule Endoscopy: Raw Image-Based Localization for Enhanced GI Tract Investigation", "comment": "Accepted at the 32nd International Conference on Neural Information\n  Processing - ICONIP 2025", "summary": "For many real-world applications involving low-power sensor edge devices deep\nneural networks used for image classification might not be suitable. This is\ndue to their typically large model size and require- ment of operations often\nexceeding the capabilities of such resource lim- ited devices. Furthermore,\ncamera sensors usually capture images with a Bayer color filter applied, which\nare subsequently converted to RGB images that are commonly used for neural\nnetwork training. However, on resource-constrained devices, such conversions\ndemands their share of energy and optimally should be skipped if possible. This\nwork ad- dresses the need for hardware-suitable AI targeting sensor edge\ndevices by means of the Video Capsule Endoscopy, an important medical proce-\ndure for the investigation of the small intestine, which is strongly limited by\nits battery lifetime. Accurate organ classification is performed with a final\naccuracy of 93.06% evaluated directly on Bayer images involv- ing a CNN with\nonly 63,000 parameters and time-series analysis in the form of Viterbi\ndecoding. Finally, the process of capturing images with a camera and raw image\nprocessing is demonstrated with a customized PULPissimo System-on-Chip with a\nRISC-V core and an ultra-low power hardware accelerator providing an\nenergy-efficient AI-based image clas- sification approach requiring just 5.31\n{\\mu}J per image. As a result, it is possible to save an average of 89.9% of\nenergy before entering the small intestine compared to classic video capsules."}
{"id": "2507.23224", "categories": ["eess.IV", "eess.SP"], "pdf": "https://arxiv.org/pdf/2507.23224", "abs": "https://arxiv.org/abs/2507.23224", "authors": ["Syed M. Arshad", "Lee C. Potter", "Yingmin Liu", "Christopher Crabtree", "Matthew S. Tong", "Rizwan Ahmad"], "title": "EMORe: Motion-Robust 5D MRI Reconstruction via Expectation-Maximization-Guided Binning Correction and Outlier Rejection", "comment": null, "summary": "We propose EMORe, an adaptive reconstruction method designed to enhance\nmotion robustness in free-running, free-breathing self-gated 5D cardiac\nmagnetic resonance imaging (MRI). Traditional self-gating-based motion binning\nfor 5D MRI often results in residual motion artifacts due to inaccuracies in\ncardiac and respiratory signal extraction and sporadic bulk motion,\ncompromising clinical utility. EMORe addresses these issues by integrating\nadaptive inter-bin correction and explicit outlier rejection within an\nexpectation-maximization (EM) framework, whereby the E-step and M-step are\nexecuted alternately until convergence. In the E-step, probabilistic (soft) bin\nassignments are refined by correcting misassignment of valid data and rejecting\nmotion-corrupted data to a dedicated outlier bin. In the M-step, the image\nestimate is improved using the refined soft bin assignments. Validation in a\nsimulated 5D MRXCAT phantom demonstrated EMORe's superior performance compared\nto standard compressed sensing reconstruction, showing significant improvements\nin peak signal-to-noise ratio, structural similarity index, edge sharpness, and\nbin assignment accuracy across varying levels of simulated bulk motion. In vivo\nvalidation in 13 volunteers further confirmed EMORe's robustness, significantly\nenhancing blood-myocardium edge sharpness and reducing motion artifacts\ncompared to compressed sensing, particularly in scenarios with controlled\ncoughing-induced motion. Although EMORe incurs a modest increase in\ncomputational complexity, its adaptability and robust handling of bulk motion\nartifacts significantly enhance the clinical applicability and diagnostic\nconfidence of 5D cardiac MRI."}
{"id": "2507.23521", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.23521", "abs": "https://arxiv.org/abs/2507.23521", "authors": ["Woo Kyoung Han", "Yongjun Lee", "Byeonghun Lee", "Sang Hyun Park", "Sunghoon Im", "Kyong Hwan Jin"], "title": "JPEG Processing Neural Operator for Backward-Compatible Coding", "comment": null, "summary": "Despite significant advances in learning-based lossy compression algorithms,\nstandardizing codecs remains a critical challenge. In this paper, we present\nthe JPEG Processing Neural Operator (JPNeO), a next-generation JPEG algorithm\nthat maintains full backward compatibility with the current JPEG format. Our\nJPNeO improves chroma component preservation and enhances reconstruction\nfidelity compared to existing artifact removal methods by incorporating neural\noperators in both the encoding and decoding stages. JPNeO achieves practical\nbenefits in terms of reduced memory usage and parameter count. We further\nvalidate our hypothesis about the existence of a space with high mutual\ninformation through empirical evidence. In summary, the JPNeO functions as a\nhigh-performance out-of-the-box image compression pipeline without changing\nsource coding's protocol. Our source code is available at\nhttps://github.com/WooKyoungHan/JPNeO."}
{"id": "2507.23648", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.23648", "abs": "https://arxiv.org/abs/2507.23648", "authors": ["Louise Guillon", "Soheib Biga", "Yendoube E. Kantchire", "Mouhamadou Lamine Sane", "Grégoire Pasquier", "Kossi Yakpa", "Stéphane E. Sossou", "Marc Thellier", "Laurent Bonnardot", "Laurence Lachaud", "Renaud Piarroux", "Ameyo M. Dorkenoo"], "title": "Towards Field-Ready AI-based Malaria Diagnosis: A Continual Learning Approach", "comment": "MICCAI 2025 AMAI Workshop, Accepted, Submitted Manuscript Version", "summary": "Malaria remains a major global health challenge, particularly in low-resource\nsettings where access to expert microscopy may be limited. Deep learning-based\ncomputer-aided diagnosis (CAD) systems have been developed and demonstrate\npromising performance on thin blood smear images. However, their clinical\ndeployment may be hindered by limited generalization across sites with varying\nconditions. Yet very few practical solutions have been proposed. In this work,\nwe investigate continual learning (CL) as a strategy to enhance the robustness\nof malaria CAD models to domain shifts. We frame the problem as a\ndomain-incremental learning scenario, where a YOLO-based object detector must\nadapt to new acquisition sites while retaining performance on previously seen\ndomains. We evaluate four CL strategies, two rehearsal-based and two\nregularization-based methods, on real-life conditions thanks to a multi-site\nclinical dataset of thin blood smear images. Our results suggest that CL, and\nrehearsal-based methods in particular, can significantly improve performance.\nThese findings highlight the potential of continual learning to support the\ndevelopment of deployable, field-ready CAD tools for malaria."}
{"id": "2507.23763", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.23763", "abs": "https://arxiv.org/abs/2507.23763", "authors": ["Liu Li", "Qiang Ma", "Cheng Ouyang", "Johannes C. Paetzold", "Daniel Rueckert", "Bernhard Kainz"], "title": "Topology Optimization in Medical Image Segmentation with Fast Euler Characteristic", "comment": null, "summary": "Deep learning-based medical image segmentation techniques have shown\npromising results when evaluated based on conventional metrics such as the Dice\nscore or Intersection-over-Union. However, these fully automatic methods often\nfail to meet clinically acceptable accuracy, especially when topological\nconstraints should be observed, e.g., continuous boundaries or closed surfaces.\nIn medical image segmentation, the correctness of a segmentation in terms of\nthe required topological genus sometimes is even more important than the\npixel-wise accuracy. Existing topology-aware approaches commonly estimate and\nconstrain the topological structure via the concept of persistent homology\n(PH). However, these methods are difficult to implement for high dimensional\ndata due to their polynomial computational complexity. To overcome this\nproblem, we propose a novel and fast approach for topology-aware segmentation\nbased on the Euler Characteristic ($\\chi$). First, we propose a fast\nformulation for $\\chi$ computation in both 2D and 3D. The scalar $\\chi$ error\nbetween the prediction and ground-truth serves as the topological evaluation\nmetric. Then we estimate the spatial topology correctness of any segmentation\nnetwork via a so-called topological violation map, i.e., a detailed map that\nhighlights regions with $\\chi$ errors. Finally, the segmentation results from\nthe arbitrary network are refined based on the topological violation maps by a\ntopology-aware correction network. Our experiments are conducted on both 2D and\n3D datasets and show that our method can significantly improve topological\ncorrectness while preserving pixel-wise segmentation accuracy."}
{"id": "2507.23236", "categories": ["eess.SP", "eess.IV"], "pdf": "https://arxiv.org/pdf/2507.23236", "abs": "https://arxiv.org/abs/2507.23236", "authors": ["Zhuoyin Dai", "Di Wu", "Yong Zeng", "Xiaoli Xu", "Xinyi Wang", "Zesong Fei"], "title": "BS-1-to-N: Diffusion-Based Environment-Aware Cross-BS Channel Knowledge Map Generation for Cell-Free Networks", "comment": null, "summary": "Channel knowledge map (CKM) inference across base stations (BSs) is the key\nto achieving efficient environmentaware communications. This paper proposes an\nenvironmentaware cross-BS CKM inference method called BS-1-to-N based on the\ngenerative diffusion model. To this end, we first design the BS location\nembedding (BSLE) method tailored for cross-BS CKM inference to embed BS\nlocation information in the feature vector of CKM. Further, we utilize the\ncross- and self-attention mechanism for the proposed BS-1-to-N model to\nrespectively learn the relationships between source and target BSs, as well as\nthat among target BSs. Therefore, given the locations of the source and target\nBSs, together with the source CKMs as control conditions, cross-BS CKM\ninference can be performed for an arbitrary number of source and target BSs.\nSpecifically, in architectures with massive distributed nodes like cell-free\nnetworks, traditional methods of sequentially traversing each BS for CKM\nconstruction are prohibitively costly. By contrast, the proposed BS-1-to-N\nmodel is able to achieve efficient CKM inference for a target BS at any\npotential location based on the CKMs of source BSs. This is achieved by\nexploiting the fact that within a given area, different BSs share the same\nwireless environment that leads to their respective CKMs. Therefore, similar to\nmulti-view synthesis, CKMs of different BSs are representations of the same\nwireless environment from different BS locations. By mining the implicit\ncorrelation between CKM and BS location based on the wireless environment, the\nproposed BS-1-to-N method achieves efficient CKM inference across BSs. We\nprovide extensive comparisons of CKM inference between the proposed BS-1-to-N\ngenerative model versus benchmarking schemes, and provide one use case study to\ndemonstrate its practical application for the optimization of BS deployment."}
