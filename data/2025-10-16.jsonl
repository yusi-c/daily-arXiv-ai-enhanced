{"id": "2510.12910", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.12910", "abs": "https://arxiv.org/abs/2510.12910", "authors": ["Neda Abdollahpour", "N. Sertac Artan", "Ian Daly", "Mohammadreza Yazdchi", "Zahra Baharlouei"], "title": "Effective Connectivity-Based Unsupervised Channel Selection Method for EEG", "comment": "(This The paper has been accepted for publication in the Journal of\n  Medical Signals & Sensors and will appear soon", "summary": "Analyzing neural data such as Electroencephalography (EEG) data often\ninvolves dealing with high-dimensional datasets, where not all channels provide\nequally meaningful informa- tion. Selecting the most relevant channels is\ncrucial for improving computational efficiency and ensuring robust insights\ninto neural dynamics. This study introduces the Importance of Channels based on\nEffective Connectivity (ICEC) criterion for quantifying effective connectivity\n(EC) in each channel. Effective connectivity refers to the causal influence one\nneural region exerts over another, providing insights into the directional flow\nof information. Using this criterion, we propose an unsupervised channel\nselection method that accounts for the intensity of interactions among\nchannels. To evaluate the proposed channel selection method, we applied it to\nthree well-known EEG datasets across four categories. The assessment involved\ncalculating the ICEC criterion using five effective connectivity metrics:\npartial directed coherence (PDC), generalized PDC (GPDC), renormalized PDC\n(RPDC), directed transfer function (DTF), and direct DTF (dDTF). To focus on\nthe effect of channel selection, we employed the Common Spatial Pattern (CSP)\nalgorithm for feature extraction and a Support Vector Machine (SVM) for\nclassification across all participants. Results were compared with other\nCSP-based methods. The evaluation included comparing participant- specific\naccuracies with and without the proposed method across five effective\nconnectivity metrics. The results showed consistent performance improvements\nand a significant reduction in the number of selected electrodes for all\nparticipants. Compared to state-of-the-art methods, our approach achieved the\nhighest accuracies: 82% (13 out of 22 channels), 86.01% (29 out of 59\nchannels), and 87.56% (48 out of 118 channels) across three datasets."}
{"id": "2510.12912", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.12912", "abs": "https://arxiv.org/abs/2510.12912", "authors": ["Abdelali Arous", "Hamza Haif", "Huseyin Arslan"], "title": "Enabling Full Duplex ISAC Leveraging Waveform Domain Separability", "comment": null, "summary": "Integrated sensing and communication (ISAC) in monostatic in-band full-duplex\n(IBFD) systems encounters significant challenges due to self-interference (SI)\nat the radar receiver during concurrent communication and radar operations.\nThis paper proposes a novel waveform-domain self-interference cancellation\n(SIC) technique that leverages the unique properties of orthogonal frequency\ndivision multiplexing (OFDM) and affine frequency division multiplexing (AFDM)\nsignals. The proposed approach designs the integrated dual-functionality frame\nto utilize OFDM for communication and AFDM for radar sensing, both generated\nusing the same modulator block. Then, we establish the conditions under which a\nwide sense stationary (WSS) process in the time domain appears as WSS in the\naffine domain and demonstrate that the interfering OFDM signal behaves as an\nadditive white Gaussian noise (AWGN) in this domain. Exploiting this property,\nthe received signal is projected into the affine domain, where the SI appears\nas AWGN, enabling its subtraction with minimal residual interference. To\nfurther mitigate the residual SI, an iterative low-complexity windowing scheme\nis applied, selectively locking onto the radar signal to reduce the processed\nsignal space. A subsequent time-domain spreading step is applied after\nconverting the SIC-processed signal into the post-coded time domain, wherein\nthe SI diminishes separately across the delay and Doppler axes. The proposed\nmethod demonstrates superior performance in terms of detection probability,\ntarget range and velocity root mean square error (RMSE), while maintaining high\nspectral efficiency and minimal computational complexity."}
{"id": "2510.12930", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.12930", "abs": "https://arxiv.org/abs/2510.12930", "authors": ["Cory Hilton", "Mohammad Rashid", "Faiz Sherman", "Steven Bush", "Jeffrey A. Nanzer"], "title": "Passive Microwave Tag Classification Using RF Fingerprinting and Machine Learning", "comment": "7 pages,7 figures", "summary": "We present an approach to identifying wireless microwave tags using radio\nfrequency (RF) fingerprinting and machine learning. The tags are designed for\nlow cost and simplicity, consisting of only two antennas and a single nonlinear\nelement (a diode). An interrogating transceiver transmits a signal consisting\nof a set of individual frequency tones that is captured by the tag. The signal\nresponse of the diode is nonlinear, and can be represented by an infinite power\nseries, the coefficients of which are similar but not identical for different\nphysical diodes due to small manufacturing perturbations. The small differences\nin the signal responses manifest in the spectral signal response of the tag,\nwhich is retransmitted back to the interrogating transceiver. Input into\nmachine learning algorithms, the slight differences in the spectral responses\nof the diodes can be used to uniquely identify devices. To demonstrate the\nconcept, we designed 2.0 GHz tags consisting of patch antennas and a single\ndiode, along with a bi-static radar system operating at the 2.0 GHz 802.11\nWi-Fi band transmitting multi-tone continuous wave signals representing common\n802.11 training fields. The received signals were processed using a set of\nalgorithms for comparison purposes. A real-time classification accuracy of 95%\nbetween two tags was achieved."}
{"id": "2510.12941", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.12941", "abs": "https://arxiv.org/abs/2510.12941", "authors": ["SaiKrishna Saketh Yellapragada", "Atchutaram K. Kocharlakota", "Mário Costa", "Esa Ollila", "Sergiy A. Vorobyov"], "title": "Computationally Efficient Neural Receivers via Axial Self-Attention", "comment": "Submitted for IEEE International Conference on Communications", "summary": "Deep learning-based neural receivers are redefining physical-layer signal\nprocessing for next-generation wireless systems. We propose an axial\nself-attention transformer neural receiver designed for applicability to 6G and\nbeyond wireless systems, validated through 5G-compliant experimental\nconfigurations, that achieves state-of-the-art block error rate (BLER)\nperformance with significantly improved computational efficiency. By\nfactorizing attention operations along temporal and spectral axes, the proposed\narchitecture reduces the quadratic complexity of conventional multi-head\nself-attention from $O((TF)^2)$ to $O(T^2F+TF^2)$, yielding substantially fewer\ntotal floating-point operations and attention matrix multiplications per\ntransformer block compared to global self-attention. Relative to convolutional\nneural receiver baselines, the axial neural receiver achieves significantly\nlower computational cost with a fraction of the parameters. Experimental\nvalidation under 3GPP Clustered Delay Line (CDL) channels demonstrates\nconsistent performance gains across varying mobility scenarios. Under\nnon-line-of-sight CDL-C conditions, the axial neural receiver consistently\noutperforms all evaluated receiver architectures, including global\nself-attention, convolutional neural receivers, and traditional LS-LMMSE at\n10\\% BLER with reduced computational complexity per inference. At stringent\nreliability targets of 1\\% BLER, the axial receiver maintains robust symbol\ndetection at high user speeds, whereas the traditional LS-LMMSE receiver fails\nto converge, underscoring its suitability for ultra-reliable low-latency\n(URLLC) communication in dynamic 6G environments and beyond. These results\nestablish the axial neural receiver as a structured, scalable, and efficient\nframework for AI-Native 6G RAN systems, enabling deployment in\nresource-constrained edge environments."}
{"id": "2510.13188", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2510.13188", "abs": "https://arxiv.org/abs/2510.13188", "authors": ["Sudipta Paul", "Amanda W. Lund", "George Jour", "Iman Osman", "Bülent Yener"], "title": "Approximate Bilevel Graph Structure Learning for Histopathology Image Classification", "comment": "Manuscript under review", "summary": "The structural and spatial arrangements of cells within tissues represent\ntheir functional states, making graph-based learning highly suitable for\nhistopathology image analysis. Existing methods often rely on fixed graphs with\npredefined edges, limiting their ability to capture the true biological\ncomplexity of tissue interactions. In this work, we propose ABiG-Net\n(Approximate Bilevel Optimization for Graph Structure Learning via Neural\nNetworks), a novel framework designed to learn optimal interactions between\npatches within whole slide images (WSI) or large regions of interest (ROI)\nwhile simultaneously learning discriminative node embeddings for the downstream\nimage classification task. Our approach hierarchically models the tissue\narchitecture at local and global scales. At the local scale, we construct\npatch-level graphs from cellular orientation within each patch and extract\nfeatures to quantify local structures. At the global scale, we learn an\nimage-level graph that captures sparse, biologically meaningful connections\nbetween patches through a first-order approximate bilevel optimization\nstrategy. The learned global graph is optimized in response to classification\nperformance, capturing the long-range contextual dependencies across the image.\nBy unifying local structural information with global contextual relationships,\nABiG-Net enhances interpretability and downstream performance. Experiments on\ntwo histopathology datasets demonstrate its effectiveness: on the Extended CRC\ndataset, ABiG-Net achieves 97.33 $\\pm$ 1.15 % accuracy for three-class\ncolorectal cancer grading and 98.33 $\\pm$ 0.58 % for binary classification; on\nthe melanoma dataset, it attains 96.27 $\\pm$ 0.74 % for tumor-lymphocyte ROI\nclassification."}
{"id": "2510.12968", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.12968", "abs": "https://arxiv.org/abs/2510.12968", "authors": ["Najme Ebrahimi", "Arun Paidmarri", "Alexandra Gallyas-Sanhueza", "Yuan Ma", "Haoling Li", "Basem Abdelaziz Abdelmagid", "Tzu-Yuan Huang", "Hua Wang"], "title": "Towards Spectrally Efficient and Physically Reconfigurable Architectures for Multibeam-Waveform Co-Design in Joint Communication and Sensing", "comment": null, "summary": "Joint Communication and Sensing (JCAS) platforms are emerging as a foundation\nof next-generation mmWave (MMW) and sub-THz systems, enabling both\nhigh-throughput data transfer and angular localization within a shared signal\npath. This paper investigates multibeam architectures for JCAS that\nsimultaneously optimize waveform shaping and beamforming across the time,\nfrequency, code, and direct analog/ radio frequency (RF) domains. The paper\ncompares Orthogonal Frequency-Division Multiplexing (OFDM), Frequency Modulated\nArrays (FMA), Time-Modulated Arrays (TMA), direct RF/MMW modulation, and\nCode-Division Multiple Access (CDMA)-based systems with respect to spectral\nefficiency, beam orthogonality, latency, and Angle-of-Arrival (AoA) estimation\naccuracy. The results highlight architecture-specific tradeoffs among beam\nagility, efficiency, accuracy and resolution, and complexity. It also provides\na framework for selecting JCAS front ends optimized for power, latency,\ninter-beam and multi-user interference, and rapid system reconfiguration"}
{"id": "2510.13267", "categories": ["eess.IV", "cs.HC", "cs.MM"], "pdf": "https://arxiv.org/pdf/2510.13267", "abs": "https://arxiv.org/abs/2510.13267", "authors": ["Emanuele Artioli", "Farzad Tashtarian", "Christian Timmerer"], "title": "DIGITWISE: Digital Twin-based Modeling of Adaptive Video Streaming Engagement", "comment": "ACM Multimedia Systems Conference 2024 (MMSys '24), April 15--18,\n  2024, Bari, Italy", "summary": "As the popularity of video streaming entertainment continues to grow,\nunderstanding how users engage with the content and react to its changes\nbecomes a critical success factor for every stakeholder. User engagement, i.e.,\nthe percentage of video the user watches before quitting, is central to\ncustomer loyalty, content personalization, ad relevance, and A/B testing. This\npaper presents DIGITWISE, a digital twin-based approach for modeling adaptive\nvideo streaming engagement. Traditional adaptive bitrate (ABR) algorithms\nassume that all users react similarly to video streaming artifacts and network\nissues, neglecting individual user sensitivities. DIGITWISE leverages the\nconcept of a digital twin, a digital replica of a physical entity, to model\nuser engagement based on past viewing sessions. The digital twin receives input\nabout streaming events and utilizes supervised machine learning to predict user\nengagement for a given session. The system model consists of a data processing\npipeline, machine learning models acting as digital twins, and a unified model\nto predict engagement. DIGITWISE employs the XGBoost model in both digital\ntwins and unified models. The proposed architecture demonstrates the importance\nof personal user sensitivities, reducing user engagement prediction error by up\nto 5.8% compared to non-user-aware models. Furthermore, DIGITWISE can optimize\ncontent provisioning and delivery by identifying the features that maximize\nengagement, providing an average engagement increase of up to 8.6%."}
{"id": "2510.13101", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.13101", "abs": "https://arxiv.org/abs/2510.13101", "authors": ["Kawon Han", "Kaitao Meng", "Alexandra Chatzicharistou", "Christos Masouros"], "title": "Constellation Design in OFDM-ISAC over Data Payloads: From MSE Analysis to Experimentation", "comment": "6 pages", "summary": "Orthogonal frequency division multiplexing (OFDM) is one of the most widely\nadopted waveforms for integrated sensing and communication (ISAC) systems,\nowing to its high spectral efficiency and compatibility with modern\ncommunication standards. This paper investigates the sensing performance of\nOFDM-based ISAC for multi-target delay (range) estimation under specific radar\nreceiver processing schemes. An estimation-theoretic framework is developed to\ncharacterize sensing performance with random communication payloads. We\nestablish the fundamental limit of delay estimation accuracy by deriving the\nclosed-form expression of the mean-square error (MSE) achieved using matched\nfiltering (MF) and reciprocal filtering (RF) receivers. The results show that,\nin multi-target scenarios, the impact of signal constellations on the delay\nestimation MSE differs across receivers: MF performance depends on the\nfourth-order moment of the zero-mean, unit-power constellation in the presence\nof multiple targets, whereas RF performance depends on its inverse second-order\nmoment, irrespective of the number of targets. Building on this analysis, we\npresent a ISAC constellation design under specific receiver architecture that\nbrings a receiver-dependent flexible trade-off between sensing and\ncommunication in OFDM-ISAC systems. The theoretical findings are validated\nthrough simulations and proof-of-concept experiments, and also the sensing and\ncommunication performance trade-off is experimentally shown with the proposed\nconstellation design."}
{"id": "2510.13408", "categories": ["eess.IV", "cs.AI", "cs.IT", "cs.MM", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.13408", "abs": "https://arxiv.org/abs/2510.13408", "authors": ["Jingkai Ying", "Zhiyuan Qi", "Yulong Feng", "Zhijin Qin", "Zhu Han", "Rahim Tafazolli", "Yonina C. Eldar"], "title": "Semantic Communication Enabled Holographic Video Processing and Transmission", "comment": "7 pages, 6 figures, Submit for review", "summary": "Holographic video communication is considered a paradigm shift in visual\ncommunications, becoming increasingly popular for its ability to offer\nimmersive experiences. This article provides an overview of holographic video\ncommunication and outlines the requirements of a holographic video\ncommunication system. Particularly, following a brief review of semantic com-\nmunication, an architecture for a semantic-enabled holographic video\ncommunication system is presented. Key technologies, including semantic\nsampling, joint semantic-channel coding, and semantic-aware transmission, are\ndesigned based on the proposed architecture. Two related use cases are\npresented to demonstrate the performance gain of the proposed methods. Finally,\npotential research topics are discussed to pave the way for the realization of\nsemantic-enabled holographic video communications."}
{"id": "2510.13399", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.13399", "abs": "https://arxiv.org/abs/2510.13399", "authors": ["Shivani Ranjan", "Anant Jain", "Robin Badal", "Amit Kumar", "Harshal Shende", "Deepak Joshi", "Pramod Yadav", "Lalan Kumar"], "title": "Working Memory Functional Connectivity Analysis for Dementia Classification using EEG", "comment": null, "summary": "Background: Dementia, particularly Alzheimer's Disease (AD), is a progressive\nneurodegenerative disorder marked by cognitive decline. Early detection,\nespecially at the Mild Cognitive Impairment (MCI) stage, is essential for\ntimely intervention. Working Memory (WM) impairment is a key early indicator of\nneurodegeneration, affecting higher cognitive processes. Electroencephalography\n(EEG), with its high temporal resolution, offers a cost-effective method to\nassess brain dynamics. This study investigates WM-related EEG functional\nconnectivity (FC) to identify brain network alterations across dementia stages.\nMethods: EEG signals were recorded from 24 participants (8 AD, 8 MCI, and 8\nhealthy controls) during WM tasks, including encoding, recall, and retrieval\nstages. Data preprocessing involved noise reduction and feature extraction\nusing Spherical and Head Harmonic Decomposition (SHD, HHD). FC was quantified\nusing Cross-Plot Transition Entropy (CPTE) and Phase Lag Index (PLI). Network\nmetrics such as Degree and Eigenvector Centrality were analyzed using Support\nVector Machine, Random Forest, and XGBoost classifiers. Results: The CPTE-based\nconnectivity metrics outperformed the traditional PLI approach in\ndifferentiating dementia stages, attaining a peak classification accuracy of\n97.53% during the retrieval phase with the Random Forest model. A connectivity\nthreshold of 0.5 was optimal for network discrimination. SHD and HHD features\nalso demonstrated strong discriminative potential. AD subjects exhibited higher\nsynchronization patterns during WM tasks than healthy controls. Conclusions:\nThe integration of WM tasks with EEG-based FC analysis provides a robust\nframework for dementia classification. The proposed CPTE-based approach offers\na robust, scalable, non-invasive, and effective diagnostic tool for early\ndetection and monitoring of neurodegenerative diseases."}
{"id": "2510.13422", "categories": ["eess.IV", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.13422", "abs": "https://arxiv.org/abs/2510.13422", "authors": ["Jiangyuan Guo", "Wei Chen", "Yuxuan Sun", "Bo Ai"], "title": "How to Adapt Wireless DJSCC Symbols to Rate Constrained Wired Networks?", "comment": "Submitted to IEEE for possible publication", "summary": "Deep joint source-channel coding (DJSCC) has emerged as a robust alternative\nto traditional separate coding for communications through wireless channels.\nExisting DJSCC approaches focus primarily on point-to-point wireless\ncommunication scenarios, while neglecting end-to-end communication efficiency\nin hybrid wireless-wired networks such as 5G and 6G communication systems.\nConsiderable redundancy in DJSCC symbols against wireless channels becomes\ninefficient for long-distance wired transmission. Furthermore, DJSCC symbols\nmust adapt to the varying transmission rate of the wired network to avoid\ncongestion. In this paper, we propose a novel framework designed for efficient\nwired transmission of DJSCC symbols within hybrid wireless-wired networks,\nnamely Rate-Controllable Wired Adaptor (RCWA). RCWA achieves redundancy-aware\ncoding for DJSCC symbols to improve transmission efficiency, which removes\nconsiderable redundancy present in DJSCC symbols for wireless channels and\nencodes only source-relevant information into bits. Moreover, we leverage the\nLagrangian multiplier method to achieve controllable and continuous\nvariable-rate coding, which can encode given features into expected rates,\nthereby minimizing end-to-end distortion while satisfying given constraints.\nExtensive experiments on diverse datasets demonstrate the superior RD\nperformance and robustness of RCWA compared to existing baselines, validating\nits potential for wired resource utilization in hybrid transmission scenarios.\nSpecifically, our method can obtain peak signal-to-noise ratio gain of up to\n0.7dB and 4dB compared to neural network-based methods and digital baselines on\nCIFAR-10 dataset, respectively."}
{"id": "2510.13442", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.13442", "abs": "https://arxiv.org/abs/2510.13442", "authors": ["Lorenz Mohr", "Marc Miranda", "Sebastian Semper", "Julia Beuster", "Carsten Andrich", "Sebastian Giehl", "Christian Schneider", "Reiner S. Thomä"], "title": "Oscillator Drift Compensation by Line-of-Sight Tracking for Distributed Multisensor ISAC", "comment": "6 pages, 4 figures", "summary": "We observed synchronization mismatches in the form of non-smooth phase\nprogressions and drifts within mobile multisensor channel sounding\nmeasurements. However, performing Doppler estimation in a distributed\nmultisensor integrated sensing and communications (ISAC) system requires\ncoherence among the nodes, which implies a continuously differentiable phase\nprogression of the received signals. To correct the sounding data in\npost-processing, we extend traditional geometry-based drift compensation\nalgorithms by utilizing Kalman filtering for line-of-sight (LoS) tracking,\nwhich improves the robustness of the LoS estimate in multipath scenarios. This\napproach smooths the phase progression and enables the correction of\ntime-varying drifts while preserving relative sensor motion. Furthermore, we\npropose using the relative residual power after high-resolution parameter\nestimation (HRPE) as a metric for ground-truth-independent comparison of\npost-processing synchronization methods for recorded channel sounding data.\nResults show that the proposed approach outperforms traditional LoS estimation\nheuristics, reducing the relative residual power by more than 5 dB and the\ndelay-Doppler estimate root mean square errors (RMSEs) by approximately 60 %."}
{"id": "2510.13714", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.13714", "abs": "https://arxiv.org/abs/2510.13714", "authors": ["Dan Jacobellis", "Mateen Ulhaq", "Fabien Racapé", "Hyomin Choi", "Neeraja J. Yadwadkar"], "title": "Dedelayed: Deleting remote inference delay via on-device correction", "comment": null, "summary": "Remote inference allows lightweight devices to leverage powerful cloud\nmodels. However, communication network latency makes predictions stale and\nunsuitable for real-time tasks. To address this, we introduce Dedelayed, a\ndelay-corrective method that mitigates arbitrary remote inference delays,\nallowing the local device to produce low-latency outputs in real time. Our\nmethod employs a lightweight local model that processes the current frame and\nfuses in features that a heavyweight remote model computes from past frames. On\nvideo from the BDD100K driving dataset, Dedelayed improves semantic\nsegmentation accuracy over the stronger of the local-only and remote-only\nbaselines across all realistic communication network delays beyond 33 ms.\nWithout incurring additional delay, it improves accuracy by 6.4 mIoU compared\nto fully local inference and 9.8 mIoU compared to remote inference, for a\nround-trip delay of 100 ms. The advantage grows under longer delays and\nhigher-motion scenes, as delay-mitigated split inference sustains accuracy more\neffectively, providing clear advantages for real-time tasks that must remain\naligned with the current world state."}
{"id": "2510.13495", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.13495", "abs": "https://arxiv.org/abs/2510.13495", "authors": ["Dexin Kong", "Diana Pamela Moya Osorio", "Erik G. Larsson"], "title": "Radio over Fiber with Cascaded Structure: Algorithm for Uplink Positioning", "comment": null, "summary": "Recent advancements in polymer microwave fiber (PMF) technology have created\nsignificant opportunities for robust, low-cost, and high-speed sub-terahertz\n(THz) radio-over- fiber communications. Recognizing these potential benefits,\nthis paper explores a novel radio-over-fiber (RoF) structure that interconnects\nmultiple radio units (RUs) in cascade via fiber, envi- sioning its application\nin indoor scenarios. This structure creates a number of research opportunities\nwhen considering cascaded distortion effects introduced by non-linear power\namplifiers (PAs) at the RUs and the propagation channel over the fiber. We\npropose maximum-likelihood and non-linear least-squares algorithms to estimate\nthe propagation distance along the RoF and the time-of-arrival between the RoF\nand the user equipment. For the case of linear PAs, we derive the Cram\\'er-Rao\nlower bound to benchmark the performance of the estimators. Finally, we\ninvestigate the use of the system for uplink positioning. Our simulation\nresults demonstrate that the proposed estimators perform satisfactorily even\nwith the cascaded effects of non- linear PAs, and that the deployment of this\nRoF structure can enable new cost-effective opportunities for high-resolution\npositioning in indoor scenarios. In the numerical evaluation, we also use\nmeasured PMF characteristics for high-density polyethylene fibers."}
{"id": "2510.13760", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2510.13760", "abs": "https://arxiv.org/abs/2510.13760", "authors": ["Mikolaj Walczak", "Uttej Kallakuri", "Edward Humes", "Xiaomin Lin", "Tinoosh Mohsenin"], "title": "Invited Paper: BitMedViT: Ternary-Quantized Vision Transformer for Medical AI Assistants on the Edge", "comment": "Accepted at 2025 IEEE/ACM International Conf. on Computer-Aided\n  Design (ICCAD) Oct. 26-30 2025, Munich, DE", "summary": "Vision Transformers (ViTs) have demonstrated strong capabilities in\ninterpreting complex medical imaging data. However, their significant\ncomputational and memory demands pose challenges for deployment in real-time,\nresource-constrained mobile and wearable devices used in clinical environments.\nWe introduce, BiTMedViT, a new class of Edge ViTs serving as medical AI\nassistants that perform structured analysis of medical images directly on the\nedge. BiTMedViT utilizes ternary- quantized linear layers tailored for medical\nimaging and com- bines a training procedure with multi-query attention,\npreserving stability under ternary weights with low-precision activations.\nFurthermore, BiTMedViT employs task-aware distillation from a high-capacity\nteacher to recover accuracy lost due to extreme quantization. Lastly, we also\npresent a pipeline that maps the ternarized ViTs to a custom CUDA kernel for\nefficient memory bandwidth utilization and latency reduction on the Jetson Orin\nNano. Finally, BiTMedViT achieves 86% diagnostic accuracy (89% SOTA) on\nMedMNIST across 12 datasets, while reducing model size by 43x, memory traffic\nby 39x, and enabling 16.8 ms inference at an energy efficiency up to 41x that\nof SOTA models at 183.62 GOPs/J on the Orin Nano. Our results demonstrate a\npractical and scientifically grounded route for extreme-precision medical\nimaging ViTs deployable on the edge, narrowing the gap between algorithmic\nadvances and deployable clinical tools."}
{"id": "2510.13498", "categories": ["eess.SP", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.13498", "abs": "https://arxiv.org/abs/2510.13498", "authors": ["Mingyu Zhao", "Qingna Li", "Hou-Duo Qi"], "title": "A Robust EDM Optimization Approach for 3D Single-Source Localization with Angle and Range Measurements", "comment": "12 pages, 9 figures", "summary": "For the problem of source localization, three elements usually play a very\nimportant role in accurate localization. They are the range measurements, the\nangle measurements and the least absolute deviation criterion, which is\nregarded as a robust metric for denoising the measurements. Building the three\nelements into a computationally tractable model is challenging. In this paper,\nwe introduce a robust Euclidean Distance Matrix (EDM) optimization model that\nsimultaneously incorporates the three elements. For the first time, we show\nthat for the case of 3D single-source localization (3DSSL), the angle\nmeasurements can be represented as a simple box constraint of distances. It is\nachieved by reducing each of the 3D angle measurements to a two-dimensional\nnonlinear optimization problem, whose global minimum and maximum solutions can\nbe characterized and utilized to get the lower and upper bounds of the\ndistances from the unknown source to the sensors. We further develop an\nefficient algorithm. The high quality of the localization by the new EDM model\nis assessed through extensive numerical experiments in comparison with leading\nsolvers for 3DSSL."}
{"id": "2510.13408", "categories": ["eess.IV", "cs.AI", "cs.IT", "cs.MM", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.13408", "abs": "https://arxiv.org/abs/2510.13408", "authors": ["Jingkai Ying", "Zhiyuan Qi", "Yulong Feng", "Zhijin Qin", "Zhu Han", "Rahim Tafazolli", "Yonina C. Eldar"], "title": "Semantic Communication Enabled Holographic Video Processing and Transmission", "comment": "7 pages, 6 figures, Submit for review", "summary": "Holographic video communication is considered a paradigm shift in visual\ncommunications, becoming increasingly popular for its ability to offer\nimmersive experiences. This article provides an overview of holographic video\ncommunication and outlines the requirements of a holographic video\ncommunication system. Particularly, following a brief review of semantic com-\nmunication, an architecture for a semantic-enabled holographic video\ncommunication system is presented. Key technologies, including semantic\nsampling, joint semantic-channel coding, and semantic-aware transmission, are\ndesigned based on the proposed architecture. Two related use cases are\npresented to demonstrate the performance gain of the proposed methods. Finally,\npotential research topics are discussed to pave the way for the realization of\nsemantic-enabled holographic video communications."}
