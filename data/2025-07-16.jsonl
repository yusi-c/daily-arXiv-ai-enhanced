{"id": "2507.10589", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.NE"], "pdf": "https://arxiv.org/pdf/2507.10589", "abs": "https://arxiv.org/abs/2507.10589", "authors": ["Gaurav Singh"], "title": "Comparative Analysis of Vision Transformers and Traditional Deep Learning Approaches for Automated Pneumonia Detection in Chest X-Rays", "comment": null, "summary": "Pneumonia, particularly when induced by diseases like COVID-19, remains a\ncritical global health challenge requiring rapid and accurate diagnosis. This\nstudy presents a comprehensive comparison of traditional machine learning and\nstate-of-the-art deep learning approaches for automated pneumonia detection\nusing chest X-rays (CXRs). We evaluate multiple methodologies, ranging from\nconventional machine learning techniques (PCA-based clustering, Logistic\nRegression, and Support Vector Classification) to advanced deep learning\narchitectures including Convolutional Neural Networks (Modified LeNet,\nDenseNet-121) and various Vision Transformer (ViT) implementations (Deep-ViT,\nCompact Convolutional Transformer, and Cross-ViT). Using a dataset of 5,856\npediatric CXR images, we demonstrate that Vision Transformers, particularly the\nCross-ViT architecture, achieve superior performance with 88.25% accuracy and\n99.42% recall, surpassing traditional CNN approaches. Our analysis reveals that\narchitectural choices impact performance more significantly than model size,\nwith Cross-ViT's 75M parameters outperforming larger models. The study also\naddresses practical considerations including computational efficiency, training\nrequirements, and the critical balance between precision and recall in medical\ndiagnostics. Our findings suggest that Vision Transformers offer a promising\ndirection for automated pneumonia detection, potentially enabling more rapid\nand accurate diagnosis during health crises."}
{"id": "2507.10615", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2507.10615", "abs": "https://arxiv.org/abs/2507.10615", "authors": ["Guofeng Tong", "Sixuan Liu", "Yang Lv", "Hanyu Pei", "Feng-Lei Fan"], "title": "A Survey on Medical Image Compression: From Traditional to Learning-Based", "comment": null, "summary": "The exponential growth of medical imaging has created significant challenges\nin data storage, transmission, and management for healthcare systems. In this\nvein, efficient compression becomes increasingly important. Unlike natural\nimage compression, medical image compression prioritizes preserving diagnostic\ndetails and structural integrity, imposing stricter quality requirements and\ndemanding fast, memory-efficient algorithms that balance computational\ncomplexity with clinically acceptable reconstruction quality. Meanwhile, the\nmedical imaging family includes a plethora of modalities, each possessing\ndifferent requirements. For example, 2D medical image (e.g., X-rays,\nhistopathological images) compression focuses on exploiting intra-slice spatial\nredundancy, while volumetric medical image faces require handling intra-slice\nand inter-slice spatial correlations, and 4D dynamic imaging (e.g., time-series\nCT/MRI, 4D ultrasound) additionally demands processing temporal correlations\nbetween consecutive time frames. Traditional compression methods, grounded in\nmathematical transforms and information theory principles, provide solid\ntheoretical foundations, predictable performance, and high standardization\nlevels, with extensive validation in clinical environments. In contrast, deep\nlearning-based approaches demonstrate remarkable adaptive learning capabilities\nand can capture complex statistical characteristics and semantic information\nwithin medical images. This comprehensive survey establishes a two-facet\ntaxonomy based on data structure (2D vs 3D/4D) and technical approaches\n(traditional vs learning-based), thereby systematically presenting the complete\ntechnological evolution, analyzing the unique technical challenges, and\nprospecting future directions in medical image compression."}
{"id": "2507.10869", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.10869", "abs": "https://arxiv.org/abs/2507.10869", "authors": ["Chetan Madan", "Aarjav Satia", "Soumen Basu", "Pankaj Gupta", "Usha Dutta", "Chetan Arora"], "title": "Focus on Texture: Rethinking Pre-training in Masked Autoencoders for Medical Image Classification", "comment": "To appear at MICCAI 2025", "summary": "Masked Autoencoders (MAEs) have emerged as a dominant strategy for\nself-supervised representation learning in natural images, where models are\npre-trained to reconstruct masked patches with a pixel-wise mean squared error\n(MSE) between original and reconstructed RGB values as the loss. We observe\nthat MSE encourages blurred image re-construction, but still works for natural\nimages as it preserves dominant edges. However, in medical imaging, when the\ntexture cues are more important for classification of a visual abnormality, the\nstrategy fails. Taking inspiration from Gray Level Co-occurrence Matrix (GLCM)\nfeature in Radiomics studies, we propose a novel MAE based pre-training\nframework, GLCM-MAE, using reconstruction loss based on matching GLCM. GLCM\ncaptures intensity and spatial relationships in an image, hence proposed loss\nhelps preserve morphological features. Further, we propose a novel formulation\nto convert matching GLCM matrices into a differentiable loss function. We\ndemonstrate that unsupervised pre-training on medical images with the proposed\nGLCM loss improves representations for downstream tasks. GLCM-MAE outperforms\nthe current state-of-the-art across four tasks - gallbladder cancer detection\nfrom ultrasound images by 2.1%, breast cancer detection from ultrasound by\n3.1%, pneumonia detection from x-rays by 0.5%, and COVID detection from CT by\n0.6%. Source code and pre-trained models are available at:\nhttps://github.com/ChetanMadan/GLCM-MAE."}
{"id": "2507.11043", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2507.11043", "abs": "https://arxiv.org/abs/2507.11043", "authors": ["He Zhichao", "Shen Xiangyu", "Zhang Yong", "Xie Nan"], "title": "Real-Time Foreign Object Recognition Based on Improved Wavelet Scattering Deep Network and Edge Computing", "comment": null, "summary": "The increasing penetration rate of new energy in the power system has put\nforward higher requirements for the operation and maintenance of substations\nand transmission lines. Using the Unmanned Aerial Vehicles (UAV) to identify\nforeign object in real time can quickly and effectively eliminate potential\nsafety hazards. However, due to the limited computation power, the captured\nimage cannot be real-time processed on edge devices in UAV locally. To overcome\nthis problem, a lightweight model based on an improved wavelet scatter deep\nnetwork is proposed. This model contains improved wavelet scattering network\nfor extracting the scatter coefficients and modulus coefficients of image\nsingle channel, replacing the role of convolutional layer and pooling layer in\nconvolutional neural network. The following 3 fully connected layers, also\nconstituted a simplified Multilayer Perceptron (MLP), are used to classify the\nextracted features. Experiments prove that the model constructed with\nbiorthogonal wavelets basis is able to recognize and classify the foreign\nobject in edge devices such as Raspberry Pi and Jetson Nano, with accuracy\nhigher than 90% and inference time less than 7ms for 720P (1280*720) images.\nFurther experiments demonstrate that the recognition accuracy of our model is\n1.1% higher than YOLOv5s and 0.3% higher than YOLOv8s."}
{"id": "2507.10706", "categories": ["eess.SP", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.10706", "abs": "https://arxiv.org/abs/2507.10706", "authors": ["Pradyumna Kunchala", "Ashish Patwari"], "title": "A Leap-on-Success Exhaustive Search Method to Find Optimal Robust Minimum Redundancy Arrays (RMRAs): New Array Configurations for Sensor Counts 11 to 20", "comment": "21 pages, 8 Tables, 4 Figures", "summary": "Two-fold redundant sparse arrays (TFRAs) are designed to maintain accurate\ndirection estimation even in the event of a single sensor failure, leveraging\nthe deliberate coarray redundancy infused into their design. Robust Minimum\nRedundancy Arrays (RMRAs), a specialized class of TFRAs, optimize this\nredundancy to achieve the maximum possible aperture for a given number of\nsensors. However, finding optimal RMRA configurations is an NP-hard problem,\nwith prior research reporting optimal solutions only for arrays of up to ten\nsensors. This paper presents newly discovered optimal RMRA configurations for\narray sizes 11 to 15, identified using a novel Leap-on-Success exhaustive\nsearch algorithm that efficiently reduces computational effort by terminating\nthe search upon locating optimal solutions. The robustness of these arrays was\nvalidated under all single-element failure scenarios using MATLAB simulations,\nconfirming their superior resilience compared to some existing TFRAs vulnerable\nto failures at specific sensor positions. Furthermore, near-optimal\nconfigurations for array sizes 16 to 20 are also reported, highlighting the\npotential applicability of the proposed method for larger array designs given\nsufficient computational resources. This work not only advances the\nstate-of-the-art in RMRA design but also introduces an effective search\nmethodology that can be leveraged for future explorations in array\nconfiguration optimization."}
{"id": "2507.11046", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2507.11046", "abs": "https://arxiv.org/abs/2507.11046", "authors": ["Faryal Aurooj Nasir", "Salman Liaquat", "Nor Muzlifah Mahyuddin"], "title": "Using Continual Learning for Real-Time Detection of Vulnerable Road Users in Complex Traffic Scenarios", "comment": "Accepted for presentation at the 9th International Conference on\n  Communications and Future Internet", "summary": "Pedestrians and bicyclists are among the vulnerable road users (VRUs) that\nare inherently exposed to intricate traffic scenarios, which puts them at\nincreased risk of sustaining injuries or facing fatal outcomes. This study\npresents an intelligent adaptive system that uses the YOLOv8-Dynamic (YOLOv8-D)\nalgorithm that detects vulnerable road users and adapts in real time to prevent\naccidents before they occur. We select YOLOv8x as the detector by comparing it\nwith other state-of-the-art object detection models, including Faster-RCNN,\nYOLOv5, YOLOv7, and variants. Compared to YOLOv5x, YOLOv8x shows improvements\nof 12.14% in F1 score and 45.61% in mean Average Precision (mAP). Against\nYOLOv7x, the improvements are 21.26% in F1 score and 128.44% in mAP. Our\nalgorithm integrates continual learning ability in the architecture of the\nYOLOv8 detector to adjust to evolving road conditions flexibly, ensuring\nadaptability across multiple dataset domains and facilitating continuous\nenhancement of detection and tracking accuracy for VRUs, embracing the dynamic\nnature of real-world environments. In our proposed framework, we optimized the\ngradient descent mechanism of YOLOv8 model and train our optimized algorithm on\ntwo statistically different datasets in terms of image viewpoint and number of\nclasses to achieve a 21.08% improvement in F1 score and a 31.86% improvement in\nmAP as compared to a custom YOLOv8 framework trained on a new dataset, thus\novercoming the issue of catastrophic forgetting, which occurs when deep models\nare trained on statistically different types of datasets."}
{"id": "2507.10838", "categories": ["eess.SP", "cs.IT", "math.IT", "math.OC"], "pdf": "https://arxiv.org/pdf/2507.10838", "abs": "https://arxiv.org/abs/2507.10838", "authors": ["Gokberk Yaylali", "Ahmad Ali Khan", "Dionysios S. Kalogerias"], "title": "Waterfilling at the Edge: Optimal Percentile Resource Allocation via Risk-Averse Reduction", "comment": "5 pages, 5 figures", "summary": "We address deterministic resource allocation in point-to-point multi-terminal\nAWGN channels without inter-terminal interference, with particular focus on\noptimizing quantile transmission rates for cell-edge terminal service.\nClassical utility-based approaches -- such as minimum rate, sumrate, and\nproportional fairness -- are either overconservative, or inappropriate, or do\nnot provide a rigorous and/or interpretable foundation for fair rate\noptimization at the edge. To overcome these challenges, we employ Conditional\nValue-at-Risk (CVaR), a popular coherent risk measure, and establish its\nequivalence with the sum-least-$\\alpha$th-quantile (SL$\\alpha$Q) utility. This\nconnection enables an exact convex reformulation of the SL$\\alpha$Q\nmaximization problem, facilitating analytical tractability and precise and\ninterpretable control over cell-edge terminal performance. Utilizing Lagrangian\nduality, we provide (for the first time) parameterized closed-form solutions\nfor the optimal resource policy -- which is of waterfilling-type -- as well as\nthe associated (auxiliary) Value-at-Risk variable. We further develop a novel\ninexact dual subgradient descent algorithm of minimal complexity to determine\nglobally optimal resource policies, and we rigorously establish its\nconvergence. The resulting edge waterfilling algorithm iteratively and\nefficiently allocates resources while explicitly ensuring transmission rate\nfairness across (cell-edge) terminals. Several (even large-scale) numerical\nexperiments validate the effectiveness of the proposed method for enabling\nrobust quantile rate optimization at the edge."}
{"id": "2507.11415", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.11415", "abs": "https://arxiv.org/abs/2507.11415", "authors": ["Hongbo Ye", "Fenghe Tang", "Peiang Zhao", "Zhen Huang", "Dexin Zhao", "Minghao Bian", "S. Kevin Zhou"], "title": "U-RWKV: Lightweight medical image segmentation with direction-adaptive RWKV", "comment": "Accepted by MICCAI2025", "summary": "Achieving equity in healthcare accessibility requires lightweight yet\nhigh-performance solutions for medical image segmentation, particularly in\nresource-limited settings. Existing methods like U-Net and its variants often\nsuffer from limited global Effective Receptive Fields (ERFs), hindering their\nability to capture long-range dependencies. To address this, we propose U-RWKV,\na novel framework leveraging the Recurrent Weighted Key-Value(RWKV)\narchitecture, which achieves efficient long-range modeling at O(N)\ncomputational cost. The framework introduces two key innovations: the\nDirection-Adaptive RWKV Module(DARM) and the Stage-Adaptive\nSqueeze-and-Excitation Module(SASE). DARM employs Dual-RWKV and QuadScan\nmechanisms to aggregate contextual cues across images, mitigating directional\nbias while preserving global context and maintaining high computational\nefficiency. SASE dynamically adapts its architecture to different feature\nextraction stages, balancing high-resolution detail preservation and semantic\nrelationship capture. Experiments demonstrate that U-RWKV achieves\nstate-of-the-art segmentation performance with high computational efficiency,\noffering a practical solution for democratizing advanced medical imaging\ntechnologies in resource-constrained environments. The code is available at\nhttps://github.com/hbyecoding/U-RWKV."}
{"id": "2507.11036", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.11036", "abs": "https://arxiv.org/abs/2507.11036", "authors": ["Salman Liaquat", "Ijaz Haider Naqvi", "Nor Muzlifah Mahyuddin"], "title": "Dual RIS-Assisted Monostatic L-Band Radar Target Detection in NLoS Scenarios", "comment": "Accepted for presentation at the 9th International Conference on\n  Communications and Future Internet", "summary": "The use of a single Reconfigurable Intelligent Surface (RIS) to boost the\nsignal-to-noise ratio (SNR) at the radar offers significant improvement in\ndetecting targets, especially in non-line-of-sight (NLoS) scenarios. However,\nthere are scenarios where no path exists between the radar and the target, even\nwith a single RIS-assisted radar, due to other present obstacles. This paper\nderives an expression for SNR in target detection scenarios where dual RISs\nassist a monostatic radar in NLoS situations. We calculate the power received\nat the radar through a dual RIS configuration. We show that the SNR performance\nof RIS-assisted radars can improve with known locations of the radar and RISs.\nOur results demonstrate that the required accuracy in target localization can\nbe achieved by controlling the number of RISs, the number of unit cells in each\nRIS, and properly selecting the locations of RISs to cover the desired region.\nThe performance of dual RIS-assisted radar systems can surpass that of single\nRIS-assisted radar systems under favourable alignment and sufficiently large\nRIS sizes."}
{"id": "2507.11523", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2507.11523", "abs": "https://arxiv.org/abs/2507.11523", "authors": ["Buddhi Wijenayake", "Athulya Ratnayake", "Praveen Sumanasekara", "Nichula Wasalathilaka", "Mathivathanan Piratheepan", "Roshan Godaliyadda", "Mervyn Ekanayake", "Vijitha Herath"], "title": "Precision Spatio-Temporal Feature Fusion for Robust Remote Sensing Change Detection", "comment": "6 pages, 4 figures, 2 pages, under review(conference paper)", "summary": "Remote sensing change detection is vital for monitoring environmental and\nurban transformations but faces challenges like manual feature extraction and\nsensitivity to noise. Traditional methods and early deep learning models, such\nas convolutional neural networks (CNNs), struggle to capture long-range\ndependencies and global context essential for accurate change detection in\ncomplex scenes. While Transformer-based models mitigate these issues, their\ncomputational complexity limits their applicability in high-resolution remote\nsensing. Building upon ChangeMamba architecture, which leverages state space\nmodels for efficient global context modeling, this paper proposes precision\nfusion blocks to capture channel-wise temporal variations and per-pixel\ndifferences for fine-grained change detection. An enhanced decoder pipeline,\nincorporating lightweight channel reduction mechanisms, preserves local details\nwith minimal computational cost. Additionally, an optimized loss function\ncombining Cross Entropy, Dice and Lovasz objectives addresses class imbalance\nand boosts Intersection-over-Union (IoU). Evaluations on SYSU-CD, LEVIR-CD+,\nand WHU-CD datasets demonstrate superior precision, recall, F1 score, IoU, and\noverall accuracy compared to state-of-the-art methods, highlighting the\napproach's robustness for remote sensing change detection. For complete\ntransparency, the codes and pretrained models are accessible at\nhttps://github.com/Buddhi19/MambaCD.git"}
{"id": "2507.11093", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.11093", "abs": "https://arxiv.org/abs/2507.11093", "authors": ["Wenxuan Sun", "Mingjie Shao", "Luteng Zhu", "Yao Ge", "Tong Zhang", "Zhi Liu"], "title": "Optimizing Fluid Antenna Configurations for Constructive Interference Precoding", "comment": null, "summary": "The fluid antenna system (FAS) has emerged as a new physical-layer concept to\nprovide enhanced propagation conditions for multiuser multiple-input\nmultiple-output (MIMO) communications over conventional fixed arrays. This work\nfocuses on minimizing the maximum symbol error probability (SEP) under $M$-ary\nphase shift keying (MPSK) signaling in a multiuser downlink equipped with FAS,\nwhere each antenna moves within nonoverlapping intervals. This specific problem\nof joint SEP minimization with FAS and constructive interference (CI) precoding\nhas not been previously addressed. The resulting problem turns out to be a\nnonconvex and nonsmooth optimization challenge. We transform the SEP\nminimization problem into a safety margin maximization problem in constructive\ninterference precoding. Then, we customize a smoothing technique and a block\ncoordinate descent (BCD) algorithm, with emphasis on low computational\ncomplexity. Simulation results show that our approach can reduce bit error rate\n(BER) compared to both the fixed arrays and FAS designed by existing particle\nswarm optimization (PSO). Also, our approach shows attractively low\ncomputational complexity compared to PSO benchmarks."}
{"id": "2507.11224", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.11224", "abs": "https://arxiv.org/abs/2507.11224", "authors": ["Ali Khandan Boroujeni", "Kuranage Roche Rayan Ranasinghe", "Giuseppe Thadeu Freitas de Abreu", "Stefan Köpsell", "Ghazal Bagheri", "Rafael F. Schaefer"], "title": "Fairness-Aware Secure Integrated Sensing and Communications with Fractional Programming", "comment": "Submitted to an IEEE journal", "summary": "We propose a novel secure integrated sensing and communications (ISAC) system\ndesigned to serve multiple communication users (CUs) and targets. To that end,\nwe formulate an optimization problem that maximizes the secrecy rate under\nconstraints balancing both communication and sensing requirements. To enhance\nfairness among users, an entropy-regularized fairness metric is introduced\nwithin the problem framework. We then propose a solution employing an\naccelerated quadratic transform (QT) with a non-homogeneous bound to\niteratively solve two subproblems, thereby effectively optimizing the overall\nobjective. This approach ensures robust security and fairness in resource\nallocation for ISAC systems. Finally, simulation results verify the performance\ngains in terms of average secrecy rate, average data rate, and beam gain."}
{"id": "2507.11249", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.11249", "abs": "https://arxiv.org/abs/2507.11249", "authors": ["Ruohai Guo", "Jiang Zhu", "Xing Jiang", "Fengzhong Qu"], "title": "Fast and Efficient Implementation of the Maximum Likelihood Estimation for the Linear Regression with Gaussian Model Uncertainty", "comment": null, "summary": "The linear regression model with a random variable (RV) measurement matrix,\nwhere the mean of the random measurement matrix has full column rank, has been\nextensively studied. In particular, the quasiconvexity of the maximum\nlikelihood estimation (MLE) problem was established, and the corresponding\nCramer-Rao bound (CRB) was derived, leading to the development of an efficient\nbisection-based algorithm known as RV-ML. In contrast, this work extends the\nanalysis to both overdetermined and underdetermined cases, allowing the mean of\nthe random measurement matrix to be rank-deficient. A remarkable contribution\nis the proof that the equivalent MLE problem is convex and satisfies strong\nduality, strengthening previous quasiconvexity results. Moreover, it is shown\nthat in underdetermined scenarios, the randomness in the measurement matrix can\nbe beneficial for estimation under certain conditions. In addition, a fast and\nunified implementation of the MLE solution, referred to as generalized RV-ML\n(GRV-ML), is proposed, which handles a more general case including both\nunderdetermined and overdetermined systems. Extensive numerical simulations are\nprovided to validate the theoretical findings."}
{"id": "2507.11284", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.11284", "abs": "https://arxiv.org/abs/2507.11284", "authors": ["Mohamed-Amine Lahmeri", "Pouya Fakharizadeh", "Víctor Mustieles-Pérez", "Martin Vossiek", "Gerhard Krieger", "Robert Schober"], "title": "Sensing Accuracy Optimization for Multi-UAV SAR Interferometry with Data Offloading", "comment": null, "summary": "The integration of unmanned aerial vehicles (UAVs) with radar imaging sensors\nhas revolutionized the monitoring of dynamic and local Earth surface processes\nby enabling high-resolution and cost-effective remote sensing. This paper\ninvestigates the optimization of the sensing accuracy of a UAV swarm deployed\nto perform multi-baseline interferometric synthetic aperture radar (InSAR)\nsensing. In conventional single-baseline InSAR systems, only one synthetic\naperture radar (SAR) antenna pair acquires two SAR images from two distinct\nangles to generate a digital elevation model (DEM) of the target area. However,\nmulti-baseline InSAR extends this concept by aggregating multiple acquisitions\nfrom different angles, thus, significantly enhancing the vertical accuracy of\nthe DEM. The heavy computations required for this process are performed on the\nground and, therefore, the radar data is transmitted in real time to a ground\nstation (GS) via a frequency-division multiple access (FDMA) air-to-ground\nbackhaul link. This work focuses on improving the sensing precision by\nminimizing the height error of the averaged DEM while simultaneously ensuring\nsensing and communication quality-of-service (QoS). To this end, the UAV\nformation, velocity, and communication power allocation are jointly optimized\nusing evolutionary algorithms (EAs). Our approach is benchmarked against\nestablished optimization methods, including genetic algorithms (GAs), simulated\nannealing (SA), and deep reinforcement learning (DRL) techniques. Numerical\nresults show that the proposed solution outperforms these baseline schemes and\nachieves sub-decimeter vertical accuracy in several scenarios. These findings\nunderline the potential of coordinated UAV swarms for delivering high-precision\nand real-time Earth observations through radar interferometry."}
{"id": "2507.11383", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.11383", "abs": "https://arxiv.org/abs/2507.11383", "authors": ["V S V Sandeep", "Sai Dinesh Kancharana", "Arun Pachai Kannu"], "title": "Sparse Regression Codes exploit Multi-User Diversity without CSI", "comment": null, "summary": "We study sparse regression codes (SPARC) for multiple access channels with\nmultiple receive antennas, in non-coherent flat fading channels. We propose a\nnovel practical decoder, referred to as maximum likelihood matching pursuit\n(MLMP), which greedily finds the support of the codewords of users with partial\nmaximum likelihood metrics. As opposed to the conventional\nsuccessive-cancellation based greedy algorithms, MLMP works as a\nsuccessive-combining energy detector. We also propose MLMP modifications to\nimprove the performance at high code rates. Our studies in short block lengths\nshow that, even without any channel state information, SPARC with MLMP decoder\nachieves multi-user diversity in some scenarios, giving better error\nperformance with multiple users than that of the corresponding single-user\ncase. We also show that SPARC with MLMP performs better than conventional\nsparse recovery algorithms and pilot-aided transmissions with polar codes."}
{"id": "2507.11413", "categories": ["eess.SP", "math.OC"], "pdf": "https://arxiv.org/pdf/2507.11413", "abs": "https://arxiv.org/abs/2507.11413", "authors": ["Christos N. Efrem", "Ioannis Krikidis"], "title": "Joint Power Allocation and Reflecting-Element Activation for Energy Efficiency Maximization in IRS-Aided Communications Under CSI Uncertainty", "comment": "5 pages, 3 figures", "summary": "We study the joint power allocation and reflecting element (RE) activation to\nmaximize the energy efficiency (EE) in communication systems assisted by an\nintelligent reflecting surface (IRS), taking into account imperfections in\nchannel state information (CSI). The robust optimization problem is mixed\ninteger, i.e., the optimization variables are continuous (transmit power) and\ndiscrete (binary states of REs). In order to solve this challenging problem we\ndevelop two algorithms. The first one is an alternating optimization (AO)\nmethod that attains a suboptimal solution with low complexity, based on the\nLambert W function and a dynamic programming (DP) algorithm. The second one is\na branch-and-bound (B&B) method that uses AO as its subroutine and is formally\nguaranteed to achieve a globally optimal solution. Both algorithms do not\nrequire any external optimization solver for their implementation. Furthermore,\nnumerical results show that the proposed algorithms outperform the baseline\nschemes, AO achieves near-optimal performance in most cases, and B&B has low\ncomputational complexity on average."}
