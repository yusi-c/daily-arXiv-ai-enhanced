{"id": "2509.12253", "categories": ["eess.IV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.12253", "abs": "https://arxiv.org/abs/2509.12253", "authors": ["Riyaadh Gani"], "title": "Physics-Informed Neural Networks vs. Physics Models for Non-Invasive Glucose Monitoring: A Comparative Study Under Realistic Synthetic Conditions", "comment": null, "summary": "Non-invasive glucose monitors often fail outside the lab because existing\ndatasets ignore hardware noise, environmental drift, and person-to-person\nphysiology. We introduce the first ultra-realistic near-infrared (NIR)\nsimulator that injects 12-bit ADC quantisation, +/-0.1% LED ageing, photodiode\ndark noise, 15-45 C temperature, 30-90% relative humidity, contact-pressure\nvariation, Fitzpatrick I-VI melanin, and diurnal glucose excursions (dawn\nphenomenon). Using this platform (rho glucose-NIR = 0.21), we benchmark six\nmethods: Enhanced Beer-Lambert (physics-engineered ridge regression), three\nphysics-informed neural networks (PINNs), a selective radiative-transfer PINN,\nand a shallow DNN. Beer-Lambert achieves 13.6 mg/dL RMSE, 95.8% Clarke-A and\n93.8% +/-15% accuracy with only 56 parameters and 0.01 ms inference,\noutperforming the best PINN (14.6 mg/dL) and the SDNN baseline (35.1 mg/dL).\nResults overturn the assumption that deeper PINNs dominate and supply an open,\nend-to-end reference stack for rapid prototyping of embedded optical glucose\nsensors."}
{"id": "2509.12287", "categories": ["eess.IV", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.12287", "abs": "https://arxiv.org/abs/2509.12287", "authors": ["Nathan He", "Cody Chen"], "title": "Enhancing Radiographic Disease Detection with MetaCheX, a Context-Aware Multimodal Model", "comment": "All authors contributed equally, 5 pages, 2 figures, 1 table", "summary": "Existing deep learning models for chest radiology often neglect patient\nmetadata, limiting diagnostic accuracy and fairness. To bridge this gap, we\nintroduce MetaCheX, a novel multimodal framework that integrates chest X-ray\nimages with structured patient metadata to replicate clinical decision-making.\nOur approach combines a convolutional neural network (CNN) backbone with\nmetadata processed by a multilayer perceptron through a shared classifier.\nEvaluated on the CheXpert Plus dataset, MetaCheX consistently outperformed\nradiograph-only baseline models across multiple CNN architectures. By\nintegrating metadata, the overall diagnostic accuracy was significantly\nimproved, measured by an increase in AUROC. The results of this study\ndemonstrate that metadata reduces algorithmic bias and enhances model\ngeneralizability across diverse patient populations. MetaCheX advances clinical\nartificial intelligence toward robust, context-aware radiographic disease\ndetection."}
{"id": "2509.12512", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.12512", "abs": "https://arxiv.org/abs/2509.12512", "authors": ["Fazle Rafsani", "Jay Shah", "Catherine D. Chong", "Todd J. Schwedt", "Teresa Wu"], "title": "DinoAtten3D: Slice-Level Attention Aggregation of DinoV2 for 3D Brain MRI Anomaly Classification", "comment": "ACCEPTED at the ICCV 2025 Workshop on Anomaly Detection with\n  Foundation Models", "summary": "Anomaly detection and classification in medical imaging are critical for\nearly diagnosis but remain challenging due to limited annotated data, class\nimbalance, and the high cost of expert labeling. Emerging vision foundation\nmodels such as DINOv2, pretrained on extensive, unlabeled datasets, offer\ngeneralized representations that can potentially alleviate these limitations.\nIn this study, we propose an attention-based global aggregation framework\ntailored specifically for 3D medical image anomaly classification. Leveraging\nthe self-supervised DINOv2 model as a pretrained feature extractor, our method\nprocesses individual 2D axial slices of brain MRIs, assigning adaptive\nslice-level importance weights through a soft attention mechanism. To further\naddress data scarcity, we employ a composite loss function combining supervised\ncontrastive learning with class-variance regularization, enhancing inter-class\nseparability and intra-class consistency. We validate our framework on the ADNI\ndataset and an institutional multi-class headache cohort, demonstrating strong\nanomaly classification performance despite limited data availability and\nsignificant class imbalance. Our results highlight the efficacy of utilizing\npretrained 2D foundation models combined with attention-based slice aggregation\nfor robust volumetric anomaly detection in medical imaging. Our implementation\nis publicly available at https://github.com/Rafsani/DinoAtten3D.git."}
{"id": "2509.12534", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.12534", "abs": "https://arxiv.org/abs/2509.12534", "authors": ["Jia-Hong Huang"], "title": "DeepEyeNet: Generating Medical Report for Retinal Images", "comment": "The paper is accepted by the Conference on Information and Knowledge\n  Management (CIKM), 2025", "summary": "The increasing prevalence of retinal diseases poses a significant challenge\nto the healthcare system, as the demand for ophthalmologists surpasses the\navailable workforce. This imbalance creates a bottleneck in diagnosis and\ntreatment, potentially delaying critical care. Traditional methods of\ngenerating medical reports from retinal images rely on manual interpretation,\nwhich is time-consuming and prone to errors, further straining\nophthalmologists' limited resources. This thesis investigates the potential of\nArtificial Intelligence (AI) to automate medical report generation for retinal\nimages. AI can quickly analyze large volumes of image data, identifying subtle\npatterns essential for accurate diagnosis. By automating this process, AI\nsystems can greatly enhance the efficiency of retinal disease diagnosis,\nreducing doctors' workloads and enabling them to focus on more complex cases.\nThe proposed AI-based methods address key challenges in automated report\ngeneration: (1) A multi-modal deep learning approach captures interactions\nbetween textual keywords and retinal images, resulting in more comprehensive\nmedical reports; (2) Improved methods for medical keyword representation\nenhance the system's ability to capture nuances in medical terminology; (3)\nStrategies to overcome RNN-based models' limitations, particularly in capturing\nlong-range dependencies within medical descriptions; (4) Techniques to enhance\nthe interpretability of the AI-based report generation system, fostering trust\nand acceptance in clinical practice. These methods are rigorously evaluated\nusing various metrics and achieve state-of-the-art performance. This thesis\ndemonstrates AI's potential to revolutionize retinal disease diagnosis by\nautomating medical report generation, ultimately improving clinical efficiency,\ndiagnostic accuracy, and patient care."}
{"id": "2509.12348", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.12348", "abs": "https://arxiv.org/abs/2509.12348", "authors": ["Hua Chen", "Tao Gong", "Tuo Wu", "Maged Elkashlan", "Baiyang Liu", "Chan-Byoung Chae", "Kin-Fai Tong", "Kai-Kit Wong"], "title": "FAS-ARIS: Turning Multipath Challenges Into Localization Opportunities", "comment": "13 pages", "summary": "Traditional single-input single-output (SISO) systems face fundamental\nlimitations in achieving accurate three-dimensional (3D) localization due to\nlimited spatial degrees of freedom (DoF) and the adverse impact of multipath\npropagation. This paper proposes a novel fluid antenna system (FAS)-active\nreconfigurable intelligent surface (ARIS) framework that transforms multipath\neffects from a hindrance into a resource for enhanced localization. By\nsynergistically combining the signal amplification capabilities of ARIS with\nthe spatial diversity enabled by FAS, the proposed system achieves robust 3D\nuser equipment (UE) positioning -- without relying on auxiliary information\nsuch as time-of-arrival (ToA) or frequency diversity. The system exploits both\nline-of-sight (LoS) and non-line-of-sight (NLoS) components through a tailored\nsignal decoupling strategy. We design novel UE pilot sequences and ARIS phase\nconfigurations to effectively separate LoS and NLoS channels, enabling\nindependent parameter estimation. A multi-stage estimation algorithm is then\napplied: the multiple signal classification (MUSIC) algorithm estimates\nangle-of-arrival (AoA) from the direct path, while maximum likelihood\nestimation with interior-point refinement recovers cascaded channel parameters\nfrom the reflected path. Finally, geometric triangulation using least-squares\nestimation determines the UE's 3D position based on the extracted AoA\ninformation. Comprehensive performance analysis, including the derivation of\nCram\\'{e}r-Rao bounds for both channel and position estimation, establishes\ntheoretical benchmarks. Simulation results confirm that the proposed FAS-ARIS\nframework achieves near-optimal localization accuracy while maintaining\nrobustness in rich multipath environments -- effectively turning conventional\nlocalization challenges into advantages."}
{"id": "2509.12596", "categories": ["eess.IV", "cs.CE"], "pdf": "https://arxiv.org/pdf/2509.12596", "abs": "https://arxiv.org/abs/2509.12596", "authors": ["Jiasong Chen", "Linchen Qian", "Ruonan Gong", "Christina Sun", "Tongran Qin", "Thuy Pham", "Caitlin Martin", "Mohammad Zafar", "John Elefteriades", "Wei Sun", "Liang Liang"], "title": "A Computational Pipeline for Patient-Specific Modeling of Thoracic Aortic Aneurysm: From Medical Image to Finite Element Analysis", "comment": null, "summary": "The aorta is the body's largest arterial vessel, serving as the primary\npathway for oxygenated blood within the systemic circulation. Aortic aneurysms\nconsistently rank among the top twenty causes of mortality in the United\nStates. Thoracic aortic aneurysm (TAA) arises from abnormal dilation of the\nthoracic aorta and remains a clinically significant disease, ranking as one of\nthe leading causes of death in adults. A thoracic aortic aneurysm ruptures when\nthe integrity of all aortic wall layers is compromised due to elevated blood\npressure. Currently, three-dimensional computed tomography (3D CT) is\nconsidered the gold standard for diagnosing TAA. The geometric characteristics\nof the aorta, which can be quantified from medical imaging, and stresses on the\naortic wall, which can be obtained by finite element analysis (FEA), are\ncritical in evaluating the risk of rupture and dissection. Deep learning based\nimage segmentation has emerged as a reliable method for extracting anatomical\nregions of interest from medical images. Voxel based segmentation masks of\nanatomical structures are typically converted into structured mesh\nrepresentation to enable accurate simulation. Hexahedral meshes are commonly\nused in finite element simulations of the aorta due to their computational\nefficiency and superior simulation accuracy. Due to anatomical variability,\npatient specific modeling enables detailed assessment of individual anatomical\nand biomechanics behaviors, supporting precise simulations, accurate diagnoses,\nand personalized treatment strategies. Finite element (FE) simulations provide\nvaluable insights into the biomechanical behaviors of tissues and organs in\nclinical studies. Developing accurate FE models represents a crucial initial\nstep in establishing a patient-specific, biomechanically based framework for\npredicting the risk of TAA."}
{"id": "2509.12359", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.12359", "abs": "https://arxiv.org/abs/2509.12359", "authors": ["Henry Carvajal Mora", "Nathaly Orozco", "Fernando Almeida García", "José Vega-Sánchez", "Felipe Grijalva", "Edgar Benitez Olivo"], "title": "Partial Secrecy Analysis in Wireless Systems: Diversity-Enhanced PLS over Generalized Fading Channels", "comment": null, "summary": "Securing information in future mobile networks is challenging, especially for\ndevices with limited computational resources. Physical layer security (PLS)\noffers a viable solution by leveraging wireless channel randomness. When full\nsecrecy is unattainable, the partial secrecy regime provides a realistic\nalternative. This work analyzes partial secrecy performance under the\ngeneralized multicluster fluctuating two-ray (MFTR) fading model, which\nsubsumes many classical fading cases. We study a system with a transmitter (A),\nlegitimate receiver (B), and eavesdropper (E), both B and E using antenna\narrays with maximal ratio combining (MRC), under i.n.i.d. fading. Exact and\nclosed-form approximations are derived for key secrecy metrics: generalized\nsecrecy outage probability (GSOP), average fractional equivocation (AFE), and\naverage information leakage rate (AILR). The results, validated by Monte Carlo\nsimulations, retain constant complexity regardless of diversity order. The MFTR\nmodel's flexibility enables comprehensive assessment across fading conditions,\nshowing that more MRC branches at B enhance secrecy performance depending on\nthe A-E link characteristics."}
{"id": "2509.12772", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.12772", "abs": "https://arxiv.org/abs/2509.12772", "authors": ["Damola Agbelese", "Krishna Chaitanya", "Pushpak Pati", "Chaitanya Parmar", "Pooya Mobadersany", "Shreyas Fadnavis", "Lindsey Surace", "Shadi Yarandi", "Louis R. Ghanem", "Molly Lucas", "Tommaso Mansi", "Oana Gabriela Cula", "Pablo F. Damasceno", "Kristopher Standish"], "title": "MEGAN: Mixture of Experts for Robust Uncertainty Estimation in Endoscopy Videos", "comment": "11 pages, 2 figures, 1 table, accepted at UNSURE, MICCAI", "summary": "Reliable uncertainty quantification (UQ) is essential in medical AI.\nEvidential Deep Learning (EDL) offers a computationally efficient way to\nquantify model uncertainty alongside predictions, unlike traditional methods\nsuch as Monte Carlo (MC) Dropout and Deep Ensembles (DE). However, all these\nmethods often rely on a single expert's annotations as ground truth for model\ntraining, overlooking the inter-rater variability in healthcare. To address\nthis issue, we propose MEGAN, a Multi-Expert Gating Network that aggregates\nuncertainty estimates and predictions from multiple AI experts via EDL models\ntrained with diverse ground truths and modeling strategies. MEGAN's gating\nnetwork optimally combines predictions and uncertainties from each EDL model,\nenhancing overall prediction confidence and calibration. We extensively\nbenchmark MEGAN on endoscopy videos for Ulcerative colitis (UC) disease\nseverity estimation, assessed by visual labeling of Mayo Endoscopic Subscore\n(MES), where inter-rater variability is prevalent. In large-scale prospective\nUC clinical trial, MEGAN achieved a 3.5% improvement in F1-score and a 30.5%\nreduction in Expected Calibration Error (ECE) compared to existing methods.\nFurthermore, MEGAN facilitated uncertainty-guided sample stratification,\nreducing the annotation burden and potentially increasing efficiency and\nconsistency in UC trials."}
{"id": "2509.12510", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.12510", "abs": "https://arxiv.org/abs/2509.12510", "authors": ["Wei Shao", "Ruoyu Zhang", "Zequan Liang", "Ehsan Kourkchi", "Setareh Rafatirad", "Houman Homayoun"], "title": "Self-Supervised and Topological Signal-Quality Assessment for Any PPG Device", "comment": "In the proceedings of IEEE-EMBS BSN 2025", "summary": "Wearable photoplethysmography (PPG) is embedded in billions of devices, yet\nits optical waveform is easily corrupted by motion, perfusion loss, and ambient\nlight, jeopardizing downstream cardiometric analytics. Existing signal-quality\nassessment (SQA) methods rely either on brittle heuristics or on data-hungry\nsupervised models. We introduce the first fully unsupervised SQA pipeline for\nwrist PPG. Stage 1 trains a contrastive 1-D ResNet-18 on 276 h of raw,\nunlabeled data from heterogeneous sources (varying in device and sampling\nfrequency), yielding optical-emitter- and motion-invariant embeddings (i.e.,\nthe learned representation is stable across differences in LED wavelength,\ndrive intensity, and device optics, as well as wrist motion). Stage 2 converts\neach 512-D encoder embedding into a 4-D topological signature via persistent\nhomology (PH) and clusters these signatures with HDBSCAN. To produce a binary\nsignal-quality index (SQI), the acceptable PPG signals are represented by the\ndensest cluster while the remaining clusters are assumed to mainly contain\npoor-quality PPG signals. Without re-tuning, the SQI attains Silhouette,\nDavies-Bouldin, and Calinski-Harabasz scores of 0.72, 0.34, and 6173,\nrespectively, on a stratified sample of 10,000 windows. In this study, we\npropose a hybrid self-supervised-learning--topological-data-analysis (SSL--TDA)\nframework that offers a drop-in, scalable, cross-device quality gate for PPG\nsignals."}
{"id": "2509.12515", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.12515", "abs": "https://arxiv.org/abs/2509.12515", "authors": ["Zequan Liang", "Ruoyu Zhang", "Wei Shao", "krishna Karthik", "Ehsan Kourkchi", "Setareh Rafatirad", "Houman Homayoun"], "title": "Rapid Adaptation of SpO2 Estimation to Wearable Devices via Transfer Learning on Low-Sampling-Rate PPG", "comment": "In the proceedings of IEEE-EMBS International Conference on Body\n  Sensor Networks 2025", "summary": "Blood oxygen saturation (SpO2) is a vital marker for healthcare monitoring.\nTraditional SpO2 estimation methods often rely on complex clinical calibration,\nmaking them unsuitable for low-power, wearable applications. In this paper, we\npropose a transfer learning-based framework for the rapid adaptation of SpO2\nestimation to energy-efficient wearable devices using low-sampling-rate (25Hz)\ndual-channel photoplethysmography (PPG). We first pretrain a bidirectional Long\nShort-Term Memory (BiLSTM) model with self-attention on a public clinical\ndataset, then fine-tune it using data collected from our wearable We-Be band\nand an FDA-approved reference pulse oximeter. Experimental results show that\nour approach achieves a mean absolute error (MAE) of 2.967% on the public\ndataset and 2.624% on the private dataset, significantly outperforming\ntraditional calibration and non-transferred machine learning baselines.\nMoreover, using 25Hz PPG reduces power consumption by 40% compared to 100Hz,\nexcluding baseline draw. Our method also attains an MAE of 3.284% in\ninstantaneous SpO2 prediction, effectively capturing rapid fluctuations. These\nresults demonstrate the rapid adaptation of accurate, low-power SpO2 monitoring\non wearable devices without the need for clinical calibration."}
{"id": "2509.12518", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.12518", "abs": "https://arxiv.org/abs/2509.12518", "authors": ["Zequan Liang", "Ruoyu Zhang", "Wei Shao", "Mahdi Pirayesh Shirazi Nejad", "Ehsan Kourkchi", "Setareh Rafatirad", "Houman Homayoun"], "title": "Generalizable Blood Pressure Estimation from Multi-Wavelength PPG Using Curriculum-Adversarial Learning", "comment": "In the proceedings of IEEE-EMBS International Conference on Body\n  Sensor Networks 2025", "summary": "Accurate and generalizable blood pressure (BP) estimation is vital for the\nearly detection and management of cardiovascular diseases. In this study, we\nenforce subject-level data splitting on a public multi-wavelength\nphotoplethysmography (PPG) dataset and propose a generalizable BP estimation\nframework based on curriculum-adversarial learning. Our approach combines\ncurriculum learning, which transitions from hypertension classification to BP\nregression, with domain-adversarial training that confuses subject identity to\nencourage the learning of subject-invariant features. Experiments show that\nmulti-channel fusion consistently outperforms single-channel models. On the\nfour-wavelength PPG dataset, our method achieves strong performance under\nstrict subject-level splitting, with mean absolute errors (MAE) of 14.2mmHg for\nsystolic blood pressure (SBP) and 6.4mmHg for diastolic blood pressure (DBP).\nAdditionally, ablation studies validate the effectiveness of both the\ncurriculum and adversarial components. These results highlight the potential of\nleveraging complementary information in multi-wavelength PPG and\ncurriculum-adversarial strategies for accurate and robust BP estimation."}
{"id": "2509.12605", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.12605", "abs": "https://arxiv.org/abs/2509.12605", "authors": ["Yang Chen", "Yeonju Lee", "Yao Shi", "Qiyu Sun"], "title": "Kalman Filtering of Stationary Graph Signals", "comment": null, "summary": "In this paper, we propose a novel definition of stationary graph signals,\nformulated with respect to a symmetric graph shift, such as the graph\nLaplacian. We show that stationary graph signals can be generated by\ntransmitting white noise through polynomial graph channels, and that their\nstationarity is preserved under polynomial channel transmission.\n  In this paper, we also investigate Kalman filtering to dynamical systems\ncharacterized by polynomial state and observation matrices. We demonstrate that\nKalman filtering maintains the stationarity of graph signals, while effectively\nincorporating both system dynamics and noise structure. In comparison to the\nstatic inverse filtering method and naive zero-signal strategy, the Kalman\nfiltering procedure yields more accurate and adaptive signal estimates,\nhighlighting its robustness and versatility in graph signal processing."}
{"id": "2509.12646", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.12646", "abs": "https://arxiv.org/abs/2509.12646", "authors": ["Yixin Ding", "Haoyu Jiang", "Xiaoli Xu", "Yanan Liang", "Yong Zeng"], "title": "Data Fusion for BS-UE Cooperative MIMO-OFDM ISAC", "comment": "6 pages, 4 figures", "summary": "Integrated sensing and communication (ISAC) is a promising technique for\nexpanding the functionalities of wireless networks with enhanced spectral\nefficiency. The 3rd Generation Partnership Project (3GPP) has defined six basic\nsensing operation modes in wireless networks. To further enhance the sensing\ncapability of wireless networks, this paper proposes a new sensing operation\nmode, i.e., the base station (BS) and user equipment (UE) cooperative sensing.\nSpecifically, after decoding the communication data, the UE further processes\nthe received signal to extract the target sensing information. We propose an\nefficient algorithm for fusing the sensing results obtained by the BS and UE,\nby exploiting the geometric relationship among BS, UE and targets as well as\nthe expected sensing quality in the BS monostatic and BS-UE bistatic sensing.\nThe results show that the proposed data fusion method for cooperative sensing\ncan effectively improve the position and velocity estimation accuracy of\nmultiple targets, and provide a new approach on the expansion of the sensing\npattern."}
{"id": "2509.12658", "categories": ["eess.SP", "cs.IT", "cs.LG", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.12658", "abs": "https://arxiv.org/abs/2509.12658", "authors": ["Po-Heng Chou", "Jiun-Jia Wu", "Wan-Jen Huang", "Ronald Y. Chang"], "title": "Sustainable LSTM-Based Precoding for RIS-Aided mmWave MIMO Systems with Implicit CSI", "comment": "6 pages, 5 figures, 2 tables, and accepted by 2025 IEEE Globecom\n  Workshops", "summary": "In this paper, we propose a sustainable long short-term memory (LSTM)-based\nprecoding framework for reconfigurable intelligent surface (RIS)-assisted\nmillimeter-wave (mmWave) MIMO systems. Instead of explicit channel state\ninformation (CSI) estimation, the framework exploits uplink pilot sequences to\nimplicitly learn channel characteristics, reducing both pilot overhead and\ninference complexity. Practical hardware constraints are addressed by\nincorporating the phase-dependent amplitude model of RIS elements, while a\nmulti-label training strategy improves robustness when multiple near-optimal\ncodewords yield comparable performance. Simulations show that the proposed\ndesign achieves over 90% of the spectral efficiency of exhaustive search (ES)\nwith only 2.2% of its computation time, cutting energy consumption by nearly\ntwo orders of magnitude. The method also demonstrates resilience under\ndistribution mismatch and scalability to larger RIS arrays, making it a\npractical and energy-efficient solution for sustainable 6G wireless networks."}
{"id": "2509.12698", "categories": ["eess.SP", "cs.ET", "cs.IT", "cs.SY", "eess.SY", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.12698", "abs": "https://arxiv.org/abs/2509.12698", "authors": ["Yifan Jiang", "Qingqing Wu", "Hongxun Hui", "Wen Chen", "Derrick Wing Kwan Ng"], "title": "Low-Altitude UAV Tracking via Sensing-Assisted Predictive Beamforming", "comment": "13 pages, submitted to IEEE Transaction journals", "summary": "Sensing-assisted predictive beamforming, as one of the enabling technologies\nfor emerging integrated sensing and communication (ISAC) paradigm, shows\nsignificant promise for enhancing various future unmanned aerial vehicle (UAV)\napplications. However, current works predominately emphasized on spectral\nefficiency enhancement, while the impact of such beamforming techniques on the\ncommunication reliability was largely unexplored and challenging to\ncharacterize. To fill this research gap and tackle this issue, this paper\ninvestigates outage capacity maximization for UAV tracking under the\nsensing-assisted predictive beamforming scheme. Specifically, a\ncellular-connected UAV tracking scheme is proposed leveraging extended Kalman\nfiltering (EKF), where the predicted UAV trajectory, sensing duration ratio,\nand target constant received signal-to-noise ratio (SNR) are jointly optimized\nto maximize the outage capacity at each time slot. To address the implicit\nnature of the objective function, closed-form approximations of the outage\nprobabilities (OPs) at both prediction and measurement stages of each time slot\nare proposed based on second-order Taylor expansions, providing an efficient\nand full characterization of outage capacity. Subsequently, an efficient\nalgorithm is proposed based on a combination of bisection search and successive\nconvex approximation (SCA) to address the non-convex optimization problem with\nguaranteed convergence. To further reduce computational complexity, a second\nefficient algorithm is developed based on alternating optimization (AO).\nSimulation results validate the accuracy of the derived OP approximations, the\neffectiveness of the proposed algorithms, and the significant outage capacity\nenhancement over various benchmarks, while also indicating a trade-off between\ndecreasing path loss and enjoying wide beam coverage for outage capacity\nmaximization."}
{"id": "2509.12748", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.12748", "abs": "https://arxiv.org/abs/2509.12748", "authors": ["Haiyang Li", "Tianqi Mao", "Pengyu Wang", "Ruiqi Liu", "Shunyu Li", "Zhaocheng Wang"], "title": "NEFT: A Unified Transformer Framework for Efficient Near-Field CSI Feedback in XL-MIMO Systems", "comment": null, "summary": "Extremely large-scale multiple-input multiple-output (XL-MIMO) systems,\noperating in the near-field region due to their massive antenna arrays, are a\nkey enabler of next-generation wireless communications but face significant\nchallenges in channel state information (CSI) feedback. Deep learning has\nemerged as a powerful tool by learning compact CSI representations for\nfeedback. However, existing methods struggle to capture the intricate structure\nof near-field CSI while incurring prohibitive computational overhead on\npractical mobile devices. To overcome these limitations, we propose the\nNear-Field Efficient Feedback Transformer (NEFT) family for accurate and\nefficient near-field CSI feedback across diverse hardware platforms. Built on a\nhierarchical Vision Transformer backbone, NEFT is extended with lightweight\nvariants to meet various deployment constraints: NEFT-Compact applies\nmulti-level knowledge distillation (KD) to reduce complexity while maintaining\naccuracy, and NEFT-Hybrid and NEFT-Edge address encoder- and edge-constrained\nscenarios via attention-free encoding and KD. Extensive simulations show that\nNEFT achieves a 15--21 dB improvement in normalized mean-squared error (NMSE)\nover state-of-the-art methods, while NEFT-Compact and NEFT-Edge reduce total\nFLOPs by 25--36% with negligible accuracy loss. Moreover, NEFT-Hybrid lowers\nencoder-side complexity by up to 64%, enabling deployment in highly asymmetric\ndevice scenarios. These results establish NEFT as a practical and scalable\nsolution for near-field CSI feedback in XL-MIMO systems."}
{"id": "2509.12770", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.12770", "abs": "https://arxiv.org/abs/2509.12770", "authors": ["Giorgi Tsintsadze", "Haran Manoharan", "Aaron Harmon", "Daniel Commerou", "Connor Buneta", "Brian Booth", "Daryl Beetner"], "title": "EMC Limit Level Guidelines for In-System Interference with GPS Receivers", "comment": null, "summary": "Because GPS signals are weak, electronic systems and components that are\nplaced near GPS receivers can easily cause disruptive electromagnetic\ninterference through their unintended radiated emissions. In this paper, EMC\nlimit level guidelines are presented for electronics that are intended to be\nplaced near to GPS receivers, as often happens in automotive and other\napplications. One of the challenges of defining limit-levels for systems\nintended to be integrated with GPS receivers is that the impact of noise at the\ninput of the receiver may vary substantially depending on the form of the noise\ndue to the correlator function implemented by GPS receiver. The quality of the\ncorrelated signal is typically represented using the carrier-to-noise ratio ($C\n/ N_0$). A theoretical model predicting the degredation of the carrier-to-noise\nratio with radio frequency interference is presented in this paper and is\nvalidated with realistic noise sources. The model is then used to develop\nguidelines to assess the impact of unintended emissions from electronic devices\non nearby GPS receivers based on the frequency, bandwidth, and magnitude of the\nnoise. These guidelines provide a more nuanced method of evaluating emissions\nthan simple limit lines that are used by many emissions standards."}
{"id": "2509.12821", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.12821", "abs": "https://arxiv.org/abs/2509.12821", "authors": ["Martin Zach", "Youssef Haouchat", "Michael Unser"], "title": "A Statistical Benchmark for Diffusion Posterior Sampling Algorithms", "comment": null, "summary": "We propose a statistical benchmark for diffusion posterior sampling (DPS)\nalgorithms for Bayesian linear inverse problems. The benchmark synthesizes\nsignals from sparse L\\'evy-process priors whose posteriors admit efficient\nGibbs methods. These Gibbs methods can be used to obtain gold-standard\nposterior samples that can be compared to the samples obtained by the DPS\nalgorithms. By using the Gibbs methods for the resolution of the denoising\nproblems in the reverse diffusion, the framework also isolates the error that\narises from the approximations to the likelihood score. We instantiate the\nbenchmark with the minimum-mean-squared-error optimality gap and posterior\ncoverage tests and provide numerical experiments for popular DPS algorithms on\nthe inverse problems of denoising, deconvolution, imputation, and\nreconstruction from partial Fourier measurements. We release the benchmark code\nat https://github.com/zacmar/dps-benchmark. The repository exposes simple\nplug-in interfaces, reference scripts, and config-driven runs so that new\nalgorithms can be added and evaluated with minimal effort. We invite\nresearchers to contribute and report results."}
{"id": "2509.12857", "categories": ["eess.SP", "G.3"], "pdf": "https://arxiv.org/pdf/2509.12857", "abs": "https://arxiv.org/abs/2509.12857", "authors": ["Yi Zhang", "Rui Guo", "Yonina C. Eldar"], "title": "Bayesian Signal Separation via Plug-and-Play Diffusion-Within-Gibbs Sampling", "comment": "5 pages, 1 figure, submitted to conference", "summary": "We propose a posterior sampling algorithm for the problem of estimating\nmultiple independent source signals from their noisy superposition. The\nproposed algorithm is a combination of Gibbs sampling method and plug-and-play\n(PnP) diffusion priors. Unlike most existing diffusion-model-based approaches\nfor signal separation, our method allows source priors to be learned separately\nand flexibly combined without retraining. Moreover, under the assumption of\nperfect diffusion model training, the proposed method provably produces samples\nfrom the posterior distribution. Experiments on the task of heartbeat\nextraction from mixtures with synthetic motion artifacts demonstrate the\nsuperior performance of our method over existing approaches."}
{"id": "2509.12870", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.12870", "abs": "https://arxiv.org/abs/2509.12870", "authors": ["Ruichen Wang", "Zhikang Ni", "Pengzhou Wang", "Xiya Cao", "Zhi Li", "Bao Zhang"], "title": "Towards personalized, precise and survey-free environment recognition: AI-enhanced sensor fusion without pre-deployment", "comment": "5 pages, 7 figures, conference", "summary": "Accurate and personalized environment recognition is essential for seamless\nindoor positioning and optimized connectivity, yet traditional fingerprinting\nrequires costly site surveys and lacks user-level adaptation. We present a\nsurvey-free, on-device sensor-fusion framework that builds a personalized,\nlightweight multi-source fingerprint (FP) database from pedestrian dead\nreckoning (PDR), WiFi/cellular, GNSS, and interaction time tags. Matching is\nperformed by an AI-enhanced dynamic time warping module (AIDTW) that aligns\nnoisy, asynchronous sequences. To turn perception into continually improving\nactions, a cloud-edge online Reinforcement Learning from Human Feedback (RLHF)\nloop aggregates desensitized summaries and human feedback in the cloud to\noptimize a policy via proximal policy optimization (PPO), and periodically\ndistills updates to devices. Across indoor/outdoor scenarios, our system\nreduces network-transition latency (measured by time-to-switch, TTS) by 32-65%\nin daily environments compared with conventional baselines, without\nsite-specific pre-deployment."}
{"id": "2509.12954", "categories": ["eess.SP", "H.1.1"], "pdf": "https://arxiv.org/pdf/2509.12954", "abs": "https://arxiv.org/abs/2509.12954", "authors": ["Traian E. Abrudan", "Kartik Patel", "John Kimionis", "Tara Esmaeilbeig", "Eleftherios Kampianakis", "Sahan Damith Liyanaarachchi", "Michael Eggleston"], "title": "Next-Generation Backscatter Networks for Integrated Communications and RF Sensing", "comment": "15 pages + appendix", "summary": "This paper provides a comprehensive analysis and theoretical foundation for\nnext-generation backscatter networks that move beyond communication and\nintegrate RF location sensing capabilities. An end-to-end system model for\nwideband OFDM backscatter systems is derived, including detailed\ncharacterization of propagation channels, receiver chain impairments, RF tag\noperation, and unsynchronized network nodes. The theoretical system model is\nvalidated through experimental evaluation using actual hardware, demonstrating\nthe detailed model's accuracy. A practical bistatic ranging method that can\noperate with unsynchronized nodes is presented, along with the Cram\\'er-Rao\nLower Bound (CRLB) derived to show the achievable performance limits. Our\nexperimental results demonstrate the system performance for communication, RF\nsensing, and ranging, while also benchmarking against the derived theoretical\nlimits. This analytical framework and experimental validation establish\nfundamental understanding of distributed, unsynchronized backscatter systems\nfor future machine-type communication networks that are deployed in massive\nscale, while remaining energy-efficient."}
{"id": "2509.12971", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.12971", "abs": "https://arxiv.org/abs/2509.12971", "authors": ["Wenyi Yan", "Zeyuan Li", "Lu Gan", "Honqing Liu", "Guoquan Li"], "title": "Difference-Based Recovery for Modulo Sampling: Tightened Bounds and Robustness Guarantees", "comment": null, "summary": "Conventional analog-to-digital converters (ADCs) clip when signals exceed\ntheir input range. Modulo (unlimited) sampling overcomes this limitation by\nfolding the signal before digitization, but existing recovery methods are\neither computationally intensive or constrained by loose oversampling bounds\nthat demand high sampling rates. In addition, none account for sampling jitter,\nwhich is unavoidable in practice. This paper revisits difference-based recovery\nand establishes new theoretical and practical guarantees. In the noiseless\nsetting, we prove that arbitrarily high difference order reduces the sufficient\noversampling factor from $2\\pi e$ to $\\pi$, substantially tightening classical\nbounds. For fixed order $N$, we derive a noise-aware sampling condition that\nguarantees stable recovery. For second-order difference-based recovery ($N=2$),\nwe further extend the analysis to non-uniform sampling, proving robustness\nunder bounded jitter. An FPGA-based hardware prototype demonstrates reliable\nreconstruction with amplitude expansion up to $\\rho = 108$, confirming the\nfeasibility of high-performance unlimited sensing with a simple and robust\nrecovery pipeline."}
{"id": "2509.13004", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.13004", "abs": "https://arxiv.org/abs/2509.13004", "authors": ["Jona Cappelle", "Jarne Van Mulders", "Sarah Goossens", "Thomas Reher", "Liesbet Van der Perre", "Lieven De Strycker", "Bram Van de Poel", "Gilles Callebaut"], "title": "RF-Powered Batteryless Plant Movement Sensor for Precision Agriculture", "comment": null, "summary": "Precision agriculture demands non-invasive, energy-efficient, and sustainable\nplant monitoring solutions. In this work, we present the design and\nimplementation of a lightweight, batteryless plant movement sensor powered\nsolely by RF energy. This sensor targets Controlled Environment Agriculture\n(CEA) and utilizes inertial measurements units (IMUs) to monitor leaf motion,\nwhich correlates with plant physiological responses to environmental stress. By\neliminating the battery, we reduce the ecological footprint, weight, and\nmaintenance requirements, transitioning from lifetime-based to operation-based\nenergy storage. Our design minimizes circuit complexity while enabling\nflexible, adaptive readout scheduling based on energy availability and sensor\ndata. We detail the energy requirements, RF power transfer considerations,\nintegration constraints, and outline future directions, including multi-antenna\npower delivery and networked sensor synchronization."}
{"id": "2509.13030", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.13030", "abs": "https://arxiv.org/abs/2509.13030", "authors": ["Ge Chen", "Panqi Chen", "Lei Cheng"], "title": "Deep Tensor Learning for Reliable Channel Charting from Incomplete and Noisy Measurements", "comment": null, "summary": "Channel charting has emerged as a powerful tool for user equipment\nlocalization and wireless environment sensing. Its efficacy lies in mapping\nhigh-dimensional channel data into low-dimensional features that preserve the\nrelative similarities of the original data. However, existing channel charting\nmethods are largely developed using simulated or indoor measurements, often\nassuming clean and complete channel data across all frequency bands. In\ncontrast, real-world channels collected from base stations are typically\nincomplete due to frequency hopping and are significantly noisy, particularly\nat cell edges. These challenging conditions greatly degrade the performance of\ncurrent methods. To address this, we propose a deep tensor learning method that\nleverages the inherent tensor structure of wireless channels to effectively\nextract informative while low-dimensional features (i.e., channel charts) from\nnoisy and incomplete measurements. Experimental results demonstrate the\nreliability and effectiveness of the proposed approach in these challenging\nscenarios."}
{"id": "2509.13071", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.13071", "abs": "https://arxiv.org/abs/2509.13071", "authors": ["Yuan Liu", "Linlong Wu", "Xuesong Cai", "M. R. Bhavani Shankar"], "title": "Scatterer Localization Using Multi-Bounce Paths", "comment": "Presented in ISCS25", "summary": "Indoor sensing is challenging because of the multi-bounce effect, spherical\nwavefront, and spatial nonstationarity (SNS) of the near-field effect. This\npaper addresses radio-based environment sensing considering these issues.\nSpecifically, graph theory (GT) is used to model the multi-bounce propagation\nof the near field. In this manner, indoor reflectors/scatterers are modeled as\nvertices in a propagation graph, the multi-bounce paths are modeled by the\nedges linking the vertices. Besides, the coupled multipath parameters in the\nnear field, i.e., range and angles, are denoted directly by the coordinates of\nvertices. Then, the space-alternating generalized expectation-maximization\n(SAGE) algorithm is adapted to the proposed Graph theory-based dictionary-aided\nMulti-bounce SAGE (GM-SAGE), where the searching parameters including range and\nangle of departure/arrival (AoD/AoA) are transformed to the coordinates of\nscatterers in the graph. The proposed algorithm is validated through\nmeasurement-calibrated ray tracing (RT) in a complex indoor office. The results\ndemonstrate that the proposed GM-SAGE can deal with multi-bounce channels."}
{"id": "2509.13287", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.13287", "abs": "https://arxiv.org/abs/2509.13287", "authors": ["Nandan Sriranga", "Haodong Yang", "Pramod K. Varshney"], "title": "Transmitter Subspace-Aware Target Detection in Two-Channel Passive Radars with Inter-Receiver Collaboration", "comment": null, "summary": "We address target detection in a single Delay-Doppler cell using spatially\ndistributed two-channel passive radars. An unknown illuminator of opportunity\n(IO) is assumed to emit a waveform lying in a known low-dimensional subspace\n(e.g., OFDM). Each receiver transforms its reference and surveillance signals\nonto the IO subspace after noise-whitening, to obtain cross-correlation (CC)\nmeasurements. To save bandwidth, receivers collaboratively exchange and\nlinearly combine the CC output, and only a subset transmits them to a fusion\ncenter (FC) over a multiple-access channel (MAC). Collaboration weights are\ndesigned using the moments of the FC measurement to enhance detection\nperformance."}
