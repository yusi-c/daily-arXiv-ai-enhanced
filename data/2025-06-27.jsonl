{"id": "2506.20783", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.20783", "abs": "https://arxiv.org/abs/2506.20783", "authors": ["Zijun Wang", "Shawn Tsai", "Rama Kiran", "Rui Zhang"], "title": "Precise Near-Field Beam Training with DFT Codebook based on Amplitude-only Measurement", "comment": null, "summary": "Extremely large antenna arrays (ELAAs) operating in high-frequency bands have\nspurred the development of near-field communication, driving advancements in\nbeam training and signal processing design. In this work, we present a\nlow-complexity near-field beam training scheme that fully utilizes the\nconventional discrete Fourier transform (DFT) codebook designed for far-field\nusers. We begin by analyzing the received beam pattern in the near field and\nderive closed-form expressions for the beam width and central gain. These\nanalytical results enable the definition of an angle-dependent, modified\nRayleigh distance, which effectively distinguishes near-field and far-field\nuser regimes. Building on the analysis, we develop a direct and computationally\nefficient method to estimate user distance, with a complexity of O(1), and\nfurther improve its accuracy through a simple refinement. Simulation results\ndemonstrate significant gains in both single- and multi-user settings, with up\nto 2.38 dB SNR improvement over exhaustive search. To further enhance\nestimation accuracy, we additionally propose a maximum likelihood estimation\n(MLE) based refinement method, leveraging the Rician distribution of signal\namplitudes and achieving accuracy close to the Cramer--Rao bound (CRB).\nSimulation shows the single-user and multi-user achievable rates can both\napproach those obtained with ideal channel state information."}
{"id": "2506.20683", "categories": ["eess.IV", "cs.AI", "cs.CV", "eess.SP"], "pdf": "https://arxiv.org/pdf/2506.20683", "abs": "https://arxiv.org/abs/2506.20683", "authors": ["Alexander Selivanov", "Philip Müller", "Özgün Turgut", "Nil Stolt-Ansó", "Daniel Rückert"], "title": "Global and Local Contrastive Learning for Joint Representations from Cardiac MRI and ECG", "comment": "accepted to MICCAI 2025 (Springer LNCS)", "summary": "An electrocardiogram (ECG) is a widely used, cost-effective tool for\ndetecting electrical abnormalities in the heart. However, it cannot directly\nmeasure functional parameters, such as ventricular volumes and ejection\nfraction, which are crucial for assessing cardiac function. Cardiac magnetic\nresonance (CMR) is the gold standard for these measurements, providing detailed\nstructural and functional insights, but is expensive and less accessible. To\nbridge this gap, we propose PTACL (Patient and Temporal Alignment Contrastive\nLearning), a multimodal contrastive learning framework that enhances ECG\nrepresentations by integrating spatio-temporal information from CMR. PTACL uses\nglobal patient-level contrastive loss and local temporal-level contrastive\nloss. The global loss aligns patient-level representations by pulling ECG and\nCMR embeddings from the same patient closer together, while pushing apart\nembeddings from different patients. Local loss enforces fine-grained temporal\nalignment within each patient by contrasting encoded ECG segments with\ncorresponding encoded CMR frames. This approach enriches ECG representations\nwith diagnostic information beyond electrical activity and transfers more\ninsights between modalities than global alignment alone, all without\nintroducing new learnable weights. We evaluate PTACL on paired ECG-CMR data\nfrom 27,951 subjects in the UK Biobank. Compared to baseline approaches, PTACL\nachieves better performance in two clinically relevant tasks: (1) retrieving\npatients with similar cardiac phenotypes and (2) predicting CMR-derived cardiac\nfunction parameters, such as ventricular volumes and ejection fraction. Our\nresults highlight the potential of PTACL to enhance non-invasive cardiac\ndiagnostics using ECG. The code is available at:\nhttps://github.com/alsalivan/ecgcmr"}
{"id": "2506.20798", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.20798", "abs": "https://arxiv.org/abs/2506.20798", "authors": ["Mohammad Taghi Dabiri", "Mazen Hasna", "Saif Al-Kuwari", "Khalid Qaraqe"], "title": "Physical Limits of Entanglement-Based Quantum Key Distribution over Long-Distance Satellite Links", "comment": null, "summary": "Entanglement-based quantum key distribution (QKD) protocols, such as E91 and\nBBM92, offer strong information-theoretic security and are naturally suited for\nsatellite-to-satellite QKD (SatQKD) links. However, implementing these\nprotocols over long-distance inter-satellite free-space optical (FSO) channels\nposes critical physical-layer challenges that are not addressed in the existing\nliterature. In particular, photon losses due to beam divergence, pointing\nerrors, and background noise can severely degrade the key generation rate and\nquantum bit error rate (QBER), especially under narrow receiver field-of-view\n(FoV) constraints. This paper presents a comprehensive performance analysis of\nentanglement-based inter-satellite QKD, focusing on photon-level modeling and\nthe impact of practical impairments. We develop analytical expressions for\nsignal detection probabilities, background photon influence, multi-pair\nemissions, and QBER, incorporating key parameters such as link distance,\ntransmitter tracking jitter, receiver misalignment, and photon pair generation\nrate. Simulation results reveal the nonlinear sensitivity of system performance\nto tracking error and FoV limitations, and highlight optimal parameter regimes\nthat jointly maximize secret key rate while maintaining QBER below acceptable\nthresholds. The proposed model provides actionable design insights for reliable\nand efficient deployment of entanglement-based SatQKD systems."}
{"id": "2506.20688", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2506.20688", "abs": "https://arxiv.org/abs/2506.20688", "authors": ["Minglong Li", "Lianlei Shan", "Weiqiang Wang", "Ke Lv", "Bin Luo", "Si-Bao Chen"], "title": "Building Lightweight Semantic Segmentation Models for Aerial Images Using Dual Relation Distillation", "comment": null, "summary": "Recently, there have been significant improvements in the accuracy of CNN\nmodels for semantic segmentation. However, these models are often heavy and\nsuffer from low inference speed, which limits their practical application. To\naddress this issue, knowledge distillation has emerged as a promising approach\nto achieve a good trade-off between segmentation accuracy and efficiency. In\nthis paper, we propose a novel dual relation distillation (DRD) technique that\ntransfers both spatial and channel relations in feature maps from a cumbersome\nmodel (teacher) to a compact model (student). Specifically, we compute spatial\nand channel relation maps separately for the teacher and student models, and\nthen align corresponding relation maps by minimizing their distance. Since the\nteacher model usually learns more information and collects richer spatial and\nchannel correlations than the student model, transferring these correlations\nfrom the teacher to the student can help the student mimic the teacher better\nin terms of feature distribution, thus improving the segmentation accuracy of\nthe student model. We conduct comprehensive experiments on three segmentation\ndatasets, including two widely adopted benchmarks in the remote sensing field\n(Vaihingen and Potsdam datasets) and one popular benchmark in general scene\n(Cityscapes dataset). The experimental results demonstrate that our novel\ndistillation framework can significantly boost the performance of the student\nnetwork without incurring extra computational overhead."}
{"id": "2506.20823", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.20823", "abs": "https://arxiv.org/abs/2506.20823", "authors": ["Mohammad Taghi Dabiri", "Mazen Hasna"], "title": "Compact Analytical Model for Real-Time Evaluation of OAM-Based Inter-Satellite Links", "comment": null, "summary": "This paper presents an efficient analytical framework for evaluating the\nperformance of inter-satellite communication systems utilizing orbital angular\nmomentum (OAM) beams under pointing errors. An accurate analytical model is\nfirst developed to characterize intermodal crosstalk caused by beam\nmisalignment in OAM-based inter-satellite links. Building upon this model, we\nderive efficient expressions to analyze and optimize system performance in\nterms of bit error rate (BER). Unlike traditional Monte Carlo-based methods\nthat are computationally intensive, the proposed approach offers accurate\nperformance predictions. This enables a substantial decrease in computation\ntime while maintaining high accuracy, thanks to the use of analytical\nexpressions for both crosstalk and BER. This fast and accurate evaluation\ncapability is particularly critical for dynamic low Earth orbit (LEO) satellite\nconstellations, where network topology and channel conditions change rapidly,\nrequiring real-time link adaptation. Furthermore, we systematically design and\nevaluate asymmetric OAM mode sets, which significantly outperform symmetric\nconfigurations in the presence of pointing errors. Our results also reveal key\ninsights into the interaction between beam divergence, tracking accuracy, and\nlink distance, demonstrating that the proposed framework enables real-time\noptimization of system parameters with high fidelity. The analytical findings\nare rigorously validated against extensive Monte Carlo simulations, confirming\ntheir practical applicability for high-mobility optical wireless systems such\nas LEO satellite networks."}
{"id": "2506.20689", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG", "I.4.6; I.2; I.5.2; I.5.1"], "pdf": "https://arxiv.org/pdf/2506.20689", "abs": "https://arxiv.org/abs/2506.20689", "authors": ["Racheal Mukisa", "Arvind K. Bansal"], "title": "U-R-VEDA: Integrating UNET, Residual Links, Edge and Dual Attention, and Vision Transformer for Accurate Semantic Segmentation of CMRs", "comment": "15 pages, 3 figures", "summary": "Artificial intelligence, including deep learning models, will play a\ntransformative role in automated medical image analysis for the diagnosis of\ncardiac disorders and their management. Automated accurate delineation of\ncardiac images is the first necessary initial step for the quantification and\nautomated diagnosis of cardiac disorders. In this paper, we propose a deep\nlearning based enhanced UNet model, U-R-Veda, which integrates convolution\ntransformations, vision transformer, residual links, channel-attention, and\nspatial attention, together with edge-detection based skip-connections for an\naccurate fully-automated semantic segmentation of cardiac magnetic resonance\n(CMR) images. The model extracts local-features and their interrelationships\nusing a stack of combination convolution blocks, with embedded channel and\nspatial attention in the convolution block, and vision transformers. Deep\nembedding of channel and spatial attention in the convolution block identifies\nimportant features and their spatial localization. The combined edge\ninformation with channel and spatial attention as skip connection reduces\ninformation-loss during convolution transformations. The overall model\nsignificantly improves the semantic segmentation of CMR images necessary for\nimproved medical image analysis. An algorithm for the dual attention module\n(channel and spatial attention) has been presented. Performance results show\nthat U-R-Veda achieves an average accuracy of 95.2%, based on DSC metrics. The\nmodel outperforms the accuracy attained by other models, based on DSC and HD\nmetrics, especially for the delineation of right-ventricle and\nleft-ventricle-myocardium."}
{"id": "2506.20858", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.20858", "abs": "https://arxiv.org/abs/2506.20858", "authors": ["Jamil Farhat", "Gianni Pasolini", "Enrico Paolini", "Muhammad Asad Ullah", "Richard Demo Souza"], "title": "Doppler Estimation and Compensation Techniques in LoRa Direct-to-Satellite Communications", "comment": null, "summary": "Within the LPWAN framework, the LoRa modulation adopted by LoRaWAN technology\nhas garnered significant interest as a connectivity solution for IoT\napplications due to its ability to offer low-cost, low-power, and long-range\ncommunications. One emerging use case of LoRa is DtS connectivity, which\nextends coverage to remote areas for supporting IoT operations. The satellite\nIoT industry mainly prefers LEO because it has lower launch costs and less path\nloss compared to Geostationary orbit. However, a major drawback of LEO\nsatellites is the impact of the Doppler effect caused by their mobility.\nEarlier studies have confirmed that the Doppler effect significantly degrades\nthe LoRa DtS performance. In this paper, we propose four frameworks for Doppler\nestimation and compensation in LoRa DtS connectivity and numerically compare\nthe performance against the ideal scenario without the Doppler effect.\nFurthermore, we investigate the trade-offs among these frameworks by analyzing\nthe interplay between spreading factor, and other key parameters related to the\nDoppler effect. The results provide insights into how to achieve robust LoRa\nconfigurations for DtS connectivity."}
{"id": "2506.20897", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.20897", "abs": "https://arxiv.org/abs/2506.20897", "authors": ["Shuki Maruyama", "Hidenori Takeshima"], "title": "Development of MR spectral analysis method robust against static magnetic field inhomogeneity", "comment": "11 pages, 6 figures", "summary": "Purpose:To develop a method that enhances the accuracy of spectral analysis\nin the presence of static magnetic field B0 inhomogeneity. Methods:The authors\nproposed a new spectral analysis method utilizing a deep learning model trained\non modeled spectra that consistently represent the spectral variations induced\nby B0 inhomogeneity. These modeled spectra were generated from the B0 map and\nmetabolite ratios of the healthy human brain. The B0 map was divided into a\npatch size of subregions, and the separately estimated metabolites and baseline\ncomponents were averaged and then integrated. The quality of the modeled\nspectra was visually and quantitatively evaluated against the measured spectra.\nThe analysis models were trained using measured, simulated, and modeled\nspectra. The performance of the proposed method was assessed using mean squared\nerrors (MSEs) of metabolite ratios. The mean absolute percentage errors (MAPEs)\nof the metabolite ratios were also compared to LCModel when analyzing the\nphantom spectra acquired under two types of B0 inhomogeneity. Results:The\nmodeled spectra exhibited broadened and narrowed spectral peaks depending on\nthe B0 inhomogeneity and were quantitatively close to the measured spectra. The\nanalysis model trained using measured spectra with modeled spectra improved\nMSEs by 49.89% compared to that trained using measured spectra alone, and by\n26.66% compared to that trained using measured spectra with simulated spectra.\nThe performance improved as the number of modeled spectra increased from 0 to\n1,000. This model showed significantly lower MAPEs than LCModel under both\ntypes of B0 inhomogeneity. Conclusion:A new spectral analysis-trained deep\nlearning model using the modeled spectra was developed. The results suggest\nthat the proposed method has the potential to improve the accuracy of spectral\nanalysis by increasing the training samples of spectra."}
{"id": "2506.20863", "categories": ["eess.SP", "quant-ph"], "pdf": "https://arxiv.org/pdf/2506.20863", "abs": "https://arxiv.org/abs/2506.20863", "authors": ["Naoki Ishikawa", "Giuseppe Thadeu Freitas de Abreu", "Petar Popovski", "Robert W. Heath Jr"], "title": "Quantum-Accelerated Wireless Communications: Concepts, Connections, and Implications", "comment": "7 pages, 6 figures", "summary": "Quantum computing is poised to redefine the algorithmic foundations of\ncommunication systems. While quantum superposition and entanglement enable\nquadratic or exponential speedups for specific problems, identifying use cases\nwhere these advantages yield engineering benefits is, however, still\nnontrivial. This article presents the fundamentals of quantum computing in a\nstyle familiar to the communications society, outlining the current limits of\nfault-tolerant quantum computing and uncovering a mathematical harmony between\nquantum and wireless systems, which makes the topic more enticing to wireless\nresearchers. Based on a systematic review of pioneering and state-of-the-art\nstudies, we distill common design trends for the research and development of\nquantum-accelerated communication systems and highlight lessons learned. The\nkey insight is that classical heuristics can sharpen certain quantum\nparameters, underscoring the complementary strengths of classical and quantum\ncomputing. This article aims to catalyze interdisciplinary research at the\nfrontier of quantum information processing and future communication systems."}
{"id": "2506.21162", "categories": ["eess.IV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.21162", "abs": "https://arxiv.org/abs/2506.21162", "authors": ["Shuwei Xing", "Derek W. Cool", "David Tessier", "Elvis C. S. Chen", "Terry M. Peters", "Aaron Fenster"], "title": "A Novel Framework for Integrating 3D Ultrasound into Percutaneous Liver Tumour Ablation", "comment": "11 pages, 5 figures", "summary": "3D ultrasound (US) imaging has shown significant benefits in enhancing the\noutcomes of percutaneous liver tumour ablation. Its clinical integration is\ncrucial for transitioning 3D US into the therapeutic domain. However,\nchallenges of tumour identification in US images continue to hinder its broader\nadoption. In this work, we propose a novel framework for integrating 3D US into\nthe standard ablation workflow. We present a key component, a clinically viable\n2D US-CT/MRI registration approach, leveraging 3D US as an intermediary to\nreduce registration complexity. To facilitate efficient verification of the\nregistration workflow, we also propose an intuitive multimodal image\nvisualization technique. In our study, 2D US-CT/MRI registration achieved a\nlandmark distance error of approximately 2-4 mm with a runtime of 0.22s per\nimage pair. Additionally, non-rigid registration reduced the mean alignment\nerror by approximately 40% compared to rigid registration. Results demonstrated\nthe efficacy of the proposed 2D US-CT/MRI registration workflow. Our\nintegration framework advanced the capabilities of 3D US imaging in improving\npercutaneous tumour ablation, demonstrating the potential to expand the\ntherapeutic role of 3D US in clinical interventions."}
{"id": "2506.20970", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.20970", "abs": "https://arxiv.org/abs/2506.20970", "authors": ["Haijia Jin", "Jun Wu", "Weijie Yuan", "Fan Liu", "Yuanhao Cui"], "title": "Co-Design of Sensing, Communications, and Control for Low-Altitude Wireless Networks", "comment": null, "summary": "The rapid advancement of Internet of Things (IoT) services and the evolution\ntoward the sixth generation (6G) have positioned unmanned aerial vehicles\n(UAVs) as critical enablers of low-altitude wireless networks (LAWNs). This\nwork investigates the co-design of integrated sensing, communication, and\ncontrol ($\\mathbf{SC^{2}}$) for multi-UAV cooperative systems with finite\nblocklength (FBL) transmission. In particular, the UAVs continuously monitor\nthe state of the field robots and transmit their observations to the robot\ncontroller to ensure stable control while cooperating to localize an unknown\nsensing target (ST). To this end, a weighted optimization problem is first\nformulated by jointly considering the control and localization performance in\nterms of the linear quadratic regulator (LQR) cost and the determinant of the\nFisher information matrix (FIM), respectively. The resultant problem,\noptimizing resource allocations, the UAVs' deployment positions, and multi-user\nscheduling, is non-convex. To circumvent this challenge, we first derive a\nclosed-form expression of the LQR cost with respect to other variables.\nSubsequently, the non-convex optimization problem is decomposed into a series\nof sub-problems by leveraging the alternating optimization (AO) approach, in\nwhich the difference of convex functions (DC) programming and projected\ngradient descent (PGD) method are employed to obtain an efficient near-optimal\nsolution. Furthermore, the convergence and computational complexity of the\nproposed algorithm are thoroughly analyzed. Extensive simulation results are\npresented to validate the effectiveness of our proposed approach compared to\nthe benchmark schemes and reveal the trade-off between control and sensing\nperformance."}
{"id": "2506.21171", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.21171", "abs": "https://arxiv.org/abs/2506.21171", "authors": ["Jing Yang", "Qunliang Xing", "Mai Xu", "Minglang Qiao"], "title": "Uncover Treasures in DCT: Advancing JPEG Quality Enhancement by Exploiting Latent Correlations", "comment": null, "summary": "Joint Photographic Experts Group (JPEG) achieves data compression by\nquantizing Discrete Cosine Transform (DCT) coefficients, which inevitably\nintroduces compression artifacts. Most existing JPEG quality enhancement\nmethods operate in the pixel domain, suffering from the high computational\ncosts of decoding. Consequently, direct enhancement of JPEG images in the DCT\ndomain has gained increasing attention. However, current DCT-domain methods\noften exhibit limited performance. To address this challenge, we identify two\ncritical types of correlations within the DCT coefficients of JPEG images.\nBuilding on this insight, we propose an Advanced DCT-domain JPEG Quality\nEnhancement (AJQE) method that fully exploits these correlations. The AJQE\nmethod enables the adaptation of numerous well-established pixel-domain models\nto the DCT domain, achieving superior performance with reduced computational\ncomplexity. Compared to the pixel-domain counterparts, the DCT-domain models\nderived by our method demonstrate a 0.35 dB improvement in PSNR and a 60.5%\nincrease in enhancement throughput on average."}
{"id": "2506.21043", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.21043", "abs": "https://arxiv.org/abs/2506.21043", "authors": ["Shweta Pal", "Arun Kumar", "Monika Agrawal"], "title": "Analysis of Null Related Beampattern Measures and Signal Quantization Effects for Linear Differential Microphone Arrays", "comment": "10 pages, 15 Figures, 3 Tables", "summary": "A differential microphone array (DMA) offers enhanced capabilities to obtain\nsharp nulls at the cost of relatively broad peaks in the beam power pattern.\nThis can be used for applications that require nullification or attenuation of\ninterfering sources. To the best of our knowledge, the existing literature\nlacks measures that directly assess the efficacy of nulls, and null-related\nmeasures have not been investigated in the context of differential microphone\narrays (DMAs). This paper offers new insights about the utility of DMAs by\nproposing measures that characterize the nulls in their beam power patterns. We\ninvestigate the performance of differential beamformers by presenting and\nevaluating null-related measures namely null depth (ND) and Null Width (NW) as\na function of depth level relative to the beam power pattern maxima. A study of\nsignal quantization effects due to data acquisition for 1st, 2nd and 3rd order\nlinear DMAs and for different beampatterns i.e. dipole, cardioid, hypercardioid\nand supercardioid is presented. An analytical expression for the quantized\nbeamformed output for any general $ N^{th} $ order DMA is formulated.\nSimulation results of the variation of ND with number of quantization bits and\nthe variation of NW as a function of depth are also presented and inferences\nare drawn. Lab experiments are conducted in a fully anechoic room to support\nthe simulation results. The measured beampattern exhibits a pronounced null\ndepth, confirming the effectiveness of the experimental setup."}
{"id": "2506.21245", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.21245", "abs": "https://arxiv.org/abs/2506.21245", "authors": ["Qifei Cui", "Xinyu Lu"], "title": "GANet-Seg: Adversarial Learning for Brain Tumor Segmentation with Hybrid Generative Models", "comment": null, "summary": "This work introduces a novel framework for brain tumor segmentation\nleveraging pre-trained GANs and Unet architectures. By combining a global\nanomaly detection module with a refined mask generation network, the proposed\nmodel accurately identifies tumor-sensitive regions and iteratively enhances\nsegmentation precision using adversarial loss constraints. Multi-modal MRI data\nand synthetic image augmentation are employed to improve robustness and address\nthe challenge of limited annotated datasets. Experimental results on the BraTS\ndataset demonstrate the effectiveness of the approach, achieving high\nsensitivity and accuracy in both lesion-wise Dice and HD95 metrics than the\nbaseline. This scalable method minimizes the dependency on fully annotated\ndata, paving the way for practical real-world applications in clinical\nsettings."}
{"id": "2506.21112", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.21112", "abs": "https://arxiv.org/abs/2506.21112", "authors": ["Yancheng Wang", "Wei Guo", "Guanying Chen", "Ye Zhang", "Shuguang Cui"], "title": "Point Cloud Environment-Based Channel Knowledge Map Construction", "comment": null, "summary": "Channel knowledge map (CKM) provides certain levels of channel state\ninformation (CSI) for an area of interest, serving as a critical enabler for\nenvironment-aware communications by reducing the overhead of frequent CSI\nacquisition. However, existing CKM construction schemes adopt over-simplified\nenvironment information, which significantly compromises their accuracy. To\naddress this issue, this work proposes a joint model- and data-driven approach\nto construct CKM by leveraging point cloud environmental data along with a few\nsamples of location-tagged channel information. First, we propose a novel point\nselector to identify subsets of point cloud that contain environmental\ninformation relevant to multipath channel gains, by constructing a set of\nco-focal ellipsoids based on different time of arrival (ToAs). Then, we trained\na neural channel gain estimator to learn the mapping between each selected\nsubset and its corresponding channel gain, using a real-world dataset we\ncollected through field measurements, comprising environmental point clouds and\ncorresponding channel data. Finally, experimental results demonstrate that: For\nCKM construction of power delay profile (PDP), the proposed method achieves a\nroot mean squared error (RMSE) of 2.95 dB, significantly lower than the 7.32 dB\nachieved by the conventional ray-tracing method; for CKM construction of\nreceived power values, i.e., radio map, it achieves an RMSE of 1.04 dB,\nsurpassing the Kriging interpolation method with an RMSE of 1.68 dB."}
{"id": "2506.21499", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.21499", "abs": "https://arxiv.org/abs/2506.21499", "authors": ["Hojat Asgariandehkordi", "Mostafa Sharifzadeh", "Hassan Rivaz"], "title": "Lightweight Physics-Informed Zero-Shot Ultrasound Plane Wave Denoising", "comment": null, "summary": "Ultrasound Coherent Plane Wave Compounding (CPWC) enhances image contrast by\ncombining echoes from multiple steered transmissions. While increasing the\nnumber of angles generally improves image quality, it drastically reduces the\nframe rate and can introduce blurring artifacts in fast-moving targets.\nMoreover, compounded images remain susceptible to noise, particularly when\nacquired with a limited number of transmissions. We propose a zero-shot\ndenoising framework tailored for low-angle CPWC acquisitions, which enhances\ncontrast without relying on a separate training dataset. The method divides the\navailable transmission angles into two disjoint subsets, each used to form\ncompound images that include higher noise levels. The new compounded images are\nthen used to train a deep model via a self-supervised residual learning scheme,\nenabling it to suppress incoherent noise while preserving anatomical\nstructures. Because angle-dependent artifacts vary between the subsets while\nthe underlying tissue response is similar, this physics-informed pairing allows\nthe network to learn to disentangle the inconsistent artifacts from the\nconsistent tissue signal. Unlike supervised methods, our model requires no\ndomain-specific fine-tuning or paired data, making it adaptable across\nanatomical regions and acquisition setups. The entire pipeline supports\nefficient training with low computational cost due to the use of a lightweight\narchitecture, which comprises only two convolutional layers. Evaluations on\nsimulation, phantom, and in vivo data demonstrate superior contrast enhancement\nand structure preservation compared to both classical and deep learning-based\ndenoising methods."}
{"id": "2506.21123", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.21123", "abs": "https://arxiv.org/abs/2506.21123", "authors": ["Hao Wu", "Chongwu Xie", "Xinyuan Yao", "Kang-Da Wu", "Shanchi Wu", "Rui Ni", "Guo-Yong Xiang", "Chen Gong"], "title": "Characterization of Rydberg-Atom Signal Reception of Dual-Frequency Signals Coupled with Two Energy Levels", "comment": null, "summary": "Rydberg atomic sensors have been adopted for novel radio frequency (RF)\nmeasurement technique and the sensing capability for signals in multiple\nfrequencies makes it attractive for multi-user communication. However, unlike\ntraditional antennas where the signals in multiple frequencies are orthogonal,\nthe received signals of atomic sensors corresponding to different energy levels\nwill be downconverted to the baseband simultaneously, resulting in multi-user\ninterference. Thus, in this paper, we analyze the mutual interference\ncharacteristics of two RF signals with different carrier frequencies coupling\ndifferent energy levels. We introduce the joint response coefficient based on\nthe receiver characteristics and analyze the interference of one user to\nanother. We analyze the bit-error rate (BER) and symbol-error rate (SER) for\ntwo signals coupling two different energy levels. We also conduct experiments\nto validate the BER and SER results."}
{"id": "2506.21535", "categories": ["eess.IV", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.21535", "abs": "https://arxiv.org/abs/2506.21535", "authors": ["Mohammed Baharoon", "Jun Ma", "Congyu Fang", "Augustin Toma", "Bo Wang"], "title": "Exploring the Design Space of 3D MLLMs for CT Report Generation", "comment": null, "summary": "Multimodal Large Language Models (MLLMs) have emerged as a promising way to\nautomate Radiology Report Generation (RRG). In this work, we systematically\ninvestigate the design space of 3D MLLMs, including visual input\nrepresentation, projectors, Large Language Models (LLMs), and fine-tuning\ntechniques for 3D CT report generation. We also introduce two knowledge-based\nreport augmentation methods that improve performance on the GREEN score by up\nto 10\\%, achieving the 2nd place on the MICCAI 2024 AMOS-MM challenge. Our\nresults on the 1,687 cases from the AMOS-MM dataset show that RRG is largely\nindependent of the size of LLM under the same training protocol. We also show\nthat larger volume size does not always improve performance if the original ViT\nwas pre-trained on a smaller volume size. Lastly, we show that using a\nsegmentation mask along with the CT volume improves performance. The code is\npublicly available at https://github.com/bowang-lab/AMOS-MM-Solution"}
{"id": "2506.21208", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.21208", "abs": "https://arxiv.org/abs/2506.21208", "authors": ["Shengjie Liu", "Chenyang Yang"], "title": "Adversarial Training: Enhancing Out-of-Distribution Generalization for Learning Wireless Resource Allocation", "comment": null, "summary": "Deep neural networks (DNNs) have widespread applications for optimizing\nresource allocation. Yet, their performance is vulnerable to distribution\nshifts between training and test data, say channels. In this letter, we resort\nto adversarial training (AT) for enhancing out-of-distribution (OOD)\ngeneralizability of DNNs trained in unsupervised manner. We reformulate AT to\ncapture the OOD degradation, and propose a one-step gradient ascent method for\nAT. The proposed method is validated by optimizing hybrid precoding. Simulation\nresults showcase the enhanced OOD performance of multiple kinds of DNNs across\nvarious channel distributions, when only Rayleigh fading channels are used for\ntraining."}
{"id": "2506.21325", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.21325", "abs": "https://arxiv.org/abs/2506.21325", "authors": ["Nima Mozaffarikhosravi", "Prathapasinghe Dharmawansa", "Italo Atzeni"], "title": "Localization-Based Beam Focusing in Near-Field Communications", "comment": null, "summary": "Shifting 6G-and-beyond wireless communication systems to higher frequency\nbands and the utilization of massive multiple-input multiple-output arrays will\nextend the near-field region, affecting beamforming and user localization\nschemes. In this paper, we propose a localization-based beam-focusing strategy\nthat leverages the dominant line-of-sight (LoS) propagation arising at mmWave\nand sub-THz frequencies. To support this approach, we analyze the 2D-MUSIC\nalgorithm for distance estimation by examining its spectrum in simplified,\ntractable setups with minimal numbers of antennas and users. Lastly, we compare\nthe proposed localization-based beam focusing, with locations estimated via\n2D-MUSIC, with zero forcing with pilot-based channel estimation in terms of\nuplink sum spectral efficiency. Our numerical results show that the proposed\nmethod becomes more effective under LoS-dominated propagation, short coherence\nblocks, and strong noise power arising at high carrier frequencies and with\nlarge bandwidths."}
{"id": "2506.21375", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.21375", "abs": "https://arxiv.org/abs/2506.21375", "authors": ["Ying Gao", "Qingqing Wu", "Weidong Mei", "Guangji Chen", "Wen Chen", "Ziyuan Zheng"], "title": "Integrating Movable Antennas and Intelligent Reflecting Surfaces for Coverage Enhancement", "comment": "13 pages, 8 figures, submitted to an IEEE journal for possible\n  publication on on May 8, 2025", "summary": "This paper investigates an intelligent reflecting surface (IRS)-aided movable\nantenna (MA) system, where multiple IRSs cooperate with a multi-MA base station\nto extend wireless coverage to multiple designated target areas. The objective\nis to maximize the worst-case signal-to-noise ratio (SNR) across all locations\nwithin these areas through joint optimization of MA positions, IRS reflection\ncoefficients, and transmit beamforming. To achieve this while balancing the\nperformance-cost trade-off, we propose three coverage-enhancement schemes: the\narea-adaptive MA-IRS scheme, the area-adaptive MA-staIRS scheme, and the shared\nMA-staIRS scheme, where staIRS denotes static IRSs with reflection coefficients\nconfigured only once during installation. These schemes lead to challenging\nnon-convex optimization problems with implicit objective functions, which are\ndifficult to solve optimally. To address these problems, we propose a general\nalgorithmic framework that can be applied to solve each problem efficiently\nalbeit suboptimally. Simulation results demonstrate that: 1) the proposed\nMA-based schemes consistently outperform their fixed-position antenna\n(FPA)-based counterparts under both area-adaptive and static IRS\nconfigurations, with the area-adaptive MA-IRS scheme achieving the best\nworst-case SNR performance; 2) as transmit antennas are typically far fewer\nthan IRS elements, the area-adaptive MA-staIRS scheme may underperform the\nbaseline FPA scheme with area-adaptive IRSs in terms of the worst-case SNR, but\na modest increase in antenna number can reverse this trend; 3) under a fixed\ntotal cost, the optimal MA-to-IRS-element ratio for the worst-case SNR\nmaximization is empirically found to be proportional to the reciprocal of their\nunit cost ratio."}
{"id": "2506.20683", "categories": ["eess.IV", "cs.AI", "cs.CV", "eess.SP"], "pdf": "https://arxiv.org/pdf/2506.20683", "abs": "https://arxiv.org/abs/2506.20683", "authors": ["Alexander Selivanov", "Philip Müller", "Özgün Turgut", "Nil Stolt-Ansó", "Daniel Rückert"], "title": "Global and Local Contrastive Learning for Joint Representations from Cardiac MRI and ECG", "comment": "accepted to MICCAI 2025 (Springer LNCS)", "summary": "An electrocardiogram (ECG) is a widely used, cost-effective tool for\ndetecting electrical abnormalities in the heart. However, it cannot directly\nmeasure functional parameters, such as ventricular volumes and ejection\nfraction, which are crucial for assessing cardiac function. Cardiac magnetic\nresonance (CMR) is the gold standard for these measurements, providing detailed\nstructural and functional insights, but is expensive and less accessible. To\nbridge this gap, we propose PTACL (Patient and Temporal Alignment Contrastive\nLearning), a multimodal contrastive learning framework that enhances ECG\nrepresentations by integrating spatio-temporal information from CMR. PTACL uses\nglobal patient-level contrastive loss and local temporal-level contrastive\nloss. The global loss aligns patient-level representations by pulling ECG and\nCMR embeddings from the same patient closer together, while pushing apart\nembeddings from different patients. Local loss enforces fine-grained temporal\nalignment within each patient by contrasting encoded ECG segments with\ncorresponding encoded CMR frames. This approach enriches ECG representations\nwith diagnostic information beyond electrical activity and transfers more\ninsights between modalities than global alignment alone, all without\nintroducing new learnable weights. We evaluate PTACL on paired ECG-CMR data\nfrom 27,951 subjects in the UK Biobank. Compared to baseline approaches, PTACL\nachieves better performance in two clinically relevant tasks: (1) retrieving\npatients with similar cardiac phenotypes and (2) predicting CMR-derived cardiac\nfunction parameters, such as ventricular volumes and ejection fraction. Our\nresults highlight the potential of PTACL to enhance non-invasive cardiac\ndiagnostics using ECG. The code is available at:\nhttps://github.com/alsalivan/ecgcmr"}
