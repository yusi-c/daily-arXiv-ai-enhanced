{"id": "2506.19051", "categories": ["eess.IV", "cs.CV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2506.19051", "abs": "https://arxiv.org/abs/2506.19051", "authors": ["Georgii Bychkov", "Khaled Abud", "Egor Kovalev", "Alexander Gushchin", "Dmitriy Vatolin", "Anastasia Antsiferova"], "title": "NIC-RobustBench: A Comprehensive Open-Source Toolkit for Neural Image Compression and Robustness Analysis", "comment": "arXiv admin note: text overlap with arXiv:2411.11795", "summary": "Adversarial robustness of neural networks is an increasingly important area\nof research, combining studies on computer vision models, large language models\n(LLMs), and others. With the release of JPEG AI -- the first standard for\nend-to-end neural image compression (NIC) methods -- the question of evaluating\nNIC robustness has become critically significant. However, previous research\nhas been limited to a narrow range of codecs and attacks. To address this, we\npresent \\textbf{NIC-RobustBench}, the first open-source framework to evaluate\nNIC robustness and adversarial defenses' efficiency, in addition to comparing\nRate-Distortion (RD) performance. The framework includes the largest number of\ncodecs among all known NIC libraries and is easily scalable. The paper\ndemonstrates a comprehensive overview of the NIC-RobustBench framework and\nemploys it to analyze NIC robustness. Our code is available online at\nhttps://github.com/msu-video-group/NIC-RobustBench."}
{"id": "2506.19055", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.19055", "abs": "https://arxiv.org/abs/2506.19055", "authors": ["Zefan Yang", "Xinrui Song", "Xuanang Xu", "Yongyi Shi", "Ge Wang", "Mannudeep K. Kalra", "Pingkun Yan"], "title": "Xray2Xray: World Model from Chest X-rays with Volumetric Context", "comment": null, "summary": "Chest X-rays (CXRs) are the most widely used medical imaging modality and\nplay a pivotal role in diagnosing diseases. However, as 2D projection images,\nCXRs are limited by structural superposition, which constrains their\neffectiveness in precise disease diagnosis and risk prediction. To address the\nlimitations of 2D CXRs, this study introduces Xray2Xray, a novel World Model\nthat learns latent representations encoding 3D structural information from\nchest X-rays. Xray2Xray captures the latent representations of the chest volume\nby modeling the transition dynamics of X-ray projections across different\nangular positions with a vision model and a transition model. We employed the\nlatent representations of Xray2Xray for downstream risk prediction and disease\ndiagnosis tasks. Experimental results showed that Xray2Xray outperformed both\nsupervised methods and self-supervised pretraining methods for cardiovascular\ndisease risk estimation and achieved competitive performance in classifying\nfive pathologies in CXRs. We also assessed the quality of Xray2Xray's latent\nrepresentations through synthesis tasks and demonstrated that the latent\nrepresentations can be used to reconstruct volumetric context."}
{"id": "2506.19106", "categories": ["eess.IV", "cs.CV", "q-bio.TO", "I.2.1; I.4.0"], "pdf": "https://arxiv.org/pdf/2506.19106", "abs": "https://arxiv.org/abs/2506.19106", "authors": ["Umair Khan", "Jouni Härkönen", "Marjukka Friman", "Leena Latonen", "Teijo Kuopio", "Pekka Ruusuvuori"], "title": "Staining normalization in histopathology: Method benchmarking using multicenter dataset", "comment": "18 pages, 9 figures", "summary": "Hematoxylin and Eosin (H&E) has been the gold standard in tissue analysis for\ndecades, however, tissue specimens stained in different laboratories vary,\noften significantly, in appearance. This variation poses a challenge for both\npathologists' and AI-based downstream analysis. Minimizing stain variation\ncomputationally is an active area of research. To further investigate this\nproblem, we collected a unique multi-center tissue image dataset, wherein\ntissue samples from colon, kidney, and skin tissue blocks were distributed to\n66 different labs for routine H&E staining. To isolate staining variation,\nother factors affecting the tissue appearance were kept constant. Further, we\nused this tissue image dataset to compare the performance of eight different\nstain normalization methods, including four traditional methods, namely,\nhistogram matching, Macenko, Vahadane, and Reinhard normalization, and two deep\nlearning-based methods namely CycleGAN and Pixp2pix, both with two variants\neach. We used both quantitative and qualitative evaluation to assess the\nperformance of these methods. The dataset's inter-laboratory staining variation\ncould also guide strategies to improve model generalizability through varied\ntraining data"}
{"id": "2506.19167", "categories": ["eess.IV", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.19167", "abs": "https://arxiv.org/abs/2506.19167", "authors": ["Benjamin Graham"], "title": "A Deep Learning Based Method for Fast Registration of Cardiac Magnetic Resonance Images", "comment": null, "summary": "Image registration is used in many medical image analysis applications, such\nas tracking the motion of tissue in cardiac images, where cardiac kinematics\ncan be an indicator of tissue health. Registration is a challenging problem for\ndeep learning algorithms because ground truth transformations are not feasible\nto create, and because there are potentially multiple transformations that can\nproduce images that appear correlated with the goal. Unsupervised methods have\nbeen proposed to learn to predict effective transformations, but these methods\ntake significantly longer to predict than established baseline methods. For a\ndeep learning method to see adoption in wider research and clinical settings,\nit should be designed to run in a reasonable time on common, mid-level\nhardware. Fast methods have been proposed for the task of image registration\nbut often use patch-based methods which can affect registration accuracy for a\nhighly dynamic organ such as the heart.\n  In this thesis, a fast, volumetric registration model is proposed for the use\nof quantifying cardiac strain. The proposed Deep Learning Neural Network (DLNN)\nis designed to utilize an architecture that can compute convolutions incredibly\nefficiently, allowing the model to achieve registration fidelity similar to\nother state-of-the-art models while taking a fraction of the time to perform\ninference. The proposed fast and lightweight registration (FLIR) model is used\nto predict tissue motion which is then used to quantify the non-uniform strain\nexperienced by the tissue. For acquisitions taken from the same patient at\napproximately the same time, it would be expected that strain values measured\nbetween the acquisitions would have very small differences. Using this metric,\nstrain values computed using the FLIR method are shown to be very consistent."}
{"id": "2506.19090", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2506.19090", "abs": "https://arxiv.org/abs/2506.19090", "authors": ["Eunhyuk Park", "Seok-Hwan Park", "Osvaldo Simeone", "Marco Di Renzo", "Shlomo Shamai"], "title": "SIM-Enabled Hybrid Digital-Wave Beamforming for Fronthaul-Constrained Cell-Free Massive MIMO Systems", "comment": "Submitted to an IEEE journal", "summary": "As the dense deployment of access points (APs) in cell-free massive\nmultiple-input multiple-output (CF-mMIMO) systems presents significant\nchallenges, per-AP coverage can be expanded using large-scale antenna arrays\n(LAAs). However, this approach incurs high implementation costs and substantial\nfronthaul demands due to the need for dedicated RF chains for all antennas. To\naddress these challenges, we propose a hybrid beamforming framework that\nintegrates wave-domain beamforming via stacked intelligent metasurfaces (SIM)\nwith conventional digital processing. By dynamically manipulating\nelectromagnetic waves, SIM-equipped APs enhance beamforming gains while\nsignificantly reducing RF chain requirements. We formulate a joint optimization\nproblem for digital and wave-domain beamforming along with fronthaul\ncompression to maximize the weighted sum-rate for both uplink and downlink\ntransmission under finite-capacity fronthaul constraints. Given the high\ndimensionality and non-convexity of the problem, we develop alternating\noptimization-based algorithms that iteratively optimize digital and wave-domain\nvariables. Numerical results demonstrate that the proposed hybrid schemes\noutperform conventional hybrid schemes, that rely on randomly set wave-domain\nbeamformers or restrict digital beamforming to simple power control. Moreover,\nthe proposed scheme employing sufficiently deep SIMs achieves near\nfully-digital performance with fewer RF chains in most simulated cases, except\nin the downlink at low signal-to-noise ratios."}
{"id": "2506.19181", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2506.19181", "abs": "https://arxiv.org/abs/2506.19181", "authors": ["Xin Zhu"], "title": "VHU-Net: Variational Hadamard U-Net for Body MRI Bias Field Correction", "comment": null, "summary": "Bias field artifacts in magnetic resonance imaging (MRI) scans introduce\nspatially smooth intensity inhomogeneities that degrade image quality and\nhinder downstream analysis. To address this challenge, we propose a novel\nvariational Hadamard U-Net (VHU-Net) for effective body MRI bias field\ncorrection. The encoder comprises multiple convolutional Hadamard transform\nblocks (ConvHTBlocks), each integrating convolutional layers with a Hadamard\ntransform (HT) layer. Specifically, the HT layer performs channel-wise\nfrequency decomposition to isolate low-frequency components, while a subsequent\nscaling layer and semi-soft thresholding mechanism suppress redundant\nhigh-frequency noise. To compensate for the HT layer's inability to model\ninter-channel dependencies, the decoder incorporates an inverse\nHT-reconstructed transformer block, enabling global, frequency-aware attention\nfor the recovery of spatially consistent bias fields. The stacked decoder\nConvHTBlocks further enhance the capacity to reconstruct the underlying\nground-truth bias field. Building on the principles of variational inference,\nwe formulate a new evidence lower bound (ELBO) as the training objective,\npromoting sparsity in the latent space while ensuring accurate bias field\nestimation. Comprehensive experiments on abdominal and prostate MRI datasets\ndemonstrate the superiority of VHU-Net over existing state-of-the-art methods\nin terms of intensity uniformity, signal fidelity, and tissue contrast.\nMoreover, the corrected images yield substantial downstream improvements in\nsegmentation accuracy. Our framework offers computational efficiency,\ninterpretability, and robust performance across multi-center datasets, making\nit suitable for clinical deployment."}
{"id": "2506.19141", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.19141", "abs": "https://arxiv.org/abs/2506.19141", "authors": ["Bruno Aristimunha", "Dung Truong", "Pierre Guetschel", "Seyed Yahya Shirazi", "Isabelle Guyon", "Alexandre R. Franco", "Michael P. Milham", "Aviv Dotan", "Scott Makeig", "Alexandre Gramfort", "Jean-Remi King", "Marie-Constance Corsi", "Pedro A. Valdés-Sosa", "Amit Majumdar", "Alan Evans", "Terrence J Sejnowski", "Oren Shriki", "Sylvain Chevallier", "Arnaud Delorme"], "title": "EEG Foundation Challenge: From Cross-Task to Cross-Subject EEG Decoding", "comment": "Approved at Neurips Competition track. webpage:\n  https://eeg2025.github.io/", "summary": "Current electroencephalogram (EEG) decoding models are typically trained on\nsmall numbers of subjects performing a single task. Here, we introduce a\nlarge-scale, code-submission-based competition comprising two challenges.\nFirst, the Transfer Challenge asks participants to build and test a model that\ncan zero-shot decode new tasks and new subjects from their EEG data. Second,\nthe Psychopathology factor prediction Challenge asks participants to infer\nsubject measures of mental health from EEG data. For this, we use an\nunprecedented, multi-terabyte dataset of high-density EEG signals (128\nchannels) recorded from over 3,000 child to young adult subjects engaged in\nmultiple active and passive tasks. We provide several tunable neural network\nbaselines for each of these two challenges, including a simple network and\ndemographic-based regression models. Developing models that generalise across\ntasks and individuals will pave the way for ML network architectures capable of\nadapting to EEG data collected from diverse tasks and individuals. Similarly,\npredicting mental health-relevant personality trait values from EEG might\nidentify objective biomarkers useful for clinical diagnosis and design of\npersonalised treatment for psychological conditions. Ultimately, the advances\nspurred by this challenge could contribute to the development of computational\npsychiatry and useful neurotechnology, and contribute to breakthroughs in both\nfundamental neuroscience and applied clinical research."}
{"id": "2506.19222", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.19222", "abs": "https://arxiv.org/abs/2506.19222", "authors": ["Xinke Ma", "Yongsheng Pan", "Qingjie Zeng", "Mengkang Lu", "Bolysbek Murat Yerzhanuly", "Bazargul Matkerim", "Yong Xia"], "title": "Deformable Medical Image Registration with Effective Anatomical Structure Representation and Divide-and-Conquer Network", "comment": null, "summary": "Effective representation of Regions of Interest (ROI) and independent\nalignment of these ROIs can significantly enhance the performance of deformable\nmedical image registration (DMIR). However, current learning-based DMIR methods\nhave limitations. Unsupervised techniques disregard ROI representation and\nproceed directly with aligning pairs of images, while weakly-supervised methods\nheavily depend on label constraints to facilitate registration. To address\nthese issues, we introduce a novel ROI-based registration approach named\nEASR-DCN. Our method represents medical images through effective ROIs and\nachieves independent alignment of these ROIs without requiring labels.\nSpecifically, we first used a Gaussian mixture model for intensity analysis to\nrepresent images using multiple effective ROIs with distinct intensities.\nFurthermore, we propose a novel Divide-and-Conquer Network (DCN) to process\nthese ROIs through separate channels to learn feature alignments for each ROI.\nThe resultant correspondences are seamlessly integrated to generate a\ncomprehensive displacement vector field. Extensive experiments were performed\non three MRI and one CT datasets to showcase the superior accuracy and\ndeformation reduction efficacy of our EASR-DCN. Compared to VoxelMorph, our\nEASR-DCN achieved improvements of 10.31\\% in the Dice score for brain MRI,\n13.01\\% for cardiac MRI, and 5.75\\% for hippocampus MRI, highlighting its\npromising potential for clinical applications. The code for this work will be\nreleased upon acceptance of the paper."}
{"id": "2506.19358", "categories": ["eess.SP", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.19358", "abs": "https://arxiv.org/abs/2506.19358", "authors": ["Yuanyuan Zhang", "Haocheng Zhao", "Sijie Xiong", "Rui Yang", "Eng Gee Lim", "Yutao Yue"], "title": "From High-SNR Radar Signal to ECG: A Transfer Learning Model with Cardio-Focusing Algorithm for Scenarios with Limited Data", "comment": null, "summary": "Electrocardiogram (ECG), as a crucial find-grained cardiac feature, has been\nsuccessfully recovered from radar signals in the literature, but the\nperformance heavily relies on the high-quality radar signal and numerous\nradar-ECG pairs for training, restricting the applications in new scenarios due\nto data scarcity. Therefore, this work will focus on radar-based ECG recovery\nin new scenarios with limited data and propose a cardio-focusing and -tracking\n(CFT) algorithm to precisely track the cardiac location to ensure an efficient\nacquisition of high-quality radar signals. Furthermore, a transfer learning\nmodel (RFcardi) is proposed to extract cardio-related information from the\nradar signal without ECG ground truth based on the intrinsic sparsity of\ncardiac features, and only a few synchronous radar-ECG pairs are required to\nfine-tune the pre-trained model for the ECG recovery. The experimental results\nreveal that the proposed CFT can dynamically identify the cardiac location, and\nthe RFcardi model can effectively generate faithful ECG recoveries after using\na small number of radar-ECG pairs for training. The code and dataset are\navailable after the publication."}
{"id": "2506.19234", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.19234", "abs": "https://arxiv.org/abs/2506.19234", "authors": ["Can Cui", "Xindong Zheng", "Ruining Deng", "Quan Liu", "Tianyuan Yao", "Keith T Wilson", "Lori A Coburn", "Bennett A Landman", "Haichun Yang", "Yaohong Wang", "Yuankai Huo"], "title": "Quantitative Benchmarking of Anomaly Detection Methods in Digital Pathology", "comment": null, "summary": "Anomaly detection has been widely studied in the context of industrial defect\ninspection, with numerous methods developed to tackle a range of challenges. In\ndigital pathology, anomaly detection holds significant potential for\napplications such as rare disease identification, artifact detection, and\nbiomarker discovery. However, the unique characteristics of pathology images,\nsuch as their large size, multi-scale structures, stain variability, and\nrepetitive patterns, introduce new challenges that current anomaly detection\nalgorithms struggle to address. In this quantitative study, we benchmark over\n20 classical and prevalent anomaly detection methods through extensive\nexperiments. We curated five digital pathology datasets, both real and\nsynthetic, to systematically evaluate these approaches. Our experiments\ninvestigate the influence of image scale, anomaly pattern types, and training\nepoch selection strategies on detection performance. The results provide a\ndetailed comparison of each method's strengths and limitations, establishing a\ncomprehensive benchmark to guide future research in anomaly detection for\ndigital pathology images."}
{"id": "2506.19376", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.19376", "abs": "https://arxiv.org/abs/2506.19376", "authors": ["Jinzhe Wang", "Qinghua Guo", "Xiaojun Yuan"], "title": "Holographic Communication via Recordable and Reconfigurable Metasurface", "comment": null, "summary": "Holographic surface based communication technologies are anticipated to play\na significant role in the next generation of wireless networks. The existing\nreconfigurable holographic surface (RHS)-based scheme only utilizes the\nreconstruction process of the holographic principle for beamforming, where the\nchannel sate information (CSI) is needed. However, channel estimation for CSI\nacquirement is a challenging task in metasurface based communications. In this\nstudy, inspired by both the recording and reconstruction processes of\nholography, we develop a novel holographic communication scheme by introducing\nrecordable and reconfigurable metasurfaces (RRMs), where channel estimation is\nnot needed thanks to the recording process. Then we analyze the input-output\nmutual information of the RRM-based communication system and compare it with\nthe existing RHS based system. Our results show that, without channel\nestimation, the proposed scheme achieves performance comparable to that of the\nRHS scheme with perfect CSI, suggesting a promising alternative for future\nwireless communication networks."}
{"id": "2506.19297", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.19297", "abs": "https://arxiv.org/abs/2506.19297", "authors": ["Yui Tatsumi", "Ziyue Zeng", "Hiroshi Watanabe"], "title": "Explicit Residual-Based Scalable Image Coding for Humans and Machines", "comment": null, "summary": "Scalable image compression is a technique that progressively reconstructs\nmultiple versions of an image for different requirements. In recent years,\nimages have increasingly been consumed not only by humans but also by image\nrecognition models. This shift has drawn growing attention to scalable image\ncompression methods that serve both machine and human vision (ICMH). Many\nexisting models employ neural network-based codecs, known as learned image\ncompression, and have made significant strides in this field by carefully\ndesigning the loss functions. In some cases, however, models are overly reliant\non their learning capacity, and their architectural design is not sufficiently\nconsidered. In this paper, we enhance the coding efficiency and\ninterpretability of ICMH framework by integrating an explicit residual\ncompression mechanism, which is commonly employed in resolution scalable coding\nmethods such as JPEG2000. Specifically, we propose two complementary methods:\nFeature Residual-based Scalable Coding (FR-ICMH) and Pixel Residual-based\nScalable Coding (PR-ICMH). These proposed methods are applicable to various\nmachine vision tasks. Moreover, they provide flexibility to choose between\nencoder complexity and compression performance, making it adaptable to diverse\napplication requirements. Experimental results demonstrate the effectiveness of\nour proposed methods, with PR-ICMH achieving up to 29.57% BD-rate savings over\nthe previous work."}
{"id": "2506.19451", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.19451", "abs": "https://arxiv.org/abs/2506.19451", "authors": ["Seunghun Lee", "Jihong Park", "Jinho Choi", "Hyuncheol Park"], "title": "Low-Complexity Semantic Packet Aggregation for Token Communication via Lookahead Search", "comment": null, "summary": "Tokens are fundamental processing units of generative AI (GenAI) and large\nlanguage models (LLMs), and token communication (TC) is essential for enabling\nremote AI-generate content (AIGC) and wireless LLM applications. Unlike\ntraditional bits, each of which is independently treated, the semantics of each\ntoken depends on its surrounding context tokens. This inter-token dependency\nmakes TC vulnerable to outage channels, where the loss of a single token can\nsignificantly distort the original message semantics. Motivated by this, this\npaper focuses on optimizing token packetization to maximize the average token\nsimilarity (ATS) between the original and received token messages under outage\nchannels. Due to inter-token dependency, this token grouping problem is\ncombinatorial, with complexity growing exponentially with message length. To\naddress this, we propose a novel framework of semantic packet aggregation with\nlookahead search (SemPA-Look), built on two core ideas. First, it introduces\nthe residual semantic score (RSS) as a token-level surrogate for the\nmessage-level ATS, allowing robust semantic preservation even when a certain\ntoken packet is lost. Second, instead of full search, SemPA-Look applies a\nlookahead search-inspired algorithm that samples intra-packet token candidates\nwithout replacement (fixed depth), conditioned on inter-packet token candidates\nsampled with replacement (fixed width), thereby achieving linear complexity.\nExperiments on a remote AIGC task with the MS-COCO dataset (text captioned\nimages) demonstrate that SemPA-Look achieves high ATS and LPIPS scores\ncomparable to exhaustive search, while reducing computational complexity by up\nto 40$\\times$. Compared to other linear-complexity algorithms such as the\ngenetic algorithm (GA), SemPA-Look achieves 10$\\times$ lower complexity,\ndemonstrating its practicality for remote AIGC and other TC applications."}
{"id": "2506.19363", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.19363", "abs": "https://arxiv.org/abs/2506.19363", "authors": ["Solveig Thrun", "Stine Hansen", "Zijun Sun", "Nele Blum", "Suaiba A. Salahuddin", "Kristoffer Wickstrøm", "Elisabeth Wetzer", "Robert Jenssen", "Maik Stille", "Michael Kampffmeyer"], "title": "Reconsidering Explicit Longitudinal Mammography Alignment for Enhanced Breast Cancer Risk Prediction", "comment": "MICCAI 2025, early accepted", "summary": "Regular mammography screening is essential for early breast cancer detection.\nDeep learning-based risk prediction methods have sparked interest to adjust\nscreening intervals for high-risk groups. While early methods focused only on\ncurrent mammograms, recent approaches leverage the temporal aspect of\nscreenings to track breast tissue changes over time, requiring spatial\nalignment across different time points. Two main strategies for this have\nemerged: explicit feature alignment through deformable registration and\nimplicit learned alignment using techniques like transformers, with the former\nproviding more control. However, the optimal approach for explicit alignment in\nmammography remains underexplored. In this study, we provide insights into\nwhere explicit alignment should occur (input space vs. representation space)\nand if alignment and risk prediction should be jointly optimized. We\ndemonstrate that jointly learning explicit alignment in representation space\nwhile optimizing risk estimation performance, as done in the current\nstate-of-the-art approach, results in a trade-off between alignment quality and\npredictive performance and show that image-level alignment is superior to\nrepresentation-level alignment, leading to better deformation field quality and\nenhanced risk prediction accuracy. The code is available at\nhttps://github.com/sot176/Longitudinal_Mammogram_Alignment.git."}
{"id": "2506.19470", "categories": ["eess.SP", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2506.19470", "abs": "https://arxiv.org/abs/2506.19470", "authors": ["Aniol Martí", "Luca Sanguinetti", "Jaume Riba", "Meritxell Lamarca"], "title": "Coherent and Noncoherent Detection in Dense Arrays: Can We Ignore Mutual Coupling?", "comment": "Accepted version of the article submitted to EUSIPCO 2025", "summary": "This paper investigates the impact of mutual coupling on MIMO systems with\ndensely deployed antennas. Leveraging multiport communication theory, we\nanalyze both coherent and noncoherent detection approaches in a single-user\nuplink scenario where the receiver ignores mutual coupling effects. Simulation\nresults indicate that while coherent detection is generally more accurate, it\nis highly sensitive to mismatches in the coupling model, leading to severe\nperformance degradation when antennas are closely spaced, to the point of\nbecoming unusable. Noncoherent detection, on the other hand, exhibits a higher\nerror probability but is more robust to coupling model mismatches."}
{"id": "2506.19387", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.19387", "abs": "https://arxiv.org/abs/2506.19387", "authors": ["Khuram Naveed", "Bruna Neves de Freitas", "Ruben Pauwels"], "title": "NAADA: A Noise-Aware Attention Denoising Autoencoder for Dental Panoramic Radiographs", "comment": "10 pages, 8 figures", "summary": "Convolutional denoising autoencoders (DAEs) are powerful tools for image\nrestoration. However, they inherit a key limitation of convolutional neural\nnetworks (CNNs): they tend to recover low-frequency features, such as smooth\nregions, more effectively than high-frequency details. This leads to the loss\nof fine details, which is particularly problematic in dental radiographs where\npreserving subtle anatomical structures is crucial. While self-attention\nmechanisms can help mitigate this issue by emphasizing important features,\nconventional attention methods often prioritize features corresponding to\ncleaner regions and may overlook those obscured by noise. To address this\nlimitation, we propose a noise-aware self-attention method, which allows the\nmodel to effectively focus on and recover key features even within noisy\nregions. Building on this approach, we introduce the noise-aware\nattention-enhanced denoising autoencoder (NAADA) network for enhancing noisy\npanoramic dental radiographs. Compared with the recent state of the art (and\nmuch heavier) methods like Uformer, MResDNN etc., our method improves the\nreconstruction of fine details, ensuring better image quality and diagnostic\naccuracy."}
{"id": "2506.19476", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.19476", "abs": "https://arxiv.org/abs/2506.19476", "authors": ["Kaidi Xu", "Shenglong Zhou", "Geoffrey Ye Li"], "title": "Neural Collapse based Deep Supervised Federated Learning for Signal Detection in OFDM Systems", "comment": null, "summary": "Future wireless networks are expected to be AI-empowered, making their\nperformance highly dependent on the quality of training datasets. However,\nphysical-layer entities often observe only partial wireless environments\ncharacterized by different power delay profiles. Federated learning is capable\nof addressing this limited observability, but often struggles with data\nheterogeneity. To tackle this challenge, we propose a neural collapse (NC)\ninspired deep supervised federated learning (NCDSFL) algorithm."}
{"id": "2506.19455", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.19455", "abs": "https://arxiv.org/abs/2506.19455", "authors": ["Zhifeng Wang", "Renjiao Yi", "Xin Wen", "Chenyang Zhu", "Kai Xu", "Kunlun He"], "title": "Angio-Diff: Learning a Self-Supervised Adversarial Diffusion Model for Angiographic Geometry Generation", "comment": null, "summary": "Vascular diseases pose a significant threat to human health, with X-ray\nangiography established as the gold standard for diagnosis, allowing for\ndetailed observation of blood vessels. However, angiographic X-rays expose\npersonnel and patients to higher radiation levels than non-angiographic X-rays,\nwhich are unwanted. Thus, modality translation from non-angiographic to\nangiographic X-rays is desirable. Data-driven deep approaches are hindered by\nthe lack of paired large-scale X-ray angiography datasets. While making\nhigh-quality vascular angiography synthesis crucial, it remains challenging. We\nfind that current medical image synthesis primarily operates at pixel level and\nstruggles to adapt to the complex geometric structure of blood vessels,\nresulting in unsatisfactory quality of blood vessel image synthesis, such as\ndisconnections or unnatural curvatures. To overcome this issue, we propose a\nself-supervised method via diffusion models to transform non-angiographic\nX-rays into angiographic X-rays, mitigating data shortages for data-driven\napproaches. Our model comprises a diffusion model that learns the distribution\nof vascular data from diffusion latent, a generator for vessel synthesis, and a\nmask-based adversarial module. To enhance geometric accuracy, we propose a\nparametric vascular model to fit the shape and distribution of blood vessels.\nThe proposed method contributes a pipeline and a synthetic dataset for X-ray\nangiography. We conducted extensive comparative and ablation experiments to\nevaluate the Angio-Diff. The results demonstrate that our method achieves\nstate-of-the-art performance in synthetic angiography image quality and more\naccurately synthesizes the geometric structure of blood vessels. The code is\navailable at https://github.com/zfw-cv/AngioDiff."}
{"id": "2506.19499", "categories": ["eess.SP", "cs.NI"], "pdf": "https://arxiv.org/pdf/2506.19499", "abs": "https://arxiv.org/abs/2506.19499", "authors": ["Noa Jie Vives Zaguirre", "Oscar Lasierra", "Filip Lemic", "Gerard Calvo Bartra", "Pablo José Galván Calderón", "Gines Garcia-Aviles", "Sergi Abadal", "Xavier Costa-Pérez"], "title": "Experimental Assessment of A Framework for In-body RF-backscattering Localization", "comment": "7 pages, 7 figures, 2 tables, accepted at IEEE International\n  Symposium on Personal, Indoor and Mobile Radio Communications 2025", "summary": "Localization of in-body devices is beneficial for Gastrointestinal (GI)\ndiagnosis and targeted treatment. Traditional methods such as imaging and\nendoscopy are invasive and limited in resolution, highlighting the need for\ninnovative alternatives. This study presents an experimental framework for\nRadio Frequency (RF)-backscatter-based in-body localization, inspired by the\nReMix approach, and evaluates its performance in real-world conditions. The\nexperimental setup includes an in-body backscatter device and various off-body\nantenna configurations to investigate harmonic generation and reception in air,\nchicken and pork tissues. The results indicate that optimal backscatter device\npositioning, antenna selection, and gain settings significantly impact\nperformance, with denser biological tissues leading to greater attenuation. The\nstudy also highlights challenges such as external interference and plastic\nenclosures affecting propagation. The findings emphasize the importance of\ninterference mitigation and refined propagation models to enhance performance."}
{"id": "2506.19590", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.19590", "abs": "https://arxiv.org/abs/2506.19590", "authors": ["Joris Wuts", "Jakub Ceranka", "Nicolas Michoux", "Frédéric Lecouvet", "Jef Vandemeulebroucke"], "title": "Learning from Anatomy: Supervised Anatomical Pretraining (SAP) for Improved Metastatic Bone Disease Segmentation in Whole-Body MRI", "comment": "This preprint is currently under review at *Computers in Biology and\n  Medicine* (Elsevier). This version has not been peer-reviewed", "summary": "The segmentation of metastatic bone disease (MBD) in whole-body MRI (WB-MRI)\nis a challenging problem. Due to varying appearances and anatomical locations\nof lesions, ambiguous boundaries, and severe class imbalance, obtaining\nreliable segmentations requires large, well-annotated datasets capturing lesion\nvariability. Generating such datasets requires substantial time and expertise,\nand is prone to error. While self-supervised learning (SSL) can leverage large\nunlabeled datasets, learned generic representations often fail to capture the\nnuanced features needed for accurate lesion detection.\n  In this work, we propose a Supervised Anatomical Pretraining (SAP) method\nthat learns from a limited dataset of anatomical labels. First, an MRI-based\nskeletal segmentation model is developed and trained on WB-MRI scans from\nhealthy individuals for high-quality skeletal delineation. Then, we compare its\ndownstream efficacy in segmenting MBD on a cohort of 44 patients with\nmetastatic prostate cancer, against both a baseline random initialization and a\nstate-of-the-art SSL method.\n  SAP significantly outperforms both the baseline and SSL-pretrained models,\nachieving a normalized surface Dice of 0.76 and a Dice coefficient of 0.64. The\nmethod achieved a lesion detection F2 score of 0.44, improving on 0.24\n(baseline) and 0.31 (SSL). When considering only clinically relevant lesions\nlarger than 1~ml, SAP achieves a detection sensitivity of 100% in 28 out of 32\npatients.\n  Learning bone morphology from anatomy yields an effective and domain-relevant\ninductive bias that can be leveraged for the downstream segmentation task of\nbone lesions. All code and models are made publicly available."}
{"id": "2506.19526", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.19526", "abs": "https://arxiv.org/abs/2506.19526", "authors": ["Prasetyo Putranto", "Anis Amazigh Hamza", "Sameh Mabrouki", "Nasrullah Armi", "Iyad Dayoub"], "title": "Reconfigurable Intelligent Surfaces for 6G and Beyond: A Comprehensive Survey from Theory to Deployment", "comment": "39 page, 21 figures, submitted to IEEE Communications Surveys &\n  Tutorials", "summary": "As the wireless research community moves toward shaping the vision of\nsixth-generation (6G) networks, reconfigurable intelligent surfaces (RIS) have\nemerged as a promising technology for controlling the propagation environment.\nAlthough RIS has not yet been standardized, its versatile applications and\nenabling capabilities have attracted growing attention in both academia and\nindustry. This survey presents a comprehensive review of RIS technology\nspanning theoretical foundations, design aspects, and practical deployment\nconsiderations. In contrast to existing surveys that focus on isolated aspects,\nthis work offers an integrated view covering use cases, control mechanisms,\nchannel sounding methodologies, and channel estimation strategies. Each of\nthese topics is reviewed through the lens of recent literature, synthesizing\nthe latest advancements to provide updated insights for both academic\nresearchers and industry practitioners. It further addresses emerging topics\nsuch as standardization activities and industrial perspectives, which are often\noverlooked in prior literature. By bridging theoretical insights with practical\nchallenges, this survey aims to provide a holistic understanding of RIS and\nsupport its evolution from a research concept toward real-world implementation."}
{"id": "2506.19600", "categories": ["eess.IV", "cs.CV", "physics.med-ph"], "pdf": "https://arxiv.org/pdf/2506.19600", "abs": "https://arxiv.org/abs/2506.19600", "authors": ["Klara Leffler", "Luigi Tommaso Luppino", "Samuel Kuttner", "Karin Söderkvist", "Jan Axelsson"], "title": "Filling of incomplete sinograms from sparse PET detector configurations using a residual U-Net", "comment": "15 pages, 9 figures", "summary": "Long axial field-of-view PET scanners offer increased field-of-view and\nsensitivity compared to traditional PET scanners. However, a significant cost\nis associated with the densely packed photodetectors required for the\nextended-coverage systems, limiting clinical utilisation. To mitigate the cost\nlimitations, alternative sparse system configurations have been proposed,\nallowing an extended field-of-view PET design with detector costs similar to a\nstandard PET system, albeit at the expense of image quality. In this work, we\npropose a deep sinogram restoration network to fill in the missing sinogram\ndata. Our method utilises a modified Residual U-Net, trained on clinical PET\nscans from a GE Signa PET/MR, simulating the removal of 50% of the detectors in\na chessboard pattern (retaining only 25% of all lines of response). The model\nsuccessfully recovers missing counts, with a mean absolute error below two\nevents per pixel, outperforming 2D interpolation in both sinogram and\nreconstructed image domain. Notably, the predicted sinograms exhibit a\nsmoothing effect, leading to reconstructed images lacking sharpness in finer\ndetails. Despite these limitations, the model demonstrates a substantial\ncapacity for compensating for the undersampling caused by the sparse detector\nconfiguration. This proof-of-concept study suggests that sparse detector\nconfigurations, combined with deep learning techniques, offer a viable\nalternative to conventional PET scanner designs. This approach supports the\ndevelopment of cost-effective, total body PET scanners, allowing a significant\nstep forward in medical imaging technology."}
{"id": "2506.19612", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.19612", "abs": "https://arxiv.org/abs/2506.19612", "authors": ["Dennis Laurijssen", "Rens Baeyens", "Walter Daems", "Jan Steckel"], "title": "A Wireless Self-Calibrating Ultrasound Microphone Array with Sub-Microsecond Synchronization", "comment": null, "summary": "We present a novel system architecture for a distributed wireless,\nself-calibrating ultrasound microphone network for synchronized in-air acoustic\nsensing. Once deployed the embedded nodes determine their position in the\nenvironment using the infrared optical tracking system found in the HTC Vive\nLighthouses. After self-calibration, the nodes start sampling the ultrasound\nmicrophone while embedding a synchronization signal in the data which is\nestablished using a wireless Sub-1GHz RF link. Data transmission is handled via\nthe Wi-Fi 6 radio that is embedded in the nodes' SoC, decoupling\nsynchronization from payload transport. A prototype system with a limited\namount of network nodes was used to verify the proposed distributed microphone\narray's wireless data acquisition and synchronization capabilities. This\narchitecture lays the groundwork for scalable, deployable ultrasound arrays for\nsound source localization applications in bio-acoustic research and industrial\nacoustic monitoring."}
{"id": "2506.19687", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.19687", "abs": "https://arxiv.org/abs/2506.19687", "authors": ["Ahmad Mustafa", "Reza Rastegar", "Ghassan AlRegib"], "title": "ReCoGNet: Recurrent Context-Guided Network for 3D MRI Prostate Segmentation", "comment": null, "summary": "Prostate gland segmentation from T2-weighted MRI is a critical yet\nchallenging task in clinical prostate cancer assessment. While deep\nlearning-based methods have significantly advanced automated segmentation, most\nconventional approaches-particularly 2D convolutional neural networks\n(CNNs)-fail to leverage inter-slice anatomical continuity, limiting their\naccuracy and robustness. Fully 3D models offer improved spatial coherence but\nrequire large amounts of annotated data, which is often impractical in clinical\nsettings. To address these limitations, we propose a hybrid architecture that\nmodels MRI sequences as spatiotemporal data. Our method uses a deep, pretrained\nDeepLabV3 backbone to extract high-level semantic features from each MRI slice\nand a recurrent convolutional head, built with ConvLSTM layers, to integrate\ninformation across slices while preserving spatial structure. This combination\nenables context-aware segmentation with improved consistency, particularly in\ndata-limited and noisy imaging conditions. We evaluate our method on the\nPROMISE12 benchmark under both clean and contrast-degraded test settings.\nCompared to state-of-the-art 2D and 3D segmentation models, our approach\ndemonstrates superior performance in terms of precision, recall, Intersection\nover Union (IoU), and Dice Similarity Coefficient (DSC), highlighting its\npotential for robust clinical deployment."}
{"id": "2506.19627", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.19627", "abs": "https://arxiv.org/abs/2506.19627", "authors": ["Carmen Álvarez Roa", "Yunus Can Gültekin", "Kaiquan Wu", "Cornelis Willem Korevaar", "Alex Alvarado"], "title": "On Error Rate Approximations for FSO Systems with Weak Turbulence and Pointing Errors", "comment": null, "summary": "Atmospheric attenuation, atmospheric turbulence, geometric spread, and\npointing errors, degrade the performance of free-space optical transmission. In\nthe weak turbulence regime, the probability density function describing the\ndistribution of the channel fading coefficient that models these four effects\nis known in the literature. This function is an integral equation, which makes\nit difficult to find simple analytical expressions of important performance\nmetrics such as the bit error rate (BER) and symbol error rate (SER). In this\npaper, we present simple and accurate approximations of the average BER and SER\nfor pulse-amplitude modulation (PAM) in the weak turbulence regime for an\nintensity modulation and direct detection system. Our numerical results show\nthat the proposed expressions exhibit excellent accuracy when compared against\nMonte Carlo simulations. To demonstrate the usefulness of the developed\napproximations, we perform two asymptotic analyses. First, we investigate the\nadditional transmit power required to maintain the same SER when the spectral\nefficiency increases by 1 bit/symbol. Second, we study the asymptotic behavior\nof our SER approximation for dense PAM constellations and high transmit power."}
{"id": "2506.19742", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.19742", "abs": "https://arxiv.org/abs/2506.19742", "authors": ["Zhuowei Xu", "Han Li", "Dai Sun", "Zhicheng Li", "Yujia Li", "Qingpeng Kong", "Zhiwei Cheng", "Nassir Navab", "S. Kevin Zhou"], "title": "NeRF-based CBCT Reconstruction needs Normalization and Initialization", "comment": null, "summary": "Cone Beam Computed Tomography (CBCT) is widely used in medical imaging.\nHowever, the limited number and intensity of X-ray projections make\nreconstruction an ill-posed problem with severe artifacts. NeRF-based methods\nhave achieved great success in this task. However, they suffer from a\nlocal-global training mismatch between their two key components: the hash\nencoder and the neural network. Specifically, in each training step, only a\nsubset of the hash encoder's parameters is used (local sparse), whereas all\nparameters in the neural network participate (global dense). Consequently, hash\nfeatures generated in each step are highly misaligned, as they come from\ndifferent subsets of the hash encoder. These misalignments from different\ntraining steps are then fed into the neural network, causing repeated\ninconsistent global updates in training, which leads to unstable training,\nslower convergence, and degraded reconstruction quality. Aiming to alleviate\nthe impact of this local-global optimization mismatch, we introduce a\nNormalized Hash Encoder, which enhances feature consistency and mitigates the\nmismatch. Additionally, we propose a Mapping Consistency Initialization(MCI)\nstrategy that initializes the neural network before training by leveraging the\nglobal mapping property from a well-trained model. The initialized neural\nnetwork exhibits improved stability during early training, enabling faster\nconvergence and enhanced reconstruction performance. Our method is simple yet\neffective, requiring only a few lines of code while substantially improving\ntraining efficiency on 128 CT cases collected from 4 different datasets,\ncovering 7 distinct anatomical regions."}
{"id": "2506.19684", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.19684", "abs": "https://arxiv.org/abs/2506.19684", "authors": ["Felipe Villenas", "Kaiquan Wu", "Yunus Can Gültekin", "Jamal Riani", "Alex Alvarado"], "title": "Beyond 200 Gb/s/lane: An Analytical Approach to Optimal Detection in Shaped IM-DD Optical Links with Relative Intensity Noise", "comment": "preprint", "summary": "Next-generation intensity-modulation (IM) and direct-detection (DD) systems\nused in data centers are expected to operate at 400 Gb/s/lane and beyond. Such\nrates can be achieved by increasing the system bandwidth or the modulation\nformat, which in turn requires maintaining or increasing the signal-to-noise\nratio (SNR). Such SNR requirements can be achieved by increasing the\ntransmitted optical power. This increase in optical power causes the emergence\nof relative intensity noise (RIN), a signal-dependent impairment inherent to\nthe transmitter laser, which ultimately limits the performance of the system.\nIn this paper, we develop an analytical symbol error rate (SER) expression for\nthe optimal detector for the IM-DD optical link under study. The developed\nexpression takes into account the signal-dependent nature of RIN and does not\nmake any assumptions on the geometry or probability distribution of the\nconstellation. Our expression is therefore applicable to general\nprobabilistically and/or geometrically shaped systems. Unlike results available\nin the literature, our proposed expression provides a perfect match to\nnumerical simulations of probabilistic and geometrically shaped systems."}
{"id": "2506.19797", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.19797", "abs": "https://arxiv.org/abs/2506.19797", "authors": ["Mubaraq Yakubu", "Navodini Wijethilake", "Jonathan Shapey", "Andrew King", "Alexander Hammers"], "title": "Systematic Review of Pituitary Gland and Pituitary Adenoma Automatic Segmentation Techniques in Magnetic Resonance Imaging", "comment": null, "summary": "Purpose: Accurate segmentation of both the pituitary gland and adenomas from\nmagnetic resonance imaging (MRI) is essential for diagnosis and treatment of\npituitary adenomas. This systematic review evaluates automatic segmentation\nmethods for improving the accuracy and efficiency of MRI-based segmentation of\npituitary adenomas and the gland itself. Methods: We reviewed 34 studies that\nemployed automatic and semi-automatic segmentation methods. We extracted and\nsynthesized data on segmentation techniques and performance metrics (such as\nDice overlap scores). Results: The majority of reviewed studies utilized deep\nlearning approaches, with U-Net-based models being the most prevalent.\nAutomatic methods yielded Dice scores of 0.19--89.00\\% for pituitary gland and\n4.60--96.41\\% for adenoma segmentation. Semi-automatic methods reported\n80.00--92.10\\% for pituitary gland and 75.90--88.36\\% for adenoma segmentation.\nConclusion: Most studies did not report important metrics such as MR field\nstrength, age and adenoma size. Automated segmentation techniques such as\nU-Net-based models show promise, especially for adenoma segmentation, but\nfurther improvements are needed to achieve consistently good performance in\nsmall structures like the normal pituitary gland. Continued innovation and\nlarger, diverse datasets are likely critical to enhancing clinical\napplicability."}
