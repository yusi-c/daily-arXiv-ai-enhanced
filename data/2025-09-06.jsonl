{"id": "2509.03686", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.03686", "abs": "https://arxiv.org/abs/2509.03686", "authors": ["Hong Zhu", "Alexander Venus", "Erik Leitinger", "Klaus Witrisal"], "title": "Multi-Sensor Fusion for Extended Object Tracking Exploiting Active and Passive Radio Signals", "comment": null, "summary": "Reliable and robust positioning of radio devices remains a challenging task\ndue to multipath propagation, hardware impairments, and interference from other\nradio transmitters. A frequently overlooked but critical factor is the agent\nitself, e.g., the user carrying the device, which potentially obstructs\nline-of-sight (LOS) links to the base stations (anchors). This paper addresses\nthe problem of accurate positioning in scenarios where LOS links are partially\nblocked by the agent. The agent is modeled as an extended object (EO) that\nscatters, attenuates, and blocks radio signals. We propose a Bayesian method\nthat fuses ``active'' measurements (between device and anchors) with\n``passive'' multistatic radar-type measurements (between anchors, reflected by\nthe EO). To handle measurement origin uncertainty, we introduce an multi-sensor\nand multiple-measurement probabilistic data association (PDA) algorithm that\njointly fuses all EO-related measurements. Furthermore, we develop an EO model\ntailored to agents such as human users, accounting for multiple reflections\nscattered off the body surface, and propose a simplified variant for\nlow-complexity implementation. Evaluation on both synthetic and real radio\nmeasurements demonstrates that the proposed algorithm outperforms conventional\nPDA methods based on point target assumptions, particularly during and after\nobstructed line-of-sight (OLOS) conditions."}
{"id": "2509.03825", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.03825", "abs": "https://arxiv.org/abs/2509.03825", "authors": ["Jeunghoon Lee"], "title": "Sensor placement for sparse force reconstruction", "comment": null, "summary": "The present study proposes a Gram-matrix-based sensor placement strategy for\nsparse force reconstruction in the frequency domain. A modal decomposition of\nthe Gram matrix reveals that its structure is dominated by a few modes near the\ntarget frequency, and that each modal contribution reflects the spatial\ncorrelation of the corresponding mode shape. This suggests that placing sensors\nnear nodal regions where spatial correlation is low can reduce coherence in the\nfrequency response function (FRF) matrix and improve force reconstruction\naccuracy. To translate the physical insight into a practical design framework,\na greedy algorithm is proposed to select sensor locations that minimize the\noff-diagonal energy of the Gram matrix. Numerical simulations and experimental\nvalidations demonstrate that the proposed method yields robust and accurate\nforce estimation, outperforming heuristic sensor layouts."}
{"id": "2509.03979", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.03979", "abs": "https://arxiv.org/abs/2509.03979", "authors": ["Gilles Callebaut", "Jan Van Moer"], "title": "A Low-Cost Open-Source BLE-Based Asian Hornet Tracking System", "comment": null, "summary": "The Asian hornet (Vespa velutina) poses a serious threat to ecosystems and\nbeekeeping. Locating nests is essential, but usually involves time-consuming\nmanual triangulation. We present a low-cost, open-source tracking system based\non Bluetooth Low Energy (BLE). The system consists of a lightweight BLE tag and\na software-defined radio (SDR) receiver implemented in GNU Radio. By bypassing\nthe BLE stack, we embed a custom pseudo-noise (PN) sequence in the uncoded PHY\nfor correlation-based detection. Using a Yagi antenna and PlutoSDR, the\nreceiver performs digital beam sweeping to determine the tag's direction. Field\ntests show reliable angular resolution at 50m and a communication range up to\n360m. While our modulation increases receiver complexity, it enables future\nimprovements such as multichannel spreading and tag identification. The design\nis fully open-source and provides a scalable framework for hornet tracking and\nrelated applications in environmental monitoring."}
{"id": "2509.03980", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.03980", "abs": "https://arxiv.org/abs/2509.03980", "authors": ["Alessandro Mirri", "Vishnu Teja Kunde", "Enrico Paolini", "Jean-Francois Chamberland"], "title": "Approximate Message Passing for Multi-Preamble Detection in OTFS Random Access", "comment": null, "summary": "This article addresses the problem of multiple preamble detection in random\naccess systems based on orthogonal time frequency space (OTFS) signaling. This\nchallenge is formulated as a structured sparse recovery problem in the complex\ndomain. To tackle it, the authors propose a new approximate message passing\n(AMP) algorithm that enforces double sparsity: the sparse selection of\npreambles and the inherent sparsity of OTFS signals in the delay-Doppler\ndomain. From an algorithmic standpoint, the non-separable complex sparsity\nconstraint necessitates a careful derivation and leads to the design of a novel\nAMP denoiser. Simulation results demonstrate that the proposed method achieves\nrobust detection performance and delivers significant gains over\nstate-of-the-art techniques."}
{"id": "2509.03543", "categories": ["eess.IV", "physics.optics"], "pdf": "https://arxiv.org/pdf/2509.03543", "abs": "https://arxiv.org/abs/2509.03543", "authors": ["Chenyu Yuan"], "title": "Latent Space Single-Pixel Imaging Under Low-Sampling Conditions", "comment": null, "summary": "In recent years, the introduction of deep learning into the field of\nsingle-pixel imaging has garnered significant attention. However, traditional\nnetworks often operate within the pixel space. To address this, we innovatively\nmigrate single-pixel imaging to the latent space, naming this framework LSSPI\n(Latent Space Single-Pixel Imaging). Within the latent space, we conduct\nin-depth explorations into both reconstruction and generation tasks for\nsingle-pixel imaging. Notably, this approach significantly enhances imaging\ncapabilities even under low sampling rate conditions. Compared to conventional\ndeep learning networks, LSSPI not only reconstructs images with higher\nsignal-to-noise ratios (SNR) and richer details under equivalent sampling rates\nbut also enables blind denoising and effective recovery of high-frequency\ninformation. Furthermore, by migrating single-pixel imaging to the latent\nspace, LSSPI achieves superior advantages in terms of model parameter\nefficiency and reconstruction speed. Its excellent computational efficiency\nfurther positions it as an ideal solution for low-sampling single-pixel imaging\napplications, effectively driving the practical implementation of single-pixel\nimaging technology."}
{"id": "2509.03983", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.03983", "abs": "https://arxiv.org/abs/2509.03983", "authors": ["Yutong Chen", "Cong Zhou", "Changsheng You", "Shuo Shi"], "title": "Joint Frequency-Space Sparse Reconstruction for DOA Estimation under Coherent Sources and Amplitude-Phase Errors", "comment": null, "summary": "In this letter, we propose a joint frequency-space sparse reconstruction\nmethod for direction-of-arrival (DOA) estimation, which effectively addresses\nthe issues arising from the existence of coherent sources and array\namplitude-phase errors. Specifically, by using an auxiliary source with known\nangles, we first construct the real steering vectors (RSVs) based on the\nspectral peaks of received signals in the frequency domain, which serve as a\ncomplete basis matrix for compensation for amplitude-phase errors. Then, we\nleverage the spectral sparsity of snapshot data in the frequency domain and the\nspatial sparsity of incident directions to perform the DOA estimation according\nto the sparse reconstruction method. The proposed method does not require\niterative optimization, hence exhibiting low computational complexity.\nNumerical results demonstrate that the proposed DOA estimation method achieves\nhigher estimation accuracy for coherent sources as compared to various\nbenchmark schemes."}
{"id": "2509.04051", "categories": ["eess.IV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.04051", "abs": "https://arxiv.org/abs/2509.04051", "authors": ["Yaojun Wu", "Chaoyi Lin", "Yiming Wang", "Semih Esenlik", "Zhaobin Zhang", "Kai Zhang", "Li Zhang"], "title": "Neural Video Compression with In-Loop Contextual Filtering and Out-of-Loop Reconstruction Enhancement", "comment": "9 pages, 8 figures, Accepted to ACMMM 2025", "summary": "This paper explores the application of enhancement filtering techniques in\nneural video compression. Specifically, we categorize these techniques into\nin-loop contextual filtering and out-of-loop reconstruction enhancement based\non whether the enhanced representation affects the subsequent coding loop.\nIn-loop contextual filtering refines the temporal context by mitigating error\npropagation during frame-by-frame encoding. However, its influence on both the\ncurrent and subsequent frames poses challenges in adaptively applying filtering\nthroughout the sequence. To address this, we introduce an adaptive coding\ndecision strategy that dynamically determines filtering application during\nencoding. Additionally, out-of-loop reconstruction enhancement is employed to\nrefine the quality of reconstructed frames, providing a simple yet effective\nimprovement in coding efficiency. To the best of our knowledge, this work\npresents the first systematic study of enhancement filtering in the context of\nconditional-based neural video compression. Extensive experiments demonstrate a\n7.71% reduction in bit rate compared to state-of-the-art neural video codecs,\nvalidating the effectiveness of the proposed approach."}
{"id": "2509.04005", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.04005", "abs": "https://arxiv.org/abs/2509.04005", "authors": ["Mingze Gong", "Shuoyao Wang", "Shijian Gao", "Jia Yan", "Suzhi Bi"], "title": "Robust MIMO Semantic Communication with Imperfect CSI via Knowledge Distillation", "comment": null, "summary": "Semantic communication (SemComm) has emerged as a new communication paradigm.\nTo enhance efficiency, multiple-input-multiple-output (MIMO) technology has\nbeen further integrated into SemComm systems. However, existing MIMO SemComm\nsystems assume perfect channel matrix estimation for channel-adaptive joint\nsource-channel coding, which is impractical due to hardware and pilot overhead\nconstraints. In this paper, we propose a semantic image transmission system\nwith channel matrix and channel noise adaptation, named HANA-JSCC, to cope with\nchannel estimation errors in MIMO systems. We propose a channel matrix adaptor\nthat collaborates with the channel codec to adapt to misaligned channel state\ninformation, thereby mitigating the impact of estimation errors. Since the\nrelationship between the estimated channel matrix and true channel matrix is\nill-posed (one-to-many), we further introduce a two-stage training strategy\nwith knowledge distillation to overcome the convergence difficulties caused by\nthe ill-posed problem. Comparing with the state-of-the-art benchmarks,\nHANA-JSCC achieves $0.40\\sim0.54$dB higher average performance across various\nnoise and estimation error levels in various datasets."}
{"id": "2509.04118", "categories": ["eess.IV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.04118", "abs": "https://arxiv.org/abs/2509.04118", "authors": ["Junqi Liao", "Yaojun Wu", "Chaoyi Lin", "Zhipin Deng", "Li Li", "Dong Liu", "Xiaoyan Sun"], "title": "EHVC: Efficient Hierarchical Reference and Quality Structure for Neural Video Coding", "comment": "9 pages, 8 figures, Accepted to ACMMM 2025", "summary": "Neural video codecs (NVCs), leveraging the power of end-to-end learning, have\ndemonstrated remarkable coding efficiency improvements over traditional video\ncodecs. Recent research has begun to pay attention to the quality structures in\nNVCs, optimizing them by introducing explicit hierarchical designs. However,\nless attention has been paid to the reference structure design, which\nfundamentally should be aligned with the hierarchical quality structure. In\naddition, there is still significant room for further optimization of the\nhierarchical quality structure. To address these challenges in NVCs, we propose\nEHVC, an efficient hierarchical neural video codec featuring three key\ninnovations: (1) a hierarchical multi-reference scheme that draws on\ntraditional video codec design to align reference and quality structures,\nthereby addressing the reference-quality mismatch; (2) a lookahead strategy to\nutilize an encoder-side context from future frames to enhance the quality\nstructure; (3) a layer-wise quality scale with random quality training strategy\nto stabilize quality structures during inference. With these improvements, EHVC\nachieves significantly superior performance to the state-of-the-art NVCs. Code\nwill be released in: https://github.com/bytedance/NEVC."}
{"id": "2509.04055", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.04055", "abs": "https://arxiv.org/abs/2509.04055", "authors": ["Benedikt Geiger", "Fan Liu", "Shihang Lu", "Andrej Rode", "Daniel Gil Gaviria", "Charlotte Muth", "Laurent Schmalen"], "title": "Constellation Shaping for OFDM-ISAC Systems: From Theoretical Bounds to Practical Implementation", "comment": "13 pages, 14 figures, Submitted to IEEE Transactions on\n  Communications (TCOM) for peer review", "summary": "Integrated sensing and communications (ISAC) promises new use cases for\nmobile communication systems by reusing the communication signal for radar-like\nsensing. However, sensing and communications (S&C) impose conflicting\nrequirements on the modulation format, resulting in a tradeoff between their\ncorresponding performance. This paper investigates constellation shaping as a\nmeans to simultaneously improve S&C performance in orthogonal frequency\ndivision multiplexing (OFDM)-based ISAC systems. We begin by deriving how the\ntransmit symbols affect detection performance and derive theoretical lower and\nupper bounds on the maximum achievable information rate under a given sensing\nconstraint. Using an autoencoder-based optimization, we investigate geometric,\nprobabilistic, and joint constellation shaping, where joint shaping combines\nboth approaches, employing both optimal maximum a-posteriori decoding and\npractical bit-metric decoding. Our results show that constellation shaping\nenables a flexible trade-off between S&C, can approach the derived upper bound,\nand significantly outperforms conventional modulation formats. Motivated by its\npractical implementation feasibility, we review probabilistic amplitude shaping\n(PAS) and propose a generalization tailored to ISAC. For this generalization,\nwe propose a low-complexity log-likelihood ratio computation with negligible\nrate loss. We demonstrate that combining conventional and generalized PAS\nenables a flexible and low-complexity tradeoff between S&C, closely approaching\nthe performance of joint constellation shaping."}
{"id": "2509.04309", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.04309", "abs": "https://arxiv.org/abs/2509.04309", "authors": ["R. Zhang", "J. Xue", "T. Zhang"], "title": "Reliable Clutter Suppression for Slow-Moving Weak Target Radar Detection", "comment": "25 pages, 20 figures, journal extended by an IEEE ICC conference\n  article", "summary": "Reliable slow-moving weak target detection in complicated environments is\nchallenging due to the masking effects from the surrounding strong reflectors.\nThe traditional Moving Target Indication (MTI) may suppress the echoes from not\nonly the static interference objects (IOs), but also the desired slow-moving\nweak target. According to the low-rank and sparse properties of the\nrange-velocity maps across different radar scans, a novel clutter suppression\nscheme based on the Go decomposition (Godec) framework is proposed in this\npaper. The simulation results show that with the existence of masking effects,\nthe target detection scheme based on Godec clutter suppression can reliably\ndetect the slow-moving weak target, compared to the traditional MTI-based\nscheme. Besides, the time consumption comparison is conducted, demonstrating\nthat the proposed solution is one that sacrifices time complexity in exchange\nfor enhanced reliability. Additionally, the tradeoffs among the number of false\nalarm cells, the detection probability and the iteration times for convergence\nhave been revealed, guiding parameter settings of the proposed solution in\npractical applications. Experiment validation is also conducted to verify the\nproposed solution, providing further insight into the scenarios where the\nsolution is most applicable."}
{"id": "2509.04412", "categories": ["eess.SP", "cs.SY", "eess.SY", "Primary 93C85, Secondary 68T42, 94A12, 90C90", "H.4.3"], "pdf": "https://arxiv.org/pdf/2509.04412", "abs": "https://arxiv.org/abs/2509.04412", "authors": ["Guangyu Lei", "Yuqi Ping", "Tianhao Liang", "Huahao Ding", "Tingting Zhang"], "title": "Relative Localization of UAV Swarms in GNSS-Denied Conditions", "comment": "Manuscript submitted to IEEE Globecom 2025", "summary": "Relative localization of unmanned aerial vehicle (UAV) swarms in global\nnavigation satellite system (GNSS) denied environments is essential for\nemergency rescue and battlefield reconnaissance. Existing methods suffer from\nsignificant localization errors among UAVs due to packet loss and high\ncomputational complexity in large swarms. This paper proposes a\nclustering-based framework where the UAVs simultaneously use communication\nsignals for channel estimation and ranging. Firstly, the spectral clustering is\nutilized to divide the UAV swarm into different sub-clusters, where matrix\ncompletion and multidimensional scaling yield high-precision relative\ncoordinates. Subsequently, a global map is created by the inter-cluster anchor\nfusion. A case study of UAV integrated communication and sensing (ISAC) system\nis presented, where the Orthogonal Time Frequency Space (OTFS) is adopted for\nranging and communication. Experimental results show that the proposed method\nreduces localization errors in large swarms and loss of range information. It\nalso explores the impact of signal parameters on communication and\nlocalization, highlighting the interplay between communication and localization\nperformance."}
